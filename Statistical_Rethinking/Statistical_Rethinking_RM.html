<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="SM">
<meta name="dcterms.date" content="2024-03-17">
<title>Statistical_Rethinking_RM</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="Statistical_Rethinking_RM_files/libs/clipboard/clipboard.min.js"></script>
<script src="Statistical_Rethinking_RM_files/libs/quarto-html/quarto.js"></script>
<script src="Statistical_Rethinking_RM_files/libs/quarto-html/popper.min.js"></script>
<script src="Statistical_Rethinking_RM_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Statistical_Rethinking_RM_files/libs/quarto-html/anchor.min.js"></script>
<link href="Statistical_Rethinking_RM_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Statistical_Rethinking_RM_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Statistical_Rethinking_RM_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Statistical_Rethinking_RM_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Statistical_Rethinking_RM_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><style>html{ scroll-behavior: smooth; }</style>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Contents</h2>
   
  <ul>
<li>
<a href="#chapter-1-the-golem-of-prague" id="toc-chapter-1-the-golem-of-prague" class="nav-link active" data-scroll-target="#chapter-1-the-golem-of-prague">Chapter 1: The Golem of Prague</a>
  <ul>
<li><a href="#hypotheses-are-not-models" id="toc-hypotheses-are-not-models" class="nav-link" data-scroll-target="#hypotheses-are-not-models">Hypotheses are not models</a></li>
  <li>
<a href="#measurement-matters" id="toc-measurement-matters" class="nav-link" data-scroll-target="#measurement-matters"><em>Measurement matters</em></a>
  <ul>
<li><a href="#observation-error" id="toc-observation-error" class="nav-link" data-scroll-target="#observation-error"><em>Observation error</em></a></li>
  <li><a href="#continuous-hypotheses" id="toc-continuous-hypotheses" class="nav-link" data-scroll-target="#continuous-hypotheses"><em>Continuous hypotheses</em></a></li>
  <li><a href="#falsification-is-consensual" id="toc-falsification-is-consensual" class="nav-link" data-scroll-target="#falsification-is-consensual"><em>Falsification is consensual</em></a></li>
  </ul>
</li>
  <li>
<a href="#three-tools-for-golem-engineering" id="toc-three-tools-for-golem-engineering" class="nav-link" data-scroll-target="#three-tools-for-golem-engineering">Three tools for golem engineering</a>
  <ul>
<li><a href="#bayesian-data-analysis" id="toc-bayesian-data-analysis" class="nav-link" data-scroll-target="#bayesian-data-analysis"><em>Bayesian data analysis</em></a></li>
  <li><a href="#multilevel-models" id="toc-multilevel-models" class="nav-link" data-scroll-target="#multilevel-models"><em>Multilevel models</em></a></li>
  <li><a href="#model-comparison-and-information-criteria" id="toc-model-comparison-and-information-criteria" class="nav-link" data-scroll-target="#model-comparison-and-information-criteria"><em>Model comparison and information criteria</em></a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#chapter-2-small-worlds-and-large-worlds" id="toc-chapter-2-small-worlds-and-large-worlds" class="nav-link" data-scroll-target="#chapter-2-small-worlds-and-large-worlds">Chapter 2: Small Worlds and Large Worlds</a>
  <ul>
<li>
<a href="#the-garden-of-forking-data" id="toc-the-garden-of-forking-data" class="nav-link" data-scroll-target="#the-garden-of-forking-data">The garden of forking data</a>
  <ul>
<li><a href="#counting-possibilities" id="toc-counting-possibilities" class="nav-link" data-scroll-target="#counting-possibilities">Counting possibilities</a></li>
  <li><a href="#using-prior-information" id="toc-using-prior-information" class="nav-link" data-scroll-target="#using-prior-information">Using prior information</a></li>
  <li><a href="#from-counts-to-probability" id="toc-from-counts-to-probability" class="nav-link" data-scroll-target="#from-counts-to-probability">From counts to probability</a></li>
  </ul>
</li>
  <li>
<a href="#building-a-model" id="toc-building-a-model" class="nav-link" data-scroll-target="#building-a-model">Building a model</a>
  <ul>
<li><a href="#a-data-story" id="toc-a-data-story" class="nav-link" data-scroll-target="#a-data-story">A data story</a></li>
  <li><a href="#bayesian-updating" id="toc-bayesian-updating" class="nav-link" data-scroll-target="#bayesian-updating">Bayesian updating</a></li>
  <li><a href="#evaluate" id="toc-evaluate" class="nav-link" data-scroll-target="#evaluate">Evaluate</a></li>
  </ul>
</li>
  <li>
<a href="#components-of-the-model" id="toc-components-of-the-model" class="nav-link" data-scroll-target="#components-of-the-model">Components of the model</a>
  <ul>
<li><a href="#likelihood" id="toc-likelihood" class="nav-link" data-scroll-target="#likelihood">Likelihood</a></li>
  <li><a href="#parameters" id="toc-parameters" class="nav-link" data-scroll-target="#parameters">Parameters</a></li>
  <li><a href="#prior" id="toc-prior" class="nav-link" data-scroll-target="#prior">Prior</a></li>
  <li><a href="#posterior" id="toc-posterior" class="nav-link" data-scroll-target="#posterior">Posterior</a></li>
  </ul>
</li>
  <li>
<a href="#making-the-model-go" id="toc-making-the-model-go" class="nav-link" data-scroll-target="#making-the-model-go">Making the model go</a>
  <ul>
<li><a href="#grid-approximation" id="toc-grid-approximation" class="nav-link" data-scroll-target="#grid-approximation">Grid approximation</a></li>
  <li><a href="#quadratic-approximation" id="toc-quadratic-approximation" class="nav-link" data-scroll-target="#quadratic-approximation">Quadratic approximation</a></li>
  <li><a href="#markov-chain-monte-carlo" id="toc-markov-chain-monte-carlo" class="nav-link" data-scroll-target="#markov-chain-monte-carlo">Markov chain Monte Carlo</a></li>
  </ul>
</li>
  <li>
<a href="#practice" id="toc-practice" class="nav-link" data-scroll-target="#practice">Practice</a>
  <ul>
<li><a href="#easy" id="toc-easy" class="nav-link" data-scroll-target="#easy">Easy</a></li>
  <li><a href="#medium" id="toc-medium" class="nav-link" data-scroll-target="#medium">Medium</a></li>
  <li><a href="#hard" id="toc-hard" class="nav-link" data-scroll-target="#hard">Hard</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#chapter-3-sampling-the-imaginary" id="toc-chapter-3-sampling-the-imaginary" class="nav-link" data-scroll-target="#chapter-3-sampling-the-imaginary">Chapter 3: Sampling the Imaginary</a>
  <ul>
<li><a href="#sampling-from-a-grid-approximate-posterior" id="toc-sampling-from-a-grid-approximate-posterior" class="nav-link" data-scroll-target="#sampling-from-a-grid-approximate-posterior">Sampling from a grid-approximate posterior</a></li>
  <li>
<a href="#sampling-to-summarize" id="toc-sampling-to-summarize" class="nav-link" data-scroll-target="#sampling-to-summarize">Sampling to summarize</a>
  <ul>
<li><a href="#intervals-of-defined-boundaries" id="toc-intervals-of-defined-boundaries" class="nav-link" data-scroll-target="#intervals-of-defined-boundaries">Intervals of defined boundaries</a></li>
  <li><a href="#intervals-of-defined-mass" id="toc-intervals-of-defined-mass" class="nav-link" data-scroll-target="#intervals-of-defined-mass">Intervals of defined mass</a></li>
  <li><a href="#point-estimates" id="toc-point-estimates" class="nav-link" data-scroll-target="#point-estimates">Point estimates</a></li>
  </ul>
</li>
  <li>
<a href="#sampling-to-simulate-prediction" id="toc-sampling-to-simulate-prediction" class="nav-link" data-scroll-target="#sampling-to-simulate-prediction">Sampling to simulate prediction</a>
  <ul>
<li><a href="#dummy-data-simulated-data" id="toc-dummy-data-simulated-data" class="nav-link" data-scroll-target="#dummy-data-simulated-data">Dummy data (simulated data)</a></li>
  <li>
<a href="#model-checking" id="toc-model-checking" class="nav-link" data-scroll-target="#model-checking">Model checking</a>
  <ul class="collapse">
<li><a href="#did-the-software-work" id="toc-did-the-software-work" class="nav-link" data-scroll-target="#did-the-software-work">Did the software work?</a></li>
  <li><a href="#is-the-model-adequate" id="toc-is-the-model-adequate" class="nav-link" data-scroll-target="#is-the-model-adequate">Is the model adequate?</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#practice-1" id="toc-practice-1" class="nav-link" data-scroll-target="#practice-1">Practice</a>
  <ul>
<li><a href="#easy-1" id="toc-easy-1" class="nav-link" data-scroll-target="#easy-1">Easy</a></li>
  <li><a href="#medium-1" id="toc-medium-1" class="nav-link" data-scroll-target="#medium-1">Medium</a></li>
  <li><a href="#hard-1" id="toc-hard-1" class="nav-link" data-scroll-target="#hard-1">Hard</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#chapter-4-linear-models" id="toc-chapter-4-linear-models" class="nav-link" data-scroll-target="#chapter-4-linear-models">Chapter 4: Linear Models</a>
  <ul>
<li>
<a href="#why-normal-distributions-are-normal" id="toc-why-normal-distributions-are-normal" class="nav-link" data-scroll-target="#why-normal-distributions-are-normal">Why normal distributions are normal</a>
  <ul>
<li><a href="#normal-by-addition" id="toc-normal-by-addition" class="nav-link" data-scroll-target="#normal-by-addition">Normal by addition</a></li>
  <li><a href="#normal-by-multiplication" id="toc-normal-by-multiplication" class="nav-link" data-scroll-target="#normal-by-multiplication">Normal by multiplication</a></li>
  <li><a href="#normal-by-log-multiplication" id="toc-normal-by-log-multiplication" class="nav-link" data-scroll-target="#normal-by-log-multiplication">Normal by log-multiplication</a></li>
  <li><a href="#using-guassian-distributions" id="toc-using-guassian-distributions" class="nav-link" data-scroll-target="#using-guassian-distributions">Using Guassian distributions</a></li>
  </ul>
</li>
  <li>
<a href="#a-language-for-describing-models" id="toc-a-language-for-describing-models" class="nav-link" data-scroll-target="#a-language-for-describing-models">A language for describing models</a>
  <ul>
<li><a href="#re-describing-the-globe-tossing-model" id="toc-re-describing-the-globe-tossing-model" class="nav-link" data-scroll-target="#re-describing-the-globe-tossing-model">Re-describing the globe tossing model</a></li>
  </ul>
</li>
  <li>
<a href="#a-gaussian-model-of-height" id="toc-a-gaussian-model-of-height" class="nav-link" data-scroll-target="#a-gaussian-model-of-height">A Gaussian model of height</a>
  <ul>
<li><a href="#the-data" id="toc-the-data" class="nav-link" data-scroll-target="#the-data">The data</a></li>
  <li><a href="#the-model" id="toc-the-model" class="nav-link" data-scroll-target="#the-model">The model</a></li>
  <li><a href="#grid-approximation-of-the-posterior-distribution" id="toc-grid-approximation-of-the-posterior-distribution" class="nav-link" data-scroll-target="#grid-approximation-of-the-posterior-distribution">Grid approximation of the posterior distribution</a></li>
  <li><a href="#sampling-from-the-posterior" id="toc-sampling-from-the-posterior" class="nav-link" data-scroll-target="#sampling-from-the-posterior">Sampling from the posterior</a></li>
  <li><a href="#fitting-the-model-with-map" id="toc-fitting-the-model-with-map" class="nav-link" data-scroll-target="#fitting-the-model-with-map">Fitting the model with <code>map</code></a></li>
  <li><a href="#sampling-from-a-map-fit" id="toc-sampling-from-a-map-fit" class="nav-link" data-scroll-target="#sampling-from-a-map-fit">Sampling from a <code>map</code> fit</a></li>
  </ul>
</li>
  <li>
<a href="#adding-a-predictor" id="toc-adding-a-predictor" class="nav-link" data-scroll-target="#adding-a-predictor">Adding a predictor</a>
  <ul>
<li><a href="#fitting-the-model" id="toc-fitting-the-model" class="nav-link" data-scroll-target="#fitting-the-model">Fitting the model</a></li>
  <li>
<a href="#interpreting-the-model-fit" id="toc-interpreting-the-model-fit" class="nav-link" data-scroll-target="#interpreting-the-model-fit">Interpreting the model fit</a>
  <ul class="collapse">
<li><a href="#tables-of-estimates" id="toc-tables-of-estimates" class="nav-link" data-scroll-target="#tables-of-estimates">Tables of estimates</a></li>
  <li><a href="#plotting-posterior-inference-aganist-the-data" id="toc-plotting-posterior-inference-aganist-the-data" class="nav-link" data-scroll-target="#plotting-posterior-inference-aganist-the-data">Plotting posterior inference aganist the data</a></li>
  <li><a href="#adding-uncertainty-around-the-mean" id="toc-adding-uncertainty-around-the-mean" class="nav-link" data-scroll-target="#adding-uncertainty-around-the-mean">Adding uncertainty around the mean</a></li>
  <li><a href="#plotting-regression-intervals-and-contours" id="toc-plotting-regression-intervals-and-contours" class="nav-link" data-scroll-target="#plotting-regression-intervals-and-contours">Plotting regression intervals and contours</a></li>
  <li><a href="#prediction-intervals" id="toc-prediction-intervals" class="nav-link" data-scroll-target="#prediction-intervals">Prediction intervals</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#polynomial-regression" id="toc-polynomial-regression" class="nav-link" data-scroll-target="#polynomial-regression">Polynomial regression</a>
  <ul>
<li><a href="#fitting-the-model-to-data" id="toc-fitting-the-model-to-data" class="nav-link" data-scroll-target="#fitting-the-model-to-data">Fitting the model to data</a></li>
  </ul>
</li>
  <li>
<a href="#practice-2" id="toc-practice-2" class="nav-link" data-scroll-target="#practice-2">Practice</a>
  <ul>
<li><a href="#easy-2" id="toc-easy-2" class="nav-link" data-scroll-target="#easy-2">Easy</a></li>
  <li><a href="#medium-2" id="toc-medium-2" class="nav-link" data-scroll-target="#medium-2">Medium</a></li>
  <li><a href="#hard-2" id="toc-hard-2" class="nav-link" data-scroll-target="#hard-2">Hard</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#chapter-5-multivariate-linear-models" id="toc-chapter-5-multivariate-linear-models" class="nav-link" data-scroll-target="#chapter-5-multivariate-linear-models">Chapter 5: Multivariate Linear Models</a>
  <ul>
<li>
<a href="#spurious-association" id="toc-spurious-association" class="nav-link" data-scroll-target="#spurious-association">Spurious association</a>
  <ul>
<li><a href="#multivariate-notation" id="toc-multivariate-notation" class="nav-link" data-scroll-target="#multivariate-notation">Multivariate notation</a></li>
  <li><a href="#fitting-the-model-1" id="toc-fitting-the-model-1" class="nav-link" data-scroll-target="#fitting-the-model-1">Fitting the model</a></li>
  <li>
<a href="#plotting-multivariate-posteriors" id="toc-plotting-multivariate-posteriors" class="nav-link" data-scroll-target="#plotting-multivariate-posteriors">Plotting multivariate posteriors</a>
  <ul class="collapse">
<li><a href="#predictor-residual-plots" id="toc-predictor-residual-plots" class="nav-link" data-scroll-target="#predictor-residual-plots">Predictor residual plots</a></li>
  <li><a href="#counterfactual-plots" id="toc-counterfactual-plots" class="nav-link" data-scroll-target="#counterfactual-plots">Counterfactual plots</a></li>
  <li><a href="#posterior-prediction-plots" id="toc-posterior-prediction-plots" class="nav-link" data-scroll-target="#posterior-prediction-plots">Posterior prediction plots</a></li>
  </ul>
</li>
  </ul>
</li>
  <li><a href="#masked-relationship" id="toc-masked-relationship" class="nav-link" data-scroll-target="#masked-relationship">Masked relationship</a></li>
  <li>
<a href="#when-adding-variables-hurts" id="toc-when-adding-variables-hurts" class="nav-link" data-scroll-target="#when-adding-variables-hurts">When adding variables hurts</a>
  <ul>
<li><a href="#multicollinear-legs" id="toc-multicollinear-legs" class="nav-link" data-scroll-target="#multicollinear-legs">Multicollinear legs</a></li>
  <li><a href="#multicollinear-milk" id="toc-multicollinear-milk" class="nav-link" data-scroll-target="#multicollinear-milk">Multicollinear milk</a></li>
  <li><a href="#post-treatment-bias" id="toc-post-treatment-bias" class="nav-link" data-scroll-target="#post-treatment-bias">Post-treatment bias</a></li>
  </ul>
</li>
  <li>
<a href="#categorical-variables" id="toc-categorical-variables" class="nav-link" data-scroll-target="#categorical-variables">Categorical variables</a>
  <ul>
<li><a href="#binary-categories" id="toc-binary-categories" class="nav-link" data-scroll-target="#binary-categories">Binary categories</a></li>
  <li><a href="#many-categories" id="toc-many-categories" class="nav-link" data-scroll-target="#many-categories">Many categories</a></li>
  <li><a href="#adding-regular-predictor-variables" id="toc-adding-regular-predictor-variables" class="nav-link" data-scroll-target="#adding-regular-predictor-variables">Adding regular predictor variables</a></li>
  <li><a href="#another-approach-unique-intercepts" id="toc-another-approach-unique-intercepts" class="nav-link" data-scroll-target="#another-approach-unique-intercepts">Another approach: Unique intercepts</a></li>
  </ul>
</li>
  <li>
<a href="#ordinary-least-squares-and-lm" id="toc-ordinary-least-squares-and-lm" class="nav-link" data-scroll-target="#ordinary-least-squares-and-lm">Ordinary least squares and <code>lm</code></a>
  <ul>
<li><a href="#design-formulas" id="toc-design-formulas" class="nav-link" data-scroll-target="#design-formulas">Design formulas</a></li>
  <li>
<a href="#using-lm" id="toc-using-lm" class="nav-link" data-scroll-target="#using-lm">Using <code>lm</code></a>
  <ul class="collapse">
<li><a href="#intercepts-are-optional" id="toc-intercepts-are-optional" class="nav-link" data-scroll-target="#intercepts-are-optional">Intercepts are optional</a></li>
  <li><a href="#categorical-variables-1" id="toc-categorical-variables-1" class="nav-link" data-scroll-target="#categorical-variables-1">Categorical variables</a></li>
  <li><a href="#transform-variables-first" id="toc-transform-variables-first" class="nav-link" data-scroll-target="#transform-variables-first">Transform variables first</a></li>
  <li><a href="#no-estimate-for-sigma" id="toc-no-estimate-for-sigma" class="nav-link" data-scroll-target="#no-estimate-for-sigma">No estimate for <span class="math inline">\(\sigma\)</span></a></li>
  </ul>
</li>
  <li><a href="#building-map-formulas-from-lm-formulas" id="toc-building-map-formulas-from-lm-formulas" class="nav-link" data-scroll-target="#building-map-formulas-from-lm-formulas">Building <code>map</code> formulas from <code>lm</code> formulas</a></li>
  </ul>
</li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li>
<a href="#practice-3" id="toc-practice-3" class="nav-link" data-scroll-target="#practice-3">Practice</a>
  <ul>
<li><a href="#easy-3" id="toc-easy-3" class="nav-link" data-scroll-target="#easy-3">Easy</a></li>
  <li><a href="#medium-3" id="toc-medium-3" class="nav-link" data-scroll-target="#medium-3">Medium</a></li>
  <li><a href="#hard-3" id="toc-hard-3" class="nav-link" data-scroll-target="#hard-3">Hard</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#chapter-6-overfitting-regularization-and-information-criteria" id="toc-chapter-6-overfitting-regularization-and-information-criteria" class="nav-link" data-scroll-target="#chapter-6-overfitting-regularization-and-information-criteria">Chapter 6: Overfitting, Regularization, and Information Criteria</a>
  <ul>
<li><a href="#the-problem-with-parameters" id="toc-the-problem-with-parameters" class="nav-link" data-scroll-target="#the-problem-with-parameters">The problem with parameters</a></li>
  <li><a href="#more-parameters-always-improve-fit" id="toc-more-parameters-always-improve-fit" class="nav-link" data-scroll-target="#more-parameters-always-improve-fit">More parameters always improve fit</a></li>
  <li><a href="#too-few-parameters-hurts-too" id="toc-too-few-parameters-hurts-too" class="nav-link" data-scroll-target="#too-few-parameters-hurts-too">Too few parameters hurts, too</a></li>
  <li>
<a href="#information-theory-and-model-performance" id="toc-information-theory-and-model-performance" class="nav-link" data-scroll-target="#information-theory-and-model-performance">Information theory and model performance</a>
  <ul>
<li><a href="#firing-the-weatherperson" id="toc-firing-the-weatherperson" class="nav-link" data-scroll-target="#firing-the-weatherperson">Firing the weatherperson</a></li>
  <li><a href="#information-and-uncertainty" id="toc-information-and-uncertainty" class="nav-link" data-scroll-target="#information-and-uncertainty">Information and uncertainty</a></li>
  <li><a href="#from-entropy-to-accuracy" id="toc-from-entropy-to-accuracy" class="nav-link" data-scroll-target="#from-entropy-to-accuracy">From entropy to accuracy</a></li>
  <li><a href="#from-divergence-to-deviance" id="toc-from-divergence-to-deviance" class="nav-link" data-scroll-target="#from-divergence-to-deviance">From divergence to deviance</a></li>
  <li><a href="#from-deviance-to-out-of-sample" id="toc-from-deviance-to-out-of-sample" class="nav-link" data-scroll-target="#from-deviance-to-out-of-sample">From deviance to out-of-sample</a></li>
  </ul>
</li>
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization">Regularization</a></li>
  <li>
<a href="#information-criteria" id="toc-information-criteria" class="nav-link" data-scroll-target="#information-criteria">Information criteria</a>
  <ul>
<li><a href="#deviance-information-criterion-dic" id="toc-deviance-information-criterion-dic" class="nav-link" data-scroll-target="#deviance-information-criterion-dic">Deviance Information Criterion (DIC)</a></li>
  <li><a href="#widely-applicable-information-criterionwaic" id="toc-widely-applicable-information-criterionwaic" class="nav-link" data-scroll-target="#widely-applicable-information-criterionwaic">Widely Applicable Information Criterion(WAIC)</a></li>
  <li><a href="#dic-and-waic-as-estimates-of-deviance" id="toc-dic-and-waic-as-estimates-of-deviance" class="nav-link" data-scroll-target="#dic-and-waic-as-estimates-of-deviance">DIC and WAIC as estimates of deviance</a></li>
  </ul>
</li>
  <li>
<a href="#using-information-criteria" id="toc-using-information-criteria" class="nav-link" data-scroll-target="#using-information-criteria">Using information criteria</a>
  <ul>
<li>
<a href="#model-comparison" id="toc-model-comparison" class="nav-link" data-scroll-target="#model-comparison">Model comparison</a>
  <ul class="collapse">
<li><a href="#comparing-waic-values" id="toc-comparing-waic-values" class="nav-link" data-scroll-target="#comparing-waic-values">Comparing WAIC values</a></li>
  <li><a href="#comparing-estimates" id="toc-comparing-estimates" class="nav-link" data-scroll-target="#comparing-estimates">Comparing estimates</a></li>
  </ul>
</li>
  <li><a href="#model-averaging" id="toc-model-averaging" class="nav-link" data-scroll-target="#model-averaging">Model averaging</a></li>
  </ul>
</li>
  <li>
<a href="#practice-4" id="toc-practice-4" class="nav-link" data-scroll-target="#practice-4">Practice</a>
  <ul>
<li><a href="#easy-4" id="toc-easy-4" class="nav-link" data-scroll-target="#easy-4">Easy</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#chapter-7-interactions" id="toc-chapter-7-interactions" class="nav-link" data-scroll-target="#chapter-7-interactions">Chapter 7: Interactions</a>
  <ul>
<li>
<a href="#building-an-interaction" id="toc-building-an-interaction" class="nav-link" data-scroll-target="#building-an-interaction">Building an interaction</a>
  <ul>
<li><a href="#adding-a-dummy-variable-doesnt-work" id="toc-adding-a-dummy-variable-doesnt-work" class="nav-link" data-scroll-target="#adding-a-dummy-variable-doesnt-work">Adding a dummy variable doesn’t work</a></li>
  <li><a href="#adding-a-linear-interaction-does-work" id="toc-adding-a-linear-interaction-does-work" class="nav-link" data-scroll-target="#adding-a-linear-interaction-does-work">Adding a linear interaction does work</a></li>
  <li><a href="#plotting-the-interaction" id="toc-plotting-the-interaction" class="nav-link" data-scroll-target="#plotting-the-interaction">Plotting the interaction</a></li>
  <li>
<a href="#interpreting-an-interaction-estimate" id="toc-interpreting-an-interaction-estimate" class="nav-link" data-scroll-target="#interpreting-an-interaction-estimate">Interpreting an interaction estimate</a>
  <ul class="collapse">
<li><a href="#parameters-change-meaning" id="toc-parameters-change-meaning" class="nav-link" data-scroll-target="#parameters-change-meaning">Parameters change meaning</a></li>
  <li><a href="#incorporating-uncertainty" id="toc-incorporating-uncertainty" class="nav-link" data-scroll-target="#incorporating-uncertainty">Incorporating uncertainty</a></li>
  </ul>
</li>
  </ul>
</li>
  <li>
<a href="#symmetry-of-the-linear-interaction" id="toc-symmetry-of-the-linear-interaction" class="nav-link" data-scroll-target="#symmetry-of-the-linear-interaction">Symmetry of the linear interaction</a>
  <ul>
<li><a href="#buridans-interaction" id="toc-buridans-interaction" class="nav-link" data-scroll-target="#buridans-interaction">Buridan’s interaction</a></li>
  <li><a href="#africa-depends-upon-ruggedness" id="toc-africa-depends-upon-ruggedness" class="nav-link" data-scroll-target="#africa-depends-upon-ruggedness">Africa depends upon ruggedness</a></li>
  </ul>
</li>
  <li>
<a href="#continuous-interactions" id="toc-continuous-interactions" class="nav-link" data-scroll-target="#continuous-interactions">Continuous interactions</a>
  <ul>
<li><a href="#the-data-1" id="toc-the-data-1" class="nav-link" data-scroll-target="#the-data-1">The data</a></li>
  <li><a href="#the-un-centered-models" id="toc-the-un-centered-models" class="nav-link" data-scroll-target="#the-un-centered-models">The un-centered models</a></li>
  <li>
<a href="#center-and-re-estimate" id="toc-center-and-re-estimate" class="nav-link" data-scroll-target="#center-and-re-estimate">Center and re-estimate</a>
  <ul class="collapse">
<li><a href="#estimation-worked-better" id="toc-estimation-worked-better" class="nav-link" data-scroll-target="#estimation-worked-better">Estimation worked better</a></li>
  <li><a href="#estimates-changed-less-across-models" id="toc-estimates-changed-less-across-models" class="nav-link" data-scroll-target="#estimates-changed-less-across-models">Estimates changed less across models</a></li>
  </ul>
</li>
  <li><a href="#plotting-implied-predictions" id="toc-plotting-implied-predictions" class="nav-link" data-scroll-target="#plotting-implied-predictions">Plotting implied predictions</a></li>
  </ul>
</li>
  <li><a href="#interactions-in-design-formulas" id="toc-interactions-in-design-formulas" class="nav-link" data-scroll-target="#interactions-in-design-formulas">Interactions in design formulas</a></li>
  <li><a href="#practice-5" id="toc-practice-5" class="nav-link" data-scroll-target="#practice-5">Practice</a></li>
  </ul>
</li>
  <li>
<a href="#chapter-8-markov-chain-monte-carlo" id="toc-chapter-8-markov-chain-monte-carlo" class="nav-link" data-scroll-target="#chapter-8-markov-chain-monte-carlo">Chapter 8: Markov Chain Monte Carlo</a>
  <ul>
<li><a href="#good-king-markov-and-his-island-kingdom" id="toc-good-king-markov-and-his-island-kingdom" class="nav-link" data-scroll-target="#good-king-markov-and-his-island-kingdom">Good King Markov and his island kingdom</a></li>
  <li>
<a href="#markov-chain-monte-carlo-1" id="toc-markov-chain-monte-carlo-1" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-1">Markov chain Monte Carlo</a>
  <ul>
<li><a href="#gibbs-sampling" id="toc-gibbs-sampling" class="nav-link" data-scroll-target="#gibbs-sampling">Gibbs sampling</a></li>
  <li><a href="#hamiltonian-monte-carlo" id="toc-hamiltonian-monte-carlo" class="nav-link" data-scroll-target="#hamiltonian-monte-carlo">Hamiltonian Monte Carlo</a></li>
  </ul>
</li>
  <li>
<a href="#easy-hmc-map2stan" id="toc-easy-hmc-map2stan" class="nav-link" data-scroll-target="#easy-hmc-map2stan">Easy HMC: <code>map2stan</code></a>
  <ul>
<li><a href="#preparation" id="toc-preparation" class="nav-link" data-scroll-target="#preparation">Preparation</a></li>
  <li><a href="#estimation" id="toc-estimation" class="nav-link" data-scroll-target="#estimation">Estimation</a></li>
  <li><a href="#sampling-agian-in-parallel" id="toc-sampling-agian-in-parallel" class="nav-link" data-scroll-target="#sampling-agian-in-parallel">Sampling agian, in parallel</a></li>
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization">Visualization</a></li>
  <li><a href="#using-the-samples" id="toc-using-the-samples" class="nav-link" data-scroll-target="#using-the-samples">Using the samples</a></li>
  </ul>
</li>
  </ul>
</li>
  </ul></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Statistical_Rethinking_RM</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>SM </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 17, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header><section id="chapter-1-the-golem-of-prague" class="level1"><h1>Chapter 1: The Golem of Prague</h1>
<p>Chapter 1 urged us to rethink the “popular statistical and scientific philosophy” by pointing out the flaws in classical statistical tools and reasoning.</p>
<p>According to the author, “classical tools are not diverse enough to handle many common research questions…And if we keep adding new types of tools, soon there will be far too many to keep track of.” I agree with these statements. The author also talked about how Fisher’s exact test is used “whenever the cell counts are small” and he had “never seen it used appropriately” except Fisher’s original use of the test. It would be nice if the author gave some examples and explanations of those inappropriate uses- I can’t decide whether to accept without more information.</p>
<p>The author mentioned why deductive falsification is impossible in scientific context:</p>
<ol type="1">
<li><p>“Hypotheses are not models. The relations among hypotheses and different kinds of models are complex. Many models correspond to the same hypothesis, and many hypotheses correspond to a single model. This makes strict falsification impossible.</p></li>
<li><p>Measurement matters. Even when we think the data falsify a model, another observer will debate our methods and measures. They don’t trust the data. Sometimes they are right.</p></li>
</ol>
<p>For both of these reasons, deductive falsification never works. The scientific method cannot be reduced to a statistical procedure, and so our statistical methods should not pretend.”</p>
<p><br></p>
<section id="hypotheses-are-not-models" class="level2"><h2 class="anchored" data-anchor-id="hypotheses-are-not-models">Hypotheses are not models</h2>
<p>He gave an example of the first statement in evolutionary context. His conclusion was:</p>
<ol type="1">
<li><p>“Any given statistical model (M) may correspond to more than one process model (P).</p></li>
<li><p>Any given hypothesis (H) may correspond to more than one process model (P).</p></li>
<li><p>Any given statistical model (M) may correspond to more than one hypothesis (H).”</p></li>
</ol>
<p>In other words, it doesn’t matter whether we reject or fail to reject the null. It won’t have “much inferential power” or give any useful insights due to possible existence of models- other than the ones under study- which can also align with the null or alternative hypotheses. The author gave a solution to this dilemma- “explicitly compare predictions of more than one model.” This is a very nice solution, as I think it will allow analysis of hypothesis or whatever you want to study in real-world conditions. And that is much more powerful than any classical tests.</p>
<p>In that case, should we disregard all studies that rely on NHST? Should we reject all findings made by rejecting the null hypothesis as senseless? And are the multiple process models the only way to go? The frequentists’ way to solve this problem is to control the conditions of the experiment/study. In nutrition studies, this can be in the form of inclusion or exclusion criteria and strict control of test subjects (and conditions) throughout the duration of the study. This is to ensure the observed effect (or lack of) is caused by (or related to) the variables of interest and not by uncontrolled confounders. If a NHST research was done well with proper control, then we could ‘more or less’ have confidence in the research’s findings.</p>
<p><br></p>
</section><section id="measurement-matters" class="level2"><h2 class="anchored" data-anchor-id="measurement-matters"><em>Measurement matters</em></h2>
<p>In the section “measurement matters,” the author reinforced the first statement, and explained the fallacy of falsification principle, stating two reasons:</p>
<ol type="1">
<li><p>“Observations are prone to error, especially at the boundaries of scientific knowledge.</p></li>
<li><p>Most hypotheses are quantitative, concerning the degrees of existence, rather than discrete, concerning total presence or absence.”</p></li>
</ol>
<section id="observation-error" class="level3"><h3 class="anchored" data-anchor-id="observation-error"><em>Observation error</em></h3>
<p>The author gave two examples of observation error. The first example pointed out possible bias or errors in observations, and potential type 1 and type 2 errors (false positives and false negatives) in classical frequentist researches. And the second example talked about errors in measurements (or studies/ experiments). Both are valid concerns and those errors are not uncommon in frequentist researches.</p>
<p>There are several ways to overcome these shortcomings, depending on research design. For example, we can increase sample size or run more tests to reduce type 1 and type 2 errors. Errors in measurements can be avoided by following protocols- taking at least two measurements for each sample, consistency in measurements, etc. However, there is no guarantee that any particular researcher or research group will follow a strict protocol without compromising, and that can lead to observation error. To prevent this, we usually avoid using finding from a single research, and wait till the findings are backed by systematic reviews and made into guidelines.</p>
<p>In both woodpecker and neutrino examples, the author’s key concerns were “whether falsification is real or spurious,” and that “both true-detection and false-detection plausible.” The null hypothesis in the woodpecker example was “The Ivory-billed Woodpecker is extinct.” According to the author, it will only take a single woodpecker to falsify this theory, and that the 2005 evidence on existence of a woodpecker was doubted by many. Since no other evidences emerged, the question remained unresolved. That means finding was not conclusive yet, and research was still ongoing. As I mentioned above, we don’t accept findings from a single research as concrete or irrefutable evidence. Thus, the dilemma over falsification and type 1 or type 2 error in the woodpecker case was not really a concern- we would just need to conduct more surveys (wider location for longer period?) or simply wait for new evidences. However, I think this is not a good case to use the null hypothesis testing. The falsification of hypothesis in this case will be simply the result of patience or luck, rather than proper research design or statistical tests. In the neutrino example, the problem was the human error which they solved by replication of experiments. This is not unusual in frequentist research. Replicating or reconducting experiment is a common occurrence, especially when lab analyses are involved. It may be an inconvenience, but it does not imply the utter failure of the theory of falsification or the null hypothesis testing.</p>
</section><section id="continuous-hypotheses" class="level3"><h3 class="anchored" data-anchor-id="continuous-hypotheses"><em>Continuous hypotheses</em></h3>
<p>The author noted “…it is a good practice to design experiments and observations that can differentiate competing hypotheses. But in many cases, the comparison must be probabilistic, a matter of degree, not kind.” Two examples of null hypotheses that support the above statement were given: “80% of swans are white” and “Black swans are rare.” The author pointed out the <em>modus tollens</em> swan story would not be applicable in this case, since the problem is not to prove or disprove the hypothesis but to estimate the distribution of swan coloration. He added “You might object that the hypothesis above is just not a good scientific hypothesis, because it isn’t easy to disprove. But if that’s the case, then most of the important questions about the world are not good scientific hypotheses.”</p>
<p>In my opinion, it is not difficult to disprove both hypotheses. The two hypothese are not good hypotheses simply because they are not specific and fail to form sensible research question or outcome- not because it is “a matter of degree.” Let’s break down the two hypotheses. First, we think about the possible research question for the hypothesis “80% of swan are white.” The research question could be “Are 80% of swan white?” or “Do 80% of swan have white feathers?” In this case, this hypothesis would be disprove if survey found any percent of white swan other than 80%. It wouldn’t matter if the actual percent was 90 or 95- we could stop the research once the number passed the threshold of 80%. Now it is clear that the problem with this hypothesis is the pointless outcome. What are we trying to achieve knowing whether 80% of swan are white, or 40% or any percentage of swan are white in color? A more sensible hypothesis would be “White coloration is the dominant trait in swan.” We can falsify this hypothesis by conducting surveys- like the author suggested- or genetic analysis, etc. Still, it is not a good hypothesis for an original research since the scope is too broad. The hypothesis only specify swan- not a particular speices or geographical location, meaning all swan species in the world are included in the research. That would be a hard task for any single researcher or research group. Hence, this hypothesis is more suitable at review level- not original research level. For original research, we can specify the species of swan and extent of study area based on the available funding.</p>
<p>The second hypothesis “Black swans are rare” has the similar problem- lack of specificity. We need to determine what is considered rare- 1 in 100 or 1 in a million? Once we have that specification, it is not difficult to tackle the second hypothesis. But we need to be aware that the second hypothesis also includes all swan species in the world- or even universe or parallel universes.</p>
<p>Another thing is the <em>modus tollens</em> swan story was merely to explain a theory- not a definitive example of how we should write hypothesis. I have yet to see a research with hypothesis written like the one in <em>modus tollens</em> swan story. All hypotheses that I have seen so far address “the degree, not kind”-like the author suggested. Hence, the author’s concern over hypotheses is somehow invalid.</p>
</section><section id="falsification-is-consensual" class="level3"><h3 class="anchored" data-anchor-id="falsification-is-consensual"><em>Falsification is consensual</em></h3>
<p>The author said “falsification is always consensual, not logical,” and “evidence often— but not always— has something to do with such falsification.” He also highlighted the arguments towards “consensus about meaning of evidence” and the danger of “historical revisionism.” I think the author is right. We hold such reverence towards the famous scientists in history, that their formulas are still widely applied to this day, without contesting their suitability in this age. Many researches were done following the same mould, that they gave similar results, which became our gold-standard- the guidelines. And those guidelines are not set in stone. They are regularly updated- albeit minor changes. Occasionally, some guidelines are completely proven false and replaced by new ones. These occasions are rare that they are called groundbreaking discovery. I remembered the day everyone at the department was talking about the guideline change on egg consumption- may seem insignificant to outsiders but we were really excited! It could be that such new discoveries are rare because we are doing the same thing over and over again, and are content when our findings (even vaguely) agree the current consensus- we seek validation from previous works by researchers more venerable than us. And that is dangerous to our patients and the public. We may be feeling relaxed because we think the worst that can happen from such findings is “the treatment is ineffective but not harmful.” We pour scorn on some of the treatments given by the healthcare providers some hundred years ago as harmful and ineffective. We can do so because we now have the knowledge collected over time. It is very possible our best guidelines may seem ‘folly’ to the researchers in the next hundred years. Thus, I agree with the author that it’s time we should do things differently.</p>
<p><br></p>
</section></section><section id="three-tools-for-golem-engineering" class="level2"><h2 class="anchored" data-anchor-id="three-tools-for-golem-engineering">Three tools for golem engineering</h2>
<p>The author gave alternative to falsification- that is to build models. According to the author, “Models can be made into testing procedures— all statistical tests are also models—but they can also be used to measure, forecast, and argue.” He also mentioned three models that are “in demand in both the social and biological sciences.”</p>
<ol type="1">
<li><p>Bayesian data analysis</p></li>
<li><p>Multilevel models</p></li>
<li><p>Model comparison using information criteria</p></li>
</ol>
<section id="bayesian-data-analysis" class="level3"><h3 class="anchored" data-anchor-id="bayesian-data-analysis"><em>Bayesian data analysis</em></h3>
<p>As explained by the author, Bayesian data analysis uses uncertainty or chance to “describe plausibility of different possibilities,” and “…we can use probability theory as a general way to represent plausibility, whether in reference to countable events in the world or rather theoretical constructs like parameters.” The author then compared this approach to frequentist approach- “Bayesian probability is a very general approach to probability…The frequentist approach requires that all probabilities be defined by connection to countable events and their frequencies in very large samples.” And the author pointed out “…This leads to frequentist uncertainty being premised on imaginary resampling of data— if we were to repeat the measurement many many times, we would end up collecting a list of values that will have some pattern to it. It means also that parameters and models cannot have probability distributions, only measurements can. The distribution of these measurements is called a sampling distribution. This resampling is never done, and in general it doesn’t even make sense…”</p>
<p>He also quoted “one of the most important frequentist statisticians of the 20<sup>th</sup> century,” Sir Ronald Fisher:</p>
<p>“[…] the only populations that can be referred to in a test of significance have no objective reality, being exclusively the product of the statistician’s imagination […]”</p>
<p>But, Fisher’s criticism was already rebuked by his contemporary Professor Egon Pearson in his <a href="https://errorstatistics.files.wordpress.com/2021/02/pearson_1955-stat-concepts-reality.pdf">“Statistical Concepts in Their Relation to Reality”</a>. Pearson said:</p>
<p>“…If probability is to be justly applied to the analysis of data, it follows that a random process must have been introduced or been naturally present at some stage in the collection of these data. Is there not then an appeal to the imagination in taking as the hypothetical population of samples that which would have been generated by repetition of this random process?…”</p>
<p>According to Pearson, Fisher was “often tilting at views which those whom he attacks have never held.” And I can use Pearson’s argument to address the “telescope” example given by the author.</p>
<p>“…Since the telescope was primitive, it couldn’t really focus the image very well. Saturn always appeared blurred. This is a statistical problem, of a sort. There’s uncertainty about the planet’s shape, but notice that none of the uncertainty is a result of variation in repeat measurements. We could look through the telescope a thousand times, and it will always give the same blurred image (for any given position of the Earth and Saturn). So the sampling distribution of any measurement is constant, because the measurement is deterministic— there’s nothing “random” about it. Frequentist statistical inference has a lot of trouble getting started here…”</p>
<p>I think, like Fisher, the author is also “tilting at views” which frequentists have never held. The problem with the telescope example is that repeated measurements were done on “ONE” sample only. That’s why he made assumption that “…none of the uncertainty is a result of variation in repeat measurements…So the sampling distribution of any measurement is constant, because the measurement is deterministic— there’s nothing “random” about it.” I have yet to see a research that only measures “one” sample repeatedly to solve a research question at population level or in real-world situations. It would be akin to asking a single child- using different sets of questions- repeatedly about what the child eats in a day to know the dietary pattern of all the children in the region. It makes no sense. Furthermore, sample representativeness play a major role in such researches. The author representation of a frequentist research has no place for sample representativeness- there is only one sample and nothing else.</p>
<p>The author also criticized about “imagined repeat sampling.” If taken out of context, such idea can be quite preposterous. But, it can actually be logical if we explain it in terms of sample representativeness. We are not imagining repeated sampling- beyond our chosen sample sets- to justify the results from our samples are applicable to the population. For example, if we were to study the dietary pattern of an ethnic group reside in the mountain, we do not need to ask dietary-related questions to every individual in the group. We select a fraction of the group- chosen at random- to infer the dietary pattern of the whole group. Such fraction (samples) should be high enough in number and have traits similar to the whole group. If results obtained from samples said “fish constitutes only a small part of their diet,” then we can assume that we will have the same result if we did the same survey repeatedly with different sample sets obtained from the group. In this case, the so-called “imagined repeat sampling” can work because samples are representative of the population.</p>
<p>The author continued in the next paragraph that “..even when a Bayesian procedure and frequentist procedure give exactly the same answer, our Bayesian golems aren’t justifying their inferences with imagined repeat sampling.” Such narrative can give a result totally opposite of what the author wants. The author wants the readers to “rethinking statistics,” by pointing out flaws in the classical statistic tests and research methodology. However, all the examples given by the author can be easily rebuked. More rebuttals will come if such narrative is introduced in a frequestist community- like academics in the nutrition field. But, these academics are not really protecting Karl Popper or E.S. Pearson. They are not defensive about the theories postulated years ago by scientists in the past. They are simply protecting their works- their findings. Majority- if not all- of these academics will not “rethink statistics” if Bayesian approach begins with denouncing the frequentist approach, especially when counter-arguments can easily be made. It will be similar to the author stabbing them with a knife first before offering a treatment. All or most of them will not accept the treatment. They will run away- either scared or hateful. Some may even stab him back. Even if they were forced to accept it, the acceptance would be superficial. Instead, we should offer them beautiful roses with exquisite scent- meaning we should focus on what Bayesian analysis can offer which frequentist apporach can’t, rather than attacking them. The thorns may still prick their fingers, but they will not be able to resist the charm of the roses. And we can offer them balm to soothe their fingers. They will be thankful, and meaningful collaborations will be made.</p>
</section><section id="multilevel-models" class="level3"><h3 class="anchored" data-anchor-id="multilevel-models"><em>Multilevel models</em></h3>
<p>The author introduced the concept of multilevel model in this section. Statistical models “contain parameters. And parameters support inference. Upon what do parameters themselves stand? Sometimes, in some of the most powerful models, it’s parameters all the way down. What this means is that any particular parameter can be usefully regarded as a placeholder for a missing model. Given some model of how the parameter gets its value, it is simple enough to embed the new model inside the old one. This results in a model with multiple levels of uncertainty, each feeding into the next—a multilevel model.”</p>
<p>The author also mentioned “four typical and complementary reasons to sue multilevel models:”</p>
<ol type="1">
<li><p><strong><em>To adjust estimates for repeat sampling.</em></strong> When more than one observation arises from the same individual, location, or time, then traditional, single-level models may mislead us.</p></li>
<li><p><strong><em>To adjust estimates for imbalance in sampling.</em></strong> When some individuals,locations,or times are sampled more than others, we may also be misled by single-level models.</p></li>
<li><p><strong><em>To study variation.</em></strong> If our research questions include variation among individuals or other groups within the data, then multilevel models are a big help, because they model variation explicitly.</p></li>
<li><p><strong><em>To avoid averaging.</em></strong> Frequently, scholars pre-average some data to construct variables for a regression analysis. This can be dangerous, because averaging removes variation. It therefore manufactures false confidence. Multilevel models allow us to preserve the uncertainty in the original, pre-averaged values, while still using the average to make predictions.</p></li>
</ol>
<p>And there are also “diverse model types that turn out to be multilevel: models for missing data (imputation), measurement error, factor analysis, some time series models, types of spatial and network regression, and phylogenetic regressions all are special applications of the multilevel strategy.”</p>
<p>The author added “this is why grasping the concept of multilevel modeling may lead to a perspective shift. Suddenly single- level models end up looking like mere components of multilevel models. The multilevel strategy provides an engineering principle to help us to introduce these components into a particular analysis, exactly where we think we need them.”</p>
<p>Based on the author’s explanation, multilevel models sound really promising, and I’m eager to learn more about them.</p>
</section><section id="model-comparison-and-information-criteria" class="level3"><h3 class="anchored" data-anchor-id="model-comparison-and-information-criteria"><em>Model comparison and information criteria</em></h3>
<p>Information criteria were developed to compare “structurally different models based upon future predictive accuracy, using different approximations for different model types.”</p>
<p>Popular information criterion AIC, and related metrics- such as DIC and WAIC- “explicitly build a model of the prediction task and use that model to estimate performance of each model you might wish to compare. Because the prediction is modeled, it depends upon assumptions. So information criteria do not in fact achieve the impossible, by seeing the future. They are still golems.” The author also mentioned that they are known as “information criteria, because they develop their measure of model accuracy from information theory.”</p>
<p>These criteria can help researchers with two common difficulties in model comparison:</p>
<ol type="1">
<li><p><strong><em>Overfitting.</em></strong> Future data will not be exactly like past data, and so any model that is unaware of this fact tends to make worse predictions than it could. So if we wish to make good predictions, we cannot judge our models simply on how well they fit our data. Information criteria provide estimates of predictive accuracy, rather than merely fit. So they compare models where it matters.</p></li>
<li><p><strong><em>Comparison of multiple non-null models to the same data.</em></strong> Frequently, several plausible models of a phenomenon are known to us. In some empirical contexts, like social networks and evolutionary phylogenies, there are no reasonable or uniquely “null” models. This was also true of the neutral evolution example. In such cases, it’s not only a good idea to explicitly compare models. It’s also mandatory. Information criteria aren’t the only way to conduct the comparison. But they are an accessible and widely used way.</p></li>
</ol>
<p><br></p>
</section></section></section><section id="chapter-2-small-worlds-and-large-worlds" class="level1"><h1>Chapter 2: Small Worlds and Large Worlds</h1>
<p><br></p>
<section id="the-garden-of-forking-data" class="level2"><h2 class="anchored" data-anchor-id="the-garden-of-forking-data">The garden of forking data</h2>
<p>“In order to make good inference about what actually happened, it helps to consider everything that could have happened. A Bayesian analysis is a garden of forking data, in which alternative sequences of events are cultivated. As we learn about what did happen, some of these alternative sequences are pruned. In the end, what remains is only what is logically consistent with our knowledge.”</p>
<section id="counting-possibilities" class="level3"><h3 class="anchored" data-anchor-id="counting-possibilities">Counting possibilities</h3>
<p><span style="color:green"><strong><em>A bag of avocado and pear (total 8)</em></strong></span></p>
<ul>
<li>Conjectures: (a,a,a,a,a,a,a,a); (p,a,a,a,a,a,a,a); (p,p,a,a,a,a,a,a); (p,p,p,a,a,a,a,a); (p,p,p,p,a,a,a,a); (p,p,p,p,p,a,a,a); (p,p,p,p,p,p,a,a); (p,p,p,p,p,p,p,a); (p,p,p,p,p,p,p,p)</li>
</ul>
<p><span style="color:green"><strong><em>Shake the bag to give equal chance and pick 4 fruits; replace the fruit after each pick</em></strong></span></p>
<ul>
<li>Data: (a,p,a,a)</li>
</ul>
<p><span style="color:green"><strong><em>Count the possible ways to have that exact data sequence for each conjecture</em></strong></span></p>
<ul>
<li><p>(a,a,a,a,a,a,a,a) → 8 * 0 * 8 * 8 = 0</p></li>
<li><p>(p,a,a,a,a,a,a,a) → 7 * 1 * 7 * 7 = 343</p></li>
<li><p>(p,p,a,a,a,a,a,a) → 6 * 2 * 6 * 6 = 432</p></li>
<li><p>(p,p,p,a,a,a,a,a) → 5 * 3 * 5 * 5 = 375</p></li>
<li><p>(p,p,p,p,a,a,a,a) → 4 * 4 * 4 * 4 = 256</p></li>
<li><p>(p,p,p,p,p,a,a,a) → 3 * 5 * 3 * 3 = 135</p></li>
<li><p>(p,p,p,p,p,p,a,a) → 2 * 6 * 2 * 2 = 48</p></li>
<li><p>(p,p,p,p,p,p,p,a) → 1 * 7 * 1 * 1 = 7</p></li>
<li><p>(p,p,p,p,p,p,p,p) → 0 * 8 * 0 * 0 = 0</p></li>
</ul>
<p>“So what good are these counts? By comparing these counts, we have part of a solution for a way to rate the relative plausibility of each conjectured bag composition. But it’s only a part of a solution, because in order to compare these counts we first have to decide how many ways each conjecture could itself be realized. We might argue that when we have no reason to assume otherwise, we can just consider each conjecture equally plausible and compare the counts directly. But often we do have reason to assume otherwise.”</p>
</section><section id="using-prior-information" class="level3"><h3 class="anchored" data-anchor-id="using-prior-information">Using prior information</h3>
<p>Two possible choices to incorporate prior information: add a new layer to the garden or multiply prior count by the new count. “It turns out that these two methods are mathematically identical, as long as the new observation is logically independent of the previous observations.”</p>
<p>“First we count the numbers of ways each conjecture could produce the new observation. Then we multiply each of these new counts by the previous numbers of ways for each conjecture.”</p>
<p>We select one more fruit from the bag. Now the data sequence is “a,p,a,a,p”</p>
<ul>
<li><p>(a,a,a,a,a,a,a,a) → 0 * 0 = 0</p></li>
<li><p>(p,a,a,a,a,a,a,a) → 343 * 1 = 343</p></li>
<li><p>(p,p,a,a,a,a,a,a) → 432 * 2 = 864</p></li>
<li><p>(p,p,p,a,a,a,a,a) → 375 * 3 = 1125</p></li>
<li><p>(p,p,p,p,a,a,a,a) → 256 * 4 = 1024</p></li>
<li><p>(p,p,p,p,p,a,a,a) → 135 * 5 = 675</p></li>
<li><p>(p,p,p,p,p,p,a,a) → 48 * 6 = 288</p></li>
<li><p>(p,p,p,p,p,p,p,a) → 7 * 7 = 49</p></li>
<li><p>(p,p,p,p,p,p,p,p) → 0 * 8 = 0</p></li>
</ul>
<p>“This updating approach amounts to nothing more than asserting that (1) when we have previous information suggesting there are W<sub>prior</sub> ways for a conjecture to produce a previous observation D<sub>prior</sub> and (2) we acquire new observations D<sub>new</sub> that the same conjecture can produce in W<sub>new</sub> ways, then (3) the number of ways the conjecture can account for both D<sub>prior</sub> as well as D<sub>new</sub> is just the product W<sub>prior</sub> × W<sub>new</sub>.”</p>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Incorporating new data types different from prior data</strong></span></span></p>
<p><em>New information: There are fewer pears than avocados. For every bag containing 5 pears and 3 avocados, there are two bags containing 4 pears and 4 avocados, three bags containing 5 avocados and 3 pears, and four bags containing 2 pears and 6 avocados. Each bag contains at least 2 pears and 2 avocados.</em></p>
<ul>
<li><p>(a,a,a,a,a,a,a,a) → 0 * 0 = 0</p></li>
<li><p>(p,a,a,a,a,a,a,a) → 343 * 0 = 0</p></li>
<li><p>(p,p,a,a,a,a,a,a) → 864 * 4 = 3456</p></li>
<li><p>(p,p,p,a,a,a,a,a) → 1125 * 3 = 3375</p></li>
<li><p>(p,p,p,p,a,a,a,a) → 1024 * 2 = 2048</p></li>
<li><p>(p,p,p,p,p,a,a,a) → 675 * 1 = 675</p></li>
<li><p>(p,p,p,p,p,p,a,a) → 288 * 0 = 0</p></li>
<li><p>(p,p,p,p,p,p,p,a) → 49 * 0 = 0</p></li>
<li><p>(p,p,p,p,p,p,p,p) → 0 * 0 = 0</p></li>
</ul>
<p>I made a mental note in the beginning that the bag contained 4 pears and 4 avocados. Now, using the counting method has gotten me nearer to the truth, but it makes no difference since I will get the wrong answer anyway. The author asked “Is there a threshold difference in these counts at which we can safely decide that one of the conjectures is the correct one?”, when one conjecture is barely more possible than the other. I think the answer is no (correct answer is in chapter 3).</p>
<p>“Which assumption should we use, when there is no previous information about the conjectures? The most common solution is to assign an equal number of ways that each conjecture could be correct, before seeing any data. This is sometimes known as the <em>principle of indifference</em>: When there is no reason to say that one conjecture is more plausible than another, weigh all of the conjectures equally. The issue of choosing a representation of “ignorance” is surprisingly complicated. The issue will arise again in later chapters. For the sort of problems we examine in this book, the principle of indifference results in inferences very comparable to mainstream non-Bayesian approaches, most of which contain implicit equal weighting of possibilities. For example a typical non-Bayesian confidence interval weighs equally all of the possible values a parameter could take, regardless of how implausible some of them are. Many non-Bayesian procedures have moved away from this, through the use of penalized likelihood and other methods.”</p>
<p><br></p>
</section><section id="from-counts-to-probability" class="level3"><h3 class="anchored" data-anchor-id="from-counts-to-probability">From counts to probability</h3>
<p><em>If p is the proportion of pear and D<sub>new</sub> = {a,p,a,a}</em></p>
<p>plausibility of p after D<sub>new</sub><span class="math inline">\(∝\)</span> ways p can produce D<sub>new</sub> × prior plausibility of p</p>
<p>“The above just means that for any value p can take, we judge the plausibility of that value p as proportional to the number of ways it can get through the garden of forking data. This expression just summarizes the calculations you did in the tables of the previous section.</p>
<p>Finally, we construct probabilities by standardizing the plausibility so that the sum of the plausibilities for all possible conjectures will be one. All you need to do in order to standardize is to add up all of the products, one for each value p can take, and then divide each product by the sum of products:”</p>
<p>plausibility of p after D<sub>new</sub> = <span class="math inline">\(\frac{ways~p~can~produce~D~new~ x~ prior~plausibility~p}{sum~of~products}\)</span></p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<thead><tr class="header">
<th style="text-align: left;">Possible_composition</th>
<th style="text-align: right;">p</th>
<th style="text-align: right;">Ways_to_produce_data</th>
<th style="text-align: right;">Plausibility</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(a,a,a,a,a,a,a,a)</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">(p,a,a,a,a,a,a,a)</td>
<td style="text-align: right;">0.125</td>
<td style="text-align: right;">343</td>
<td style="text-align: right;">0.210</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(p,p,a,a,a,a,a,a)</td>
<td style="text-align: right;">0.250</td>
<td style="text-align: right;">432</td>
<td style="text-align: right;">0.270</td>
</tr>
<tr class="even">
<td style="text-align: left;">(p,p,p,a,a,a,a,a)</td>
<td style="text-align: right;">0.375</td>
<td style="text-align: right;">375</td>
<td style="text-align: right;">0.230</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(p,p,p,p,a,a,a,a)</td>
<td style="text-align: right;">0.500</td>
<td style="text-align: right;">256</td>
<td style="text-align: right;">0.160</td>
</tr>
<tr class="even">
<td style="text-align: left;">(p,p,p,p,p,a,a,a)</td>
<td style="text-align: right;">0.625</td>
<td style="text-align: right;">135</td>
<td style="text-align: right;">0.080</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(p,p,p,p,p,p,a,a)</td>
<td style="text-align: right;">0.750</td>
<td style="text-align: right;">48</td>
<td style="text-align: right;">0.030</td>
</tr>
<tr class="even">
<td style="text-align: left;">(p,p,p,p,p,p,p,a)</td>
<td style="text-align: right;">0.875</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0.004</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(p,p,p,p,p,p,p,p)</td>
<td style="text-align: right;">1.000</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.000</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>OR</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ways</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">343</span>, <span class="fl">432</span>, <span class="fl">375</span>, <span class="fl">256</span>, <span class="fl">135</span>, <span class="fl">48</span>, <span class="fl">7</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">ways</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">ways</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.000000000 0.214912281 0.270676692 0.234962406 0.160401003 0.084586466
[7] 0.030075188 0.004385965 0.000000000</code></pre>
</div>
</div>
<p>“These plausibilities are also probabilities— they are non-negative (zero or positive) real numbers that sum to one. And all of the mathematical things you can do with probabilities you can also do with these values. Specifically, each piece of the calculation has a direct partner in applied probability theory. These partners have stereotyped names, so it’s worth learning them, as you’ll see them again and again.</p>
<p>• A conjectured proportion of pears, p, is usually called a parameter value. It’s just a way of indexing possible explanations of the data.</p>
<p>• The relative number of ways that a value p can produce the data is usually called a likelihood. It is derived by enumerating all the possible data sequences that could have happened and then eliminating those sequences inconsistent with the data.</p>
<p>• The prior plausibility of any specific p is usually called the prior probability.</p>
<p>• The new, updated plausibility of any specific p is usually called the posterior probability.</p>
<p><em>If we really have shuffled a deck of cards enough to erase any prior knowledge of the ordering- in randomization process-, then the order the cards end up in is very likely to be one of the many orderings with high information entropy.</em>”</p>
<p><br></p>
</section></section><section id="building-a-model" class="level2"><h2 class="anchored" data-anchor-id="building-a-model">Building a model</h2>
<p>“Designing a simple Bayesian model benefits from a design loop with three steps.</p>
<ol type="1">
<li><p>Data story: Motivate the model by narrating how the data might arise.</p></li>
<li><p>Update: Educate your model by feeding it the data.</p></li>
<li><p>Evaluate: All statistical models require supervision, leading possibly to model revision.”</p></li>
</ol>
<p><br></p>
<section id="a-data-story" class="level3"><h3 class="anchored" data-anchor-id="a-data-story">A data story</h3>
<p>“Bayesian data analysis usually means producing a story for how the data came to be. This story may be descriptive, specifying associations that can be used to predict outcomes, given observations. Or it may be causal, a theory of how some events produce other events. Typically, any story you intend to be causal may also be descriptive. But many descriptive stories are hard to interpret causally. But all data stories are complete, in the sense that they are sufficient for specifying an algorithm for simulating new data.</p>
<p>You can motivate your data story by trying to explain how each piece of data is born. This usually means describing aspects of the underlying reality as well as the sampling process.</p>
<p>The data story is then translated into a formal probability model. This probability model is easy to build, because the construction process can be usefully broken down into a series of component decisions.”</p>
<p><br></p>
</section><section id="bayesian-updating" class="level3"><h3 class="anchored" data-anchor-id="bayesian-updating">Bayesian updating</h3>
<p>“A Bayesian model begins with one set of plausibilities assigned to each of these possibilities. These are the prior plausibilities. Then it updates them in light of the data, to produce the posterior plausibilities. This updating process is a kind of learning, called Bayesian updating.</p>
<p>Notice that every updated set of plausibilities becomes the initial plausibilities for the next observation. Every conclusion is the starting point for future inference. However, this updating process works backwards, as well as forwards. Knowing the final observation, it is possible to mathematically divide out the observation, to infer the previous plausibility curve. So the data could be presented to your model in any order, or all at once even. In most cases, you will present the data all at once, for the sake of convenience. But it’s important to realize that this merely represents abbreviation of an iterated learning process.</p>
<p>Bayesian estimates are valid for any sample size. This does not mean that more data isn’t helpful—it certainly is. Rather, the estimates have a clear and valid interpretation, no matter the sample size. But the price for this power is dependency upon the initial estimates, the prior. If the prior is a bad one, then the resulting inference will be misleading.”</p>
<p><br></p>
</section><section id="evaluate" class="level3"><h3 class="anchored" data-anchor-id="evaluate">Evaluate</h3>
<p>“If there are important differences between the model and reality, then there is no logical guarantee of large world performance. And even if the two worlds did match, any particular sample of data could still be misleading. So it’s worth keeping in mind at least two cautious principles: (1) the model’s certainty is no guarantee that the model is a good one and (2) it is important to supervise and critique your model’s work.</p>
<p>Note that the goal is not to test the truth value of the model’s assumptions. All manner of small world assumptions about error distributions and the like can be violated in the large world, but a model may still produce a perfectly useful estimate. Instead, the objective is to check the model’s adequacy for some purpose. This usually means asking and answering additional questions, beyond those that originally constructed the model.”</p>
<p><br></p>
</section></section><section id="components-of-the-model" class="level2"><h2 class="anchored" data-anchor-id="components-of-the-model">Components of the model</h2>
<p>“The usual way we build a statistical model involves choosing distributions and devices for each that represent the relative numbers of ways things can happen. These distributions and devices are</p>
<ol type="1">
<li><p>a likelihood function- the number of ways each conjecture could produce an observation</p></li>
<li><p>one or more parameters- the accumulated number of ways each conjecture could produce the entire data</p></li>
<li><p>a prior- the initial plausibility of each conjectured cause of the data”</p></li>
</ol>
<p><br></p>
<section id="likelihood" class="level3"><h3 class="anchored" data-anchor-id="likelihood">Likelihood</h3>
<p>“The likelihood is a mathematical formula that specifies the plausibility of the data. What this means is that the likelihood maps each conjecture onto the relative number of ways the data could occur, given that possibility.”</p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Binomial distribution</strong></span></span></p>
<ul>
<li><p>each event is independent of other events</p></li>
<li><p>the probability of “an observation” is the same on every event</p></li>
<li><p>the common “coin tossing” distribution where there is only two possible answers (e.g., land or water in globe example; failure or success, etc.)</p></li>
</ul>
<p>In the given globe example, there are two possible outcomes: either land or water. Out of 9 tosses (n), 6 tosses land on water. The probability of getting water (p) is the same (0.5%) on every toss. Then, we can use binomial distribution formula in R to compute the “likelihood of data w (water)- 6 W’s in 9 tosses- under any value of p with”:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span> <span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1640625</code></pre>
</div>
</div>
<p>If probability for getting water is 0.2,</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.002752512</code></pre>
</div>
</div>
<p><em>“The job of the likelihood is to tell us the relative number of ways to see the data w, given values for p and n.”</em></p>
<p><br></p>
</section><section id="parameters" class="level3"><h3 class="anchored" data-anchor-id="parameters">Parameters</h3>
<p>“It is typical to conceive of data and parameters as completely different kinds of entities. Data are measured and known; parameters are unknown and must be estimated from data. Usefully, in the Bayesian framework the distinction between a datum and a parameter is fuzzy. A datum can be recast as a very narrow probability density for a parameter, and a parameter as a datum with uncertainty. This continuity between certainty (data) and uncertainty (parameters) can be exploited (Ch 14) to incorporate measurement error and missing data into your modeling.</p>
<p>In globe tossing example, n and w are data, and p is unknown parameter. Your Bayesian machine can tell you what the data say about any parameter, once you tell it the likelihood and which bits have been observed. In some cases, the golem will just tell you that not much can be learned—Bayesian data analysis isn’t magic, after all. But it is usually an advance to learn that our data don’t discriminate among the possibilities.”</p>
<p><br></p>
</section><section id="prior" class="level3"><h3 class="anchored" data-anchor-id="prior">Prior</h3>
<p>“A Bayesian machine must have an initial plausibility assignment for each possible value of the parameter. The prior is this initial set of plausibilities. Priors are useful for constraining parameters to reasonable ranges, as well as for expressing any knowledge we have about the parameter, before any data are observed.</p>
<p>Within Bayesian data analysis in the natural and social sciences, the prior is considered to be just part of the model. As such it should be chosen, evaluated, and revised just like all of the other components of the model. In practice, the subjectivist and the non-subjectivist will often analyze data in nearly the same way.</p>
<p>If you don’t have a strong argument for any particular prior, then try different ones. Because the prior is an assumption, it should be interrogated like other assumptions: by altering it and checking how sensitive inference is to the assumption.”</p>
<p><br></p>
</section><section id="posterior" class="level3"><h3 class="anchored" data-anchor-id="posterior">Posterior</h3>
<p>“Once you have chosen a likelihood, which parameters are to be estimated, and a prior for each parameter, a Bayesian model treats the estimates as a purely logical consequence of those assumptions. For every unique combination of data, likelihood, parameters, and prior, there is a unique set of estimates. The resulting estimates—the relative plausibility of different parameter values, conditional on the data—are known as the posterior distribution. The posterior distribution takes the form of the probability of the parameters, conditional on the data: <code>Pr(p|n, w).</code></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Bayes Theorem</strong></span></span></p>
<p>The mathematical procedure that defines the logic of the posterior distribution is Bayes’ theorem. The joint probability of the data w and any particular value of p is: <code>Pr(w, p) = Pr(w|p) Pr(p)</code>- the probability of w and p is the product of likelihood Pr(w|p) and the prior probability Pr(p).”</p>
<p>Example- the probability of mango both sweet and yellow is equal to the probability that mango is sweet given that it is yellow, multiplies by the probability that it is yellow: <code>Pr(s, y) = Pr(s|y) Pr(y)</code></p>
<p>OR the probability of mango both sweet and yellow is equal to the probability that mango is yellow given that it is sweet, multiplies by the probability that it is sweet: <code>Pr(s, y) = Pr(y|s) Pr(s)</code></p>
<p>Now since both right-hand sides are equal to the same thing, we can set them equal to one another and solve for the posterior probability: Pr(s|y) = <span class="math inline">\(\frac{Pr(y|s)~Pr(s)}{Pr(y)}\)</span></p>
<p><span style="color:brown"><strong><em>Bayes’ theorem</em></strong></span>: the probability of any particular value of p, considering the data, is equal to the product of the likelihood and prior, divided by this thing Pr(w), which I’ll call the <em>average likelihood</em>. In word form:</p>
<p><span class="math display">\[\text{Posterior =}\frac{\text{Likelihood x Prior}}{\text{Average Likelihood}}\]</span></p>
<p><span style="color:brown"><strong><em>Average Likelihood:</em></strong></span></p>
<ul>
<li><p>commonly called “evidence” or “probability of the data”</p></li>
<li><p>Likelihood of the data averaged over the prior</p></li>
<li><p>To standardize the posterior, to ensure it sums (integrates) to one</p></li>
</ul>
<p><br></p>
</section></section><section id="making-the-model-go" class="level2"><h2 class="anchored" data-anchor-id="making-the-model-go">Making the model go</h2>
<p>“Bayesian model is a machine, a figurative golem. It has built-in definitions for the likelihood, the parameters, and the prior. And then at its heart lies a motor that processes data, producing a posterior distribution. The action of this motor can be thought of as conditioning the prior on the data.</p>
<p>Three different conditioning engines, numerical techniques for computing posterior distributions, that can accommodate whichever prior is most useful for inference:</p>
<ol type="1">
<li><p>Grid approximation</p></li>
<li><p>Quadratic approximation</p></li>
<li><p>Markov chain Monte Carlo (MCMC)”</p></li>
</ol>
<p><br></p>
<section id="grid-approximation" class="level3"><h3 class="anchored" data-anchor-id="grid-approximation">Grid approximation</h3>
<p>While most parameters are continuous, capable of taking on an infinite number of values, it turns out that we can achieve an excellent approximation of the continuous posterior distribution by considering only a finite grid of parameter values. At any particular value of a parameter, p′, it’s a simple matter to compute the posterior probability: just multiply the prior probability of p′ by the likelihood at p′. Repeating this procedure for each value in the grid generates an approximate picture of the exact posterior distribution. This procedure is called grid approximation.</p>
<p>But in most of your real modeling, grid approximation isn’t practical. The reason is that it scales very poorly, as the number of parameters increases.</p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Building a grid approximation</strong></span></span></p>
<ol type="1">
<li><p>Define the grid- decide how many points to use in estimating the posterior, and then make a list of the parameter values on the grid.</p></li>
<li><p>Compute the value of the prior at each parameter value on the grid.</p></li>
<li><p>Compute the likelihood at each parameter value.</p></li>
<li><p>Compute the unstandardized posterior at each parameter value, by multiplying the prior by the likelihood.</p></li>
<li><p>Finally, standardize the posterior, by dividing each value by the sum of all values.</p></li>
</ol>
<p><br></p>
<p><span style="color:gray"><strong><em>Building a grid approximation for globe tossing example</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define grid</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">0</span> , to<span class="op">=</span><span class="fl">1</span> , length.out<span class="op">=</span><span class="fl">20</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># define prior</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span> <span class="fl">1</span> , <span class="fl">20</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># compute likelihood at each value in grid</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span> <span class="fl">6</span> , size<span class="op">=</span><span class="fl">9</span> , prob<span class="op">=</span><span class="va">p_grid</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># compute product of likelihood and prior</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior, so it sums to 1</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display the posterior distribution </span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">p_grid</span> , <span class="va">posterior</span> , type<span class="op">=</span><span class="st">"b"</span> ,</span>
<span>    xlab<span class="op">=</span><span class="st">"probability of water"</span> , ylab<span class="op">=</span><span class="st">"posterior probability"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span> <span class="st">"20 points"</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/globe%20tossing%20example-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:gray"><strong><em>Try with a 5-point grid</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span> <span class="co"># 1 form a uniform prior distribution, assigning equal probability to each value in the grid. Using a decimal here will mean the same but may assume less degree of uncertainty?</span></span>
<span></span>
<span><span class="co"># compute likelihood at each value in the grid</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute product of likelihood and prior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior, so it sums to 1</span></span>
<span></span>
<span><span class="va">std.posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">std.posterior</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior probability"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"5 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5-point%20grid-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:gray"><strong><em>Try with a 100-point grid</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute likelihood at each value in grid</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute the unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior </span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"100 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/100-point%20grid-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>In this simple example, you can go crazy and use 100,000 points, but there won’t be much change in inference after the first 100.</em></p>
<p><br></p>
<p><span style="color:gray"><strong><em>Try with a step prior</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">40</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&lt;</span> <span class="fl">0.5</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span> <span class="co">#ifelse(test, yes, no)</span></span>
<span></span>
<span><span class="co"># calculate the likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"o"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"40 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/step%20prior-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:gray"><strong><em>Try with a peaked prior</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">40</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">-</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate the likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardised posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"40 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/peaked%20prior-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
</section><section id="quadratic-approximation" class="level3"><h3 class="anchored" data-anchor-id="quadratic-approximation">Quadratic approximation</h3>
<p>Under quite general conditions, the region near the peak of the posterior distribution will be nearly Gaussian—or “normal”—in shape. This means the posterior distribution can be usefully approximated by a Gaussian distribution. A Gaussian distribution is convenient, because it can be completely described by only two numbers: the location of its center (mean) and its spread (variance).</p>
<p>A Gaussian approximation is called “quadratic approximation” because the logarithm of a Gaussian distribution forms a parabola. And a parabola is a quadratic function. So this approximation essentially represents any log-posterior with a parabola.</p>
<p>The procedure to carry out quadratic approximation in R contains two steps:</p>
<ol type="1">
<li><p>Find the posterior mode. This is usually accomplished by some optimization algorithm, a procedure that virtually “climbs” the posterior distribution, as if it were a mountain. The golem doesn’t know where the peak is, but it does know the slope under its feet. There are many well-developed optimization procedures, most of them more clever than simple hill climbing. But all of them try to find peaks.</p></li>
<li><p>Once you find the peak of the posterior, you must estimate the curvature near the peak. This curvature is sufficient to compute a quadratic approximation of the entire posterior distribution. In some cases, these calculations can be done analytically, but usually your computer uses some numerical technique instead.</p></li>
</ol>
<p><span style="color:gray"><strong><em>Compute the quadratic approximation to the globe tossing data</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">globe.qa</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span>           <span class="co">#  map is maximum a posteriori- the mode of the posterior distribution</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">w</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">9</span>,<span class="va">p</span><span class="op">)</span> ,  <span class="co"># binomial likelihood</span></span>
<span>        <span class="va">p</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>     <span class="co"># uniform prior</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>w<span class="op">=</span><span class="fl">6</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># display summary of quadratic approximation</span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">globe.qa</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      mean        sd      5.5%    94.5%
p 0.666667 0.1571337 0.4155371 0.917797</code></pre>
</div>
</div>
<p><em>To use map, you provide a formula, a list of data, and a list of start values for the parameters. The formula defines the likelihood and prior.</em></p>
<p>The function precis presents a brief summary of the quadratic approximation. In this case, it shows a MAP value of p = 0.67, which it calls the “Mean.” The curvature is labeled “Std- Dev” This stands for standard deviation. This value is the standard deviation of the posterior distribution, while the mean value is its peak. Finally, the last two values in the precis output show the 89% percentile interval. You can read this kind of approximation like: Assuming the posterior is Gaussian, it is maximized at 0.67, and its standard deviation is 0.16.</p>
<p>Since we already know the posterior, let’s compare to see how good the approximation is. I’ll use the analytical approach here, which uses dbeta.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># analytical calculation</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fl">6</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">9</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span> <span class="va">x</span> , <span class="va">w</span><span class="op">+</span><span class="fl">1</span> , <span class="va">n</span><span class="op">-</span><span class="va">w</span><span class="op">+</span><span class="fl">1</span> <span class="op">)</span> , from<span class="op">=</span><span class="fl">0</span> , to<span class="op">=</span><span class="fl">1</span> <span class="op">)</span> </span>
<span><span class="co"># Use Laplace's rule of succession- add one to both w and n-w to avoid assigning zero probability, </span></span>
<span><span class="co"># ensure at least there's one w and one n-w, even if none have been observed yet</span></span>
<span></span>
<span><span class="co"># quadratic approximation</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">x</span> , <span class="fl">0.67</span> , <span class="fl">0.16</span> <span class="op">)</span> , lty<span class="op">=</span><span class="fl">2</span> , add<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/dbeta-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><span style="color:gray"><strong><em>Double the sample size</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">globe.qa1</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span>           <span class="co">#  map is maximum a posteriori- the mode of the posterior distribution</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">w</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">18</span>,<span class="va">p</span><span class="op">)</span> ,  <span class="co"># binomial likelihood</span></span>
<span>        <span class="va">p</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>     <span class="co"># uniform prior</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>w<span class="op">=</span><span class="fl">12</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># display summary of quadratic approximation</span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">globe.qa1</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       mean        sd      5.5%     94.5%
p 0.6666662 0.1111104 0.4890903 0.8442421</code></pre>
</div>
</div>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># analytical calculation</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fl">12</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">18</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span> <span class="va">x</span> , <span class="va">w</span><span class="op">+</span><span class="fl">1</span> , <span class="va">n</span><span class="op">-</span><span class="va">w</span><span class="op">+</span><span class="fl">1</span> <span class="op">)</span> , from<span class="op">=</span><span class="fl">0</span> , to<span class="op">=</span><span class="fl">1</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># quadratic approximation</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">x</span> , <span class="fl">0.67</span> , <span class="fl">0.11</span> <span class="op">)</span> , lty<span class="op">=</span><span class="fl">2</span> , add<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/increase%20tosses1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><span style="color:gray"><strong><em>Quadruple the sample size</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">globe.qa2</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span>           <span class="co">#  map is maximum a posteriori- the mode of the posterior distribution</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">w</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">36</span>,<span class="va">p</span><span class="op">)</span> ,  <span class="co"># binomial likelihood</span></span>
<span>        <span class="va">p</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>     <span class="co"># uniform prior</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>w<span class="op">=</span><span class="fl">24</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># display summary of quadratic approximation</span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">globe.qa2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       mean         sd      5.5%     94.5%
p 0.6666665 0.07856691 0.5411014 0.7922316</code></pre>
</div>
</div>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># analytical calculation</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fl">24</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">36</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span> <span class="va">x</span> , <span class="va">w</span><span class="op">+</span><span class="fl">1</span> , <span class="va">n</span><span class="op">-</span><span class="va">w</span><span class="op">+</span><span class="fl">1</span> <span class="op">)</span> , from<span class="op">=</span><span class="fl">0</span> , to<span class="op">=</span><span class="fl">1</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># quadratic approximation</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">x</span> , <span class="fl">0.67</span> , <span class="fl">0.078</span> <span class="op">)</span> , lty<span class="op">=</span><span class="fl">2</span> , add<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/increase%20tosses2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This phenomenon, where the quadratic approximation improves with the amount of data, is very common. It’s one of the reasons that so many classical statistical procedures are nervous about small samples: Those procedures use quadratic (or other) approximations that are only known to be safe with infinite data. Often, these approximations are useful with less than infinite data, obviously. But the rate of improvement as sample size increases varies greatly depending upon the details. In some model types, the quadratic approximation can remain terrible even with thousands of samples.</p>
<p><strong><em>Maximum likelihood estimation:</em></strong> The quadratic approximation, either with a uniform prior or with a lot of data, is usually equivalent to a maximum likelihood estimate (MLE) and its standard error. The MLE is a very common non-Bayesian parameter estimate. This equivalence between a Bayesian approximation and a common non-Bayesian estimator is both a blessing and a curse. It is a blessing, because it allows us to re-interpret a wide range of published non-Bayesian model fits in Bayesian terms. It is a curse, because maximum likelihood estimates have some curious drawbacks.</p>
<p><br></p>
</section><section id="markov-chain-monte-carlo" class="level3"><h3 class="anchored" data-anchor-id="markov-chain-monte-carlo">Markov chain Monte Carlo</h3>
<p>The conceptual challenge with MCMC lies in its highly non-obvious strategy. Instead of attempting to compute or approximate the posterior distribution directly, MCMC techniques merely draw samples from the posterior. You end up with a collection of parameter values, and the frequencies of these values correspond to the posterior plausibilities. You can then build a picture of the posterior from the histogram of these samples.</p>
<p>We nearly always work directly with these samples, rather than first constructing some mathematical estimate from them. And the samples are in many ways more convenient than having the posterior, because they are easier to think with.</p>
<p><br></p>
</section></section><section id="practice" class="level2"><h2 class="anchored" data-anchor-id="practice">Practice</h2>
<section id="easy" class="level3"><h3 class="anchored" data-anchor-id="easy">Easy</h3>
<p>2E1. (2), (4)</p>
<p>2E2. (3)</p>
<p>2E3. (1), (4)</p>
<p>2E4. In the context of the globe tossing example, “the probability of water is 0.7” means we estimates there is 70% chance of landing on water in the next toss, based on the observed data (the previous tosses). We may as well say 70% of the earth is water. This is a probability, but the “probability does not exist-” our best guess is 70% of earth is water based on previously observed data, but it may or may not reflect reality. If the next toss fell on land, the probability of water would be less than 70% for the subsequent toss. We can get a consistent probability of water after enough tosses, but we cannot say for sure this is the actual distribution of water on earth. Therefore, it remains as a probability. Once we have a concrete measurement of actual percentage of earth covered by water, it becomes an objective reality- a factual statement. At that point, the need for probability ceases.</p>
<p><br></p>
</section><section id="medium" class="level3"><h3 class="anchored" data-anchor-id="medium">Medium</h3>
<p>2M1.</p>
<p><span style="color: blue"><em>(1) W, W, W</em></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>  </span>
<span><span class="co"># choose 100 coz chapter says not much difference after 100</span></span>
<span></span>
<span><span class="co"># define a uniform prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">100</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># calculate likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">3</span>, size <span class="op">=</span> <span class="fl">3</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"100 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/2M11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color: blue"><em>(2) W, W, W, L</em></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a uniform prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">100</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># calculate likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">3</span>, size <span class="op">=</span> <span class="fl">4</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"100 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/2M12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color: blue"><em>(3) L, W, W, L, W, W, W</em></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a uniform prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">100</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># calculate likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">5</span>, size <span class="op">=</span> <span class="fl">7</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"100 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/2M13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>2M2. Assume a prior for p that is equal to zero when p &lt; 0.5 and is a positive constant when p ≥ 0.5.</p>
</blockquote>
<p><span style="color: blue"><em>(1) W, W, W</em></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>  </span>
<span></span>
<span><span class="co"># define a  prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&lt;</span> <span class="fl">0.5</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># calculate likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">3</span>, size <span class="op">=</span> <span class="fl">3</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"100 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/2M21-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color: blue"><em>(2) W, W, W, L</em></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&lt;</span> <span class="fl">0.5</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>  </span>
<span></span>
<span><span class="co"># calculate likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">3</span>, size <span class="op">=</span> <span class="fl">4</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"100 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/2M22-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color: blue"><em>(3) L, W, W, L, W, W, W</em></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define a grid</span></span>
<span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># define a prior</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&lt;</span> <span class="fl">0.5</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># calculate likelihood</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">5</span>, size <span class="op">=</span> <span class="fl">7</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># calculate unstandardized posterior</span></span>
<span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="co"># standardize the posterior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the posterior distribution</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>    xlab <span class="op">=</span> <span class="st">"probability of water"</span>, ylab <span class="op">=</span> <span class="st">"posterior distribution"</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"100 points"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/2M23-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>2M3. Suppose there are two globes, one for Earth and one for Mars. The Earth globe is 70% covered in water. The Mars globe is 100% land. Further suppose that one of these globes—you don’t know which—was tossed in the air and produced a “land” observation. Assume that each globe was equally likely to be tossed. Show that the posterior probability that the globe was the Earth, conditional on seeing “land” (Pr(Earth|land)), is 0.23.</p>
</blockquote>
<pre><code>
# Probability land on earth, given that 70% of earth is water
Pr(land|earth) = 0.3

# Probability of land on mars
Pr(land|mars) = 1 

# Probability that earth is tossed
Pr(earth) = 0.5

# Probability that mars is tossed
Pr(mars) = 0.5

# Probability that it is both land and earth
Pr(land, earth) = Pr(land|earth) * Pr(earth)
                = 0.3 * 0.5
                = 0.15

# Probability that it is both land and mars
Pr(land, mars) = Pr(land|mars) * Pr(mars)
               = 1 * 0.5
               = 0.5

# Total probability of land in all possible scenarios (both on earth and mars)
Pr(land) = Pr(land, earth) + Pr(land, mars)
         = 0.15 + 0.5
         = 0.65

# Find the probability of earth, conditional on seeing land
Pr(earth|land) = (Pr(land|earth) * Pr(earth))/ Pr(land)
               = (0.3 * 0.5)/ 0.65
               = 0.2307692
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>2M4. Suppose you have a deck with only three cards. Each card has two sides, and each side is either black or white. One card has two black sides. The second card has one black and one white side. The third card has two white sides. Now suppose all three cards are placed in a bag and shuffled. Someone reaches into the bag and pulls out a card and places it flat on a table. A black side is shown facing up, but you don’t know the color of the side facing down. Show that the probability that the other side is also black is 2/3. Use the counting method (Section 2 of the chapter) to approach this problem. This means counting up the ways that each card could produce the observed data (a black side facing up on the table).</p>
</blockquote>
<pre><code># First card has two black sides
C1 &lt;- b,b

# Second card has one black and one white side
C2 &lt;- b,w

# Third card has two white sides
C3 &lt;- w,w

# Possible conjectures 
conjectures &lt;- (b,b), (b,w), (w,w)

# One card is drawn with black side facing up
data &lt;- b

# Count the possible ways to have the observe data for each conjecture (data: b)
(b,b) -&gt; 2  
(b,w) -&gt; 1
(w,w) -&gt; 0
total ways to see a black side up -&gt; 3

# Count the possible ways that the other side is also black (data: b,b)
(b,b) -&gt; 2 x 1 -&gt; 2
(b,w) -&gt; 1 x 0 -&gt; 0
(w,w) -&gt; 0 x 0 -&gt; 0
total ways to see another side also black -&gt; 2

# Possible ways to get both side black
(b,b) -&gt; total ways to see another side also black / total ways to see a black side up
      -&gt; 2/3
      
</code></pre>
<p><span style="color:blue"><strong><em>If we calculate probability as shown in chapter 2</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">ways</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">ways</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">ways</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6666667 0.3333333 0.0000000</code></pre>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>2M5. Now suppose there are four cards: B/B, B/W, W/W, and another B/B. Again suppose a card is drawn from the bag and a black side appears face up. Again calculate the probability that the other side is black.</p>
</blockquote>
<pre><code># Possible conjectures
conjectures: (B/B), (B/W), (W/W), (B/B)

# First observation
data: B

# Possible ways to get the observed data for each conjecture
(B/B) -&gt; 2
(B/W) -&gt; 1
(W/W) -&gt; 0
(B/B) -&gt; 2
Total ways to get initial black side -&gt; 5

# Probability to see black on second observation (data: B/B)
(B/B) -&gt; 2 x 1 = 2
(B/W) -&gt; 1 x 0 = 0
(W/W) -&gt; 0 x 0 = 0
(B/B) -&gt; 2 x 1 = 2
Total ways to get another black side -&gt; 4

Hence, the probability of getting a card with both sides black by counting method is 4/5. 
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>2M6. Imagine that black ink is heavy, and so cards with black sides are heavier than cards with white sides. As a result, it’s less likely that a card with black sides is pulled from the bag. So again assume there are three cards: B/B, B/W, and W/W. After experimenting a number of times, you conclude that for every way to pull the B/B card from the bag, there are 2 ways to pull the B/W card and 3 ways to pull the W/W card. Again suppose that a card is pulled and a black side appears face up. Show that the probability the other side is black is now 0.5. Use the counting method, as before.</p>
</blockquote>
<pre><code># Possible conjectures
conjectures : (B/B), (B/W), (W/W)

# New information
Pr(B/B) &lt; Pr(B/W) &lt; Pr(W/W)
1 (B/B) = 2 (B/W) + 3 (W/W)

# Likelihood of drawing each card
(B/B) -&gt; 1
(B/W) -&gt; 2
(W/W) -&gt; 3

# Count the possible ways to get data (B)
(B/B) -&gt; 2 x 1 = 2
(B/W) -&gt; 1 x 2 = 2
(W/W) -&gt; 0 x 3 = 0
Total counts of way to get initial B = 4

# Count the possible ways to get data (B/B)
(B/B) -&gt; 2 x 1 = 2
(B/W) -&gt; 2 x 0 = 0
(W/W) -&gt; 0 x 0 = 0
Total counts of way to get B/B = 2

Probability the other side is also black = 2/4 = 0.5
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>2M7. Assume again the original card problem, with a single card showing a black side face up.Before looking at the other side, we draw another card from the bag and lay it face up on the table. The face that is shown on the new card is white. Show that the probability that the first card, the one showing a black side, has black on its other side is now 0.75. Use the counting method, if you can. Hint: Treat this like the sequence of globe tosses, counting all the ways to see each observation, for each possible first card.</p>
</blockquote>
<pre><code># Possible conjectures
conjectures: (B/B), (B/W), (W/W)

# Count the possible ways to get data (B)
(B/B) -&gt; 2 
(B/W) -&gt; 1 
(W/W) -&gt; 0 

# Count the possible ways to get data (W)
(B/B) -&gt; 0
(B/W) -&gt; 1 
(W/W) -&gt; 2 

# Count the possible ways to get data (B/x, W/x)
(B/B) , (B/W) -&gt; 2 x 1 = 2
(B/B) , (W/W) -&gt; 2 x 2 = 4
(B/W) , (B/B) -&gt; 1 x 0 = 0
(B/W) , (W/W) -&gt; 1 x 2 = 2
Total counts of ways to get data (B/x, W/x) = 8

# Count the possible ways to get data (B/B, W/x)
(B/B) , (B/W) -&gt; 2 x 1 = 2
(B/B) , (W/W) -&gt; 4 x 1 = 4
(B/W) , (B/B) -&gt; 0 x 0 = 0
(B/W) , (W/W) -&gt; 2 x 0 = 0
Total counts of ways to get data (B/B, W/x) = 6

Probability that the first card has both black sides = 6/8 = 0.75
</code></pre>
<p><br></p>
</section><section id="hard" class="level3"><h3 class="anchored" data-anchor-id="hard">Hard</h3>
<blockquote class="blockquote">
<p>2H1. Suppose there are two species of panda bear. Both are equally common in the wild and live in the same places. They look exactly alike and eat the same food, and there is yet no genetic assay capable of telling them apart. They differ however in their family sizes. Species A gives birth to twins 10% of the time, otherwise birthing a single infant. Species B births twins 20% of the time, otherwise birthing singleton infants. Assume these numbers are known with certainty, from many years of field research. Now suppose you are managing a captive panda breeding program. You have a new female panda of unknown species, and she has just given birth to twins. What is the probability that her next birth will also be twins?</p>
</blockquote>
<pre><code># Probability of species A gives birth to twins
Pr(twin|SpA) = 0.1

# Probability of species B gives birth to twins
Pr(twin|SpB) = 0.2

# Probability that the new female panda belongs to species A or species B
Pr(SpA) = 0.5
Pr(SpB) = 0.5

# Total probability of having twins (average likelihood)
Pr(twins) = (Pr(twins|SpA) * Pr(SpA)) + (Pr(twins|SpB) * Pr(SpB))
          = (0.1 * 0.5) + (0.2 * 0.5)
          = 0.15
          
# Total probability of having two set of twins (average likelihood)
Pr(2twins) = (Pr(2twins|SpA) * Pr(SpA)) + (Pr(2twins|SpB) * Pr(SpB))
          = (0.01 * 0.5) + (0.04 * 0.5)
          = 0.025

# Probability of having another set of twins given that the first set is twin, regardless of species
Pr (second_twins|first_twins) = Pr(first_twins, second_twins)/ Pr(twins)
                              = Pr(2twins)/ Pr(twins)
                              = 0.025/ 0.15 
                              = 0.1666667
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>2H2. Recall all the facts from the problem above. Now compute the probability that the panda we have is from species A, assuming we have observed only the first birth and that it was twins.</p>
</blockquote>
<pre><code># Probability of panda from species A giving birth to twins
Pr(twins|SpA) = 0.1
Pr(twin|SpB)  = 0.2

# Probability that the new female panda belongs to species A or species B
Pr(SpA) = 0.5
Pr(SpB) = 0.5

# Total probability of having twins (average likelihood)
Pr(twins) = (Pr(twins|SpA) * Pr(SpA)) + (Pr(twins|SpB) * Pr(SpB))
          = (0.1 * 0.5) + (0.2 * 0.5)
          = 0.15

# Probability that panda is from species A after observing first birth of twins
Pr(SpA|twins) = (Pr(twins|SpA) * Pr(SpA))/ Pr(twins)
              = (0.1 * 0.5)/ 0.15
              = 0.3333333
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>2H3. Continuing on from the previous problem, suppose the same panda mother has a second birth and that it is not twins, but a singleton infant. Compute the posterior probability that this panda is species A.</p>
</blockquote>
<pre><code># Probability that the new female panda belongs to species A or species B
Pr(SpA) = 0.5
Pr(SpB) = 0.5

# Probability of panda from species A and B giving birth to twins
Pr(twins|SpA) = 0.1
Pr(twin|SpB)  = 0.2

# Probability of panda from species A and B giving birth to singleton
Pr(singleton|SpA) = 0.9
Pr(singleton|SpB) = 0.8

# Probability of panda from species A and B having a twin and a singleton 
Pr(singleton, twins|SpA) = 0.1 * 0.9 = 0.09
Pr(singleton, twins|SpB) = 0.2 * 0.8 = 0.16

# Total probability of having a twin and a singleton (average likelihood)
Pr(singleton, twins) = (Pr(singleton, twins|SpA) * Pr(SpA)) + (Pr(singleton, twins|SpB) * Pr(SpB))
                     = (0.09 * 0.5) + (0.16 * 0.5)
                     = 0.125

# Probability that the new panda is from species A given the birth of a singleton and a twins
Pr(SpA|sigleton, twins) = (Pr(singleton, twins|SpA) * Pr(SpA))/ Pr(singleton, twins)
                        = (0.09 * 0.5)/ 0.125
                        = 0.36

OR

# Probability of the new panda is from species A or B after the first birth of twins
Pr(SpA) = 0.33
Pr(SpB) = 0.67

# Probability of panda from species A and B giving birth to singleton
Pr(singleton|SpA) = 0.9
Pr(singleton|SpB) = 0.8

# Total probability of having singleton after the first birth of twins (average likelihood)
Pr(singleton) = (Pr(singleton|SpA) * Pr(SpA)) + (Pr(singleton|SpB) * Pr(SpB))
              = (0.9 * 0.33) + (0.8 * 0.67)
              = 0.833

# Probability that the new panda is from species A given the second birth of a singleton
Pr(SpA|singleton) = (Pr(singleton|SpA) * Pr(SpA))/ Pr(singleton)
                  = (0.9 * 0.33)/ 0.833
                  = 0.3565426
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>2H4. A common boast of Bayesian statisticians is that Bayesian inference makes it easy to use all of the data, even if the data are of different types. So suppose now that a veterinarian comes along who has a new genetic test that she claims can identify the species of our mother panda. But the test, like all tests, is imperfect. This is the information you have about the test: • The probability it correctly identifies a species A panda is 0.8. • The probability it correctly identifies a species B panda is 0.65. The vet administers the test to your panda and tells you that the test is positive for species A. First ignore your previous information from the births and compute the posterior probability that your panda is species A. Then redo your calculation, now using the birth data as well.</p>
</blockquote>
<pre><code>
# Without using birth data
# Initital probability of speacies A and B
Pr(SpA) = 0.5
Pr(SpB) = 0.5

# Probability that the test correctly identifies a species A or B panda
Pr(correct_A|SpA) = 0.8
Pr(correct_B|SpB) = 0.65

# Probability that the test wrongly identifies a species A or B panda
Pr(wrong_A|SpA) = 0.2
Pr(wrong_B|SpB) = 0.35

# Total probability that the test correctly identifies species A (average likelihood)
Pr(correct_A) = (Pr(correct_A|SpA) * Pr(SpA)) + (Pr(wrong_B|SpB) * Pr(SpB))
              = (0.8 * 0.5) + (0.35 * 0.5)
              = 0.575
              
# Probability that the panda is from species A, given the correct test result
Pr(SpA|correct_A) = (Pr(correct_A|SpA) * Pr(SpA))/ Pr(correct_A)
                  = (0.8 * 0.5)/ 0.575
                  = 0.6956522

# Using birth data
# Probability that the test correctly identifies a species A or B panda
Pr(correct_A|SpA) = 0.8
Pr(correct_B|SpB) = 0.65

# Probability that the test wrongly identifies a species A or B panda
Pr(wrong_A|SpA) = 0.2
Pr(wrong_B|SpB) = 0.35

# Prior probability of species A and B
Pr(SpA) = 0.36
Pr(SpB) = 0.64

# Total probability that the test correctly identifies species A (average likelihood)
Pr(correct_A) = (Pr(correct_A|SpA) * Pr(SpA)) + (Pr(wrong_B|SpB) * Pr(SpB))
              = (0.8 * 0.36) + (0.35 * 0.64)
              = 0.512

# Probability that the panda is from species A, given the test result
Pr(SpA|correct_A) = (Pr(correct_A|SpA) * Pr(SpA))/ Pr(correct_A)
                  = (0.8 * 0.36)/ 0.512
                  = 0.5625
</code></pre>
<p><br></p>
</section></section></section><section id="chapter-3-sampling-the-imaginary" class="level1"><h1>Chapter 3: Sampling the Imaginary</h1>
<p><br></p>
<section id="sampling-from-a-grid-approximate-posterior" class="level2"><h2 class="anchored" data-anchor-id="sampling-from-a-grid-approximate-posterior">Sampling from a grid-approximate posterior</h2>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Compute the posterior for the globe tossing model, using grid approximation</strong></span></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/sampling_from_grid-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Draw the samples</strong></span></span></p>
<p>Now we wish to draw 10,000 samples from this posterior. Imagine the posterior is a bucket full of parameter values, numbers such as 0.1, 0.7, 0.5, 1, etc. Within the bucket, each value exists in proportion to its posterior probability, such that values near the peak are much more common than those in the tails. We’re going to scoop out 10,000 values from the bucket. Provided the bucket is well mixed, the resulting samples will have the same proportions as the exact posterior density. Therefore the individual values of p will appear in our samples in proportion to the posterior plausibility of each value.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, prob <span class="op">=</span> <span class="va">posterior</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">samples</span>, xlab<span class="op">=</span><span class="st">"sample number"</span>, ylab<span class="op">=</span><span class="st">"proportion of water(p)"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/create_sample-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The workhorse here is sample, which randomly pulls values from a vector. </span></span>
<span><span class="co"># The vector in this case is p_grid, the grid of parameter values. </span></span>
<span><span class="co"># The probability of each value is given by posterior, which you computed just above.</span></span>
<span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">samples</span>, xlab<span class="op">=</span> <span class="st">"proportion of water(p)"</span>, ylab<span class="op">=</span> <span class="st">"Density"</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/create_sample-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># show density estimate computed from the samples</span></span>
<span><span class="co"># You can see that the estimated density is very similar to ideal posterior you computed </span></span>
<span><span class="co"># via grid approximation.</span></span>
<span></span>
<span><span class="co"># Draw more samples</span></span>
<span><span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, prob <span class="op">=</span> <span class="va">posterior</span>, size <span class="op">=</span> <span class="fl">1e6</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">samples</span>, xlab<span class="op">=</span><span class="st">"sample number"</span>, ylab<span class="op">=</span><span class="st">"proportion of water(p)"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/create_sample-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">dens</span><span class="op">(</span><span class="va">samples</span>, xlab<span class="op">=</span> <span class="st">"proportion of water(p)"</span>, ylab<span class="op">=</span> <span class="st">"Density"</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/create_sample-4.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># If you draw even more samples, maybe 1e5 or 1e6, the density estimate will get more </span></span>
<span><span class="co"># and more similar to the ideal.</span></span>
<span><span class="co"># All you’ve done so far is crudely replicate the posterior density you had already computed.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="sampling-to-summarize" class="level2"><h2 class="anchored" data-anchor-id="sampling-to-summarize">Sampling to summarize</h2>
<p>It is necessary to summarize and interpret the posterior distribution. Exactly how it is summarized depends upon your purpose. But common questions include:</p>
<p>• How much posterior probability lies below some parameter value?</p>
<p>• How much posterior probability lies between two parameter values?</p>
<p>• Which parameter value marks the lower 5% of the posterior probability?</p>
<p>• Which range of parameter values contains 90% of the posterior probability?</p>
<p>• Which parameter value has highest posterior probability?</p>
<p>These simple questions can be usefully divided into questions about:</p>
<ol type="1">
<li><p>intervals of defined boundaries,</p></li>
<li><p>intervals of defined probability mass, and</p></li>
<li><p>point estimates.</p></li>
</ol>
<p><br></p>
<section id="intervals-of-defined-boundaries" class="level3"><h3 class="anchored" data-anchor-id="intervals-of-defined-boundaries">Intervals of defined boundaries</h3>
<p>Suppose I ask you for the posterior probability that the proportion of water is less than 0.5. Using the grid-approximate posterior, you can just add up all of the probabilities, where the corresponding parameter value is less than 0.5:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># add up posterior probability where p &lt; 0.5</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">posterior</span><span class="op">[</span> <span class="va">p_grid</span> <span class="op">&lt;</span> <span class="fl">0.5</span> <span class="op">]</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1718746</code></pre>
</div>
</div>
<p>So let’s see how to perform the same calculation, using samples from the posterior. This approach does generalize to complex models with many parameters, and so you can use it everywhere. All you have to do is similarly add up all of the samples below 0.5, but also divide the resulting count by the total number of samples. In other words, find the frequency of parameter values below 0.5:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">samples</span> <span class="op">&lt;</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 17.1943</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The answer is the posterior probability below a parameter value of 0.5.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>And that’s nearly the same answer as the grid approximation provided, although your answer will not be exactly the same, because the exact samples you drew from the posterior will be different.</p>
<p>Using the same approach, you can ask how much posterior probability lies between 0.5 and 0.75:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">samples</span> <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="op">&amp;</span> <span class="va">samples</span> <span class="op">&lt;</span> <span class="fl">0.75</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 60.4792</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># So about 61% of the posterior probability lies between 0.5 and 0.75.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><span style="color:brown"><strong><em>Counting with sum</em></strong></span></p>
<p>In the R code examples just above, I used the function sum to effectively count up how many samples fulfill a logical criterion. Why does this work? It works because R internally converts a logical expression, like samples &lt; 0.5, to a vector of TRUE and FALSE results, one for each element of samples, saying whether or not each element matches the criterion.Go ahead and enter samples &lt; 0.5 on the R prompt, to see this for yourself. Then when you sum this vector of TRUE and FALSE, R counts each TRUE as 1 and each FALSE as 0. So it ends up counting how many TRUE values are in the vector, which is the same as the number of elements in samples that match the logical criterion.</p>
<p><br></p>
</section><section id="intervals-of-defined-mass" class="level3"><h3 class="anchored" data-anchor-id="intervals-of-defined-mass">Intervals of defined mass</h3>
<p>It is more common to see scientific journals reporting an interval of defined mass, usually known as a confidence interval. An interval of posterior probability, such as the ones we are working with, may instead be called a credible interval, although the terms may also be used interchangeably.</p>
<p>These posterior intervals report two parameter values that contain between them a specified amount of posterior probability, a probability mass. For this type of interval, it is easier to find the answer by using samples from the posterior than by using a grid approximation.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Suppose for example you want to know the boundaries of the lower 80% posterior probability. </span></span>
<span><span class="co"># You know this interval starts at p = 0. To find out where it stops, think of the samples as data </span></span>
<span><span class="co"># and ask where the 80th percentile lies:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">samples</span>, <span class="fl">0.8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      80% 
0.7607608 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Lower 80% posterior probability exists below a parameter value of about 0.75. </span></span>
<span></span>
<span><span class="co"># For the middle 80% interval lies between the 10th percentile and the 90th percentile.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">samples</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      10%       90% 
0.4484484 0.8118118 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Intervals of this sort are called percentile intervals (PI).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Percentile Intervals (PI)</strong></span></span></p>
<ul>
<li><p>Intervals which assign equal probability mass to each tail</p></li>
<li><p>Do a good job of communicating the shape of a distribution, as long as the distribution isn’t too asymmetrical</p></li>
<li><p>Not perfect for supporting inferences about which parameters are consistent with the data, see the figure and computation below:</p></li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This posterior is consistent with observing three waters in three tosses and a uniform (flat) prior. </span></span>
<span><span class="co"># It is highly skewed, having its maximum value at the boundary, p = 1. </span></span>
<span><span class="co"># You can compute it, via grid approximation, with:</span></span>
<span></span>
<span><span class="co"># Create sample using grid approximation</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">3</span>, size <span class="op">=</span> <span class="fl">3</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">prior</span> <span class="op">*</span> <span class="va">likelihood</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="va">samples2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span> <span class="co"># sample from posterior</span></span>
<span></span>
<span><span class="co"># Compute the 50% percentile confidence interval from the samples with PI (part of rethinking)</span></span>
<span><span class="fu">PI</span><span class="op">(</span><span class="va">samples2</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      25%       75% 
0.7027027 0.9279279 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This interval assigns 25% of the probability mass above and below the interval. </span></span>
<span><span class="co"># So it provides the central 50% probability. But in this example, it ends up excluding </span></span>
<span><span class="co"># the most probable parameter values, near p = 1. So in terms of describing </span></span>
<span><span class="co"># the shape of the posterior distribution—which is really all these intervals are asked to do—</span></span>
<span><span class="co"># the percentile interval can be misleading.</span></span>
<span><span class="va">pi_50</span> <span class="op">&lt;-</span> <span class="fu">PI</span><span class="op">(</span><span class="va">samples2</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a data frame for plotting</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot 50% PI </span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&gt;</span> <span class="va">pi_50</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&amp;</span> <span class="va">p_grid</span> <span class="op">&lt;</span> <span class="va">pi_50</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="st">"purple"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">'50% Percentile interval'</span>,</span>
<span>       x <span class="op">=</span> <span class="st">'proportion of water (p)'</span>,</span>
<span>       y <span class="op">=</span> <span class="st">'density'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/creat_sample2-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb60"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The posterior density here corresponds to a flat prior and observing </span></span>
<span><span class="co"># three water samples in three total tosses of the globe. </span></span>
<span><span class="co"># This interval assigns equal mass (25%) to both the left and right tail. </span></span>
<span><span class="co"># As a result, it omits the most probable parameter value, p = 1.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Highest Posterior Density Interval (HPDI)</strong></span></span></p>
<ul>
<li><p>The narrowest interval containing the specified probability mass</p></li>
<li><p>If you think about it, there must be an infinite number of posterior intervals with the same mass. But if you want an interval that best represents the parameter values most consistent with the data, then you want the densest of these intervals- the HPDI.</p></li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create sample using grid approximation</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">3</span>, size <span class="op">=</span> <span class="fl">3</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">prior</span> <span class="op">*</span> <span class="va">likelihood</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="va">samples2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute it from the samples with HPDI (part of rethinking)</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">samples2</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     |0.5      0.5| 
0.8418418 1.0000000 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This interval captures the parameters with highest posterior probability, </span></span>
<span><span class="co"># as well as being noticeably narrower: </span></span>
<span><span class="co"># 0.16 in width rather than 0.23 for the percentile interval.</span></span>
<span><span class="va">hpdi_50</span> <span class="op">&lt;-</span> <span class="fu">HPDI</span><span class="op">(</span><span class="va">samples2</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a data frame for plotting</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot 50% PI </span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&gt;</span> <span class="va">hpdi_50</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&amp;</span> <span class="va">p_grid</span> <span class="op">&lt;</span> <span class="va">hpdi_50</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="st">"purple"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">'50% Percentile interval'</span>,</span>
<span>       x <span class="op">=</span> <span class="st">'proportion of water (p)'</span>,</span>
<span>       y <span class="op">=</span> <span class="st">'density'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/HPDI_50-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This interval finds the narrowest region with 50% of the posterior probability. </span></span>
<span><span class="co"># Such a region always includes the most probable parameter value.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>HPDI vs.&nbsp;PI</strong></span></span></p>
<ul>
<li><p>The two types of intervals are very similar</p></li>
<li>
<p>HPDI has some advantages over the PI</p>
<ul>
<li>only look so different if the posterior distribution is highly skewed, otherwise nearly identical:</li>
</ul>
</li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare HPDI and PI</span></span>
<span></span>
<span><span class="co"># Create samples using observation six waters in nine tosses</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">6</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">prior</span> <span class="op">*</span> <span class="va">likelihood</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span></span>
<span><span class="va">samples3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute 80% HPDI and PI from samples</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     |0.8      0.8| 
0.4624625 0.8248248 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">PI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      10%       90% 
0.4484484 0.8148148 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb69"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute 95% HPDI and PI from samples</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>    |0.95     0.95| 
0.3713714 0.8948949 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb71"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">PI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       3%       98% 
0.3493493 0.8778779 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb73"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Add name for 80% HPDI and PI</span></span>
<span><span class="va">hpdi_80</span> <span class="op">&lt;-</span> <span class="fu">HPDI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span><span class="va">pi_80</span> <span class="op">&lt;-</span> <span class="fu">PI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a data frame for plotting</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot 80% HPDI and PI on the same graph</span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&gt;</span> <span class="va">hpdi_80</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&amp;</span> <span class="va">p_grid</span> <span class="op">&lt;</span> <span class="va">hpdi_80</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="st">"blue"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&gt;</span> <span class="va">pi_80</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&amp;</span> <span class="va">p_grid</span> <span class="op">&lt;</span> <span class="va">pi_80</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="st">"green"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">'80% HPDI and 80% PI'</span>,</span>
<span>       x <span class="op">=</span> <span class="st">'proportion of water (p)'</span>,</span>
<span>       y <span class="op">=</span> <span class="st">'density'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/HPDI,PI-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb74"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Add name for 95% HPDI and PI </span></span>
<span><span class="va">hpdi_95</span> <span class="op">&lt;-</span> <span class="fu">HPDI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="va">pi_95</span> <span class="op">&lt;-</span> <span class="fu">PI</span><span class="op">(</span><span class="va">samples3</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot 95% HPDI and PI on the same graph</span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&gt;</span> <span class="va">hpdi_95</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&amp;</span> <span class="va">p_grid</span> <span class="op">&lt;</span> <span class="va">hpdi_95</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="st">"brown"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span>data <span class="op">=</span> <span class="va">df</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&gt;</span> <span class="va">pi_95</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">&amp;</span> <span class="va">p_grid</span> <span class="op">&lt;</span> <span class="va">pi_95</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>              <span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>,</span>
<span>              fill <span class="op">=</span> <span class="st">"yellow"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">'95% HPDI and 95% PI'</span>,</span>
<span>       x <span class="op">=</span> <span class="st">'proportion of water (p)'</span>,</span>
<span>       y <span class="op">=</span> <span class="st">'density'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/HPDI,PI-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb75"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span> <span class="co"># When the posterior is bell shaped, it hardly matters which type of interval you use.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li>HPDI also has some disadvantages
<ul>
<li>HPDI is more computationally intensive than PI</li>
<li>HPDI suffers from greater simulation variance (it is sensitive to how many samples you draw from the posterior.)</li>
</ul>
</li>
</ul>
<pre><code>Overall, if the choice of interval type makes a big difference, then you shouldn’t be using intervals 
to summarize the posterior. Remember, the entire posterior distribution is the Bayesian estimate. It summarizes the relative plausibilities of each possible value of the parameter. Intervals of the 
distribution are just helpful for summarizing it. If choice of interval leads to different 
inferences, then you’d be better off just plotting the entire posterior distribution.
</code></pre>
<p><br></p>
</section><section id="point-estimates" class="level3"><h3 class="anchored" data-anchor-id="point-estimates">Point estimates</h3>
<p>The Bayesian parameter estimate is precisely the entire posterior distribution, which is not a single number, but instead a function that maps each unique parameter value onto a plausibility value. So really the most important thing to note is that you don’t have to choose a point estimate. It’s hardly ever necessary.</p>
<p><span style="color:brown"><strong><em>Which point estimate to choose if we must report: Mean, Median or Mode (MAP)?</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb77"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Use the globe tossing example where 3 water observations out of 3 tosses</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">3</span>, size <span class="op">=</span> <span class="fl">3</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">prior</span> <span class="op">*</span> <span class="va">likelihood</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="va">samples2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute the MAP from posterior</span></span>
<span><span class="co"># It is very common for scientists to report the parameter value with highest </span></span>
<span><span class="co"># posterior probability, a maximum a posteriori (MAP) estimate.</span></span>
<span><span class="va">p_grid</span><span class="op">[</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span> <span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb79"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute MAP using samples from posterior</span></span>
<span><span class="fu">chainmode</span><span class="op">(</span> <span class="va">samples2</span>, adj <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span> <span class="co"># rethinking</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9679314</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb81"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">map_value</span> <span class="op">&lt;-</span> <span class="va">p_grid</span><span class="op">[</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span> <span class="op">]</span></span>
<span></span>
<span><span class="co"># mean of the samples</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">samples2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8004773</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb83"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mean_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">samples2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># median of the samples</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">samples2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8418418</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb85"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">median_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">samples2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a data frame for plotting</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot with lines for mean, median, and mode</span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span>, y <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">"yellow"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">map_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">mean_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">median_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">map_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">map_value</span>, <span class="fl">2</span><span class="op">)</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">mean_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">mean_value</span>, <span class="fl">2</span><span class="op">)</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">median_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">median_value</span>, <span class="fl">2</span><span class="op">)</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">map_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"mode"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">mean_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"mean"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">median_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"median"</span>,</span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">'Posterior with Mean, Median, and Mode (MAP)'</span>,</span>
<span>       x <span class="op">=</span> <span class="st">'proportion of water (p)'</span>,</span>
<span>       y <span class="op">=</span> <span class="st">'density'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/point_estimate-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The value for median, mean, and mode (MAP) are different. In this case, <strong><em>use a loss function to estimate the cost associated with using any particular point estimate.</em></strong></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Using loss function</strong></span></span></p>
<ul>
<li><p>Different loss functions imply different point estimates</p></li>
<li>
<p>The loss is proportional to the distance of your decision from the true value</p>
<ul>
<li>Loss <span class="math inline">\(\propto\)</span> d - p, where d is the decision and p is the correct answer or true value</li>
</ul>
</li>
</ul>
<ul>
<li><p>The parameter value that maximizes expected winnings (minimizes expected loss) is the median of the posterior distribution</p></li>
<li><p>Calculating expected loss for any given decision means using the posterior to average over our uncertainty in the true value (unknown in most cases)</p></li>
</ul>
<pre><code>In order to decide upon a point estimate, a single-value summary of the posterior distribution, we need 
to pick a loss function. Different loss functions nominate different point estimates. The two most 
common examples are the absolute loss (d - p), which leads to the median as the point estimate, and the quadratic loss (d − p)2, which leads to the posterior mean (mean(samples)) as the point estimate. When 
the posterior distribution is symmetrical and normal-looking, then the median and mean converge to the same point.
</code></pre>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb87"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># If our decision is p = 0.5,</span></span>
<span><span class="co"># compute the weighted average loss, where each loss is weighted by its </span></span>
<span><span class="co"># corresponding posterior probability</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fl">0.5</span> <span class="op">-</span> <span class="va">p_grid</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3128752</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb89"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># repeating this calculation for every possible decision, using the function sapply</span></span>
<span><span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">p_grid</span> , <span class="kw">function</span><span class="op">(</span><span class="va">d</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">posterior</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span> <span class="va">d</span> <span class="op">-</span> <span class="va">p_grid</span> <span class="op">)</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="co"># Now the symbol loss contains a list of loss values, one for each possible </span></span>
<span><span class="co"># decision, corresponding the values in p_grid</span></span>
<span></span>
<span><span class="co"># Find the parameter value that minimizes the loss</span></span>
<span><span class="va">p_grid</span><span class="op">[</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">loss</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8408408</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb91"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># And this is actually the posterior median, the parameter value that splits </span></span>
<span><span class="co"># the posterior density such that half of the mass is above it </span></span>
<span><span class="co"># and half below it</span></span>
<span></span>
<span><span class="co"># Check with posterior median</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">samples2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8418418</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb93"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The answer match with the value that minimizes the loss</span></span>
<span></span>
<span><span class="co"># Plot the loss function</span></span>
<span><span class="co"># Find x, y values for minimum loss</span></span>
<span><span class="va">min_loss_x</span> <span class="op">&lt;-</span> <span class="va">p_grid</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">loss</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">min_loss_y</span> <span class="op">&lt;-</span> <span class="va">loss</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">loss</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Create data frame and plot </span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">loss</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">loss</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">'grey75'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">min_loss_x</span>, y <span class="op">=</span> <span class="va">min_loss_y</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">3</span>, shape <span class="op">=</span> <span class="fl">21</span>, color <span class="op">=</span> <span class="st">'black'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">map_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">mean_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">median_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">map_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"mode"</span>, </span>
<span>            vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">mean_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"mean"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">median_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"median"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">min_loss_x</span>, y <span class="op">=</span> <span class="va">min_loss_y</span>, label <span class="op">=</span> <span class="st">"value that \nminimizes loss"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="fl">1.2</span>, hjust <span class="op">=</span> <span class="fl">0.5</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">'decision'</span>,</span>
<span>       y <span class="op">=</span> <span class="st">'expected proportional loss'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/loss-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb94"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Expected loss under the rule that loss is proportional to absolute distance </span></span>
<span><span class="co"># of decision (horizontal axis) from the true value. The point marks the value </span></span>
<span><span class="co"># of p that minimizes the expected loss, the posterior median.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="sampling-to-simulate-prediction" class="level2"><h2 class="anchored" data-anchor-id="sampling-to-simulate-prediction">Sampling to simulate prediction</h2>
<p>Samples from posterior ease simulation of the model’s implied observations. Generating implied observations from a model is useful for at least four distinct reasons.</p>
<ol type="1">
<li><p>Model checking- to check whether the fit worked correctly and to investigate model behavior</p></li>
<li><p>Software validation- simulate observations under a known model and then attempt to recover the values of the parameters the data were simulated under</p></li>
<li><p>Research design- simulate observations from hypothesis to evaluate whether the research design can be effective</p></li>
<li><p>Forecasting- can be useful as applied prediction, but also for model criticism and revision</p></li>
</ol>
<p><br></p>
<section id="dummy-data-simulated-data" class="level3"><h3 class="anchored" data-anchor-id="dummy-data-simulated-data">Dummy data (simulated data)</h3>
<p>Likelihood functions work in both directions. Given a realized observation, the likelihood function says how plausible the observation is. And given only the parameters, the likelihood defines a distribution of possible observations that we can sample from, to simulate observation. In this way, Bayesian models are always generative, capable of simulating predictions.</p>
<p>With the globe tossing model, the dummy data arises from a binomial likelihood:</p>
<p>Pr(w|n,p) = <span class="math inline">\(\frac{n!}{w!(n - w)!}\)</span>p<sup>w</sup> (1 - p)<sup>n-w</sup></p>
<p>where w is an observed count of “water” and n is the number of tosses. Suppose n = 2, two tosses of the globe. Then there are only three possible observations: 0 water, 1 water, 2 water. You can quickly compute the likelihood of each, for any given value of p.&nbsp;Let’s use p = 0.7, which is just about the true proportion of water on the Earth:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb95"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">2</span>, size <span class="op">=</span> <span class="fl">2</span>, prob <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.09 0.42 0.49</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb97"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 9% chance of observing w = 0, a 42% chance of w = 1, and a 49% chance of w = 2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we’re going to simulate observations, using these likelihoods. So a single dummy data observation of w can be sampled with:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb98"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1</span>, size <span class="op">=</span> <span class="fl">2</span>, prob <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
<p>The “r” in rbinom stands for “random.” It can also generate more than one simulation at a time. A set of 10 simulations can be made by:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb100"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">10</span>, size <span class="op">=</span> <span class="fl">2</span>, prob <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] 2 1 1 2 1 2 1 2 2 1</code></pre>
</div>
</div>
<p>Let’s generate 100,000 dummy observations, just to verify that each value (0, 1, or 2) appears in proportion to its likelihood:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb102"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">dummy_w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e5</span>, size <span class="op">=</span> <span class="fl">2</span>, prob <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">dummy_w</span><span class="op">)</span> <span class="op">/</span><span class="fl">1e5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>dummy_w
      0       1       2 
0.08999 0.42250 0.48751 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb104"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># values are very close to the likelihood values calculated above</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now let’s simulate the same sample size as before, 9 tosses.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb105"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">dummy_w_9</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e5</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">dummy_w_9</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>dummy_w_9
      0       1       2       3       4       5       6       7       8       9 
0.00003 0.00036 0.00366 0.02126 0.07359 0.16986 0.26792 0.26880 0.15568 0.03884 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb107"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">simplehist</span><span class="op">(</span><span class="va">dummy_w_9</span>, xlab <span class="op">=</span> <span class="st">"dummy water count"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/9tosses-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb108"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Distribution of simulated sample observations from 9 tosses of the globe. </span></span>
<span><span class="co"># These samples assume the proportion of water is 0.7.</span></span>
<span><span class="co"># Notice that most of the time the expected observation does not contain water </span></span>
<span><span class="co"># in its true proportion, 0.7. That’s the nature of observation: There is a </span></span>
<span><span class="co"># one-to-many relationship between data and data-generating processes.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Test with sample size = 40 and probability p = 0.5</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb109"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">dummy_w_40</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e5</span>, size <span class="op">=</span> <span class="fl">40</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu">simplehist</span><span class="op">(</span><span class="va">dummy_w_40</span>, xlab <span class="op">=</span> <span class="st">"dummy water count"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/40tosses-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Sampling distribution</strong></span></span></p>
<p>In this book, inference about parameters is never done directly through a sampling distribution. The posterior distribution is not sampled, but deduced logically. Then samples can be drawn from the posterior, to aid in inference. In neither case is “sampling” a physical act. In both cases, it’s just a mathematical device and produces only small world numbers.</p>
<p><br></p>
</section><section id="model-checking" class="level3"><h3 class="anchored" data-anchor-id="model-checking">Model checking</h3>
<ul>
<li><p>Ensures the model fitting worked correctly</p></li>
<li><p>Evaluate the adequacy of a model for some purpose</p></li>
</ul>
<p><br></p>
<section id="did-the-software-work" class="level4"><h4 class="anchored" data-anchor-id="did-the-software-work">Did the software work?</h4>
<ul>
<li><p>Use retrodictions (implied predictions) to check whether the software worked- by checking for correspondence between implied predictions and the data used to fit the model</p></li>
<li><p>An exact match is neither expected nor desired, but when there is no correspondence at all, it probably means the software did something wrong.</p></li>
<li><p>There is no way to really be sure that software works correctly. Even when the retrodictions correspond to the observed data, there may be subtle mistakes.</p></li>
</ul>
<p><br></p>
</section><section id="is-the-model-adequate" class="level4"><h4 class="anchored" data-anchor-id="is-the-model-adequate">Is the model adequate?</h4>
<ul>
<li><p>Look for aspects of the data that are not well described by the model’s expectations</p></li>
<li><p>The goal is not to test whether the model’s assumptions are “true,” because all models are false</p></li>
<li><p>The goal is to assess exactly how the model fails to describe the data, as a path towards model comprehension, revision, and improvement</p></li>
</ul>
<p><span style="color:brown"><strong><em>Basic model checks using simulated observations for the globe tossing model</em></strong></span></p>
<p>The implied predictions of the model are uncertain in two ways, and we’d like to propagate the parameter uncertainty as we evaluate the implied predictions, i.e.&nbsp;get a posterior predictive distribution.</p>
<ul>
<li>Observation uncertainty
<ul>
<li>There is uncertainty in the predicted observations, because even if you know p with certainty, you won’t know the next globe toss with certainty (unless p = 0 or p = 1).</li>
</ul>
</li>
</ul>
<ul>
<li>Uncertainty about p
<ul>
<li>Since there is uncertainty about p, there is uncertainty about everything that depends upon p.</li>
<li>The uncertainty in p will interact with the sampling variation, when we try to assess what the model tells us about outcomes.</li>
</ul>
</li>
</ul>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Posterior predictive distribution</strong></span></span></p>
<p>For each possible value of the parameter p, there is an implied distribution of outcomes. So if you were to compute the sampling distribution of outcomes at each value of p, then you could average all of these prediction distributions together, using the posterior probabilities of each value of p, to get a posterior predictive distribution.</p>
<ul>
<li><p>The sampling distributions for all values of p are combined, using the posterior probabilities to compute the weighted average frequency of each possible observation.</p></li>
<li><p>It incorporates all of the uncertainty embodied in the posterior distribution for the parameter p.&nbsp;As a result, it is honest- the distribution may be narrower (overconfidence) if we discard uncertainty about the parameters.</p></li>
</ul>
<p><span style="color:purple"><strong><em>Calculate posterior predictive distribution</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb110"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># To simulate predicted observations for a single value of p, say p = 0.6, </span></span>
<span><span class="co"># you can use rbinom to generate random binomial samples:</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span></span>
<span><span class="fu">simplehist</span><span class="op">(</span><span class="va">w</span>, xlab <span class="op">=</span> <span class="st">"number of water samples"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/PPD-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb111"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># All you need to propagate parameter uncertainty into these predictions is </span></span>
<span><span class="co"># replace the value 0.6 with samples from the posterior:</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">samples</span><span class="op">)</span></span>
<span><span class="fu">simplehist</span><span class="op">(</span><span class="va">w</span>, xlab <span class="op">=</span> <span class="st">"number of water samples"</span>, main <span class="op">=</span> <span class="st">"PPD"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/PPD-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb112"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># For each sampled value, a random binomial observation is generated. </span></span>
<span><span class="co"># Since the sampled values appear in proportion to their posterior probabilities,</span></span>
<span><span class="co"># the resulting simulated observations are averaged over the posterior. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>In your own modeling, you’ll have to imagine aspects of the data that are relevant in your context, for your purposes, i.e. inspect the data in new ways, e.g. correlation between samples that may be bias. 
</code></pre>
<p><br></p>
</section></section></section><section id="practice-1" class="level2"><h2 class="anchored" data-anchor-id="practice-1">Practice</h2>
<section id="easy-1" class="level3"><h3 class="anchored" data-anchor-id="easy-1">Easy</h3>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb114"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">0</span> , to<span class="op">=</span><span class="fl">1</span> , length.out<span class="op">=</span><span class="fl">10000</span> <span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span> <span class="fl">1</span> , <span class="fl">10000</span> <span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span> <span class="fl">6</span> , size<span class="op">=</span><span class="fl">9</span> , prob<span class="op">=</span><span class="va">p_grid</span> <span class="op">)</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span> <span class="va">p_grid</span> , prob<span class="op">=</span><span class="va">posterior</span> , size<span class="op">=</span><span class="fl">1e4</span> , replace<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<blockquote class="blockquote">
<p>3E1. How much posterior probability lies below p = 0.2?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb115"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">samples</span> <span class="op">&lt;</span> <span class="fl">0.2</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 5e-04</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb117"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 5 x 10^-4^ % of posterior probability lies below p = 0.2.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3E2. How much posterior probability lies above p = 0.8?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb118"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">samples</span> <span class="op">&gt;</span> <span class="fl">0.8</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1219</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb120"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 12% of posterior probability lies between p = 0.2 and p = 0.8</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3E3. How much posterior probability lies between p = 0.2 and p = 0.8?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb121"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">samples</span> <span class="op">&gt;</span> <span class="fl">0.2</span> <span class="op">&amp;</span> <span class="va">samples</span> <span class="op">&lt;</span> <span class="fl">0.8</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8776</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb123"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 88% of posterior probability lies between p = 0.2 and p = 0.8</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3E4. 20% of the posterior probability lies below which value of p?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb124"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">samples</span>, <span class="fl">0.2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      20% 
0.5145315 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb126"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 20% of the posterior probability lies below p = 0.51</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<blockquote class="blockquote">
<p>3E5. 20% of the posterior probability lies above which value of p?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb127"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 20% is the quantile in the upper end of distribution,</span></span>
<span><span class="co"># hence we find quantile value below 80%</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">samples</span>, <span class="fl">0.8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      80% 
0.7618962 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb129"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 20% of the posterior probability lies above p = 0.76</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3E6. Which values of p contain the narrowest interval equal to 66% of the posterior probability?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb130"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">samples</span>, <span class="fl">0.66</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>    |0.66     0.66| 
0.5138514 0.7886789 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb132"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># p interval of 0.5-0.8 contain the narrowest interval equal to 66% of </span></span>
<span><span class="co"># the posterior probability</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3E7. Which values of p contain 66% of the posterior probability, assuming equal posterior probability both below and above the interval?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb133"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">PI</span><span class="op">(</span><span class="va">samples</span>, <span class="fl">0.66</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      17%       83% 
0.4972327 0.7745775 </code></pre>
</div>
</div>
<p><br></p>
</section><section id="medium-1" class="level3"><h3 class="anchored" data-anchor-id="medium-1">Medium</h3>
<blockquote class="blockquote">
<p>3M1. Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb135"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">8</span>, size <span class="op">=</span> <span class="fl">15</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">~</span><span class="va">p_grid</span>, type <span class="op">=</span><span class="st">"l"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3M1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3M2. Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb136"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">8</span>, size <span class="op">=</span> <span class="fl">15</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">101</span><span class="op">)</span></span>
<span><span class="va">sample3m2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate 90% HPDI for p </span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample3m2</span>, <span class="fl">0.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     |0.9      0.9| 
0.3250325 0.7145715 </code></pre>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3M3. Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in p.&nbsp;What is the probability of observing 8 water in 15 tosses?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb138"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">15</span>, prob <span class="op">=</span> <span class="va">sample3m2</span><span class="op">)</span></span>
<span><span class="fu">simplehist</span><span class="op">(</span><span class="va">w</span>, xlab<span class="op">=</span> <span class="st">"number of water observations"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3M3-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb139"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">w</span> <span class="op">==</span> <span class="fl">8</span><span class="op">)</span><span class="op">/</span><span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1442</code></pre>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3M4. Using the posterior distribution constructed from the new (8/15) data,now calculate the probability of observing 6 water in 9 tosses.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb141"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">sample3m2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">w</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>w
     0      1      2      3      4      5      6      7      8      9 
0.0057 0.0293 0.0733 0.1422 0.1941 0.2010 0.1752 0.1169 0.0515 0.0108 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb143"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Probability of 6w in 9n is 18%</span></span>
<span></span>
<span><span class="co"># Generate the answer only</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">w</span> <span class="op">==</span> <span class="fl">6</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
 FALSE   TRUE 
0.8248 0.1752 </code></pre>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3M5. Start over at 3M1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority of the Earth’s surface is water. Repeat each problem above and compare the inferences. What difference does the better prior make? If it helps, compare inferences (using both priors) to the true value p = 0.7.</p>
</blockquote>
<p><em>For 3M1 and 3M3</em></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb145"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Set up a 1x2 layout for side-by-side plots</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># First plot</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">8</span>, size <span class="op">=</span> <span class="fl">15</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">posterior</span> <span class="op">~</span> <span class="va">p_grid</span>, type <span class="op">=</span> <span class="st">"l"</span>, col <span class="op">=</span> <span class="st">"blue"</span>, lty <span class="op">=</span> <span class="fl">1</span>, </span>
<span>     xlab <span class="op">=</span> <span class="st">"Probability of water"</span>, ylab <span class="op">=</span> <span class="st">"Posterior distribution"</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"Prior = 1"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Second plot</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">15</span>, prob <span class="op">=</span> <span class="va">sample3m2</span><span class="op">)</span></span>
<span><span class="fu">simplehist</span><span class="op">(</span><span class="va">w</span>, col <span class="op">=</span> <span class="st">"black"</span>, lty <span class="op">=</span> <span class="fl">1</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"Count of water observations"</span>, ylab <span class="op">=</span> <span class="st">"Frequency"</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"Prior = 1"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3M51-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb146"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Set up a 1x2 layout for side-by-side plots</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Third plot</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">p_grid</span> <span class="op">&lt;</span> <span class="fl">0.5</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">8</span>, size <span class="op">=</span> <span class="fl">15</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">102</span><span class="op">)</span></span>
<span><span class="va">sample3m5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, prob <span class="op">=</span> <span class="va">posterior</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">posterior</span> <span class="op">~</span> <span class="va">p_grid</span>, type <span class="op">=</span> <span class="st">"l"</span>, col <span class="op">=</span> <span class="st">"red"</span>, lty <span class="op">=</span> <span class="fl">1</span>, </span>
<span>     xlab <span class="op">=</span> <span class="st">"Probability of water"</span>, ylab <span class="op">=</span> <span class="st">"Posterior distribution"</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"Prior = 0 or 1"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fourth plot</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">15</span>, prob <span class="op">=</span> <span class="va">sample3m5</span><span class="op">)</span></span>
<span><span class="fu">simplehist</span><span class="op">(</span><span class="va">w</span>, col <span class="op">=</span> <span class="st">"black"</span>, lty <span class="op">=</span> <span class="fl">1</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"Count of water observations"</span>, ylab <span class="op">=</span> <span class="st">"Frequency"</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"Prior = 0 or 1"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3M51-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb147"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># When the prior becomes more informative, there is a mismatch between prediction and observed data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><em>For 3M2</em></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb148"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate 90% HPDI for p when prior = 1</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample3m2</span>, <span class="fl">0.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     |0.9      0.9| 
0.3250325 0.7145715 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb150"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate 90% HPDI for p when prior = 0 or 1</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample3m5</span>, <span class="fl">0.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     |0.9      0.9| 
0.5000500 0.7139714 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb152"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># narrower interval for 90% HPDI when prior is more informative</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><em>For 3M4</em></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb153"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># % Probability of 6w in 9n when prior = 1</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">sample3m2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">w</span> <span class="op">==</span> <span class="fl">6</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
 FALSE   TRUE 
0.8264 0.1736 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb155"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># % Probability of 6w in 9n when prior = 0 or 1</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">9</span>, prob <span class="op">=</span> <span class="va">sample3m5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">w</span> <span class="op">==</span><span class="fl">6</span><span class="op">)</span><span class="op">/</span> <span class="fl">1e4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
 FALSE   TRUE 
0.8264 0.1736 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb157"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># No difference in probability percentage </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="hard-1" class="level3"><h3 class="anchored" data-anchor-id="hard-1">Hard</h3>
<blockquote class="blockquote">
<p>3H1. Using grid approximation, compute the posterior distribution for the probability of a birth being a boy. Assume a uniform prior probability. Which parameter value maximizes the posterior probability?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb158"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load homework data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">homeworkch3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Total number of boys born across all this birth</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 111</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb160"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute posterior distribution for a birth being a boy</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">111</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">prior</span> <span class="op">*</span> <span class="va">likelihood</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot posterior with abline</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">~</span><span class="va">p_grid</span>, type <span class="op">=</span> <span class="st">"l"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">0.5</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H1-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb161"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Find parameter value that maximizes posterior probability</span></span>
<span><span class="va">p_grid</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5527638</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb163"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Show parameter with max posterior probability in plot</span></span>
<span><span class="va">v</span> <span class="op">&lt;-</span> <span class="va">p_grid</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">~</span><span class="va">p_grid</span>, type <span class="op">=</span> <span class="st">"l"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">0.5</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">v</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"topright"</span>, legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"p = 0.5"</span>, <span class="st">"p = 0.553"</span><span class="op">)</span>, </span>
<span>       col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>, <span class="st">"blue"</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H1-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb164"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># OR</span></span>
<span><span class="co"># Use loss function to calculate parameter value that maximizes posterior probability</span></span>
<span><span class="co"># Add sample</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">102</span><span class="op">)</span></span>
<span><span class="va">sample3h1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e4</span>, prob <span class="op">=</span> <span class="va">posterior</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate mode (MAP) value</span></span>
<span><span class="va">map_value</span> <span class="op">&lt;-</span> <span class="va">p_grid</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">map_value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5527638</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb166"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate mean value</span></span>
<span><span class="va">mean_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample3h1</span><span class="op">)</span></span>
<span><span class="va">mean_value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5547302</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb168"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate median value</span></span>
<span><span class="va">median_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">sample3h1</span><span class="op">)</span></span>
<span><span class="va">median_value</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5527638</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb170"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate loss</span></span>
<span><span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">p_grid</span> , <span class="kw">function</span><span class="op">(</span><span class="va">d</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">d</span> <span class="op">-</span> <span class="va">p_grid</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the loss function</span></span>
<span><span class="co"># Find x, y values for minimum loss</span></span>
<span><span class="va">min_loss_x</span> <span class="op">&lt;-</span> <span class="va">p_grid</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">loss</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">min_loss_y</span> <span class="op">&lt;-</span> <span class="va">loss</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="va">loss</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Create data frame and plot </span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">loss</span>, <span class="va">posterior</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="va">loss</span><span class="op">)</span>, fill <span class="op">=</span> <span class="st">'lightblue'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">min_loss_x</span>, y <span class="op">=</span> <span class="va">min_loss_y</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">3</span>, shape <span class="op">=</span> <span class="fl">21</span>, color <span class="op">=</span> <span class="st">'black'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">map_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">mean_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="va">median_value</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"grey"</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">map_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"mode"</span>, </span>
<span>            vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">3</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">mean_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"mean"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">median_value</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">df</span><span class="op">$</span><span class="va">posterior</span><span class="op">)</span>, label <span class="op">=</span> <span class="st">"median"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span>, hjust <span class="op">=</span> <span class="op">-</span><span class="fl">5</span>, color <span class="op">=</span> <span class="st">"black"</span>, angle <span class="op">=</span> <span class="fl">90</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="va">min_loss_x</span>, y <span class="op">=</span> <span class="va">min_loss_y</span>, label <span class="op">=</span> <span class="st">"value that minimizes loss"</span>, </span>
<span>           vjust <span class="op">=</span> <span class="fl">1.6</span>, hjust <span class="op">=</span> <span class="fl">0.5</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">'parameter value'</span>,</span>
<span>       y <span class="op">=</span> <span class="st">'expected proportional loss'</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H1-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb171"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The parameter value that maximizes probability is 0.553 </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3H2. Using the sample function, draw 10,000 random parameter values from the posterior distribution you calculated above. Use these samples to estimate the 50%, 89%, and 97% highest posterior density intervals.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb172"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate 50% HPDI</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample3h1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>     |0.5      0.5| 
0.5226131 0.5678392 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb174"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate 89% HPDI</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample3h1</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>    |0.89     0.89| 
0.5025126 0.6080402 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb176"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate 97% HPDI</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample3h1</span>, prob <span class="op">=</span> <span class="fl">0.97</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>    |0.97     0.97| 
0.4824121 0.6331658 </code></pre>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3H3. Use rbinom to simulate 10,000 replicates of 200 births. You should end up with 10,000 numbers, each one a count of boys out of 200 births. Compare the distribution of predicted numbers of boys to the actual count in the data (111 boys out of 200 births). There are many good ways to visualize the simulations, but the dens command (part of the rethinking package) is probably the easiest way in this case. Does it look like the model fits the data well? That is, does the distribution of predictions include the actual observation as a central, likely outcome?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb178"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Use rbinom to simulate 10,000 replicates of 200 births</span></span>
<span><span class="va">replicate_w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">10000</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">sample3h1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare predictive posterior distribution and actual count using dens function</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">replicate_w</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"darkgreen"</span>, </span>
<span>     main <span class="op">=</span> <span class="st">"PPD with 200 grids, 1e4 samples, 1e4 observations"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">111</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H3-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb179"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># PPD is not an exact fit- is that because i used 200 grids only?</span></span>
<span></span>
<span><span class="co"># Try increasing grid size</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10000</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">111</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior_w</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">103</span><span class="op">)</span></span>
<span><span class="va">sample_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">10000</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior_w</span><span class="op">)</span></span>
<span><span class="va">replicate_w1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">10000</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">sample_grid</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">replicate_w1</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"darkgreen"</span>, </span>
<span>     main <span class="op">=</span> <span class="st">"PPD with 1e4 grids, 1e4 samples, 1e4 observations"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">111</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H3-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb180"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Try with codes from answer key</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">homeworkch3</span><span class="op">)</span></span>
<span><span class="va">boys</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth2</span><span class="op">)</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">0</span> , to<span class="op">=</span><span class="fl">1</span> , length.out<span class="op">=</span><span class="fl">1000</span> <span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span> <span class="va">boys</span> , size<span class="op">=</span><span class="fl">200</span> , prob<span class="op">=</span><span class="va">p</span> <span class="op">)</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span></span>
<span><span class="va">p.samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span> <span class="va">p</span> , size<span class="op">=</span><span class="fl">10000</span> , replace<span class="op">=</span><span class="cn">TRUE</span> , prob<span class="op">=</span><span class="va">posterior</span> <span class="op">)</span></span>
<span><span class="va">bsim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span> <span class="fl">10000</span> , size<span class="op">=</span><span class="fl">200</span> , prob<span class="op">=</span><span class="va">p.samples</span> <span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span> <span class="va">bsim</span> , adj<span class="op">=</span><span class="fl">0.1</span>, main <span class="op">=</span> <span class="st">"Given answer: 1000 grids, 1e4 samples, 1e4 observations"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> v<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth1</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth2</span><span class="op">)</span> , col<span class="op">=</span><span class="st">"red"</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H3-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb181"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Can't get the exact fit like the graph in answer key even when I just c/p the codes.</span></span>
<span></span>
<span><span class="co"># Try increasing sample with 1e5 grids</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1e5</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1e5</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">111</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior_w</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">sample_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e5</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior_w</span><span class="op">)</span></span>
<span><span class="va">replicate_w1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e5</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">sample_grid</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">replicate_w1</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"darkgreen"</span>, </span>
<span>     main <span class="op">=</span> <span class="st">"PPD with 1e5 grids, 1e5 samples, 1e5 observations"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">111</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H3-4.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb182"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Try with 1e4 observations to see difference</span></span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1e5</span><span class="op">)</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1e5</span><span class="op">)</span></span>
<span><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">111</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior</span></span>
<span><span class="va">posterior_w</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">sample_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid</span>, size <span class="op">=</span> <span class="fl">1e5</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior_w</span><span class="op">)</span></span>
<span><span class="va">replicate_w1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">200</span>, prob <span class="op">=</span> <span class="va">sample_grid</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">replicate_w1</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"darkgreen"</span>, </span>
<span>     main <span class="op">=</span> <span class="st">"PPD with 1e5 grids, 1e5 samples, 1e4 observations"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">111</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H3-5.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb183"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># All graphs have slightly different peaks. Is it because of variations in </span></span>
<span><span class="co"># grid size/ sample size/ observation size or variations in draw?</span></span>
<span><span class="co"># But PPDs' peaks are within ± 3 of actual counts. This only shows the fit of data-shows model works</span></span>
<span><span class="co"># Doesn't show if a model is good or not- whether reflect the real world. </span></span>
<span><span class="co"># So, it doesn't matter if slightly different fit, I think. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3H4. Now compare 10,000 counts of boys from 100 simulated first borns only to the number of boys in the first births, birth1. How does the model look in this light?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb184"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate posterior for first born boys</span></span>
<span><span class="va">first_born_boy</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth1</span><span class="op">)</span></span>
<span><span class="va">p_grid_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">prior_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">likelihood_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">first_born_boy</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="va">p_grid_3h4</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior_3h4</span> <span class="op">&lt;-</span> <span class="va">prior_3h4</span> <span class="op">*</span> <span class="va">likelihood_3h4</span></span>
<span><span class="va">posterior_3h4</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior_3h4</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior_3h4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create samples</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">111</span><span class="op">)</span></span>
<span><span class="va">sample_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid_3h4</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior_3h4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create observations</span></span>
<span><span class="va">w_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="va">sample_3h4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare PPD with actual count</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">w_3h4</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">first_born_boy</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H4-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb185"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Let's try increasing the grid to 1e5</span></span>
<span><span class="va">p_grid_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">1e5</span><span class="op">)</span></span>
<span><span class="va">prior_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1e5</span><span class="op">)</span></span>
<span><span class="va">likelihood_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">first_born_boy</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="va">p_grid_3h4</span><span class="op">)</span></span>
<span><span class="va">unstd.posterior_3h4</span> <span class="op">&lt;-</span> <span class="va">prior_3h4</span> <span class="op">*</span> <span class="va">likelihood_3h4</span></span>
<span><span class="va">posterior_3h4</span> <span class="op">&lt;-</span> <span class="va">unstd.posterior_3h4</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd.posterior_3h4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create samples</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">111</span><span class="op">)</span></span>
<span><span class="va">sample_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_grid_3h4</span>, size <span class="op">=</span> <span class="fl">1e4</span>, replace <span class="op">=</span> <span class="cn">TRUE</span>, prob <span class="op">=</span> <span class="va">posterior_3h4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create observations</span></span>
<span><span class="va">w_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="va">sample_3h4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare PPD with actual count</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">w_3h4</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">first_born_boy</span>, col <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H4-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb186"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Better fit with increased grid size. </span></span>
<span></span>
<span><span class="co"># If we use the same posterior distribution (given answer)</span></span>
<span><span class="va">w_3h4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1e4</span>, size <span class="op">=</span> <span class="fl">100</span>, prob <span class="op">=</span> <span class="va">sample3h1</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">w_3h4</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">first_born_boy</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H4-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb187"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># So, a new posterior with new conditions- changes in number of actual </span></span>
<span><span class="co"># counts and total counts- will make the model fit the data. I think this is</span></span>
<span><span class="co"># caused by simulation not exactly halving the observations, i.e., we gave</span></span>
<span><span class="co"># no command that the observation is 51 for 100.</span></span>
<span><span class="co"># Given answer: Not bad, but not right on center now. The frequency of boys </span></span>
<span><span class="co"># among first borns is a little less than the model tends to predict. </span></span>
<span><span class="co"># The model doesn’t have a problem accounting for this variation though, </span></span>
<span><span class="co"># as the red line is well within density of simulated data.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>3H5. The model assumes that sex of first and second births are independent. To check this assumption, focus now on second births that followed female first borns. Compare 10,000 simulated counts of boys to only those second births that followed girls. To do this correctly, you need to count the number of first borns who were girls and simulate that many births, 10,000 times. Compare the counts of boys in your simulations to the actual observed count of boys following girls. How does the model look in this light? Any guesses what is going on in these data?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb188"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Count number of second born boys when first borns are girl</span></span>
<span><span class="va">second_boy_first_girl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth1</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">&amp;</span> <span class="va">birth2</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Count the number of first born girls</span></span>
<span><span class="va">first_girl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">birth1</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate observations for total number of second births when first births are girls</span></span>
<span><span class="va">w_3h5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span> <span class="fl">10000</span> , size <span class="op">=</span> <span class="va">first_girl</span> , prob <span class="op">=</span> <span class="va">sample3h1</span> <span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">w_3h5</span>, adj <span class="op">=</span> <span class="fl">0.1</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">second_boy_first_girl</span> , col <span class="op">=</span> <span class="st">"green"</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H5-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb189"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The sex of first and second birth may not be independent. </span></span>
<span></span>
<span><span class="co"># Run codes in given answer</span></span>
<span><span class="co"># Create a new vector of birth 2 when birth 1 is 0</span></span>
<span><span class="va">b01</span> <span class="op">&lt;-</span> <span class="va">birth2</span><span class="op">[</span><span class="va">birth1</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Simulate 1e4 observations for new vector size using samples from model posterior</span></span>
<span><span class="va">b01sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span> <span class="fl">10000</span> , size<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">b01</span><span class="op">)</span> , prob<span class="op">=</span><span class="va">p.samples</span> <span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">b01sim</span>,adj<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add a line for actual count of second born boys when first borns are girls</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> v<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">b01</span><span class="op">)</span> , col<span class="op">=</span><span class="st">"red"</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3H5-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
</section></section></section><section id="chapter-4-linear-models" class="level1"><h1>Chapter 4: Linear Models</h1>
<p>Under a probability interpretation, which is necessary for Bayesian work, linear regression uses a Gaussian (normal) distribution to describe our golem’s uncertainty about some measurement of interest.</p>
<section id="why-normal-distributions-are-normal" class="level2"><h2 class="anchored" data-anchor-id="why-normal-distributions-are-normal">Why normal distributions are normal</h2>
<p>A thousand friends line up on the halfway line of a soccer field. Each flips a coin 16 times- moves a step to the left if the coin comes up head and to the right if tail. Then, measure the distance of each person from the halfway line. “The distances will be distributed in approximately normal, or Gaussian, fashion. This is true even though the underlying distribution is binomial. It does this because <em>there are so many more possible ways to realize a sequence of left-right steps that sums to zero. There are slightly fewer ways to realize a sequence that ends up one step left or right of zero, and so on, with the number of possible sequences declining in the characteristic bell curve of the normal distribution</em>.”</p>
<section id="normal-by-addition" class="level3"><h3 class="anchored" data-anchor-id="normal-by-addition">Normal by addition</h3>
<p>Simulate the above experiment in R:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb190"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">01</span><span class="op">)</span></span>
<span><span class="co"># To simulate this, we generate for each person a list of 16 random numbers between −1 and 1. </span></span>
<span><span class="co"># These are the individual steps. Then we add these steps together to get the position after 16 steps. </span></span>
<span><span class="co"># Then we need to replicate this procedure 1000 times.</span></span>
<span><span class="va">pos</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">16</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="co"># runif to generate random deviates following the uniform distribution </span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">pos</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c41-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb191"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/density.html">density</a></span><span class="op">(</span><span class="va">pos</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c41-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb192"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span>  <span class="co"># Plot the density for 4 steps, 8 steps, and 16 steps</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Plot for 4 steps</span></span>
<span>  <span class="va">pos4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">4</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu">dens</span><span class="op">(</span><span class="va">pos4</span>, main <span class="op">=</span> <span class="st">"4 steps"</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Plot for 8 steps</span></span>
<span>  <span class="va">pos8</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">8</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu">dens</span><span class="op">(</span><span class="va">pos8</span>, main <span class="op">=</span> <span class="st">"8 steps"</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Plot for 16 steps</span></span>
<span>  <span class="fu">dens</span><span class="op">(</span><span class="va">pos</span>, main <span class="op">=</span> <span class="st">"16 steps"</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Plot for 100 steps</span></span>
<span>  <span class="va">pos100</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">1000</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">100</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu">dens</span><span class="op">(</span><span class="va">pos100</span>, main <span class="op">=</span> <span class="st">"100 steps"</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c41-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb193"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The more steps are taken, the closer the match between the real empirical distribution </span></span>
<span><span class="co"># of positions and the ideal normal distribution.</span></span>
<span><span class="co"># After 16 steps, it has already taken on a familiar “bell” curve of the Gaussian distribution </span></span>
<span><span class="co"># emerging from the randomness, i.e., the distribution of positions is stabilizing on the Gaussian. </span></span>
<span><span class="co"># But they all look bell shape to me. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Why addition should result in a bell curve of sums?</em></strong></span></p>
<ul>
<li><p>Whatever the average value of the source distribution, each sample from it can be thought of as a fluctuation from that average value.</p></li>
<li><p>When we begin to add these fluctuations together, they also begin to cancel one another out. A large positive fluctuation will cancel a large negative one.</p></li>
<li><p>The more terms in the sum, the more chances for each fluctuation to be canceled by another, or by a series of smaller ones in the opposite direction. So eventually the most likely sum, in the sense that there are the most ways to realize it, will be a sum in which every fluctuation is canceled by another, a sum of zero (relative to the mean).</p></li>
<li><p>It doesn’t matter what shape the underlying distribution possesses- uniform or anything else. Depending upon the underlying distribution, the convergence might be slow (often rapid), but it will be inevitable.</p></li>
</ul>
<p><br></p>
</section><section id="normal-by-multiplication" class="level3"><h3 class="anchored" data-anchor-id="normal-by-multiplication">Normal by multiplication</h3>
<p>Simulate growth multiplication of an organism:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb194"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Sample 12 random numbers between 1.0 and 1.1, each representing a proportional </span></span>
<span><span class="co"># increase in growth. Thus 1.0 means no additional growth and 1.1 means a 10% increase. </span></span>
<span><span class="co"># The product of all 12 is computed and returned as output.</span></span>
<span><span class="co"># prod returns the product of all the values present in its arguments.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 2.317942</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb196"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Generate 10,000 random products</span></span>
<span><span class="va">growth</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">growth</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"darkred"</span><span class="op">)</span> <span class="co">#norm.comp overlay normal density comparison if true</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c42-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb197"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Small effects that multiply together are approximately additive, and so </span></span>
<span><span class="co"># they also tend to stabilize on Gaussian distributions.  For example, if there</span></span>
<span><span class="co"># are two loci with alleles increasing growth by 10% each, the product is: 1.1 × 1.1 = 1.21</span></span>
<span><span class="co"># The smaller the effect of each locus, the better this additive approximation will be.</span></span>
<span></span>
<span><span class="co"># Verify this effect by comparing big vs. small increase in percent value</span></span>
<span><span class="va">big</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">0</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">small</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">0</span>, <span class="fl">0.01</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the distributions</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">big</span>, col <span class="op">=</span> <span class="st">"blue"</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, main <span class="op">=</span> <span class="st">"Big effect"</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">small</span>, col <span class="op">=</span> <span class="st">"red"</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, main <span class="op">=</span> <span class="st">"Small effect"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c42-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb198"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The interacting growth deviations, as long as they are sufficiently small, </span></span>
<span><span class="co"># converge to a Gaussian distribution- extends well beyond purely additive interactions.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="normal-by-log-multiplication" class="level3"><h3 class="anchored" data-anchor-id="normal-by-log-multiplication">Normal by log-multiplication</h3>
<p>Large deviates that are multiplied together do not produce Gaussian distributions, but they do tend to produce Gaussian distributions on the log scale. For example:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb199"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">log.big</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span> <span class="fl">10000</span> , <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">12</span>,<span class="fl">0</span>,<span class="fl">0.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">log.big</span>, norm.comp <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"blue"</span>, main <span class="op">=</span> <span class="st">"Big effect on log scale"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c43-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb200"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># We get the Gaussian distribution back, because adding logs is equivalent to multiplying </span></span>
<span><span class="co"># the original numbers. So even multiplicative interactions of large deviations can produce </span></span>
<span><span class="co"># Gaussian distributions, once we measure the outcomes on the log scale. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="using-guassian-distributions" class="level3"><h3 class="anchored" data-anchor-id="using-guassian-distributions">Using Guassian distributions</h3>
<p>The justifications for using the Gaussian distribution- as a skeleton for hypotheses, building up models of measurements as aggregations of normal distributions- fall into two broad categories:</p>
<ol type="1">
<li>ontological justification
<ul>
<li>Repeatedly adding finite fluctuations results in a distribution of sums that have shed all information about the underlying process, aside from mean and spread. One consequence of this is that statistical models based on Gaussian distributions cannot reliably identify micro-process. But it also means that these models can do useful work, even when they cannot identify process.</li>
</ul>
</li>
</ol>
<ol start="2" type="1">
<li>epistemological justification
<ul>
<li>Gaussian distribution is the most natural expression of our state of ignorance, because if all we are willing to assume is that a measure has finite variance, the Gaussian distribution is the shape that can be realized in the largest number of ways and does not introduce any new assumptions. It is the least surprising and least informative assumption to make. In this way, the Gaussian is the distribution most consistent with our assumptions. Or rather, it is the most consistent with our golem’s assumptions.</li>
</ul>
</li>
</ol>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Gaussian distribution</strong></span></span></p>
<ul>
<li>The probability density of some value y, given a Gaussian (normal) distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, is:</li>
</ul>
<p><span class="math display">\[p(y|\mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(- \frac{(y-\mu)^2}{2\sigma^2}\right)\]</span></p>
<ul>
<li><p>(y − <span class="math inline">\(\mu\)</span>)<sup>2</sup> gives the normal distribution its fundamental shape, a quadratic shape. Once you exponentiate the quadratic shape, you get the classic bell curve. The rest of it just scales and standardizes the distribution so that it sums to one, as all probability distributions must. But an expression as simple as exp(−y<sup>2</sup>) yields the Gaussian prototype.</p></li>
<li><p>The value y in the Gaussian distribution can be any continuous value, as Gussian is a continuous distribution.</p></li>
<li><p>The binomial, in contrast, requires integers. Probability distributions with only discrete outcomes, like the binomial, are usually called <em>probability mass functions</em> and denoted <em>Pr</em>. Continuous ones like the Gaussian are called <em>probability density functions</em>, denoted with <em>p</em> or just plain old <em>f</em>.</p></li>
<li><p>For mathematical reasons, probability densities, but not masses, can be greater than 1. For example:</p></li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb201"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate p(0|0, 0.1)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">0.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 3.989423</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb203"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Probability density is the rate of change in cumulative probability. </span></span>
<span><span class="co"># So where cumulative probability is increasing rapidly, density can easily exceed 1. </span></span>
<span><span class="co"># But if we calculate the area under the density function, it will never exceed 1. </span></span>
<span><span class="co"># Such areas are also called probability mass.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li>The Gaussian distribution is routinely seen without <span class="math inline">\(\sigma\)</span> but with another parameter, <span class="math inline">\(\tau\)</span> . The parameter <span class="math inline">\(\tau\)</span> in this context is usually called precision and defined as <span class="math inline">\(\tau\)</span> = 1/<span class="math inline">\(\sigma\)</span><sup>2</sup>. This change of parameters gives us the equivalent formula (just substitute <span class="math inline">\(\sigma\)</span> = 1/ <span class="math inline">\(\sqrt\tau\)</span>):</li>
</ul>
<p><span class="math display">\[p(y|\mu, \tau) = \sqrt\frac{\tau}{{2\pi}} \exp\left(- \frac{1}{2}\tau(y - \mu)^2 \right)\]</span></p>
<p><br></p>
</section></section><section id="a-language-for-describing-models" class="level2"><h2 class="anchored" data-anchor-id="a-language-for-describing-models">A language for describing models</h2>
<ol type="1">
<li><p>First, we recognize a set of measurements that we hope to predict or understand, the <em>outcome</em> variable or variables.</p></li>
<li><p>For each of these outcome variables, we define a likelihood distribution that defines the plausibility of individual observations. In linear regression, this distribution is always Gaussian.</p></li>
<li><p>Then we recognize a set of other measurements that we hope to use to predict or understand the outcome. Call these <em>predictor</em> variables.</p></li>
<li><p>We relate the exact shape of the likelihood distribution—its precise location and variance and other aspects of its shape, if it has them—to the predictor variables. In choosing a way to relate the predictors to the outcomes, we are forced to name and define all of the parameters of the model.</p></li>
<li><p>Finally, we choose priors for all of the parameters in the model. These priors define the initial information state of the model, before seeing the data.</p></li>
</ol>
<ul>
<li>After all these decisions are made, summarize the model:</li>
</ul>
<p><span class="math display">\[
\text{outcome}_i \sim \text{Normal}(\mu_i, \sigma) \\
\mu_i = \beta \times \text{predictor}_i \\
\beta \sim \text{Normal}(0, 10) \\
\sigma \sim \text{HalfCauchy}(0, 1)
\]</span></p>
<div style="border: 1px solid #999; padding: 10px; background-color: #f9f9f9; margin: 10px 0;">
<p>outcome<sub>i</sub> = outcome variable for the i<sup>th</sup> observation</p>
<p>Normal(<span class="math inline">\(\mu\)</span><sub>i</sub>, <span class="math inline">\(\sigma\)</span>) = normal distribution with mean <span class="math inline">\(\mu\)</span><sub>i</sub> and standard deviation <span class="math inline">\(\sigma\)</span></p>
<p><span class="math inline">\(\mu\)</span><sub>i</sub> = mean (<span class="math inline">\(\mu\)</span><sub>i</sub>) of the normal distribution for the i<sup>th</sup> observation</p>
<p><span class="math inline">\(\beta\times\text{predictor}\)</span> = the product of a coefficient (<span class="math inline">\(\beta\)</span>) and a predictor variable (predictor<sub>i</sub>)</p>
</div>
<p><br></p>
<section id="re-describing-the-globe-tossing-model" class="level3"><h3 class="anchored" data-anchor-id="re-describing-the-globe-tossing-model">Re-describing the globe tossing model</h3>
<p>The model:</p>
<p><span class="math display">\[\text{w} \sim \text{Binomial(n, p)}\]</span> <span class="math display">\[\text{p} \sim \text{Uniform(0, 1)}\]</span></p>
<pre><code>w   = observed count of water samples
n   = total number of samples
p   = proportion of water on actual globe

The count w is distributed binomially with sample size n and probability p. 
The prior for p is assumed to be uniform between zero and one. 

In these models, the first line defines the likelihood function used in Bayes’ theorem. 
The other line defines priors. Both of the lines in this model are stochastic, as 
indicated by the ∼ symbol. A stochastic relationship is just a mapping of a variable 
or parameter onto a distribution. It is stochastic because no single instance of the 
variable on the left is known with certainty. Instead, the mapping is probabilistic: 
Some values are more plausible than others, but very many different values are 
plausible under any model. 
</code></pre>
<p><br></p>
<p><span style="color:purple"><strong><em>From model definition to Bayes’ theorem</em></strong></span></p>
<p>To relate the mathematical format above to Bayes’ theorem, you could use the model definition to define the posterior distribution:</p>
<p><span class="math display">\[\text{Pr(p|w,n)} = \frac{\text{Binomial(w|n,p) Uniform(p|0,1)}}{\int \text{Binomial(w|n,p) Uniform(p|0,1)dp}}\]</span></p>
<p><br></p>
<p><span class="math display">\[\text{posterior probability of any particular value of p} = \frac{likelihood \times prior}{\text{average likelihood}}\]</span></p>
<p>In R code form:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb205"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fl">6</span>; <span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">9</span>;</span>
<span><span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">w</span>, <span class="va">n</span>, <span class="va">p_grid</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">posterior</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">~</span><span class="va">p_grid</span>, type <span class="op">=</span> <span class="st">"l"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c45-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
</section></section><section id="a-gaussian-model-of-height" class="level2"><h2 class="anchored" data-anchor-id="a-gaussian-model-of-height">A Gaussian model of height</h2>
<p>There are an infinite number of possible Gaussian distributions. Some have small means. Others have large means. Some are wide, with a large <span class="math inline">\(\sigma\)</span>. Others are narrow. We want our Bayesian machine to consider every possible distribution, each defined by a combination of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, and rank them by posterior plausibility. Posterior plausibility provides a measure of the logical compatibility of each possible distribution with the data and model.</p>
<p>In practice we’ll use approximations to the formal analysis. So we won’t really consider every possible value of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. The “estimate” here will be the entire posterior distribution, not any point within it. And as a result, the posterior distribution will be a distribution of Gaussian distributions. Yes, a distribution of distributions.</p>
<p><br></p>
<section id="the-data" class="level3"><h3 class="anchored" data-anchor-id="the-data">The data</h3>
<p>A data frame is a special kind of list in R. So you access the individual variables with the usual list “double bracket” notation, like d[[1]] for the first variable or d[[‘x’]] for the variable named x. Unlike regular lists, however, data frames force all variables to have the same length. That isn’t always a good thing. And that’s why some statistical packages, like the powerful Stan Markov chain sampler (mc-stan.org), accept plain lists of data, rather than proper data frames.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb206"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Howell1"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># name the data frame as "d"</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span></span>
<span><span class="co"># Inspect the structure of the data frame</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   544 obs. of  4 variables:
 $ height: num  152 140 137 157 145 ...
 $ weight: num  47.8 36.5 31.9 53 41.3 ...
 $ age   : num  63 63 65 41 51 35 32 27 19 54 ...
 $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb208"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Select the height column</span></span>
<span> <span class="va">d0</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">height</span></span>
<span> </span>
<span><span class="co"># Filter the data frame down to individuals of age 18 or greater </span></span>
<span> <span class="va">d2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">age</span> <span class="op">&gt;=</span> <span class="fl">18</span>, <span class="op">]</span></span>
<span><span class="co"># You can access any value in the matrix with d[row,col], replacing row and col </span></span>
<span><span class="co"># with row and column numbers. If row or col are lists of numbers, then you get</span></span>
<span><span class="co"># more than one row or column. If you leave the spot for row or col blank, then </span></span>
<span><span class="co"># you get all of whatever you leave blank. For example,d[ 3 , ]gives all columns </span></span>
<span><span class="co"># at row 3. Typing d[,] just gives you the entire matrix, because it returns all </span></span>
<span><span class="co"># rows and all columns.</span></span>
<span> </span>
<span><span class="co"># d[ d$age &gt;= 18 , ] gives you all of the rows in which d$age is greater-than- </span></span>
<span><span class="co"># or-equal-to 18. It also gives you all of the columns, because the spot after </span></span>
<span><span class="co"># the comma is blank.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="the-model" class="level3"><h3 class="anchored" data-anchor-id="the-model">The model</h3>
<p>Our goal is to model these values using a Gaussian distribution.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb209"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># First, plot the distribution of heights</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c47-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Whatever the reason, adult heights are nearly always approximately normal. So it’s reasonable for the moment to adopt the stance that the model’s likelihood should be Gaussian. But be careful about choosing the Gaussian distribution only when the plotted outcome variable looks Gaussian to you. Gawking at the raw data, to try to decide how to model them, is usually not a good idea. The data could be a mixture of different Gaussian distributions, for example, and in that case you won’t be able to detect the underlying normality just by eyeballing the outcome distribution. Furthermore, the empirical distribution needn’t be actually Gaussian in order to justify using a Gaussian likelihood.</p>
<p>There are an infinite number of Gaussain distributions , with an infinite number of different means and standard deviations. We’re ready to write down the general model and compute the plausibility of each combination of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. To define the heights as normally distributed with a mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, we write:</p>
<p><span class="math display">\[\text{h}_i \sim \text{Normal}(\mu, \sigma)\]</span></p>
<pre><code>h             = the list of heights
subscript i   = index- each individual element of this list (row numbers)
</code></pre>
<p><br></p>
<p>Then, we add priors assuming Pr(<span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>) = Pr(<span class="math inline">\(\mu\)</span>) Pr(<span class="math inline">\(\sigma\)</span>):</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{h}_i &amp;\sim \text{Normal}(\mu, \sigma) \ &amp;&amp;&amp; [\text{Likelihood}]\\

\mu &amp;\sim \text{Normal}(178, 20) \ &amp;&amp;&amp; [\mu \text{ prior}]\\

\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; [\sigma \text{ prior}]
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>Plot the priors to have a sense of the assumption they build into the model:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb211"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">178</span>, <span class="fl">20</span><span class="op">)</span>, from <span class="op">=</span> <span class="fl">100</span>, to <span class="op">=</span> <span class="fl">250</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c48-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb212"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># golem is assuming that the average height (not each individual height) is almost certainly </span></span>
<span><span class="co"># between 140 cm and 220 cm. So this prior carries a little information, but not a lot. </span></span>
<span><span class="co"># The σ prior is a truly flat prior, a uniform one, that functions just to constrain σ </span></span>
<span><span class="co"># to have positive probability between zero and 50cm. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb213"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span>, from <span class="op">=</span> <span class="op">-</span><span class="fl">10</span>, to <span class="op">=</span> <span class="fl">60</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c49-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb214"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># A standard deviation like σ must be positive, so bounding it at zero makes sense. </span></span>
<span><span class="co"># How should we pick the upper bound? In this case, a standard deviation of 50cm would </span></span>
<span><span class="co"># imply that 95% of individual heights lie within 100cm of the average height. </span></span>
<span><span class="co"># That’s a very large range.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Simulate heights by sampling from priors (every posterior is also potentially a prior for a subsequent analysis, so you can process priors just like posteriors.):</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb215"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">sample_mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1e4</span>, <span class="fl">178</span>, <span class="fl">20</span><span class="op">)</span></span>
<span></span>
<span><span class="va">sample_sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1e4</span>, <span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span></span>
<span><span class="va">prior_h</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1e4</span>, <span class="va">sample_mu</span>, <span class="va">sample_sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">prior_h</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c50-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb216"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The density plot you get shows a vaguely bell-shaped density with thick tails. </span></span>
<span><span class="co"># It is the expected distribution of heights, averaged over the prior. Notice that </span></span>
<span><span class="co"># the prior probability distribution of height is not itself Gaussian. This is okay. </span></span>
<span><span class="co"># The distribution you see is not an empirical expectation, but rather the distribution </span></span>
<span><span class="co"># of relative plausibilities of different heights, before seeing the data.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="grid-approximation-of-the-posterior-distribution" class="level3"><h3 class="anchored" data-anchor-id="grid-approximation-of-the-posterior-distribution">Grid approximation of the posterior distribution</h3>
<p>The guts of the golem:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb217"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a grid of mu and sigma values</span></span>
<span><span class="va">mu.list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">140</span>, to<span class="op">=</span><span class="fl">160</span> , length.out<span class="op">=</span><span class="fl">200</span> <span class="op">)</span></span>
<span><span class="va">sigma.list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">4</span> , to<span class="op">=</span><span class="fl">9</span> , length.out<span class="op">=</span><span class="fl">200</span> <span class="op">)</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span> mu<span class="op">=</span><span class="va">mu.list</span> , sigma<span class="op">=</span><span class="va">sigma.list</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate log-likelihood</span></span>
<span><span class="va">post</span><span class="op">$</span><span class="va">LL</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span> , <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="co">#calculate PDF of normal distribution</span></span>
<span>                <span class="va">d2</span><span class="op">$</span><span class="va">height</span> , <span class="co"># sum to add up all log-likelihoods</span></span>
<span>                mean<span class="op">=</span><span class="va">post</span><span class="op">$</span><span class="va">mu</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> ,</span>
<span>                sd<span class="op">=</span><span class="va">post</span><span class="op">$</span><span class="va">sigma</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> ,</span>
<span>                log<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span> <span class="op">)</span> <span class="op">)</span> <span class="co"># return log-likelihoods</span></span>
<span></span>
<span><span class="co"># Calculate probabilities from log-likelihoods</span></span>
<span><span class="va">post</span><span class="op">$</span><span class="va">prod</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">LL</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">mu</span> , <span class="fl">178</span> , <span class="fl">20</span> , <span class="cn">TRUE</span> <span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">sigma</span> , <span class="fl">0</span> , <span class="fl">50</span> , <span class="cn">TRUE</span> <span class="op">)</span></span>
<span><span class="co"># sum of all log-likelihoods + the log-likelihood of a normal distribution </span></span>
<span><span class="co"># with a fixed mean of 178 and standard deviation of 20 + he log-likelihood of </span></span>
<span><span class="co"># a uniform distribution for sigma values between 0 and 50</span></span>
<span></span>
<span><span class="co"># Taking the sum effectively combines the contributions from the likelihood and the priors.</span></span>
<span><span class="co"># This is constructing the unnormalized log-posterior distribution by summing up the </span></span>
<span><span class="co"># log-likelihood and the log-prior terms. The final step of the analysis involves </span></span>
<span><span class="co"># normalizing these probabilities to obtain a proper probability distribution.</span></span>
<span></span>
<span><span class="co"># Use exp function to exponentiate the log-likelihoods, transforming them back to probabilities</span></span>
<span><span class="va">post</span><span class="op">$</span><span class="va">prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">prod</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">post</span><span class="op">$</span><span class="va">prod</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="co"># subtracting helps with numerical stability by preventing very large or small values</span></span>
<span></span>
<span><span class="co"># Simple contour plot</span></span>
<span><span class="fu">contour_xyz</span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">mu</span> , <span class="va">post</span><span class="op">$</span><span class="va">sigma</span> , <span class="va">post</span><span class="op">$</span><span class="va">prob</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c51-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb218"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Simple heat map</span></span>
<span><span class="fu">image_xyz</span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">mu</span> , <span class="va">post</span><span class="op">$</span><span class="va">sigma</span> , <span class="va">post</span><span class="op">$</span><span class="va">prob</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c51-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
</section><section id="sampling-from-the-posterior" class="level3"><h3 class="anchored" data-anchor-id="sampling-from-the-posterior">Sampling from the posterior</h3>
<p>Since there are two parameters, and we want to sample combinations of them, we first randomly sample row numbers in post in proportion to the values in post$prob. Then we pull out the parameter values on those randomly sampled rows.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb219"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># First randomly sample row numbers in post in proportion to the values in post$prob</span></span>
<span><span class="va">sample.rows</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span> , size<span class="op">=</span><span class="fl">1e4</span> , replace<span class="op">=</span><span class="cn">TRUE</span> ,</span>
<span>    prob<span class="op">=</span><span class="va">post</span><span class="op">$</span><span class="va">prob</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Pull out the parameter values on those randomly sampled rows</span></span>
<span><span class="va">sample.mu</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">mu</span><span class="op">[</span> <span class="va">sample.rows</span> <span class="op">]</span></span>
<span><span class="va">sample.sigma</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">sigma</span><span class="op">[</span> <span class="va">sample.rows</span> <span class="op">]</span></span>
<span><span class="co"># You end up with 10,000 samples, with replacement, from the posterior for the height data.</span></span>
<span></span>
<span><span class="co"># Plot the samples</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">sample.mu</span> , <span class="va">sample.sigma</span> , cex<span class="op">=</span><span class="fl">0.5</span> , pch<span class="op">=</span><span class="fl">16</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.1</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.17-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb220"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Samples from the posterior distribution for the heights data. The density of </span></span>
<span><span class="co"># points is highest in the center, reflecting the most plausible combinations of μ and σ.</span></span>
<span><span class="co"># There are many more ways for these parameter values to produce the data, conditional on the model.</span></span>
<span></span>
<span><span class="co"># Describe the distribution of confidence in each combination of μ and σ by summarizing the samples</span></span>
<span><span class="co"># Characterize the shapes of the marginal posterior densities of μ and σ</span></span>
<span><span class="co"># The jargon “marginal” here means “averaging over the other parameters.” </span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">sample.mu</span>, main <span class="op">=</span> <span class="st">"sample.mu"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.17-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb221"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">dens</span><span class="op">(</span><span class="va">sample.sigma</span>, main <span class="op">=</span> <span class="st">"sample.sigma"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.17-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb222"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># As sample size increases, posterior densities approach the normal distribution. </span></span>
<span><span class="co"># If you look closely, though, you’ll notice that the density for σ has a longer right-hand tail.</span></span>
<span><span class="co"># This condition is very common for standard deviation parameters.</span></span>
<span></span>
<span><span class="co"># Summarize the widths of these densities with highest posterior density intervals</span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample.mu</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
153.9698 155.1759 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb224"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">sample.sigma</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
7.266332 8.195980 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb226"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Since these samples are just vectors of numbers, you can compute any statistic </span></span>
<span><span class="co"># from them that you could from ordinary data. If you want the mean or median, </span></span>
<span><span class="co"># just use the corresponding R functions.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Sample size and the normality of <span class="math inline">\(\sigma\)</span>’s posterior</strong></span></span></p>
<ul>
<li><p>Repeat the above analysis using only a fraction of the original data to demonstrate the posterior is not always so Gaussian in shape</p></li>
<li><p>For a Gaussian likelihood and a Gaussian prior on μ, the posterior distribution is always Gaussian as well, regardless of sample size.</p></li>
<li><p>There’s no trouble with the mean, μ. It is the standard deviation σ that causes problems- need to be careful of abusing the quadratic approximation.</p></li>
<li><p>The deep reasons for the posterior of σ tending to have a long right-hand tail are complex. But a useful way to conceive of the problem is that variances must be positive. As a result, there must be more uncertainty about how big the variance (or standard deviation) is than about how small it is. For example, if the variance is estimated to be near zero, then you know for sure that it can’t be much smaller. But it could be a lot bigger.</p></li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb227"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Take only 20 samples from height data</span></span>
<span><span class="va">d3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span>, size <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a grid from mean and SD values</span></span>
<span><span class="va">mu.list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">150</span>, to<span class="op">=</span><span class="fl">170</span> , length.out<span class="op">=</span><span class="fl">200</span> <span class="op">)</span></span>
<span><span class="va">sigma.list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">4</span> , to<span class="op">=</span><span class="fl">20</span> , length.out<span class="op">=</span><span class="fl">200</span> <span class="op">)</span></span>
<span><span class="va">post2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span> mu<span class="op">=</span><span class="va">mu.list</span> , sigma<span class="op">=</span><span class="va">sigma.list</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate log-likelihoods</span></span>
<span><span class="va">post2</span><span class="op">$</span><span class="va">LL</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">post2</span><span class="op">)</span> , <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">d3</span> , mean<span class="op">=</span><span class="va">post2</span><span class="op">$</span><span class="va">mu</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> , sd<span class="op">=</span><span class="va">post2</span><span class="op">$</span><span class="va">sigma</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> ,</span>
<span>    log<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate probabilities from log-likelihood values</span></span>
<span><span class="va">post2</span><span class="op">$</span><span class="va">prod</span> <span class="op">&lt;-</span> <span class="va">post2</span><span class="op">$</span><span class="va">LL</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">post2</span><span class="op">$</span><span class="va">mu</span> , <span class="fl">178</span> , <span class="fl">20</span> , <span class="cn">TRUE</span> <span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="va">post2</span><span class="op">$</span><span class="va">sigma</span> , <span class="fl">0</span> , <span class="fl">50</span> , <span class="cn">TRUE</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Exponentiate the log-likelihoods back to probability</span></span>
<span><span class="va">post2</span><span class="op">$</span><span class="va">prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span> <span class="va">post2</span><span class="op">$</span><span class="va">prod</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">post2</span><span class="op">$</span><span class="va">prod</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Randomly sample row numbers in post2 in proportion to probability</span></span>
<span><span class="va">sample2.rows</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">post2</span><span class="op">)</span> , size<span class="op">=</span><span class="fl">1e4</span> , replace<span class="op">=</span><span class="cn">TRUE</span> ,</span>
<span>    prob<span class="op">=</span><span class="va">post2</span><span class="op">$</span><span class="va">prob</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Draw the parameter values from randomly sampled row numbers</span></span>
<span><span class="va">sample2.mu</span> <span class="op">&lt;-</span> <span class="va">post2</span><span class="op">$</span><span class="va">mu</span><span class="op">[</span> <span class="va">sample2.rows</span> <span class="op">]</span></span>
<span><span class="va">sample2.sigma</span> <span class="op">&lt;-</span> <span class="va">post2</span><span class="op">$</span><span class="va">sigma</span><span class="op">[</span> <span class="va">sample2.rows</span> <span class="op">]</span></span>
<span></span>
<span><span class="co"># Plot the samples</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">sample2.mu</span> , <span class="va">sample2.sigma</span> , cex<span class="op">=</span><span class="fl">0.5</span> ,</span>
<span>    col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.1</span><span class="op">)</span> ,</span>
<span>    xlab<span class="op">=</span><span class="st">"mu"</span> , ylab<span class="op">=</span><span class="st">"sigma"</span> , pch<span class="op">=</span><span class="fl">16</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.21-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb228"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Notice a distinctly longer tail at the top of the cloud of points</span></span>
<span></span>
<span><span class="co"># Inspect the marginal posterior density for σ, averaging over μ</span></span>
<span><span class="fu">dens</span><span class="op">(</span> <span class="va">sample2.sigma</span> , norm.comp<span class="op">=</span><span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"purple"</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.21-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb229"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now you can see that the posterior for σ is not Gaussian, but rather has a long tail of</span></span>
<span><span class="co"># uncertainty towards higher values.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="fitting-the-model-with-map" class="level3"><h3 class="anchored" data-anchor-id="fitting-the-model-with-map">Fitting the model with <code>map</code>
</h3>
<ul>
<li><p>Quadratic approximation is as a handy way to quickly make inferences about the shape of the posterior.</p></li>
<li><p>The posterior’s peak will lie at the maximum a posteriori estimate (MAP), and we can get a useful image of the posterior’s shape by using the quadratic approximation of the posterior distribution at this peak.</p></li>
</ul>
<p><br></p>
<p><span style="color:brown; text-decoration:underline"><strong>Use <code>map</code> to find the values of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> that maximize the posterior probability:</strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb230"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load Howell1 data and select out the adults</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Howell1</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span> <span class="va">d</span><span class="op">$</span><span class="va">age</span> <span class="op">&gt;=</span> <span class="fl">18</span> , <span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li>Define the model, using R’s formula syntax:</li>
</ul>
<p>$$</p>
<p><span class="math display">\[\begin{align*}
\text{h}_i &amp; \sim \text{Normal}(\mu, \sigma) \ &amp;&amp;&amp; \text{[height} &amp; \sim \text{dnorm(mu, sigma)}\text{]}\\

\mu &amp;\sim \text{Normal}(178, 20) \ &amp;&amp;&amp; [\text{mu} &amp;\sim \text{dnorm}(178, 20)]\\

\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; [\text{sigma} &amp;\sim \text{dunif}(0, 50)]
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<ul>
<li>Now, place the R code equivalents into <code>alist</code>.</li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb231"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">flist</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>    <span class="va">mu</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">20</span> <span class="op">)</span> ,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Note the commas at the end of each line, except the last. </span></span>
<span><span class="co"># These commas separate each line of the model definition.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<ul>
<li>Fit the model to the data in the data frame d2 with:</li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb232"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m4.1</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span> <span class="va">flist</span> , data<span class="op">=</span><span class="va">d2</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># After executing this code, you’ll have a fit model stored in the symbol m4.1.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<ul>
<li>Now take a look at the fit maximum a posteriori model:</li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb233"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
mu    154.607025 0.4119967 153.948575 155.265475
sigma   7.731371 0.2913896   7.265674   8.197067</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb235"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># These numbers provide Gaussian approximations for each parameter’s marginal distribution. </span></span>
<span><span class="co"># This means the plausibility of each value of μ, after averaging over the plausibilities </span></span>
<span><span class="co"># of each value of σ, is given by a Gaussian distribution with mean 154.6 and standard deviation 0.4.</span></span>
<span><span class="co"># The 5.5% and 94.5% quantiles are percentile interval boundaries, corresponding to an 89% interval.</span></span>
<span><span class="co"># They are almost identical with the HPDIs from the grid approximation earlier.</span></span>
<span><span class="co"># When the posterior is approximately Gaussian, then this is what you should expect.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown; text-decoration:underline"><strong>Start values for <code>map</code></strong></span></p>
<p><code>map</code> estimates the posterior by climbing it like a hill. To do this, it has to start climbing someplace, at some combination of parameter values. Unless you tell it otherwise, map starts at random values sampled from the prior. But it’s also possible to specify a starting value for any parameter in the model.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb236"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Use parameters μ and σ as starting values- good guesses of the rough location of the MAP values</span></span>
<span><span class="va">start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    mu<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span>,</span>
<span>    sigma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>Note that the list of start values is a regular list, not an alist like the formula list is. 
The two functions alist and list do the same basic thing: allow you to make a collection of arbitrary R objects. They differ in one important respect: list evaluates the code you embed inside it, while
alist does not. So when you define a list of formulas, you should use alist, so the code isn’t 
executed. But when you define a list of start values for parameters, you should use list, so 
that code like mean(d2$height) will be evaluated to a numeric value.
</code></pre>
<p><br></p>
<p>See the effect of a more information prior for <span class="math inline">\(\mu\)</span>:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb238"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Change the standard deviation of the prior to 0.1, so it’s a very narrow prior</span></span>
<span><span class="va">m4.2</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>            <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>            <span class="va">mu</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">0.1</span> <span class="op">)</span> ,</span>
<span>            <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>        data<span class="op">=</span><span class="va">d2</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">m4.2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean        sd      5.5%     94.5%
mu    177.86375 0.1002354 177.70356 178.02395
sigma  24.51757 0.9289228  23.03297  26.00217</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb240"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Notice that the estimate for μ has hardly moved off the prior. </span></span>
<span><span class="co"># The prior was very concentrated around 178. Also notice that the estimate for </span></span>
<span><span class="co"># σ has changed quite a lot, even though we didn’t change its prior at all.</span></span>
<span><span class="co"># Once the golem is certain that the mean is near 178—as the prior insists—then </span></span>
<span><span class="co"># the golem has to estimate σ conditional on that fact. This results in a different</span></span>
<span><span class="co"># posterior for σ, even though all we changed is prior information about the other parameter.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="sampling-from-a-map-fit" class="level3"><h3 class="anchored" data-anchor-id="sampling-from-a-map-fit">Sampling from a <code>map</code> fit</h3>
<p>Getting samples from the quadratic approximate posterior distribution requires recognizing that a quadratic approximation to a posterior distribution with more than one parameter dimension— μ and σ each contribute one dimension— is just a multi-dimensional Gaussian distribution.</p>
<p>As a consequence, when R constructs a quadratic approximation, it calculates not only standard deviations for all parameters, but also the covariances among all pairs of parameters.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb241"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#  A multi-dimensional Gaussian distribution requires a list of means and </span></span>
<span><span class="co"># a matrix of variances and covariances</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span> <span class="va">m4.1</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                mu        sigma
mu    0.1697412635 0.0002180627
sigma 0.0002180627 0.0849078849</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb243"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The above is a variance-covariance matrix- it tells us how each parameter relates </span></span>
<span><span class="co"># to every other param- eter in the posterior distribution.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>A variance-covariance matrix can be factored into two elements:</p>
<ol type="1">
<li><p>a vector of variances for the parameters</p></li>
<li><p>a correlation matrix that tells us how changes in any parameter lead to correlated changes in the others.</p></li>
</ol>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb244"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span> <span class="va">m4.1</span> <span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>        mu      sigma 
0.16974126 0.08490788 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb246"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The two-element vector in the output is the list of variances. </span></span>
<span><span class="co"># If you take the square root of this vector, you get the standard deviations that </span></span>
<span><span class="co"># are shown in precis output.</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov2cor</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span> <span class="va">m4.1</span> <span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>               mu       sigma
mu    1.000000000 0.001816409
sigma 0.001816409 1.000000000</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb248"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The two-by-two matrix in the output is the correlation matrix. Each entry shows </span></span>
<span><span class="co"># the correlation, bounded between −1 and +1, for each pair of parameters. The 1’s </span></span>
<span><span class="co"># indicate a parameter’s correlation with itself. If these values were anything </span></span>
<span><span class="co"># except 1, we would be worried. The other entries are typically closer to zero, </span></span>
<span><span class="co"># and they are very close to zero in this example. This indicates that learning </span></span>
<span><span class="co"># μ tells us nothing about σ and likewise that learning σ tells us nothing about μ.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>To get samples from this multi-dimensional posterior, we sample vectors of values from a multi-dimensional Gaussian distribution- instead of sampling single values from a simple Gaussian distribution.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb249"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">m4.1</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>        mu    sigma
1 155.1039 7.135917
2 154.5828 7.429587
3 154.4296 7.765402
4 154.7250 7.822866
5 154.3468 8.037140
6 154.5909 7.901778</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb251"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># You end up with a data frame, post, with 10,000 (1e4) rows and two columns, </span></span>
<span><span class="co"># one column for μ and one for σ. Each value is a sample from the posterior, </span></span>
<span><span class="co"># so the mean and standard deviation of each column will be very close to the</span></span>
<span><span class="co"># MAP values from before.</span></span>
<span></span>
<span><span class="co"># Confirm this by summarizing the samples</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">post</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%   histogram
mu    154.606917 0.4139880 153.950806 155.263315    ▁▁▁▅▇▂▁▁
sigma   7.730378 0.2909896   7.261593   8.192475 ▁▁▁▂▅▇▇▃▁▁▁</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb253"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare with values from quadratic approximate posterior distribution</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
mu    154.607025 0.4119967 153.948575 155.265475
sigma   7.731371 0.2913896   7.265674   8.197067</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb255"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare with the samples from the grid approximation</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">post</span>, cex<span class="op">=</span><span class="fl">0.5</span> , pch<span class="op">=</span><span class="fl">16</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">sample.mu</span> , <span class="va">sample.sigma</span> , cex<span class="op">=</span><span class="fl">0.5</span> , pch<span class="op">=</span><span class="fl">16</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.1</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.32-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb256"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># There is resembalance with the grid approximation</span></span>
<span><span class="co"># These samples also preserve the covariance between μ and σ. This hardly matters right now, </span></span>
<span><span class="co"># because μ and σ don’t covary at all in this model. But once you add a predictor variable </span></span>
<span><span class="co"># to your model, covariance will matter a lot.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Under the hood with multivariate sampling</em></strong></span></p>
<p>The function extract.samples is for convenience. The work is done by a multi-dimensional version of rnorm, mvrnorm. The function rnorm simulates random Gaussian values, while mvrnorm simulates random vectors of multivariate Gaussian values. Here’s how to use it directly to do what extract.samples does:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb257"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># library(MASS)</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">mvrnorm</span><span class="op">(</span> n<span class="op">=</span><span class="fl">1e4</span> , mu<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m4.1</span><span class="op">)</span> , Sigma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">m4.1</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># You don’t usually need to use mvrnorm directly like this, but sometimes you want to</span></span>
<span><span class="co"># simulate multi-variate Gaussian outcomes. In that case, you’ll need to access mvrnorm directly.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Getting <span class="math inline">\(\sigma\)</span> right</em></strong></span></p>
<ul>
<li><p>The quadratic assumption for σ can be problematic- more uncertainty at higher values.</p></li>
<li><p>A conventional way to improve the situation is the estimate log(σ) instead- while the posterior distribution of σ will often not be Gaussian, the distribution of its logarithm can be much closer to Gaussian.</p></li>
<li><p>So if we impose the quadratic approximation on the logarithm, rather than the standard deviation itself, we can often get a better approximation of the uncertainty.</p></li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb258"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">435</span><span class="op">)</span></span>
<span><span class="co"># Estimate log(σ) using map</span></span>
<span><span class="va">m4.1_logsigma</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>          <span class="co"># the exp inside the likelihood converts a continuous parameter, log_sigma, </span></span>
<span>          <span class="co"># to be strictly positive, because exp(x) &gt; 0 for any real value x.</span></span>
<span>            <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">log_sigma</span><span class="op">)</span> <span class="op">)</span> ,</span>
<span>            <span class="va">mu</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">20</span> <span class="op">)</span> ,</span>
<span>            <span class="va">log_sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">2</span> , <span class="fl">10</span> <span class="op">)</span>   </span>
<span>            <span class="co"># Since log_sigma is continuous now, it can have a Gaussian prior.</span></span>
<span><span class="op">)</span> , data<span class="op">=</span><span class="va">d2</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># When you extract samples, it is log_sigma that has a Gaussian distribution. </span></span>
<span><span class="co"># To get the distribution of sigma, you just need to use the same exp as in the </span></span>
<span><span class="co"># model definition, to get back on the natural scale:</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">m4.1_logsigma</span> <span class="op">)</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">log_sigma</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare the three samples of sigma</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">sigma</span>, main <span class="op">=</span><span class="st">"log.sigma"</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">sample.sigma</span>, main <span class="op">=</span><span class="st">"sample.sigma"</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span> <span class="va">sample2.sigma</span> , main <span class="op">=</span> <span class="st">"smaller.sample.sigma"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.35-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb259"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># log.sima and sample.sigma have same sample sizes, while smaller.sample.sigma has</span></span>
<span><span class="co"># significantly smaller sample size of 20. </span></span>
<span><span class="co"># When you have a lot of data, this won’t make any noticeable difference. </span></span>
<span><span class="co"># But the use of exp to effectively constrain a parameter to be positive is a </span></span>
<span><span class="co"># robust and useful one. And it relates to link functions.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="adding-a-predictor" class="level2"><h2 class="anchored" data-anchor-id="adding-a-predictor">Adding a predictor</h2>
<p>Typically, we are interested in modeling how an outcome is related to some predictor variable. And by including a predictor variable in a particular way, we’ll have linear regression.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb260"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># See how height covaries with weight</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span> <span class="op">~</span> <span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/c4.37-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb261"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># there’s obviously a relationship: Knowing a person’s weight helps you predict height.</span></span>
<span><span class="co"># Incorporate predictor variables to Gaussian model to make this vague observation into</span></span>
<span><span class="co"># a more precise quantitative model that relates values of weight to plausible values of height</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<section id="fitting-the-model" class="level3"><h3 class="anchored" data-anchor-id="fitting-the-model">Fitting the model</h3>
<p>All we have to do is incorporate our new model for the mean into the model specification inside map and be sure to add our new parameters to the start list.</p>
<p>Repeat model definition, with corresponding R code:</p>
<p>$$</p>
<p><span class="math display">\[\begin{align*}
\text{h}_i &amp; \sim \text{Normal}(\mu_i, \sigma) \ &amp;&amp;&amp; \text{height} &amp; \sim \text{dnorm(mu, sigma)} \\

\mu_i &amp; = \alpha + \beta x_i \ &amp;&amp;&amp; \text{mu} &amp; \leftarrow \text{a + b*weight} \\

\alpha &amp;\sim \text{Normal}(178, 100) \ &amp;&amp;&amp; a &amp;\sim \text{dnorm}(178, 100)\\

\beta &amp;\sim \text{Normal}(0, 10) \ &amp;&amp;&amp; b &amp;\sim \text{dnorm}(0, 10)\\

\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; \text{sigma} &amp;\sim \text{dunif}(0, 50)

\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>Build the MAP model fit using the above formulas:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb262"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data Howell1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Howell1</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">age</span> <span class="op">&gt;=</span> <span class="fl">18</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># fit model</span></span>
<span><span class="va">m4.3</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">178</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Note that starting b at zero is not the same as having β’s prior with mean zero. </span></span>
<span><span class="co"># The values in the start list don’t alter the posterior probabilities, while priors definitely do.</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%       94.5%
a     113.9017831 1.90520985 110.8568898 116.9466764
b       0.9045383 0.04191883   0.8375439   0.9715327
sigma   5.0717137 0.19113878   4.7662370   5.3771904</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb264"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Another way to fit the same model without a separate line for linear model</span></span>
<span><span class="co"># Merge the linear model into likelihood function</span></span>
<span><span class="va">m4.3</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">178</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%       94.5%
a     113.9037379 1.90528037 110.8587319 116.9487439
b       0.9044977 0.04192039   0.8375008   0.9714946
sigma   5.0719079 0.19115708   4.7664020   5.3774138</code></pre>
</div>
</div>
<p><br></p>
</section><section id="interpreting-the-model-fit" class="level3"><h3 class="anchored" data-anchor-id="interpreting-the-model-fit">Interpreting the model fit</h3>
<p>Two broad categories of processing:</p>
<ol type="1">
<li><p>reading tables</p></li>
<li><p>plotting</p></li>
</ol>
<p>Plotting the implications of your estimates will allow you to inquire about several things that are sometimes hard to read from tables:</p>
<ul>
<li><p>Whether or not the model fitting procedure worked correctly</p></li>
<li><p>The absolute magnitude, rather than merely relative magnitude, of a relationship between outcome and predictor</p></li>
<li><p>The uncertainty surrounding an average relationship</p></li>
<li><p>The uncertainty surrounding the implied predictions of the model, as these are distinct from mere parameter uncertainty</p></li>
</ul>
<p><br></p>
<p><span style="color:purple"><strong><em>What do parameters mean?</em></strong></span></p>
<p>Posterior probabilities of parameter values describe the relative compatibility of different states of the world with the data, ac- cording to the model.</p>
<p><br></p>
<section id="tables-of-estimates" class="level4"><h4 class="anchored" data-anchor-id="tables-of-estimates">Tables of estimates</h4>
<p>With the new linear regression fit to the Kalahari data, we inspect the estimates:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb266"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%       94.5%
a     113.9037379 1.90528037 110.8587319 116.9487439
b       0.9044977 0.04192039   0.8375008   0.9714946
sigma   5.0719079 0.19115708   4.7664020   5.3774138</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb268"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The first row gives the quadratic approximation for α, the second the approximation </span></span>
<span><span class="co"># for β, and the third approximation for σ.</span></span>
<span><span class="co"># Since β is a slope, the value 0.90 can be read as a person 1 kg heavier is expected </span></span>
<span><span class="co"># to be 0.90 cm taller. 89% of the posterior probability lies between 0.84 and 0.97. </span></span>
<span><span class="co"># The estimate of α, a in the precis table, indicates that a person of weight 0 should be 114cm tall.</span></span>
<span><span class="co"># The estimate for σ, sigma, informs us of the width of the distribution of heights around the mean.</span></span>
<span><span class="co"># The estimate tells us that 95% of plausible heights lie within 10cm (2σ) of the mean height. </span></span>
<span><span class="co"># But there is also uncertainty about this, as indicated by the 89% percentile interval</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>The numbers in the default precis output aren’t sufficient to describe the quadratic posterior completely. For that, we also require the variance-covariance matrix. We’re interested in correlations among parameters—we already have their variance in the table above—so let’s go straight to the correlation matrix:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb269"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Correlation matrix</span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">m4.3</span> , corr<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span><span class="co"># This code not working</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%       94.5%
a     113.9037379 1.90528037 110.8587319 116.9487439
b       0.9044977 0.04192039   0.8375008   0.9714946
sigma   5.0719079 0.19115708   4.7664020   5.3774138</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb271"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov2cor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                  a             b         sigma
a      1.0000000000 -0.9898830051  0.0009627185
b     -0.9898830051  1.0000000000 -0.0009551558
sigma  0.0009627185 -0.0009551558  1.0000000000</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb273"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Notice that α and β are almost perfectly negatively correlated. Right now, </span></span>
<span><span class="co"># this is harmless. It just means that these two parameters carry the same information—</span></span>
<span><span class="co"># as you change the slope of the line, the best intercept changes to match it. </span></span>
<span><span class="co"># But in more complex models, strong correlations like this can make it difficult </span></span>
<span><span class="co"># to fit the model to the data. One of the tricks to avoid it is centering.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Centering</strong></span></span></p>
<p>Centering is the procedure of subtracting the mean of a variable from each value.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb274"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a centered version of the weight variable</span></span>
<span><span class="va">d2</span><span class="op">$</span><span class="va">weight.c</span> <span class="op">&lt;-</span> <span class="va">d2</span><span class="op">$</span><span class="va">weight</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Confirm that the average value of weight.c is zero</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight.c</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 1.168257e-15</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb276"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Refit the model and see the changes</span></span>
<span></span>
<span><span class="va">m4.4</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight.c</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d2</span>,</span>
<span>start <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">178</span>, b <span class="op">=</span> <span class="fl">0</span>, sigma <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># I got error "Start values for parameters may be too far from MAP." if specify start value.</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.4</span>, corr <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%       94.5%
a     154.5972636 0.27033038 154.1652235 155.0293038
b       0.9050132 0.04192753   0.8380049   0.9720215
sigma   5.0718661 0.19115312   4.7663665   5.3773657</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb278"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cov2cor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">m4.4</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                  a             b         sigma
a      1.000000e+00 -2.006485e-09  4.770265e-05
b     -2.006485e-09  1.000000e+00 -2.855619e-05
sigma  4.770265e-05 -2.855619e-05  1.000000e+00</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb280"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The estimates for β and σ are unchanged (within rounding error), but the estimate for</span></span>
<span><span class="co"># α (a) is now the same as the average height value in the raw data. </span></span>
<span><span class="co"># And the correlations among parameters are now all zero</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 154.5971</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb282"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The estimate for the intercept, α, still means the same thing it did before: </span></span>
<span><span class="co"># the expected value of the outcome variable, when the predictor variable is equal to zero. </span></span>
<span><span class="co"># But now the mean value of the predictor is also zero. So the intercept also means: </span></span>
<span><span class="co"># the expected value of the outcome, when the predictor is at its average value. </span></span>
<span><span class="co"># This makes interpreting the intercept a lot easier.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="plotting-posterior-inference-aganist-the-data" class="level4"><h4 class="anchored" data-anchor-id="plotting-posterior-inference-aganist-the-data">Plotting posterior inference aganist the data</h4>
<p>Not only does plotting help in interpreting the posterior, but it also provides an informal check on model assumptions. When the model’s predictions don’t come close to key observations or patterns in the plotted data, then you might suspect the model either did not fit correctly or is rather badly specified.</p>
<p>We’re going to start with a simple version of that task, superimposing just the MAP values over the height and weight data.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb283"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># superimpose the MAP values for mean height over the actual data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight</span>, data <span class="op">=</span> <span class="va">d2</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span><span class="op">[</span><span class="st">"a"</span><span class="op">]</span>, b <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span><span class="op">[</span><span class="st">"b"</span><span class="op">]</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.45-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb284"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Height in centimeters (vertical) plotted against weight in kilograms (horizontal), </span></span>
<span><span class="co"># with the maximum a posteriori (MAP) line for the mean height at each weight plotted in black.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="adding-uncertainty-around-the-mean" class="level4"><h4 class="anchored" data-anchor-id="adding-uncertainty-around-the-mean">Adding uncertainty around the mean</h4>
<p>The posterior distribution considers every possible regression line connecting height to weight. It assigns a relative plausibility to each. This means that each combination of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> has a posterior probability. It could be that there are many lines with nearly the same posterior probability as the MAP line. Or it could be instead that the posterior distribution is rather narrow near the MAP line.</p>
<p>So how can we get that uncertainty onto the plot? Together, a combination of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> define a line. And so we could sample a bunch of lines from the posterior distribution. Then we could display those lines on the plot, to visualize the uncertainty in the regression relationship.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb285"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># To better appreciate how the posterior distribution contains lines, extract some samples from the model</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Inspect the first 5 rows of the samples</span></span>
<span><span class="va">post</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>         a         b    sigma
1 111.2442 0.9678210 5.021772
2 117.0870 0.8423942 5.318267
3 117.1865 0.8331993 5.077028
4 116.7522 0.8359394 5.214674
5 114.5915 0.8914661 4.811527</code></pre>
</div>
</div>
<p><br></p>
<p>Each row is a correlated random sample from the joint posterior of all three parameters, using the covariances provided by vcov(m4.3). The paired values of a and b on each row define a line. The average of very many of these lines is the MAP line. But the scatter around that average is meaningful, because it alters our confidence in the relationship between the predictor and the outcome.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb287"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># extracts the first 10 cases and re-estimates the model</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">dN</span> <span class="op">&lt;-</span> <span class="va">d2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">N</span>, <span class="op">]</span></span>
<span><span class="va">mN</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">178</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, data <span class="op">=</span> <span class="va">dN</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot 20 of these lines, to see what the uncertainty looks like</span></span>
<span><span class="co"># extract 20 samples from the posterior</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mN</span>, n <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># display raw data and sample size</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dN</span><span class="op">$</span><span class="va">weight</span>, <span class="va">dN</span><span class="op">$</span><span class="va">height</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span>,</span>
<span>     col <span class="op">=</span> <span class="va">rangi2</span>, xlab <span class="op">=</span> <span class="st">"weight"</span>, ylab <span class="op">=</span> <span class="st">"height"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="fu">concat</span><span class="op">(</span><span class="st">"N = "</span>, <span class="va">N</span><span class="op">)</span><span class="op">)</span> <span class="co"># add text to the plot indicating sample size</span></span>
<span></span>
<span><span class="co"># plot the lines with transparency</span></span>
<span><span class="co"># i-th sample is a set of random parameter values sampled from posterior distribution</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span> <span class="co"># loops over all 20 lines, using abline to display each</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, b <span class="op">=</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>, <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.48-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb288"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The cloud of regression lines displays greater uncertainty at extreme values for weight. </span></span>
<span><span class="co"># This is very common.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb289"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compare higher N values (bigger sample size)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>, mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="fl">4</span>,<span class="fl">4</span>,<span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 20 samples</span></span>
<span><span class="co">## show error in knitting if I use 10 sample here, although it works above with warning</span></span>
<span><span class="co">## 10 samples is too low to reach stable estimates</span></span>
<span><span class="va">N0</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">dN0</span> <span class="op">&lt;-</span> <span class="va">d2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">N0</span>, <span class="op">]</span></span>
<span><span class="va">mN0</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">178</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, data <span class="op">=</span> <span class="va">dN0</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">post0</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mN0</span>, n <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dN0</span><span class="op">$</span><span class="va">weight</span>, <span class="va">dN0</span><span class="op">$</span><span class="va">height</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span>,</span>
<span>     col <span class="op">=</span> <span class="va">rangi2</span>, xlab <span class="op">=</span> <span class="st">"weight"</span>, ylab <span class="op">=</span> <span class="st">"height"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="fu">concat</span><span class="op">(</span><span class="st">"N = "</span>, <span class="va">N0</span><span class="op">)</span><span class="op">)</span> </span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="va">post0</span><span class="op">$</span><span class="va">a</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, b <span class="op">=</span> <span class="va">post0</span><span class="op">$</span><span class="va">b</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>, <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># 50 samples</span></span>
<span><span class="va">N1</span> <span class="op">=</span> <span class="fl">50</span></span>
<span><span class="va">dN1</span> <span class="op">&lt;-</span> <span class="va">d2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">N1</span>, <span class="op">]</span></span>
<span><span class="va">mN1</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span>  <span class="op">)</span>, data <span class="op">=</span> <span class="va">dN1</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">post1</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">mN1</span>, n<span class="op">=</span><span class="fl">20</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">dN1</span><span class="op">$</span><span class="va">weight</span> , <span class="va">dN1</span><span class="op">$</span><span class="va">height</span> ,</span>
<span>    xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span> ,</span>
<span>    col<span class="op">=</span><span class="va">rangi2</span> , xlab<span class="op">=</span><span class="st">"weight"</span> , ylab<span class="op">=</span><span class="st">"height"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="fu">concat</span><span class="op">(</span><span class="st">"N = "</span>,<span class="va">N1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> a<span class="op">=</span><span class="va">post1</span><span class="op">$</span><span class="va">a</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> , b<span class="op">=</span><span class="va">post1</span><span class="op">$</span><span class="va">b</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>,<span class="fl">0.3</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># 150 samples</span></span>
<span><span class="va">N2</span> <span class="op">=</span> <span class="fl">150</span></span>
<span><span class="va">dN2</span> <span class="op">&lt;-</span> <span class="va">d2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">N2</span>, <span class="op">]</span></span>
<span><span class="va">mN2</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span>  <span class="op">)</span>, data <span class="op">=</span> <span class="va">dN2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">post2</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">mN2</span>, n<span class="op">=</span><span class="fl">20</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">dN2</span><span class="op">$</span><span class="va">weight</span> , <span class="va">dN2</span><span class="op">$</span><span class="va">height</span> ,</span>
<span>    xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span> ,</span>
<span>    col<span class="op">=</span><span class="va">rangi2</span> , xlab<span class="op">=</span><span class="st">"weight"</span> , ylab<span class="op">=</span><span class="st">"height"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="fu">concat</span><span class="op">(</span><span class="st">"N = "</span>,<span class="va">N2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> a<span class="op">=</span><span class="va">post2</span><span class="op">$</span><span class="va">a</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> , b<span class="op">=</span><span class="va">post2</span><span class="op">$</span><span class="va">b</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>,<span class="fl">0.3</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># 352 samples</span></span>
<span><span class="va">N3</span> <span class="op">=</span> <span class="fl">352</span></span>
<span><span class="va">dN3</span> <span class="op">&lt;-</span> <span class="va">d2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">N3</span>, <span class="op">]</span></span>
<span><span class="va">mN3</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span>  <span class="op">)</span>, data <span class="op">=</span> <span class="va">dN3</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">post3</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">mN3</span>, n<span class="op">=</span><span class="fl">20</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">dN3</span><span class="op">$</span><span class="va">weight</span> , <span class="va">dN3</span><span class="op">$</span><span class="va">height</span> ,</span>
<span>    xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">height</span><span class="op">)</span> ,</span>
<span>    col<span class="op">=</span><span class="va">rangi2</span> , xlab<span class="op">=</span><span class="st">"weight"</span> , ylab<span class="op">=</span><span class="st">"height"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="fu">concat</span><span class="op">(</span><span class="st">"N = "</span>,<span class="va">N3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> a<span class="op">=</span><span class="va">post3</span><span class="op">$</span><span class="va">a</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> , b<span class="op">=</span><span class="va">post3</span><span class="op">$</span><span class="va">b</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>,<span class="fl">0.3</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.48.1-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb290"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The cloud of regression lines grows more compact as the sample size increases. </span></span>
<span><span class="co"># This is a result of the model growing more confident about the location of the mean.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="plotting-regression-intervals-and-contours" class="level4"><h4 class="anchored" data-anchor-id="plotting-regression-intervals-and-contours">Plotting regression intervals and contours</h4>
<p>It’s much more common to see the uncertainty displayed by plotting an interval or contour around the MAP regression line, than a cloud of regression lines.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb291"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Example:</span></span>
<span></span>
<span><span class="co"># See the vector</span></span>
<span><span class="va">post_test</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mN</span>, n <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="va">mu_at_40</span> <span class="op">&lt;-</span> <span class="va">post_test</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post_test</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">40</span></span>
<span><span class="va">mu_at_40</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] 148.1149 145.7450 146.1799 146.6578 147.2442 147.2029 146.4644 148.5382
 [9] 148.3957 144.6175 145.9421 150.5419 148.1460 148.9402 148.6208 147.8840
[17] 148.7102 146.5478 147.3967 150.1586</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb293"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># It’s a vector of predicted means, one for each random sample from the posterior. </span></span>
<span><span class="co"># Since joint a and b went into computing each, the variation across those means </span></span>
<span><span class="co"># incorporates the uncertainty in and correlation between both parameters.</span></span>
<span></span>
<span><span class="co"># make a list of 10,000 values of μ for an individual who weighs 50 kilograms, </span></span>
<span><span class="co"># by using samples from the posterior (μ_i = α + βx_i)</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mN</span>, n <span class="op">=</span> <span class="fl">1e4</span><span class="op">)</span></span>
<span><span class="va">mu_at_50</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">50</span> <span class="co"># value of x_i is 50 in this case</span></span>
<span></span>
<span><span class="va">post3</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mN3</span>, n <span class="op">=</span> <span class="fl">1e4</span><span class="op">)</span></span>
<span><span class="va">mu_at_50_3</span> <span class="op">&lt;-</span> <span class="va">post3</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post3</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">50</span></span>
<span></span>
<span><span class="co"># Plot the density for the vector of means</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">mu_at_50</span>, col <span class="op">=</span> <span class="va">rangi2</span>, lwd <span class="op">=</span> <span class="fl">2</span>, xlab <span class="op">=</span> <span class="st">"mu|weight = 50 (10 samples)"</span><span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">mu_at_50_3</span>, col <span class="op">=</span> <span class="va">rangi2</span>, lwd <span class="op">=</span> <span class="fl">2</span>, xlab <span class="op">=</span> <span class="st">"mu|weight = 50 (352 samples)"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.50-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb294"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The quadratic approximate posterior distribution of the mean height, μ, when </span></span>
<span><span class="co"># weight is 50 kg. This distribution represents the relative plausibility of </span></span>
<span><span class="co"># different values of the mean.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Since the posterior for <span class="math inline">\(\mu\)</span> is a distribution, you can find intervals for it, just like for any posterior distribution. To find the 89% highest posterior density interval of <span class="math inline">\(\mu\)</span> at 50 kg, just use the HPDI command as usual:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb295"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">mu_at_50</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
154.2911 159.0406 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb297"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Wider interval of distribution (more uncertainty) with low number of observed data.</span></span>
<span></span>
<span><span class="fu">HPDI</span><span class="op">(</span><span class="va">mu_at_50_3</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
158.5784 159.6810 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb299"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The central 89% of the ways for the model to produce the data place the average </span></span>
<span><span class="co"># height between about 159 cm and 160 cm (conditional on the model and data), </span></span>
<span><span class="co"># assuming the weight is 50 kg.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>We need to repeat the above calculation for every weight value on the horizontal axis, not just when it is 50 kg. We want to draw 89% HPDIs around the MAP slope. This can be done by using <code>link</code> function. What <code>link</code> will do is take your <code>map</code> model fit, sample from the posterior distribution, and then compute <span class="math inline">\(\mu\)</span> for each case in the data and sample from the posterior distribution.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb300"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span> <span class="co"># to compactly show data frame</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:1000, 1:352] 157 157 157 157 157 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb302"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># You end up with a big matrix of values of μ. Each row is a sample from the posterior distribution. </span></span>
<span><span class="co"># The default is 1000 samples, but you can use as many or as few as you like. </span></span>
<span><span class="co"># Each column is a case (row) in the data. There are 352 rows in d2, corresponding </span></span>
<span><span class="co"># to 352 individuals. So there are 352 columns in the matrix mu above.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Now we have a distribution of <span class="math inline">\(\mu\)</span> for each individual in the original data. We actually want something slightly different: a distribution of <span class="math inline">\(\mu\)</span> for each unique weight value on the horizontal axis.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb303"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># define sequence of weights to compute predictions for</span></span>
<span><span class="co"># these values will be on the horizontal axis</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">25</span> , to<span class="op">=</span><span class="fl">70</span> , by<span class="op">=</span><span class="fl">1</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># use link to compute mu</span></span>
<span><span class="co"># for each sample from posterior</span></span>
<span><span class="co"># and for each weight in weight.seq</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m4.3</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>weight<span class="op">=</span><span class="va">weight.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:1000, 1:46] 137 136 135 137 136 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb305"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now there are only 46 columns in mu, because we fed it 46 different values for weight.</span></span>
<span></span>
<span><span class="co"># Plot the distribution of μ values at each height</span></span>
<span><span class="co"># use type="n" to hide raw data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , <span class="va">d2</span> , type<span class="op">=</span><span class="st">"n"</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># loop over samples and plot each mu value</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span> , pch<span class="op">=</span><span class="fl">16</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.1</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.54-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb306"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The first 100 values in the distribution of μ at each weight value.</span></span>
<span><span class="co"># At each weight value in weight.seq, a pile of computed μ values are shown. </span></span>
<span><span class="co"># Each of these piles is a Gaussian distribution. You can see now that the amount </span></span>
<span><span class="co"># of uncertainty in μ depends upon the value of weight.</span></span>
<span></span>
<span><span class="co">## The final step is to summarize the distribution for each weight value.</span></span>
<span><span class="co"># summarize the distribution of mu</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span> <span class="co"># 2 is columns, 1 is rows</span></span>
<span><span class="va">mu.mean</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] 136.5387 137.4419 138.3451 139.2484 140.1516 141.0548 141.9580 142.8613
 [9] 143.7645 144.6677 145.5709 146.4742 147.3774 148.2806 149.1838 150.0870
[17] 150.9903 151.8935 152.7967 153.6999 154.6032 155.5064 156.4096 157.3128
[25] 158.2160 159.1193 160.0225 160.9257 161.8289 162.7322 163.6354 164.5386
[33] 165.4418 166.3450 167.2483 168.1515 169.0547 169.9579 170.8612 171.7644
[41] 172.6676 173.5708 174.4741 175.3773 176.2805 177.1837</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb308"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Read apply(mu,2,mean) as compute the mean of each column (dimension “2”) of the matrix mu. </span></span>
<span><span class="co"># mu.mean contains the average μ at each weight value.</span></span>
<span></span>
<span><span class="va">mu.HPDI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">HPDI</span> , prob<span class="op">=</span><span class="fl">0.89</span> <span class="op">)</span></span>
<span><span class="va">mu.HPDI</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
|0.89 135.2116 136.1477 137.0875 138.0581 139.0424 140.0165 140.9624 141.9149
0.89| 137.8682 138.6893 139.5160 140.3634 141.2290 142.0834 142.9203 143.7605
          [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]
|0.89 142.8937 143.8693 144.8117 145.7576 146.7200 147.6602 148.6317 149.5628
0.89| 144.6261 145.4950 146.3290 147.1679 148.0313 148.8955 149.7764 150.6369
         [,17]    [,18]    [,19]    [,20]    [,21]    [,22]    [,23]    [,24]
|0.89 150.5203 151.4356 152.3918 153.2448 154.1990 155.0672 155.9486 156.8240
0.89| 151.5409 152.3959 153.3029 154.1384 155.0763 155.9642 156.8680 157.7924
         [,25]    [,26]    [,27]    [,28]    [,29]    [,30]    [,31]    [,32]
|0.89 157.7122 158.6214 159.4167 160.2795 161.1081 161.9967 162.8568 163.6530
0.89| 158.7463 159.7201 160.5823 161.5313 162.4416 163.4424 164.4155 165.3188
         [,33]    [,34]    [,35]    [,36]    [,37]    [,38]    [,39]    [,40]
|0.89 164.4585 165.4464 166.2849 167.1235 167.9488 168.8205 169.6570 170.4754
0.89| 166.2431 167.3467 168.2769 169.2420 170.1812 171.1650 172.1245 173.0716
         [,41]    [,42]    [,43]    [,44]    [,45]    [,46]
|0.89 171.3490 172.0761 172.9161 173.8268 174.6666 175.5090
0.89| 174.0722 174.9148 175.8667 176.8964 177.8580 178.8198</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb310"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># mu.HPDI contains 89% lower and upper bounds for each weight value.</span></span>
<span></span>
<span><span class="co">## You can plot these summaries on top of the data with a few lines of R code:</span></span>
<span><span class="co"># plot raw data</span></span>
<span><span class="co"># fading out points to make line and interval more visible</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , data<span class="op">=</span><span class="va">d2</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.5</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the MAP line, aka the mean mu for each weight</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot a shaded region for 89% HPDI</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.HPDI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.54-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb311"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The !Kung height data again, now with 89% HPDI of the mean indicated by the shaded region.</span></span>
<span><span class="co"># The confidence interval for the regression line clings tightly to the MAP line. Thus there is </span></span>
<span><span class="co"># very little uncertainty about the average height as a function of average weight. But you have</span></span>
<span><span class="co"># to keep in mind that these inferences are always conditional on the model. Even a very bad model </span></span>
<span><span class="co"># can have very tight confidence intervals. It may help if you think of the regression line as: </span></span>
<span><span class="co"># Conditional on the assumption that height and weight are related by a straight line, then this is </span></span>
<span><span class="co"># the most plausible line, and these are its plausible bounds.</span></span>
<span></span>
<span><span class="co">## Compare this region to the distributions of blue points on the left.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , <span class="va">d2</span> , type<span class="op">=</span><span class="st">"n"</span> <span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span> , pch<span class="op">=</span><span class="fl">16</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.1</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , data<span class="op">=</span><span class="va">d2</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.5</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.HPDI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.54-3.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Recipe for generating predictions and intervals from the posterior of a fit model</strong></span></span></p>
<ol type="1">
<li><p>Use <code>link</code> to generate distributions of posterior values for <span class="math inline">\(\mu\)</span>. The default behavior of <code>link</code> is to use the original data, so you have to pass it a list of new horizontal axis values you want to plot posterior predictions across.</p></li>
<li><p>Use summary functions like <code>mean</code> or <code>HPDI</code> or <code>PI</code> to find averages and lower and upper bounds of <span class="math inline">\(\mu\)</span> for each value of the predictor variable.</p></li>
<li><p>Finally, use plotting functions like <code>lines</code> and <code>shade</code> to draw the lines and intervals. Or you might plot the distributions of the predictions, or do further numerical calculations with them. It’s really up to you.</p></li>
</ol>
<p><br></p>
<p><span style="color:purple"><strong><em>Manual method for using <code>link</code>:</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb312"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># extract samples from the fitted model</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Predict mu based on weight using linear function</span></span>
<span><span class="va">mu.link</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">weight</span><span class="op">)</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">weight</span></span>
<span></span>
<span><span class="co"># Define sequence of weights, with increment of 1, to compute predictions</span></span>
<span><span class="co"># This clears the repetition in weights?</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="fl">25</span> , to<span class="op">=</span><span class="fl">70</span> , by<span class="op">=</span><span class="fl">1</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># For each value in weight.seq, calculate corresponding mu values based on the linear</span></span>
<span><span class="co"># prediction function mu.link</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.link</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate a vector of mean mu and HPDI for each column (each sample) of mu</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.HPDI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">HPDI</span> , prob<span class="op">=</span><span class="fl">0.89</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># The values in mu.mean and mu.HPDI should be very similar (allowing for </span></span>
<span><span class="co"># simulation variance) to what you got the automated way, using link.</span></span>
<span><span class="va">mu.mean</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] 136.5133 137.4178 138.3224 139.2269 140.1314 141.0360 141.9405 142.8450
 [9] 143.7496 144.6541 145.5586 146.4632 147.3677 148.2723 149.1768 150.0813
[17] 150.9859 151.8904 152.7949 153.6995 154.6040 155.5085 156.4131 157.3176
[25] 158.2222 159.1267 160.0312 160.9358 161.8403 162.7448 163.6494 164.5539
[33] 165.4584 166.3630 167.2675 168.1721 169.0766 169.9811 170.8857 171.7902
[41] 172.6947 173.5993 174.5038 175.4083 176.3129 177.2174</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb314"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mu.HPDI</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]    [,7]     [,8]
|0.89 135.1228 136.0959 137.0740 137.9998 139.0036 139.9663 140.939 141.8791
0.89| 137.8980 138.7439 139.6029 140.4033 141.2856 142.1233 142.978 143.7991
          [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]
|0.89 142.8616 143.8437 144.7841 145.7358 146.7126 147.6459 148.6075 149.5439
0.89| 144.6673 145.5337 146.3656 147.2065 148.0735 148.9037 149.7694 150.6253
         [,17]    [,18]    [,19]    [,20]    [,21]    [,22]    [,23]    [,24]
|0.89 150.5018 151.4115 152.3266 153.2726 154.1779 155.0555 155.9667 156.8508
0.89| 151.5096 152.3599 153.2230 154.1386 155.0351 155.9255 156.8672 157.7912
         [,25]    [,26]    [,27]    [,28]    [,29]    [,30]    [,31]    [,32]
|0.89 157.7197 158.6131 159.4452 160.3071 161.1376 161.9978 162.8348 163.6932
0.89| 158.7213 159.6908 160.6091 161.5680 162.4994 163.4657 164.4168 165.3884
         [,33]    [,34]    [,35]    [,36]    [,37]    [,38]    [,39]    [,40]
|0.89 164.5319 165.3337 166.2479 167.0883 167.9306 168.7694 169.6736 170.4944
0.89| 166.3476 167.2650 168.2961 169.2527 170.2184 171.1847 172.2148 173.1613
         [,41]    [,42]    [,43]    [,44]    [,45]    [,46]
|0.89 171.3201 172.1598 172.9758 173.8282 174.6616 175.4985
0.89| 174.1044 175.0752 176.0202 176.9998 177.9621 178.9302</code></pre>
</div>
</div>
<p><br></p>
</section><section id="prediction-intervals" class="level4"><h4 class="anchored" data-anchor-id="prediction-intervals">Prediction intervals</h4>
<p>Now let’s generate an 89% prediction interval for actual heights, not just the average height, <span class="math inline">\(\mu\)</span> by incorporating the standard deviation <span class="math inline">\(\sigma\)</span> and its uncertainty as well.</p>
<p>Imagine simulating heights. For any unique weight value, you sample from a Gaussian distribution with the correct mean <span class="math inline">\(\mu\)</span> for that weight, using the correct value of <span class="math inline">\(\sigma\)</span> sampled from the same posterior distribution. If you do this for every sample from the posterior, for every weight value of interest, you end up with a collection of simulated heights that embody the uncertainty in the posterior as well as the uncertainty in the Gaussian likelihood.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb316"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">sim.height</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span><span class="va">m4.3</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>weight <span class="op">=</span> <span class="va">weight.seq</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">sim.height</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:1000, 1:46] 138 133 130 138 121 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb318"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This matrix is much like the earlier one, mu, but it contains simulated heights, </span></span>
<span><span class="co"># not distributions of plausible average height, μ.</span></span>
<span></span>
<span><span class="co"># summarize these simulated heights in the same way we summarized the distributions of μ, </span></span>
<span><span class="co"># by using apply</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span><span class="va">height.PI</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>        [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
5%  128.0257 129.3800 129.6916 131.1780 131.9763 132.9732 133.6551 135.0385
94% 145.1718 146.2804 146.5564 147.6428 147.9392 149.4940 149.8135 151.3247
        [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]
5%  135.4157 136.7905 136.8810 138.1681 139.2892 140.0822 141.0531 142.3578
94% 151.6734 152.7652 154.1218 154.7414 155.3389 156.7849 157.1990 158.6948
       [,17]    [,18]    [,19]    [,20]    [,21]    [,22]    [,23]    [,24]
5%  142.6614 143.8248 144.5495 145.6911 146.5705 147.7918 148.7379 149.1228
94% 158.6664 159.5101 160.9669 161.7695 163.2296 163.4734 164.3689 165.0375
       [,25]    [,26]    [,27]    [,28]    [,29]    [,30]    [,31]    [,32]
5%  149.6368 151.2258 151.5497 152.6808 153.4813 154.9450 155.7315 157.0476
94% 166.1384 167.1709 168.3096 168.9101 170.0511 170.6098 171.5950 172.4373
       [,33]    [,34]    [,35]    [,36]    [,37]    [,38]    [,39]    [,40]
5%  157.3364 158.2040 159.3102 160.2719 160.7322 161.6270 162.7587 163.2640
94% 173.2906 175.1593 174.6574 176.2359 177.6501 178.4217 178.8976 179.2978
       [,41]    [,42]    [,43]    [,44]    [,45]    [,46]
5%  163.6216 165.5888 166.1724 166.8258 169.0068 168.7557
94% 180.9031 182.1532 183.7335 183.9171 184.6704 185.9164</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb320"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now height.PI contains the 89% posterior prediction interval of observable </span></span>
<span><span class="co"># (according to the model) heights, across the values of weight in weight.seq.</span></span>
<span></span>
<span><span class="co">## Plot everything we’ve built up: (1) the MAP line, (2) the shaded region of 89% plausible μ, </span></span>
<span><span class="co">## and (3) the boundaries of the simulated heights the model expects</span></span>
<span><span class="co"># plot raw data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , <span class="va">d2</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.5</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># draw MAP line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># draw HPDI region for line</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.HPDI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># draw PI region for simulated heights</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">height.PI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.59-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb321"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 89% prediction interval for height, as a function of weight. The solid line is </span></span>
<span><span class="co"># the MAP estimate of the mean height at each weight. The two shaded regions show </span></span>
<span><span class="co"># different 89% plausible regions. The narrow shaded interval around the line is </span></span>
<span><span class="co"># the distribution of μ. The wider shaded region represents the region within which </span></span>
<span><span class="co"># the model expects to find 89% of actual heights in the population, at each weight.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Notice that the outline for the wide shaded interval is a little jagged. This is the simulation variance in the tails of the sampled Gaussian values. If it really bothers you, increase the number of samples you take from the posterior distribution. The optional n parameter for sim.height controls how many samples are used.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb322"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Increase samples for simulation</span></span>
<span><span class="va">sim.height</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span><span class="va">m4.3</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>weight <span class="op">=</span> <span class="va">weight.seq</span><span class="op">)</span>, n <span class="op">=</span> <span class="fl">1e4</span><span class="op">)</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the PI again</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , <span class="va">d2</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.5</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.HPDI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">height.PI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.62-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Compare 67% and 97% intervals</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb323"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate height</span></span>
<span><span class="va">sim.height</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span><span class="va">m4.3</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>weight <span class="op">=</span> <span class="va">weight.seq</span><span class="op">)</span><span class="op">)</span></span>
<span>                  </span>
<span><span class="co"># Plot for 67%</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.67</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight</span>, <span class="va">d2</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.5</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"67% interval"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.HPDI</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot for 97%</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.97</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight</span>, <span class="va">d2</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.5</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"97% interval"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.HPDI</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI</span>, <span class="va">weight.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/67.97-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Manual method for using <code>sim</code>:</em></strong></span></p>
<p>For every distribution like <code>dnorm</code>, there is a companion simulation function. For the Gaussian distribution, the companion is <code>rnorm</code>, and it simulates sampling from a Gaussian distribution. What we want R to do is simulate a height for each set of samples, and to do this for each value of weight.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb324"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract posterior or prior samples from map model</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m4.3</span><span class="op">)</span> <span class="co"># default n = 1e4</span></span>
<span></span>
<span><span class="co"># Define weight sequence</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fl">25</span><span class="op">:</span><span class="fl">70</span></span>
<span></span>
<span><span class="co"># Simulate height </span></span>
<span><span class="va">sim.height</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">weight</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span> <span class="co"># use rnorm to generate random normal values based on the parameters</span></span>
<span>        n<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span> ,</span>
<span>        mean<span class="op">=</span><span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">weight</span> ,</span>
<span>        sd<span class="op">=</span><span class="va">post</span><span class="op">$</span><span class="va">sigma</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate predicted interval of height</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">sim.height</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.89</span> <span class="op">)</span></span>
<span><span class="va">height.PI</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>        [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
5%  128.3884 129.2736 130.2988 130.8303 131.9955 132.8478 133.6574 134.4935
94% 144.8649 145.6431 146.6622 147.3777 148.2592 149.1830 150.1585 150.9093
        [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]
5%  135.5869 136.4315 137.3949 138.2955 139.3066 140.1335 140.9863 141.8547
94% 151.9254 152.9101 153.6763 154.5660 155.4227 156.5028 157.4568 158.4198
       [,17]    [,18]    [,19]    [,20]    [,21]    [,22]    [,23]    [,24]
5%  142.7477 143.8488 144.7845 145.6808 146.6204 147.3504 148.2321 149.0631
94% 159.1023 159.9364 160.8981 161.7570 162.7998 163.7500 164.6164 165.1787
       [,25]    [,26]    [,27]    [,28]    [,29]    [,30]    [,31]    [,32]
5%  150.1110 150.9457 151.8835 152.8803 153.6890 154.6917 155.5799 156.4665
94% 166.2316 167.2236 168.3244 169.1053 169.9668 170.8769 171.8860 172.6328
       [,33]    [,34]    [,35]    [,36]    [,37]    [,38]    [,39]    [,40]
5%  157.2903 158.3571 159.0885 160.0308 160.8785 161.8910 162.6509 163.5740
94% 173.6574 174.3895 175.4786 176.2984 177.1460 178.2647 178.8724 180.1459
       [,41]    [,42]    [,43]    [,44]    [,45]    [,46]
5%  164.6782 165.4097 166.2182 167.0491 168.0197 168.8356
94% 180.8342 181.7266 182.9200 183.6104 184.3734 185.3674</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb326"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The values in height.PI will be practically identical to the ones computed above for 89%.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section></section><section id="polynomial-regression" class="level2"><h2 class="anchored" data-anchor-id="polynomial-regression">Polynomial regression</h2>
<p>It helps to see how to model the outcome as a curved function of a single predictor. The models so far all assume that a straight line describes the relationship. But there’s nothing special about straight lines, aside from their simplicity.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb327"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Howell1"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create data set d including all data </span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   544 obs. of  4 variables:
 $ height: num  152 140 137 157 145 ...
 $ weight: num  47.8 36.5 31.9 53 41.3 ...
 $ age   : num  63 63 65 41 51 35 32 27 19 54 ...
 $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb329"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot d</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.64-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb330"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The relationship is visibly curved, now that we’ve included the non-adult individuals.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Polynomial regression is one of the ways to model a curved relationship between two variables. In this context, “polynomial” means equations for <span class="math inline">\(\mu_i\)</span> that add additional terms with squares, cubes, and even higher powers of the predictor variable. There’s still only one predictor variable in the model, so this is still a bivariate regression. But the definition of <span class="math inline">\(\mu_i\)</span> has more parameters now.</p>
<p>The most common polynomial regression, a parabolic model of the mean:</p>
<p><span class="math display">\[\mu_i = \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i^2\]</span> <br></p>
<p>The above is a parabolic (second order) polynomial. The <span class="math inline">\(\alpha + \beta_1 \text{x}_i\)</span> part is the same linear function of x in a linear regression, just with a little “1” subscript added to the parameter name, so we can tell it apart from the new parameter. The additional term uses the square of <span class="math inline">\(x_i\)</span> to construct a parabola, rather than a perfectly straight line. The new parameter <span class="math inline">\(\beta_2\)</span> measures the curvature of the relationship.</p>
<p>The parabolic model of <span class="math inline">\(\mu_i\)</span> above is still called a “linear model” of the mean. What “linear” usually means in this context is that <span class="math inline">\(\mu_i\)</span> is a linear function of any single parameter.</p>
<p><br></p>
<section id="fitting-the-model-to-data" class="level3"><h3 class="anchored" data-anchor-id="fitting-the-model-to-data">Fitting the model to data</h3>
<p>The first thing to do is to standardize the predictor variable. This means to first center the variable and then divide it by its standard deviation.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb331"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Subtract the mean and then divide by the standard deviation to standardize weight</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">weight.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">weight</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span><span class="op">)</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span><span class="co"># This new variable weight.s has mean zero and standard deviation 1.</span></span>
<span></span>
<span><span class="co"># Plot the standardized data to verify no information has been lost</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.65-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb332"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The same curved relationship as before, but now with a different range on the horizontal axis.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Parabolic regression</strong></span></span></p>
<p>To fit the parabolic model, just modify the definition of <span class="math inline">\(\mu_i\)</span>. Here’s the model (with very weak priors):</p>
<p>$$</p>
<p><span class="math display">\[\begin{align*}

\text{h}_i &amp; \sim \text{Normal}(\mu_i, \sigma) \ &amp;&amp;&amp; \text{height} &amp; \sim \text{dnorm(mu, sigma)} \\

\mu_i &amp; = \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i^2 \ &amp;&amp;&amp; \text{mu} &amp; \leftarrow \text{a + b1*weight.s + b2*weight.s^2} \\

\alpha &amp;\sim \text{Normal}(178, 100) \ &amp;&amp;&amp; a &amp;\sim \text{dnorm}(178, 100)\\

\beta_1 &amp;\sim \text{Normal}(0, 10) \ &amp;&amp;&amp; b1 &amp;\sim \text{dnorm}(0, 10)\\

\beta_2 &amp;\sim \text{Normal}(0, 10) \ &amp;&amp;&amp; b2 &amp;\sim \text{dnorm}(0,10)\\         

\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; \text{sigma} &amp;\sim \text{dunif}(0, 50)

\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb333"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Build the square weight.s as separate variable</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">weight.s2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">weight.s</span><span class="op">^</span><span class="fl">2</span></span>
<span></span>
<span><span class="co"># Fit the model by modifying the definition of mu so that it contains </span></span>
<span><span class="co"># both the ordinary and quadratic terms</span></span>
<span><span class="va">m4.5</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b1</span><span class="op">*</span><span class="va">weight.s</span> <span class="op">+</span> <span class="va">b2</span><span class="op">*</span><span class="va">weight.s2</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">178</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">b1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">b2</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summarize the map model</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
a     146.663372 0.3736588 146.066193 147.260551
b1     21.400360 0.2898512  20.937122  21.863599
b2     -8.415054 0.2813197  -8.864657  -7.965451
sigma   5.749786 0.1743169   5.471194   6.028378</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb335"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The parameter α (a) is still the intercept, so it tells us the expected value of height </span></span>
<span><span class="co"># when weight.s is zero. But it is no longer equal to the mean height in the sample, </span></span>
<span><span class="co"># since there is no guarantee it should in a polynomial regression.</span></span>
<span><span class="co"># β1 and β2 parameters are the linear and square components of the curve, respectively.</span></span>
<span></span>
<span><span class="co">## Plot the model fits</span></span>
<span><span class="co"># Calculate the mean relationship and the 89% intervals of the mean and the predictions</span></span>
<span><span class="co"># Define predictor values for weight</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="op">-</span><span class="fl">2.2</span> , to<span class="op">=</span><span class="fl">2</span> , length.out<span class="op">=</span><span class="fl">30</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a list with weight.s and weight.s2 values (pre-calculation)</span></span>
<span><span class="va">pred_dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span> weight.s<span class="op">=</span><span class="va">weight.seq</span> , weight.s2<span class="op">=</span><span class="va">weight.seq</span><span class="op">^</span><span class="fl">2</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate predicted mu values based on model m4.5 using predictor values in pred_dat</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m4.5</span> , data<span class="op">=</span><span class="va">pred_dat</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate mean of predicted mu values across columns</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate prediction interval with prob 89% of the predicted mu values</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.89</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate height values based on model m4.5 using predictor values in pred_dat</span></span>
<span><span class="va">sim.height</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span> <span class="va">m4.5</span> , data<span class="op">=</span><span class="va">pred_dat</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate prediction interval for simulated heights with prob 89%</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">sim.height</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.89</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot MAP, PI of predicted means and PI of simulated heights</span></span>
<span><span class="co"># Plot raw data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span> , <span class="va">d</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.5</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Add map line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade prediction interval for mu values</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade prediction interval for simulated heights</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">height.PI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.66-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb336"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The curve does a much better job of finding a central path through the data, than </span></span>
<span><span class="co"># the linear model. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Cubic regression</strong></span></span></p>
<p>The model is (hiding the priors, but they are the same as before):</p>
<p><span class="math display">\[\text{h}_i \sim \text{Normal}(\mu_i, \sigma)\]</span> <span class="math display">\[\mu_i = \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i^2 + \beta_3 \text{x}_i^3\]</span></p>
<p><br></p>
<p>Fit the model with a slight modification of the parabolic model’s code:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb337"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a separate variable for cubic weight</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">weight.s3</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">weight.s</span><span class="op">^</span><span class="fl">3</span></span>
<span></span>
<span><span class="co"># Fit the map model</span></span>
<span><span class="va">m4.6</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b1</span><span class="op">*</span><span class="va">weight.s</span> <span class="op">+</span> <span class="va">b2</span><span class="op">*</span><span class="va">weight.s2</span> <span class="op">+</span> <span class="va">b3</span><span class="op">*</span><span class="va">weight.s3</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b2</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b3</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Summarize the map model</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4.6</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
a     146.726822 0.3133552 146.226020 147.227624
b1     15.025323 0.4840313  14.251748  15.798899
b2     -6.533714 0.2662315  -6.959204  -6.108225
b3      3.592713 0.2357316   3.215969   3.969458
sigma   4.820986 0.1461592   4.587395   5.054577</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb339"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Define predictor values for weight</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">2.2</span>, to <span class="op">=</span> <span class="fl">2</span>, length.out <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a list with weight.s, weight.s2 and weight.s3 values</span></span>
<span><span class="va">pred_dat_c</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>weight.s <span class="op">=</span> <span class="va">weight.seq</span>, weight.s2 <span class="op">=</span> <span class="va">weight.seq</span><span class="op">^</span><span class="fl">2</span>, weight.s3 <span class="op">=</span> <span class="va">weight.seq</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate predicted mu values for based on model and predictor values</span></span>
<span><span class="va">mu_c</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m4.6</span>, data <span class="op">=</span> <span class="va">pred_dat_c</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate mean of predicted mu values across column</span></span>
<span><span class="va">mu.mean_c</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu_c</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate PI of predicted mu values (89% interval)</span></span>
<span><span class="va">mu.PI_c</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu_c</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate height values based on model and predictor values</span></span>
<span><span class="va">sim.height_c</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span><span class="va">m4.6</span>, data <span class="op">=</span> <span class="va">pred_dat_c</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate PI of simulated heights</span></span>
<span><span class="va">height.PI_c</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height_c</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot raw data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add map line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean_c</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI for mu values</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI_c</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI of simulated heights</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI_c</span>, <span class="va">weight.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.70-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb340"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This cubic curve is even more flexible than the parabola, so it fits the data even better.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Compare linear, parabolic and cubic regressions</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb341"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the linear regression</span></span>
<span><span class="va">m4_l</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight.s</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">178</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4_l</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
a     138.264232 0.4007022 137.623833 138.904632
b      25.927289 0.4007599  25.286797  26.567781
sigma   9.345976 0.2833471   8.893132   9.798819</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb343"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">2.2</span>, to <span class="op">=</span> <span class="fl">2</span>, length.out <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span><span class="va">pred_dat_l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>weight.s <span class="op">=</span> <span class="va">weight.seq</span><span class="op">)</span></span>
<span><span class="va">mu_l</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m4_l</span>, data <span class="op">=</span> <span class="va">pred_dat_l</span><span class="op">)</span></span>
<span><span class="va">mu.mean_l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu_l</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span><span class="va">mu.PI_l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu_l</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span><span class="va">sim.height_l</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span><span class="va">m4_l</span>, data <span class="op">=</span> <span class="va">pred_dat_l</span><span class="op">)</span></span>
<span><span class="va">height.PI_l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height_l</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.5</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"(a)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean_l</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI_l</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI_l</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the parabolic regression</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span> , <span class="va">d</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.5</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"(b)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">height.PI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the cubic regression</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.5</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"(c)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean_c</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI_c</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI_c</span>, <span class="va">weight.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/regression-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb344"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Polynomial regressions of height on weight (standardized),for the full !Kung data. </span></span>
<span><span class="co"># In each plot, the raw data are shown by the circles. The solid curves show the path </span></span>
<span><span class="co"># of μ in each model, and the shaded regions show the 89% interval of the mean (close to </span></span>
<span><span class="co"># the solid curve) and the 89% interval of predictions (wider). </span></span>
<span><span class="co"># (a) Linear regression. (b) A second order polynomial, a parabolic regression. </span></span>
<span><span class="co"># (c) A third order polynomial, a cubic regression.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Converting back to natural scale</strong></span></span></p>
<p>The three plots above have standard units on the horizontal axis. These units are sometimes called z-scores. But suppose you fit the model using standardized variables, but want to plot the estimates on the original scale. All that’s really needed is first to turn off the horizontal axis when you plot the raw data:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb345"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Turn off the horizontal axis using xaxt (x-axis shouldn't be plotted- to plot manually)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.5</span><span class="op">)</span>, xaxt <span class="op">=</span> <span class="st">"n"</span><span class="op">)</span> <span class="co"># n = none</span></span>
<span></span>
<span><span class="co">## Construct the axis, using axis function</span></span>
<span><span class="co"># Defines location of the labels, in standardized units</span></span>
<span><span class="va">at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span>,<span class="op">-</span><span class="fl">1</span>,<span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert those units back to the original scale</span></span>
<span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="va">at</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Draw the axis                     # round the labels to 1 decimal place</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span>side <span class="op">=</span> <span class="fl">1</span> , at <span class="op">=</span> <span class="va">at</span> , labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">labels</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="co"># 1=below, 2=left, 3=above, 4=right</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4.71-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
</section></section><section id="practice-2" class="level2"><h2 class="anchored" data-anchor-id="practice-2">Practice</h2>
<section id="easy-2" class="level3"><h3 class="anchored" data-anchor-id="easy-2">Easy</h3>
<p><br></p>
<p>4E1. <span class="math inline">\(\text{y}_i \sim \text{Normal}(\mu, \sigma)\)</span></p>
<p><br></p>
<p>4E2. two parameters: mu and sigma</p>
<p><br></p>
<p>4E3. <span class="math inline">\(Pr(\mu, \sigma|y) = \frac{Normal(y|\mu,\sigma) Normal(\mu|0,10) Uniform(\sigma|0,10) }{\int \int Normal(y|\mu,\sigma) Normal(\mu|0,10) Uniform(\sigma|0,10)d\mu d\sigma}\)</span></p>
<p><br></p>
<p>4E4. <span class="math inline">\(\mu_i = \alpha + \beta \text{x}_i\)</span></p>
<p><br></p>
<p>4E5. three parameters: alpha, beta and sigma</p>
<p><br></p>
</section><section id="medium-2" class="level3"><h3 class="anchored" data-anchor-id="medium-2">Medium</h3>
<p>4M1.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb346"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Generate samples for mu</span></span>
<span><span class="va">sample_mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1e4</span>, <span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Generate samples for sigma</span></span>
<span><span class="va">sample_sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1e4</span>, <span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate heights from prior</span></span>
<span><span class="va">prior_height</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1e4</span>, <span class="va">sample_mu</span>, <span class="va">sample_sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot heights</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">prior_height</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4M1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p>4M2.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb347"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Howell1"</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">age</span> <span class="op">&gt;=</span> <span class="fl">18</span>, <span class="op">]</span></span>
<span></span>
<span></span>
<span><span class="va">m.4m2</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>    <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d2</span></span>
<span><span class="op">)</span> </span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.4m2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
mu    154.334718 0.4124415 153.675557 154.993879
sigma   7.735763 0.2918871   7.269271   8.202255</code></pre>
</div>
</div>
<p><br></p>
<p>4M3. <span class="math display">\[\text{y}_i \sim \text{Normal}(\mu, \sigma)\]</span> <span class="math display">\[\mu = \alpha + \beta \text{x}_i \]</span> <span class="math display">\[\alpha \sim \text{Normal(0, 50)}\]</span> <span class="math display">\[\beta \sim \text{Normal(0, 10)}\]</span> <span class="math display">\[\sigma \sim \text{Uniform(0, 50)}\]</span></p>
<p><br></p>
<p>4M4. We don’t know the age and gender of students. So, we will use uninformative priors, inclusive school age children to adult. 200 is chosen considering the adult height (may not be necessary?) and mean <span class="math inline">\(\beta\)</span> is zero considering height will not increase if the students are adult, but <span class="math inline">\(\sigma\)</span> is 40 to leave room for potential increase in height.</p>
<p><span class="math display">\[\text{h}_i \sim \text{Normal}(\mu, \sigma)\]</span> <span class="math display">\[\mu = \alpha + \beta \text{y}_i\]</span> <span class="math display">\[\alpha \sim \text{Normal}(0, 200)\]</span> <span class="math display">\[\beta \sim \text{Normal}(0, 40)\]</span> <span class="math display">\[\sigma \sim \text{Uniform}(0, 50)\]</span></p>
<p><br></p>
<p>4M5. Since average age is 120 cm, we will assume the students are around 7 years old, and estimate annual growth at 6-7 cm per year based on literature.</p>
<p><span class="math display">\[\text{h}_i \sim \text{Normal}(\mu, \sigma)\]</span> <span class="math display">\[\mu = \alpha + \beta \text{y}_i\]</span></p>
<p><span class="math display">\[\alpha \sim \text{Normal}(120, 20)\]</span> <span class="math display">\[\beta \sim \text{Normal}(6, 10)\]</span></p>
<p><span class="math display">\[\sigma \sim \text{Uniform}(0, 30)\]</span></p>
<p><br></p>
<p>4M6. If the variance among heights for students of the same age is never more than 64cm:</p>
<p><span class="math display">\[\text{h}_i \sim \text{Normal}(\mu, \sigma)\]</span></p>
<p><span class="math display">\[\mu = \alpha + \beta \text{y}_i\]</span></p>
<p><span class="math display">\[\alpha \sim \text{Normal}(120, 20)\]</span></p>
<p><span class="math display">\[\beta \sim \text{Normal}(6, 10)\]</span> <span class="math display">\[\sigma \sim \text{Uniform}(0, 64)\]</span></p>
<p><br></p>
</section><section id="hard-2" class="level3"><h3 class="anchored" data-anchor-id="hard-2">Hard</h3>
<blockquote class="blockquote">
<p>4H1. The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb349"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create map model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Howell1"</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">mN</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span> </span>
<span>     <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">120</span>, <span class="fl">20</span><span class="op">)</span>,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">64</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  </span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">mN</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean         sd      5.5%     94.5%
a     75.557160 1.04839485 73.881622 77.232697
b      1.761392 0.02721691  1.717894  1.804890
sigma  9.345995 0.28334886  8.893148  9.798841</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb351"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract samples from map model</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mN</span>, n <span class="op">=</span> <span class="fl">1e5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># For individual1 with weight 46.95</span></span>
<span><span class="va">mu_at_46.95</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">46.95</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">mu_at_46.95</span>, xlab <span class="op">=</span> <span class="st">"mu|weight = 46.95"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4H1-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb352"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">mu_at_46.95</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 158.2527</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb354"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">mu_at_46.95</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
157.4462 159.0633 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb356"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># For individual2 with weight 43.72</span></span>
<span><span class="va">mu_at_43.72</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">43.72</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">mu_at_43.72</span>, xlab <span class="op">=</span> <span class="st">"mu|weight = 43.72"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4H1-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb357"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">mu_at_43.72</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 152.5638</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb359"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">mu_at_43.72</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
151.8321 153.3024 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb361"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># For individual3 with weight 64.78</span></span>
<span><span class="va">mu_at_64.78</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">64.78</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">mu_at_64.78</span>, xlab <span class="op">=</span> <span class="st">"mu|weight = 64.78"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4H1-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb362"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">mu_at_64.78</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 189.6566</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb364"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">mu_at_64.78</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
188.2339 191.0790 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb366"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># For individual4 with weight 32.59</span></span>
<span><span class="va">mu_at_32.59</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">32.59</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">mu_at_32.59</span>, xlab <span class="op">=</span> <span class="st">"mu|weight = 32.59"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4H1-4.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb367"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">mu_at_32.59</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 132.9605</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb369"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">mu_at_32.59</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
132.3014 133.6105 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb371"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># For individual5 with weight 54.63</span></span>
<span><span class="va">mu_at_54.63</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span> <span class="op">*</span> <span class="fl">54.63</span></span>
<span><span class="fu">dens</span><span class="op">(</span><span class="va">mu_at_54.63</span>, xlab <span class="op">=</span> <span class="st">"mu|weight = 54.63"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4H1-5.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb372"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">mu_at_54.63</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 171.7795</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb374"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">mu_at_54.63</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>   |0.89    0.89| 
170.7338 172.8234 </code></pre>
</div>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Given Answer:</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb376"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># First, fit the model with map, to provide a quadratic approximation of the posterior. </span></span>
<span><span class="co"># I’ll use quite flat priors here, but if you used stronger priors, that’s fine. </span></span>
<span><span class="co"># What matters is the procedure be coherent.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Howell1</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">age</span><span class="op">&gt;=</span><span class="fl">18</span>,<span class="op">]</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">100</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d2</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Then produce samples from the quadratic approximate posterior. You could use mvrnorm directly, </span></span>
<span><span class="co"># or the convenient extract.samples function:</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">m</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   10000 obs. of  3 variables:
 $ a    : num  115 114 115 113 116 ...
 $ b    : num  0.891 0.903 0.868 0.92 0.86 ...
 $ sigma: num  5.08 4.74 5.16 5.21 5.22 ...
 - attr(*, "source")= chr "quap posterior: 10000 samples from m"</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb378"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now we want to plug the weights in the table into this model, and then average over </span></span>
<span><span class="co"># the posterior to compute predictions for each individual’s height. The question is ambiguous </span></span>
<span><span class="co"># as to whether it wants μ only or rather the distribution of individual height measurements </span></span>
<span><span class="co"># (using σ). I’ll show the harder approach, that uses σ and simulates individual heights. </span></span>
<span><span class="co"># Also, I won’t use link or sim, but it’s fine if you did.</span></span>
<span></span>
<span><span class="co"># For the first individual, the code might look like this:</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span> <span class="fl">1e5</span> , <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="fl">46.95</span> , <span class="va">post</span><span class="op">$</span><span class="va">sigma</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 156.3435</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb380"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">HPDI</span><span class="op">(</span><span class="va">y</span>,prob<span class="op">=</span><span class="fl">0.90</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>    |0.9     0.9| 
148.1546 164.8277 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb382"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># How does the code work? The first line, which includes rnorm, simulates 100-thousand heights, </span></span>
<span><span class="co"># using the samples from the posterior and an assumed weight of 46.95 kg. The second line then </span></span>
<span><span class="co"># computes the average of these simulated heights. That gives the expected (mean) height. </span></span>
<span><span class="co"># The third line then computes the 90% HPDI of height.</span></span>
<span><span class="co"># You could have also computed the expected heights straight from the MAP. </span></span>
<span><span class="co"># That approach is fine, and will give nearly the same answer.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>4H2. Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right, you should end up with a new data frame with 192 rows in it.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb383"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Select out all the rows in the Howell1 data with ages below 18 years of age</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Howell1"</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">age</span> <span class="op">&lt;</span> <span class="fl">18</span>, <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   192 obs. of  4 variables:
 $ height: num  121.9 105.4 86.4 129.5 109.2 ...
 $ weight: num  19.6 13.9 10.5 23.6 16 ...
 $ age   : num  12 8 6.5 13 7 17 16 11 17 8 ...
 $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb385"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## (a) Fit a linear regression to these data, using map. Present and interpret the estimates. </span></span>
<span><span class="co">## For every 10 units of increase in weight, how much taller does the model predict a child gets?</span></span>
<span></span>
<span><span class="co"># Fit a linear regression using map</span></span>
<span><span class="va">mN</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span> </span>
<span>     <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">120</span>, <span class="fl">20</span><span class="op">)</span>,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">64</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  </span>
<span>  data <span class="op">=</span> <span class="va">d2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">mN</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean         sd      5.5%     94.5%
a     58.527862 1.39427353 56.299543 60.756180
b      2.707042 0.06817725  2.598081  2.816002
sigma  8.438096 0.43070578  7.749745  9.126447</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb387"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The model predicts the child's height at 58.53 cm when the predictor value is zero.</span></span>
<span><span class="co"># Every 1 unit increase in weight, the model predicts 2.71 cm increase in height.</span></span>
<span><span class="co"># So, height will be increased by 27.1 cm (sd = 0.07) for every 10 units increase in weight. </span></span>
<span></span>
<span><span class="co">## (b) Plot the raw data, with height on the vertical axis and weight on the horizontal axis. </span></span>
<span><span class="co">## Superimpose the MAP regression line and 89% HPDI for the mean. Also superimpose the </span></span>
<span><span class="co">## 89% HPDI for predicted heights.</span></span>
<span></span>
<span><span class="co"># Compute mu for each chase in data and sample for posterior distribution</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mN</span><span class="op">)</span></span>
<span><span class="va">mu.link</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">weight</span><span class="op">)</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">weight</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">50</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.link</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:10000, 1:51] 58.8 56.8 57.1 56.6 61 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb389"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute mean and HPDI of mu </span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span><span class="va">mu.HPDI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">HPDI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the raw data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight</span>, <span class="va">d2</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"red"</span>, <span class="fl">0.4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add map line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade 89% HDPI</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.HPDI</span>, <span class="va">weight.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4H2-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb390"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## (c) What aspects of the model fit concern you? Describe the kinds of assumptions</span></span>
<span><span class="co">## you would change, if any, to improve the model. You don’t have to write any new code. </span></span>
<span><span class="co">## Just explain what the model appears to be doing a bad job of, and what you hypothesize </span></span>
<span><span class="co">## would be a better model.</span></span>
<span></span>
<span><span class="co"># The MAP line of the linear regression does not follow the central path of the data.</span></span>
<span><span class="co"># Hence, the model does not fit the data well. A cubic regression might be a better </span></span>
<span><span class="co"># model, considering the curvature of the distribution. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Check model fit with cubic regression</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb391"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Test cubic regression</span></span>
<span><span class="co"># Standardize the weights</span></span>
<span><span class="va">weight.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span><span class="op">)</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Pre-calculate weight.s2 and weight.s3</span></span>
<span><span class="va">weight.s2</span> <span class="op">&lt;-</span> <span class="va">weight.s</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">weight.s3</span> <span class="op">&lt;-</span> <span class="va">weight.s</span><span class="op">^</span><span class="fl">3</span></span>
<span></span>
<span><span class="co"># Fit the map model</span></span>
<span><span class="va">mN</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span> </span>
<span>     <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b1</span><span class="op">*</span><span class="va">weight.s</span> <span class="op">+</span> <span class="va">b2</span><span class="op">*</span><span class="va">weight.s2</span> <span class="op">+</span> <span class="va">b3</span><span class="op">*</span><span class="va">weight.s3</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">120</span>, <span class="fl">20</span><span class="op">)</span>,</span>
<span>        <span class="va">b1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">b2</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">b3</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">64</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  </span>
<span>  data <span class="op">=</span> <span class="va">d2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">mN</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean        sd        5.5%      94.5%
a     114.6859399 0.4257396 114.0055258 115.366354
b1     28.0288745 0.5392952  27.1669767  28.890772
b2     -6.8890924 0.4302736  -7.5767528  -6.201432
b3      0.5985093 0.2163291   0.2527736   0.944245
sigma   4.1795770 0.2133009   3.8386809   4.520473</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb393"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Define weight sequence</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">2</span>, to <span class="op">=</span> <span class="fl">3</span>, length.out <span class="op">=</span> <span class="fl">61</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a list of predictor data</span></span>
<span><span class="va">pred_dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>weight.s <span class="op">=</span> <span class="va">weight.seq</span>, weight.s2 <span class="op">=</span> <span class="va">weight.seq</span><span class="op">^</span><span class="fl">2</span>, weight.s3 <span class="op">=</span> <span class="va">weight.seq</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate predicted mu values for based on model and predictor values</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">mN</span>, data <span class="op">=</span> <span class="va">pred_dat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate mean of predicted mu values across column</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate PI of predicted mu values (89% interval)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate height values based on model and predictor values</span></span>
<span><span class="va">sim.height</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span><span class="va">mN</span>, data <span class="op">=</span> <span class="va">pred_dat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate PI of simulated heights</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.89</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot raw data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span>, <span class="va">d2</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"red"</span>, <span class="fl">0.5</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="st">"weight"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add map line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI for mu values</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI of simulated heights</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI</span>, <span class="va">weight.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/test.cubic-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb394"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Convert back to natural scale</span></span>
<span><span class="co"># Remove x-axis </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">height</span> <span class="op">~</span> <span class="va">weight.s</span>, <span class="va">d2</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"red"</span>, <span class="fl">0.5</span><span class="op">)</span>, xaxt <span class="op">=</span> <span class="st">"n"</span>, xlab <span class="op">=</span> <span class="st">"weight"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Defines location of the labels, in standardized units</span></span>
<span><span class="va">at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert those units back to the original scale</span></span>
<span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="va">at</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d2</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Draw the axis                    </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span>side <span class="op">=</span> <span class="fl">1</span> , at <span class="op">=</span> <span class="va">at</span> , labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">labels</span>,<span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Draw map line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">weight.seq</span>, <span class="va">mu.mean</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI for mu values</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">weight.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI of simulated heights</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI</span>, <span class="va">weight.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/test.cubic-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Given answer:</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb395"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">37</span><span class="op">)</span></span>
<span><span class="co">## (a)First make a new data frame with just the non-adults in it:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Howell1</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">d3</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span> <span class="va">d</span><span class="op">$</span><span class="va">age</span> <span class="op">&lt;</span> <span class="fl">18</span> , <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   192 obs. of  4 variables:
 $ height: num  121.9 105.4 86.4 129.5 109.2 ...
 $ weight: num  19.6 13.9 10.5 23.6 16 ...
 $ age   : num  12 8 6.5 13 7 17 16 11 17 8 ...
 $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb397"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now find the quadratic approximate posterior. The code is the same as before. </span></span>
<span><span class="co"># The data frame just changes.</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">weight</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">100</span> , <span class="fl">100</span> <span class="op">)</span>,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d3</span> <span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean        sd      5.5%     94.5%
a     58.236647 1.3962430 56.005181 60.468113
b      2.719778 0.0682463  2.610707  2.828849
sigma  8.432267 0.4299375  7.745143  9.119390</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb399"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The estimates suggest that the MAP coefficient for weight is 2.7. This implies that </span></span>
<span><span class="co"># for a unit change of 1kg of weight, we predict an average of 2.7cm of increase in height.</span></span>
<span></span>
<span><span class="co">## (b) Now to plot the raw data and superimpose the model estimates, modify the code in </span></span>
<span><span class="co">## Chapter 4. We will sample from the naive posterior, then compute 90% intervals for the </span></span>
<span><span class="co">## mean and predicted heights. This is what the complete code looks like, if you opt not </span></span>
<span><span class="co">## to use the convenience functions link and sim:</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">m</span> <span class="op">)</span></span>
<span><span class="va">w.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fl">1</span>,to<span class="op">=</span><span class="fl">45</span>,length.out<span class="op">=</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">z</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span>    <span class="fu">HPDI</span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">z</span> , prob<span class="op">=</span><span class="fl">0.9</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">pred.ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span>    <span class="fu">HPDI</span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">z</span>,<span class="va">post</span><span class="op">$</span><span class="va">sigma</span><span class="op">)</span> , <span class="fl">0.9</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># And then to plot everything:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , data<span class="op">=</span><span class="va">d3</span> ,</span>
<span>    col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"slateblue"</span>,<span class="fl">0.5</span><span class="op">)</span> , cex<span class="op">=</span><span class="fl">0.5</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="va">mu</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="va">mu.ci</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="va">mu.ci</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="va">pred.ci</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">w.seq</span> , <span class="va">pred.ci</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3.7-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb400"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## (c) The major problem with this model appears to be that the relationship between </span></span>
<span><span class="co">## weight and height, for non-adults, isn’t very linear. Instead it is curved. As a result, </span></span>
<span><span class="co">## at low weight values, the predicted mean is above most of the actual heights. At middle </span></span>
<span><span class="co">## weight values, the predicted mean is below most of the heights. Then again at high </span></span>
<span><span class="co">## weight values, the mean is above the heights.</span></span>
<span><span class="co"># A parabolic model would likely fit these data much better. But that’s not the only option. </span></span>
<span><span class="co"># What we’re after essentially is some way to model a reduction of the slope between height </span></span>
<span><span class="co"># and weight, as weight increases. And onwards to the next solution, which does that, for the </span></span>
<span><span class="co"># entire data.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>4H3. Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body weight that scales with height!” Let’s take your colleague’s advice and see what happens.</p>
</blockquote>
<blockquote class="blockquote">
<ol type="a">
<li>Model the relationship between height (cm) and the natural logarithm of weight (log-kg). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Fit this model, using quadratic approximation:</li>
</ol>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb401"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Use entire Howell1 data frame</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Howell1"</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   544 obs. of  4 variables:
 $ height: num  152 140 137 157 145 ...
 $ weight: num  47.8 36.5 31.9 53 41.3 ...
 $ age   : num  63 63 65 41 51 35 32 27 19 54 ...
 $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb403"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">qfit</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">178</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  </span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">qfit</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
a     -23.784249 1.3351162 -25.918022 -21.650475
b      47.075335 0.3825453  46.463953  47.686716
sigma   5.134699 0.1556681   4.885911   5.383487</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb405"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># When predictor value is zero, the height is -23.78, meaning there is no height at zero weight.</span></span>
<span><span class="co"># When log value of weight increases by 1 unit, height will increase by 47 cm. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<ol start="2" type="a">
<li>Use samples from the quadratic approximate posterior of the model in (a) to superimpose on the plot: (1) the predicted mean height as a function of weight, (2) the 97% HPDI for the mean, and (3) the 97% HPDI for predicted heights.</li>
</ol>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb406"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Define weight sequence</span></span>
<span><span class="va">weight.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">3</span>, to <span class="op">=</span> <span class="fl">80</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate mu values for each data and sample from posterior distribution using link</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">qfit</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>weight <span class="op">=</span> <span class="va">weight.seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:1000, 1:78] 27.9 28.8 26 28.4 28.1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb408"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute mean and HPDI of mu </span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span><span class="va">mu.HPDI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">HPDI</span>, prob <span class="op">=</span> <span class="fl">0.97</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Start with the given plot</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , data<span class="op">=</span><span class="va">Howell1</span> ,</span>
<span>    col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.4</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot the MAP line, aka the mean mu for each weight</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">weight.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot a shaded region for 97% HPDI</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.HPDI</span> , <span class="va">weight.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Pre-define data</span></span>
<span><span class="va">pre_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span> <span class="op">(</span>weight <span class="op">=</span> <span class="va">weight.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Simulate height values based on model and predictor values</span></span>
<span><span class="va">sim.height</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span><span class="va">qfit</span>, data <span class="op">=</span> <span class="va">pre_data</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate PI of simulated heights</span></span>
<span><span class="va">height.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">sim.height</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.97</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade predicted height HPDI</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">height.PI</span>, <span class="va">weight.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/4H3b-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Given answer:</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb409"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## (a) You can just use log inside the call to map:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Howell1</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="va">mlw</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> mean<span class="op">=</span><span class="va">mu</span> , sd<span class="op">=</span><span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">weight</span><span class="op">)</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">138</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">mlw</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%     94.5%
a     -23.800660 1.3349769 -25.934211 -21.66711
b      47.079780 0.3825054  46.468463  47.69110
sigma   5.134167 0.1556277   4.885444   5.38289</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb411"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Pretty hard to know what to make of these estimates, aside from the fact that the </span></span>
<span><span class="co"># confidence intervals are quite narrow, owing to there being 544 rows. The estimate </span></span>
<span><span class="co"># for b (β) is hard to understand, because it refers to log-kg, not raw kg. It means </span></span>
<span><span class="co"># that for every increase of 1 log-kg of weight, you expect a increase of 47 cm of height. </span></span>
<span><span class="co"># But what’s a log-kg? You want to know what the model predicts on the natural scale </span></span>
<span><span class="co"># of measurement. So now to plotting...</span></span>
<span></span>
<span><span class="co">## (b) Begin by sampling from the naive posterior and computing the confidence intervals </span></span>
<span><span class="co">## as per the examples in the book. Again, I’ll not use the convenience functions, </span></span>
<span><span class="co">## but it’s fine if you did.</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">mlw</span><span class="op">)</span></span>
<span><span class="va">lw.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fl">1.4</span>,to<span class="op">=</span><span class="fl">4.2</span>,length.out<span class="op">=</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">lw.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span><span class="op">+</span><span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">z</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">lw.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span> <span class="fu">HPDI</span><span class="op">(</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span><span class="op">+</span><span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">z</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">h.ci</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">lw.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span></span>
<span>    <span class="fu">HPDI</span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10000</span>,<span class="va">post</span><span class="op">$</span><span class="va">a</span><span class="op">+</span><span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">*</span><span class="va">z</span>,<span class="va">post</span><span class="op">$</span><span class="va">sigma</span><span class="op">)</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Now you have lists of numbers that can be plotted to produce the confidence curves. </span></span>
<span><span class="co"># But how to translate back to the non-log scale of measurement on the horizontal axis? </span></span>
<span><span class="co"># Just exponentiate the x-axis coordinates in lw.seq, and the job is done:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">height</span> <span class="op">~</span> <span class="va">weight</span> , data<span class="op">=</span><span class="va">d</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"slateblue"</span>,<span class="fl">0.4</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">lw.seq</span><span class="op">)</span> , <span class="va">mu</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">lw.seq</span><span class="op">)</span> , <span class="va">mu.ci</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">lw.seq</span><span class="op">)</span> , <span class="va">mu.ci</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">lw.seq</span><span class="op">)</span> , <span class="va">h.ci</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">lw.seq</span><span class="op">)</span> , <span class="va">h.ci</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/3.11-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb412"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The model may have been linear, but plotted on the raw scale of measurement, it is </span></span>
<span><span class="co"># clearly non-linear. Not only is the trend for the mean curved, but the variance around </span></span>
<span><span class="co"># the mean is not constant, on this scale. Instead, the variance around the mean increases </span></span>
<span><span class="co"># with weight. On the scale you fit the model on, the variance was assumed to be constant. </span></span>
<span><span class="co"># But once you transform the measurement scale, it usually won’t be.</span></span>
<span></span>
<span><span class="co"># Notice also that the estimate for the mean is so precise that you can hardly even see </span></span>
<span><span class="co"># the confidence interval for it. Don’t get too confident about such results, though. </span></span>
<span><span class="co"># Remember, all inferences of the model are conditional on the model. Even estimated </span></span>
<span><span class="co"># trends that do a terrible job of prediction can have tight confidence intervals, </span></span>
<span><span class="co"># when the data set is large.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section></section><section id="chapter-5-multivariate-linear-models" class="level1"><h1>Chapter 5: Multivariate Linear Models</h1>
<p><br></p>
<p>Multivariate regression uses more than one predictor variable to model an outcome. Reasons often given for multivariate models include:</p>
<ul>
<li>Statistical “control” for confounds
<ul>
<li>A confound is a variable that may be correlated with another variable of interest. In a particularly important type of confound, known as Simpson’s paradox, the entire direction of an apparent association between a predictor and outcome can be reversed by considering a confound</li>
</ul>
</li>
<li>Multiple causation
<ul>
<li>Even when confounds are absent, due for example to tight experimental control, a phenomenon may really arise from multiple causes. Furthermore, when causation is multiple, one cause can hide another. Multivariate models can help in such settings.</li>
</ul>
</li>
<li>Interaction
<ul>
<li>Even when variables are completely uncorrelated, the importance of each may still depend upon the other. Such interactions occur in a very large number of systems. So effective inference about one variable will usually depend upon consideration of other variables.</li>
</ul>
</li>
</ul>
<p><br></p>
<section id="spurious-association" class="level2"><h2 class="anchored" data-anchor-id="spurious-association">Spurious association</h2>
<p>Linear regression model for correlation between age at marriage and divorce rate:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{D}_i &amp;\sim \text{Normal}(\mu_i, \sigma) \\
\mu_i &amp;= \alpha + \beta_A \text{A}_i \\
\alpha &amp;\sim \text{Normal}(10, 10) \\
\beta_A &amp;\sim \text{Normal}(0, 1) \\
\sigma &amp;\sim \text{Uniform}(0, 10)
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>Di = the divorce rate for State i

Ai = State i’s median age at marriage
</code></pre>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb414"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># load data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">WaffleDivorce</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">WaffleDivorce</span></span>
<span></span>
<span><span class="co">## Median age at marriage vs. divorce rate</span></span>
<span><span class="co"># standardize predictor</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span><span class="op">)</span><span class="op">)</span><span class="op">/</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit model</span></span>
<span><span class="va">m5.1</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bA</span> <span class="op">*</span> <span class="va">MedianAgeMarriage.s</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">10</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span> , data <span class="op">=</span> <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Check precis output</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean        sd      5.5%      94.5%
a      9.688152 0.2045088  9.361307 10.0149961
bA    -1.042985 0.2025337 -1.366673 -0.7192971
sigma  1.446398 0.1447678  1.215031  1.6777648</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb416"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># each additional standard deviation of delay in marriage (1.24 years- the difference between</span></span>
<span><span class="co"># two data points after converting back to natural scale) predicts a decrease of </span></span>
<span><span class="co"># about one divorce per thousand adults, with a 89% interval from about −1.4 to −0.7.</span></span>
<span><span class="co"># So it’s reliably negative, even though the magnitude of the difference may vary quite a lot—</span></span>
<span><span class="co"># the upper bound is half the lower bound. Of course there’s nothing special about the interval</span></span>
<span><span class="co"># boundaries, but the magnitude of the difference means that even though the association here </span></span>
<span><span class="co"># (conditional on model and data) is implausibly positive, it could be both much stronger </span></span>
<span><span class="co"># or weaker than the mean.</span></span>
<span></span>
<span><span class="co"># compute percentile interval of mean</span></span>
<span><span class="va">MAM.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="op">-</span><span class="fl">3</span> , to<span class="op">=</span><span class="fl">3.5</span> , length.out<span class="op">=</span><span class="fl">30</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.1</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>MedianAgeMarriage.s<span class="op">=</span><span class="va">MAM.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot it all</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">MedianAgeMarriage.s</span> , data<span class="op">=</span><span class="va">d</span> , col<span class="op">=</span><span class="va">rangi2</span> , main <span class="op">=</span> <span class="st">"Standardized scale"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m5.1</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">MAM.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert to natural scale</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">MedianAgeMarriage.s</span> , data<span class="op">=</span><span class="va">d</span> , col<span class="op">=</span><span class="va">rangi2</span>, xaxt <span class="op">=</span> <span class="st">"n"</span>,</span>
<span>      xlab <span class="op">=</span><span class="st">"MedianAgeMarriage"</span>, main <span class="op">=</span> <span class="st">"Natural scale"</span><span class="op">)</span></span>
<span><span class="va">at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="op">-</span><span class="fl">2</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="va">at</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span>side <span class="op">=</span> <span class="fl">1</span> , at <span class="op">=</span> <span class="va">at</span> , labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">labels</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m5.1</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">MAM.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co">## Marriage rate vs. divorce rate</span></span>
<span><span class="co"># standardize predictor (marriage rate)</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit model</span></span>
<span><span class="va">m5.2</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span> <span class="op">*</span> <span class="va">Marriage.s</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">10</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span> , data <span class="op">=</span> <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># check precis output</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean        sd     5.5%     94.5%
a     9.6881735 0.2364299 9.310313 10.066034
bR    0.6437531 0.2324626 0.272233  1.015273
sigma 1.6722796 0.1673005 1.404901  1.939658</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb418"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This shows an increase of 0.6 divorces for every additional standard deviation </span></span>
<span><span class="co"># of marriage rate (3.8). this relationship isn’t as strong as the previous one.</span></span>
<span></span>
<span><span class="co"># compute percentile interval of mean</span></span>
<span><span class="va">MAM.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="op">-</span><span class="fl">3</span> , to<span class="op">=</span><span class="fl">3</span> , length.out<span class="op">=</span><span class="fl">30</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.2</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>Marriage.s<span class="op">=</span><span class="va">MAM.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot it all</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">Marriage.s</span> , data<span class="op">=</span><span class="va">d</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m5.2</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">MAM.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert to natural scale</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">Marriage.s</span> , data<span class="op">=</span><span class="va">d</span> , col<span class="op">=</span><span class="va">rangi2</span>, xaxt <span class="op">=</span> <span class="st">"n"</span>,</span>
<span>      xlab <span class="op">=</span><span class="st">"Marriage"</span><span class="op">)</span></span>
<span><span class="va">at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="op">-</span><span class="fl">2</span>, <span class="op">-</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="va">at</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span>side <span class="op">=</span> <span class="fl">1</span> , at <span class="op">=</span> <span class="va">at</span> , labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">labels</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m5.2</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">MAM.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p>Merely comparing parameter means between different bivariate regressions is no way to decide which predictor is better. Both of these predictors could provide independent value, or they could be redundant, or one could eliminate the value of the other. So we’ll build a multivariate model with the goal of measuring the partial value of each predictor. The question we want answered is:</p>
<p><strong><em>What is the predictive value of a variable, once I already know all of the other predictor variables?</em></strong></p>
<p>So for example once you fit a multivariate regression to predict divorce using both marriage rate and age at marriage, the model answers the questions:</p>
<ol type="1">
<li><p>After I already know marriage rate, what additional value is there in also knowing age at marriage?</p></li>
<li><p>After I already know age at marriage, what additional value is there in also knowing marriage rate?</p></li>
</ol>
<p>The parameter estimates corresponding to each predictor are the (often opaque) answers to these questions.</p>
<p><br></p>
<section id="multivariate-notation" class="level3"><h3 class="anchored" data-anchor-id="multivariate-notation">Multivariate notation</h3>
<p>Multivariate regression formulas look a lot like the polynomial models- they add more parameters and variables to the definition of <span class="math inline">\(\mu_i\)</span>. The strategy is straightforward:</p>
<ol type="1">
<li><p>Nominate the predictor variables you want in the linear model of the mean.</p></li>
<li><p>For each predictor, make a parameter that will measure its association with the outcome.</p></li>
<li><p>Multiply the parameter by the variable and add that term to the linear model.</p></li>
</ol>
<p>Example model that predicts divorce rate, using both marriage rate and age at marriage:</p>
<p>$$</p>
<p><span class="math display">\[\begin{align*}
\text{D}_i &amp;\sim \text{Normal}(\mu, \sigma)\ &amp;&amp;&amp;  \text{[likelihood]}\\
\mu_i &amp;= \alpha + \beta_R R_i + \beta_A A_i\ &amp;&amp;&amp;  \text{[linear model]}\\
\alpha &amp;\sim \text{Normal}(10, 10)\ &amp;&amp;&amp;           \text{[prior for }\alpha]\\
\beta_R &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{[prior for }\beta_R]\\
\beta_A &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{[prior for }\beta_A]\\
\sigma &amp;\sim \text{Uniform}(0, 10)\ &amp;&amp;&amp;           \text{[prior for }\sigma]
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>R = marriage rate 

A = age at marriage
</code></pre>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Compact notation and the design matrix</strong></span></span></p>
<p>Linear model with n number of predictor variables:</p>
<p><span class="math display">\[\mu_i = \alpha + \beta_1 \text{x}_{1i} + \beta_2 \text{x}_{2i} + ... + \beta_n \text{x}_{ni}\]</span></p>
<p>In compact form:</p>
<p><span class="math display">\[\mu_i = \alpha + \sum_{j = 1}^{n} \beta_j \text{x}_{ji}\]</span></p>
<pre><code>
j = an index over predictor variables 

n = the number of predictor variables
</code></pre>
<p><br></p>
<p>Both of these forms may be read as <em>the mean is a modeled as the sum of an intercept and an additive combination of the products of parameters and predictors.</em> Even more compactly, using matrix notation:</p>
<p><span class="math display">\[m = Xb\]</span></p>
<pre><code>
m = a vector of predicted means, one for each row in the data

b = a (column) vector of parameters, one for each predictor variable

X = a matrix

This matrix is called a design matrix. It has as many rows as the data, and as many columns as
there are predictors plus one. So X is basically a data frame, but with an extra first column. 
The extra column is filled with 1s. These 1s are multiplied by the first parameter, which is 
the intercept, and so return the unmodified intercept. When X is matrix-multiplied by b, you get 
the predicted means. In R notation, this operation is X %*% b.
</code></pre>
<p><br></p>
</section><section id="fitting-the-model-1" class="level3"><h3 class="anchored" data-anchor-id="fitting-the-model-1">Fitting the model</h3>
<p>To fit this model to the divorce data, we just expand the linear model.</p>
<p>$$</p>
<p><span class="math display">\[\begin{align*}
\text{D}_i &amp;\sim \text{Normal}(\mu, \sigma)\ &amp;&amp;&amp;  \text{Divorce} \sim \text{dnorm(mu, sigma)}\\
\mu_i &amp;= \alpha + \beta_R R_i + \beta_A A_i\ &amp;&amp;&amp;  \text{mu} \leftarrow \text{a + bR}^* \text{Marriage.s + bA}^* \text{MedianAgeMarriage.s}\\
\alpha &amp;\sim \text{Normal}(10, 10)\ &amp;&amp;&amp;           \text{a} \sim \text{dnorm}(10, 10)\\
\beta_R &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{bR} \sim \text{dnorm}(0, 1)\\
\beta_A &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{bA} \sim \text{dnorm}(0, 1)\\
\sigma &amp;\sim \text{Uniform}(0, 10)\ &amp;&amp;&amp;           \text{sigma} \sim \text{dunif}(0, 10)
\end{align*}\]</span></p>
<p>$$</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb422"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m5.3</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">Marriage.s</span> <span class="op">+</span> <span class="va">bA</span><span class="op">*</span><span class="va">MedianAgeMarriage.s</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">10</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">m5.3</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
a      9.6881894 0.2036169  9.3627703 10.0136086
bR    -0.1319927 0.2794354 -0.5785844  0.3145990
bA    -1.1345835 0.2797244 -1.5816371 -0.6875299
sigma  1.4400875 0.1443540  1.2093819  1.6707931</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb424"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The posterior mean for marriage rate, bR, is now close to zero, with plenty of probability </span></span>
<span><span class="co"># of both sides of zero. The posterior mean for age at marriage, bA, has actually gotten slightly </span></span>
<span><span class="co"># farther from zero, but is essentially unchanged.</span></span>
<span></span>
<span><span class="co"># Visualize the posterior distribution estimates</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.3</span><span class="op">)</span><span class="op">)</span> <span class="co"># same as plot(m5.3)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.4-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb425"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The result, with MAP values shown by the points and the percentile intervals </span></span>
<span><span class="co"># by the solid horizontal lines. </span></span>
<span><span class="co"># You can interpret these estimates as saying: Once we know median age at marriage for a State, </span></span>
<span><span class="co"># there is little or no additional predictive power in also knowing the rate of marriage in that State.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="plotting-multivariate-posteriors" class="level3"><h3 class="anchored" data-anchor-id="plotting-multivariate-posteriors">Plotting multivariate posteriors</h3>
<p>Three types of interpretive plots:</p>
<ol type="1">
<li><p><strong><em>Predictor residual plots.</em></strong> These plots show the outcome against residual predictor values.</p></li>
<li><p><strong><em>Counterfactual plots.</em></strong> These show the implied predictions for imaginary experiments in which the different predictor variables can be changed independently of one another.</p></li>
<li><p><strong><em>Posterior prediction plots.</em></strong> These show model-based predictions against raw data, or otherwise display the error in prediction.</p></li>
</ol>
<p><br></p>
<section id="predictor-residual-plots" class="level4"><h4 class="anchored" data-anchor-id="predictor-residual-plots">Predictor residual plots</h4>
<p>A predictor variable residual is the average prediction error when we use all of the other predictor variables to model a predictor of interest. The benefit of computing these things is that, once plotted against the outcome, we have a bivariate regression of sorts that has already “controlled” for all of the other predictor variables. It just leaves in the variation that is not expected by the model of the mean, <span class="math inline">\(\mu\)</span>, as a function of the other predictors.</p>
<p>In our multivariate model of divorce rate, we have two predictors:</p>
<ol type="1">
<li><p>marriage rate (Marriage.s)</p></li>
<li><p>median age at marriage (MedianAgeMarriage.s)</p></li>
</ol>
<p>To compute predictor residuals for either, we just use the other predictor to model it. The model for marraige rate:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{R}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta \text{A}_i\\
\alpha &amp;\sim \text{Normal}(0, 10)\\
\beta &amp;\sim \text{Normal}(0, 1)\\
\sigma &amp;\sim \text{Uniform}(0, 10)
\end{align*}\]</span></p>
<p>$$</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb426"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the model using standardized variables</span></span>
<span><span class="va">m5.4</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">Marriage.s</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">MedianAgeMarriage.s</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data <span class="op">=</span> <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co">## Compute the residuals by subtracting the observed marriage rate in each State from </span></span>
<span><span class="co">## the predicted rate, based upon median age at marriage</span></span>
<span><span class="co"># compute expected value at MAP, for each State</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.4</span><span class="op">)</span><span class="op">[</span><span class="st">'a'</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.4</span><span class="op">)</span><span class="op">[</span><span class="st">'b'</span><span class="op">]</span><span class="op">*</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span></span>
<span></span>
<span><span class="co"># compute residual for each State</span></span>
<span><span class="va">m.resid</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span> <span class="op">-</span> <span class="va">mu</span></span>
<span><span class="va">m.resid</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] -0.41039253  1.05933362 -0.09690521  0.64777219  0.16144520  0.68823308
 [7]  0.09429038  1.09979450  1.45833169 -0.62121677  0.43447165  1.74603417
[13] -0.14195507 -0.03965562 -0.28598813 -0.01066719 -0.08241099 -0.17094350
[19]  0.03951710 -1.54277737  0.23795980  0.26887909 -0.75286829 -1.12626332
[25] -0.36020824 -0.65938316 -0.62828206 -0.51094295 -0.47048206 -0.45387517
[31] -0.07057491  0.47475071 -0.12800631  1.30107715 -0.70497848  0.02061573
[37] -0.35066664 -0.61415148 -0.11405755 -0.33158344 -0.26442862 -0.67846636
[43] -0.12553000  0.91602784 -0.49204157  0.30034382  0.25015953 -0.05608069
[49] -0.62598757  1.72254381</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb428"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># States with positive residuals marry fast for their age of marriage, </span></span>
<span><span class="co"># while States with negative residuals marry slow for their age of marriage. </span></span>
<span></span>
<span><span class="co"># plot the relationship between these two variables, and show the residuals</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Marriage.s</span> <span class="op">~</span> <span class="va">MedianAgeMarriage.s</span> , <span class="va">d</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m5.4</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># loop over States</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">m.resid</span><span class="op">)</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># x location of line segment</span></span>
<span>    <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># observed endpoint of line segment</span></span>
<span>    <span class="co"># draw the line segment</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">x</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">mu</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>,<span class="va">y</span><span class="op">)</span> , lwd<span class="op">=</span><span class="fl">0.5</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>,<span class="fl">0.7</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.4a-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb429"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Residual marriage rate in each State, after accounting for the linear association </span></span>
<span><span class="co"># with median age at marriage. Each gray line segment is a residual, the distance of </span></span>
<span><span class="co"># each observed marriage rate from the expected value, attempting to predict marriage </span></span>
<span><span class="co"># rate with median age at marriage alone. So States that lie above the black regression </span></span>
<span><span class="co"># line have higher rates of marriage than expected, according to age at marriage. </span></span>
<span><span class="co"># Those below the line have lower rates than expected.</span></span>
<span><span class="co"># Notice that the residuals are variation in marriage rate that is left over, </span></span>
<span><span class="co"># after taking out the purely linear relationship between the two variables.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Residual plots for the divorce rate</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb430"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Compute the predicted divorce rate value at MAP based on marriage rate</span></span>
<span><span class="co"># Fit the model using standardized variables</span></span>
<span></span>
<span><span class="va">m5.41</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">Marriage.s</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data <span class="op">=</span> <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">m5.41</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
Quadratic approximate posterior distribution

Formula:
Divorce ~ dnorm(mu, sigma)
mu &lt;- a + b * Marriage.s
a ~ dnorm(0, 10)
b ~ dnorm(0, 1)
sigma ~ dunif(0, 10)

Posterior means:
        a         b     sigma 
9.6826905 0.6437267 1.6721694 

Log-likelihood: -96.66 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb432"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compute expected value at MAP, for each State</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.41</span><span class="op">)</span><span class="op">[</span><span class="st">'a'</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.41</span><span class="op">)</span><span class="op">[</span><span class="st">'b'</span><span class="op">]</span><span class="op">*</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span></span>
<span></span>
<span><span class="co"># compute residual for each State</span></span>
<span><span class="va">d.resid</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span> <span class="op">-</span> <span class="va">mu</span></span>
<span><span class="va">d.resid</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1]  3.00273290  1.81966080  1.08578338  2.75186273 -1.51082239  1.34339878
 [7] -2.47183202 -1.28880315 -2.97352913 -0.65488250  1.48069204 -2.19389449
[13] -2.94644016 -1.30742817  1.37053097  0.28238915  0.58069204  2.56374252
[19]  1.23493482  4.43835066 -0.57522624 -1.15148827  0.12986510 -1.46674068
[25]  1.55527857  0.07392520 -0.30912528 -0.79556999  0.99596606 -2.68199308
[31]  0.46883386 -2.52098346  0.16883386 -2.79898583  0.36206702  2.49255022
[37]  0.92307664 -1.20063971  0.58410788 -1.24132721  1.21968242  1.83832905
[43]  0.08238915 -1.09052187  0.54681462 -0.84811566  0.09933867  0.86374252
[49] -0.88878154 -1.17696658</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb434"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># plot the relationship between these two variables, and show the residuals</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">Marriage.s</span> , <span class="va">d</span> , col<span class="op">=</span><span class="st">"brown"</span> , pch <span class="op">=</span> <span class="fl">16</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m5.41</span>, col <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># loop over States</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">d.resid</span><span class="op">)</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># x location of line segment</span></span>
<span>    <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># observed endpoint of line segment</span></span>
<span>    <span class="co"># draw the line segment</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">x</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">mu</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>,<span class="va">y</span><span class="op">)</span> , lwd<span class="op">=</span><span class="fl">0.5</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown"</span>,<span class="fl">0.7</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># To add PI shade</span></span>
<span><span class="co"># compute percentile interval of mean</span></span>
<span><span class="va">MAM.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="op">-</span><span class="fl">2</span> , to<span class="op">=</span><span class="fl">3</span> , length.out<span class="op">=</span><span class="fl">30</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.41</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>Marriage.s<span class="op">=</span><span class="va">MAM.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">MAM.seq</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/divorce-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb435"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Compute the predicted divorce rate value at MAP based on median age of marriage</span></span>
<span><span class="co"># Fit the model using standardized variables</span></span>
<span></span>
<span><span class="va">m5.42</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">MedianAgeMarriage.s</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data <span class="op">=</span> <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">m5.42</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
Quadratic approximate posterior distribution

Formula:
Divorce ~ dnorm(mu, sigma)
mu &lt;- a + b * MedianAgeMarriage.s
a ~ dnorm(0, 10)
b ~ dnorm(0, 1)
sigma ~ dunif(0, 10)

Posterior means:
        a         b     sigma 
 9.683948 -1.042932  1.446408 

Log-likelihood: -89.4 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb437"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compute expected value at MAP, for each State</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.42</span><span class="op">)</span><span class="op">[</span><span class="st">'a'</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.42</span><span class="op">)</span><span class="op">[</span><span class="st">'b'</span><span class="op">]</span><span class="op">*</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span></span>
<span></span>
<span><span class="co"># compute residual for each State</span></span>
<span><span class="va">d.resid</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span> <span class="op">-</span> <span class="va">mu</span></span>
<span><span class="va">d.resid</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1]  2.38373352  2.09987159  0.90304313  2.34511428 -1.05833763  1.61918121
 [7] -1.68744223 -0.32606147 -0.32634183 -0.89378532  1.68690506 -0.67447570
[13] -4.37736689 -0.89061378  1.01918121 -0.03240456  0.03214774  1.86442390
[19]  1.18690506  3.60621468  0.16097199  0.16731508 -0.19378532 -2.07764725
[25]  1.20304313 -0.56468071 -0.88081879 -1.43240456  1.04166237 -2.20358031
[31]  0.30304313 -1.11654684 -0.08081879 -2.31626648  0.02235275  1.72897620
[37]  0.67076698 -1.10675185  1.51572931 -1.29378532  0.83531929  0.99987159
[43] -0.40012841 -1.79350496  0.62552430 -0.49378532  0.18690506  0.33214774
[49] -1.17764725 -0.93874765</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb439"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># States with positive residuals marry fast for their age of marriage, </span></span>
<span><span class="co"># while States with negative residuals marry slow for their age of marriage. </span></span>
<span></span>
<span><span class="co"># plot the relationship between these two variables, and show the residuals</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">MedianAgeMarriage.s</span> , <span class="va">d</span> , col<span class="op">=</span><span class="st">"brown"</span> , pch <span class="op">=</span> <span class="fl">16</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m5.42</span>, col <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># loop over States</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">d.resid</span><span class="op">)</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># x location of line segment</span></span>
<span>    <span class="va">y</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># observed endpoint of line segment</span></span>
<span>    <span class="co"># draw the line segment</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">x</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">mu</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>,<span class="va">y</span><span class="op">)</span> , lwd<span class="op">=</span><span class="fl">0.5</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown"</span>,<span class="fl">0.7</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># To add PI shade</span></span>
<span><span class="co"># compute percentile interval of mean</span></span>
<span><span class="va">MAM.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="op">-</span><span class="fl">3</span> , to<span class="op">=</span><span class="fl">4</span> , length.out<span class="op">=</span><span class="fl">30</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.42</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>MedianAgeMarriage.s<span class="op">=</span><span class="va">MAM.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">MAM.seq</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown"</span>, alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/divorce1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Predictor residual plots for the divorce data</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb440"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Divorce rate vs. marriage rate residuals</span></span>
<span><span class="co"># Fit a map model for divorce rate based on marriage rate residuals</span></span>
<span><span class="va">m5.43</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">m.resid</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">m5.43</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
Quadratic approximate posterior distribution

Formula:
Divorce ~ dnorm(mu, sigma)
mu &lt;- a + b * m.resid
a ~ dnorm(0, 10)
b ~ dnorm(0, 1)
sigma ~ dunif(0, 10)

Posterior means:
         a          b      sigma 
 9.6817817 -0.1761405  1.7973428 

Log-likelihood: -100.26 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb442"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot the data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Divorce</span> <span class="op">~</span> <span class="va">m.resid</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="va">rangi2</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">16</span><span class="op">)</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"Marriage rate residuals"</span>, ylab <span class="op">=</span> <span class="st">"Divorce rate"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m5.43</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">15</span>, <span class="st">"faster"</span>, pos <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.05</span>, <span class="fl">15</span>, <span class="st">"slower"</span>, pos <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI </span></span>
<span><span class="va">mar.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">2</span>, to <span class="op">=</span> <span class="fl">2</span>, length.out <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m5.43</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>m.resid <span class="op">=</span> <span class="va">mar.seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">mar.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Divorce rate Vs. Age of marriage residuals</span></span>
<span><span class="co"># Fit the model using standardized variables</span></span>
<span><span class="va">m5.44</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">MedianAgeMarriage.s</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">Marriage.s</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data <span class="op">=</span> <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">m5.44</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
Quadratic approximate posterior distribution

Formula:
MedianAgeMarriage.s ~ dnorm(mu, sigma)
mu &lt;- a + b * Marriage.s
a ~ dnorm(0, 10)
b ~ dnorm(0, 1)
sigma ~ dunif(0, 10)

Posterior means:
            a             b         sigma 
-8.852854e-07 -7.142382e-01  6.859048e-01 

Log-likelihood: -52.1 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb444"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compute expected value at MAP, for each State</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.44</span><span class="op">)</span><span class="op">[</span><span class="st">'a'</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.44</span><span class="op">)</span><span class="op">[</span><span class="st">'b'</span><span class="op">]</span><span class="op">*</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span></span>
<span></span>
<span><span class="co"># compute residual for each State</span></span>
<span></span>
<span><span class="va">ma.resid</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span> <span class="op">-</span> <span class="va">mu</span></span>
<span><span class="va">ma.resid</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] -0.59011537  0.42022916 -0.16926052 -0.22823415  0.40916367  0.35212520
 [7]  0.67631950  1.00058850  2.47776087 -0.30740359  0.24965918  1.58032770
[13] -1.22557803  0.34430987 -0.34370080 -0.26522621 -0.47402856 -0.61604195
[19] -0.03243244 -0.96561738  0.66076355  1.15552783 -0.40143413 -0.70751718
[25] -0.35732160 -0.64978385 -0.58818021 -0.62254227 -0.04218292  0.32418876
[31] -0.15045441  1.26317917 -0.23086416  0.63228166 -0.40661945 -0.63678321
[37] -0.27172653 -0.02662697  0.76384972 -0.10053640 -0.36769223 -0.82097398
[43] -0.42604571 -0.43053617 -0.01819150  0.35081019  0.11801642 -0.45522245
[49] -0.35020112  0.50001875</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb446"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate residual for median age of marriage</span></span>
<span><span class="co"># Fit a map model of divorce rate based on median age of marriage</span></span>
<span><span class="va">m5.45</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">Divorce</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">ma.resid</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">m5.45</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
Quadratic approximate posterior distribution

Formula:
Divorce ~ dnorm(mu, sigma)
mu &lt;- a + b * ma.resid
a ~ dnorm(0, 10)
b ~ dnorm(0, 1)
sigma ~ dunif(0, 10)

Posterior means:
        a         b     sigma 
 9.683126 -1.131675  1.586691 

Log-likelihood: -94.03 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb448"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot the data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Divorce</span> <span class="op">~</span> <span class="va">ma.resid</span>, <span class="va">d</span>, col <span class="op">=</span> <span class="va">rangi2</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">16</span><span class="op">)</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"Age of marriage residuals"</span>, ylab <span class="op">=</span> <span class="st">"Divorce rate"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m5.45</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">0</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">15</span>, <span class="st">"older"</span>, pos <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.05</span>, <span class="fl">15</span>, <span class="st">"younger"</span>, pos <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Shade PI </span></span>
<span><span class="va">mar.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">3</span>, to <span class="op">=</span> <span class="fl">3</span>, length.out <span class="op">=</span> <span class="fl">30</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m5.45</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>ma.resid <span class="op">=</span> <span class="va">mar.seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">mar.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/divorce2-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb449"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Left: States with fast marriage rates for their median age of marriage have about </span></span>
<span><span class="co"># the same divorce rates as do States with slow marriage rates. This plot displays the </span></span>
<span><span class="co"># linear relationship between divorce and marriage rates, having statistically </span></span>
<span><span class="co"># “controlled” for median age of marriage. The vertical dashed line indicates marriage </span></span>
<span><span class="co"># rate that exactly matches the expectation from median age at marriage. The slope of </span></span>
<span><span class="co"># the regression line is −0.13, exactly what we found in the multivariate model, m5.3.</span></span>
<span><span class="co">## I got -0.17 for residual plot here.</span></span>
<span></span>
<span><span class="co"># Right: States with old median age of marriage for their marriage rate have lower </span></span>
<span><span class="co"># divorce rates, while States with young median age of marriage have higher divorce rates.</span></span>
<span><span class="co"># This plot displays linear relationship between divorce and median age at marriage, </span></span>
<span><span class="co"># “controlling” for marriage rate. The slope of the regression line </span></span>
<span><span class="co"># here is −1.13, again the same as in the multivariate model, m5.3.</span></span>
<span></span>
<span><span class="co"># There’s direct value in seeing the model-based predictions displayed against the outcome, </span></span>
<span><span class="co"># after subtracting out the influence of other predictors.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="counterfactual-plots" class="level4"><h4 class="anchored" data-anchor-id="counterfactual-plots">Counterfactual plots</h4>
<p>A second sort of inferential plot displays the implied predictions of the model. The counterfactual plots can be produced for any values of the predictor variables you like, even unobserved or impossible combinations.</p>
<p>The simplest use of a counterfactual plot is to see how the predictions change as you change only one predictor at a time. This means holding the values of all predictors constant, except for a single predictor of interest. Such predictions will not necessarily look like your raw data— they are counterfactual after all— but they will help you understand the implications of the model.</p>
<p><br></p>
<p><strong><em>Counterfactual plots for the multivariate divorce model, m5.3</em></strong><span></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb450"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Begin with a plot showing the impact of changes in Marriage.s on predictions</span></span>
<span></span>
<span><span class="co"># prepare new counterfactual data</span></span>
<span><span class="va">A.avg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span> <span class="op">)</span> </span>
<span><span class="va">R.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="op">-</span><span class="fl">3</span> , to<span class="op">=</span><span class="fl">3</span> , length.out<span class="op">=</span><span class="fl">30</span> <span class="op">)</span></span>
<span><span class="va">pred.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    Marriage.s<span class="op">=</span><span class="va">R.seq</span>,</span>
<span>    MedianAgeMarriage.s<span class="op">=</span><span class="va">A.avg</span></span>
<span><span class="op">)</span> <span class="co"># Marriage.s changes across the values in MR.seq, while the other predictor is held </span></span>
<span>  <span class="co"># constant at its mean, MAM.avg</span></span>
<span></span>
<span><span class="co"># compute counterfactual mean divorce (mu)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.3</span> , data<span class="op">=</span><span class="va">pred.data</span> <span class="op">)</span> <span class="co">#m5.3: divorce based on marriage.s &amp; MedianAgemarriage.s</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># simulate counterfactual divorce outcomes</span></span>
<span><span class="va">R.sim</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span> <span class="va">m5.3</span> , data<span class="op">=</span><span class="va">pred.data</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">R.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">R.sim</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># display predictions, hiding raw data with type="n"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">Marriage.s</span> , data<span class="op">=</span><span class="va">d</span> , type<span class="op">=</span><span class="st">"n"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span> <span class="st">"MedianAgeMarriage.s = 0"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">R.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">R.seq</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">R.PI</span> , <span class="va">R.seq</span> <span class="op">)</span></span>
<span></span>
<span><span class="co">## Now with Marriage.s set to its average and MedianAgeMarriage.s allowed to vary</span></span>
<span></span>
<span><span class="co"># Prepare new counterfactual data</span></span>
<span><span class="va">R.avg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span> <span class="op">)</span></span>
<span><span class="va">A.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span> from<span class="op">=</span><span class="op">-</span><span class="fl">3</span> , to<span class="op">=</span><span class="fl">3.5</span> , length.out<span class="op">=</span><span class="fl">30</span> <span class="op">)</span></span>
<span><span class="va">pred.data2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    Marriage.s<span class="op">=</span><span class="va">R.avg</span>,</span>
<span>    MedianAgeMarriage.s<span class="op">=</span><span class="va">A.seq</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate counterfactual mean divorce (mu)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.3</span> , data<span class="op">=</span><span class="va">pred.data2</span> <span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># simulate counterfactual divorce outcomes</span></span>
<span><span class="va">A.sim</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span> <span class="va">m5.3</span> , data<span class="op">=</span><span class="va">pred.data2</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">A.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">A.sim</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># display predictions, hiding raw data with type="n"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">Divorce</span> <span class="op">~</span> <span class="va">MedianAgeMarriage.s</span> , data<span class="op">=</span><span class="va">d</span> , type<span class="op">=</span><span class="st">"n"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span> <span class="st">"Marriage.s = 0"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">A.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.PI</span> , <span class="va">A.seq</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">A.PI</span> , <span class="va">A.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.9-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb451"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Each plot shows the change in predicted mean across values of a single predictor, </span></span>
<span><span class="co"># holding the other predictor constant at its mean value (zero in both cases). </span></span>
<span><span class="co"># Shaded regions show 89% percentile intervals of the mean (dark, narrow) and </span></span>
<span><span class="co"># 89% prediction intervals (light, wide).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>In this example, the difficulty of separately manipulating marriage rate and marriage age doesn’t impede inference much, only because marriage rate has almost no effect on prediction, once median age of marriage is taken into account. But in many problems, more than one predictor variable has a sizable impact on the outcome. In that case, while these counterfactual plots always help in understanding the model, they may also mislead by displaying predictions for impossible combinations of predictor values. If our goal is to intervene in the world, there may not be any realistic way to manipulate each predictor without also manipulating the others.</p>
<p><br></p>
</section><section id="posterior-prediction-plots" class="level4"><h4 class="anchored" data-anchor-id="posterior-prediction-plots">Posterior prediction plots</h4>
<p>Checking the model fit against the observed data is useful in many ways. Two uses among them are:</p>
<ol type="1">
<li>Did the model fit correctly?
<ul>
<li>Many common software and user errors can be more easily diagnosed by comparing implied predictions to the raw data. Some caution is required, because not all models try to exactly match the sample.</li>
</ul>
</li>
<li>How does the model fail?
<ul>
<li>Sometimes, the model fits correctly but is still so poor for our purposes that it must be discarded. More often, a model predicts well in some respects, but not in others. By inspecting the individual cases where the model makes poor predictions, you might get an idea of how to improve the model.</li>
</ul>
</li>
</ol>
<p><br></p>
<p><span style="color:purple"><strong><em>Posterior predictive plots for the multivariate divorce model, m5.3</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb452"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## begin by simulating predictions, averaging over the posterior</span></span>
<span></span>
<span><span class="co"># call link without specifying new data</span></span>
<span><span class="co"># so it uses original data</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.3</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># summarize samples across cases</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># simulate observations</span></span>
<span><span class="co"># again no new data, so uses original data</span></span>
<span><span class="va">divorce.sim</span> <span class="op">&lt;-</span> <span class="fu">sim</span><span class="op">(</span> <span class="va">m5.3</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span><span class="va">divorce.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">divorce.sim</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot predictions against observed</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">mu.mean</span> <span class="op">~</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span> , col<span class="op">=</span><span class="va">rangi2</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">mu.PI</span><span class="op">)</span> ,</span>
<span>    xlab<span class="op">=</span><span class="st">"Observed divorce"</span> , ylab<span class="op">=</span><span class="st">"Predicted divorce"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#  add a line to show perfect prediction and </span></span>
<span><span class="co"># line segments for the confidence interval of each prediction</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> a<span class="op">=</span><span class="fl">0</span> , b<span class="op">=</span><span class="fl">1</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>,<span class="fl">2</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="va">i</span><span class="op">]</span>,<span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="va">i</span><span class="op">]</span><span class="op">)</span> ,</span>
<span>        col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># label a few select points using 'identify' (only work in R Script)</span></span>
<span><span class="co"># identify( x=d$Divorce , y=mu.mean , labels=d$Loc , cex=0.8 )</span></span>
<span><span class="co"># rmarkdown doesn't allow to select data points </span></span>
<span></span>
<span><span class="co"># Define the indices of the points to label</span></span>
<span><span class="va">indices</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">13</span>, <span class="fl">44</span><span class="op">)</span>  </span>
<span></span>
<span><span class="co"># Add text labels to specific points</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span>, y <span class="op">=</span> <span class="va">mu.mean</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span>, labels <span class="op">=</span> <span class="va">d</span><span class="op">$</span><span class="va">Loc</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span>, cex <span class="op">=</span> <span class="fl">0.8</span>, pos <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.11-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb453"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Predicted divorce rate against observed, with 89% confidence in- tervals of the average prediction. </span></span>
<span><span class="co"># The dashed line shows perfect prediction. The model under-predicts for States with very high divorce </span></span>
<span><span class="co"># rates while it over-predicts for States with very low divorce rates- e.g., Idaho (ID) and Utah (UT), </span></span>
<span><span class="co"># both of which have much lower divorce rates than the model expects them to have.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>The plot above makes it hard to see the amount of prediction error, in many cases. For this reason, lots of people also use residual plots that show the mean prediction error for each row.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb454"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># compute residuals</span></span>
<span><span class="va">divorce.resid</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span> <span class="op">-</span> <span class="va">mu.mean</span></span>
<span></span>
<span><span class="co"># get ordering by divorce rate</span></span>
<span><span class="va">o</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/order.html">order</a></span><span class="op">(</span><span class="va">divorce.resid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># make the plot</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/dotchart.html">dotchart</a></span><span class="op">(</span> <span class="va">divorce.resid</span><span class="op">[</span><span class="va">o</span><span class="op">]</span> , labels<span class="op">=</span><span class="va">d</span><span class="op">$</span><span class="va">Loc</span><span class="op">[</span><span class="va">o</span><span class="op">]</span> , xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">6</span>,<span class="fl">5</span><span class="op">)</span> , cex<span class="op">=</span><span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> v<span class="op">=</span><span class="fl">0</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>,<span class="fl">0.2</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">j</span> <span class="op">&lt;-</span> <span class="va">o</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co"># which State in order</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">[</span><span class="va">j</span><span class="op">]</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="va">j</span><span class="op">]</span>,<span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="va">j</span><span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">i</span>,<span class="fl">2</span><span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">[</span><span class="va">j</span><span class="op">]</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">divorce.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="va">j</span><span class="op">]</span>,<span class="va">divorce.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="va">j</span><span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">i</span>,<span class="fl">2</span><span class="op">)</span>,</span>
<span>            pch<span class="op">=</span><span class="fl">3</span> , cex<span class="op">=</span><span class="fl">0.6</span> , col<span class="op">=</span><span class="st">"gray"</span> <span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.14-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb455"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Average prediction error for each State, with 89% interval of the mean (black line) </span></span>
<span><span class="co"># and 89% prediction interval (gray +). </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Yet another common use for these simulations is to construct novel predictor residual plots. Once you’ve computed the divorce residuals, as you did just above, you can plot those residuals against new predictor variables. This is a quick way to see if remaining variation in the outcome is associated with another predictor.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb456"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate waffle houses per capita</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">Wafflehouse_per_capita</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">WaffleHouses</span><span class="op">/</span><span class="va">d</span><span class="op">$</span><span class="va">Population</span></span>
<span></span>
<span><span class="co"># Fit the map model </span></span>
<span><span class="va">m5.6c</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">divorce.resid</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">d</span><span class="op">$</span><span class="va">Wafflehouse_per_capita</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">m5.6c</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
Quadratic approximate posterior distribution

Formula:
divorce.resid ~ dnorm(mu, sigma)
mu &lt;- a + b * d$Wafflehouse_per_capita
a ~ dnorm(0, 10)
b ~ dnorm(0, 1)
sigma ~ dunif(0, 10)

Posterior means:
          a           b       sigma 
-0.25729610  0.05312554  1.36080979 

Log-likelihood: -86.35 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb458"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot divorce residue against waffle house per capita</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">divorce.resid</span> <span class="op">~</span> <span class="va">Wafflehouse_per_capita</span>, data <span class="op">=</span> <span class="va">d</span>, col <span class="op">=</span> <span class="va">rangi2</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"Waffles per capita"</span>, ylab <span class="op">=</span> <span class="st">"Divorce error"</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add the regression line</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.6c</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.6c</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define the indices of the points to label</span></span>
<span><span class="va">indices</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">20</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">25</span>, <span class="fl">11</span>, <span class="fl">40</span>, <span class="fl">13</span><span class="op">)</span>  </span>
<span></span>
<span><span class="co"># Add text labels to specific points</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">d</span><span class="op">$</span><span class="va">Wafflehouse_per_capita</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span>, y <span class="op">=</span> <span class="va">divorce.resid</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span>, </span>
<span>     labels <span class="op">=</span> <span class="va">d</span><span class="op">$</span><span class="va">Loc</span><span class="op">[</span><span class="va">indices</span><span class="op">]</span>, cex <span class="op">=</span> <span class="fl">0.8</span>, pos <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.14a-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb459"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># I couldn't use PI function to get the CI of the abline. I think it is because the calculation</span></span>
<span><span class="co"># of PI  considers divorce.resid as samples and treat them as such, while in reality, they are</span></span>
<span><span class="co"># prediction error of each sample. </span></span>
<span></span>
<span><span class="co">## So, I will use lm function and ggplot to recreate the plot in textbook</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">Wafflehouse_per_capita</span>, y <span class="op">=</span> <span class="va">divorce.resid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>              color  <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"gray"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span> </span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>label<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">divorce.resid</span> <span class="op">&gt;</span> <span class="fl">2.33022867</span>,<span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">Loc</span><span class="op">)</span>,<span class="st">''</span><span class="op">)</span><span class="op">)</span>, </span>
<span>            hjust <span class="op">=</span> <span class="fl">0</span>, vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  </span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">divorce.resid</span> <span class="op">&gt;</span> <span class="fl">1.73858361</span> <span class="op">&amp;</span> <span class="va">divorce.resid</span> <span class="op">&lt;=</span> <span class="fl">1.8</span>, </span>
<span>                               <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">Loc</span><span class="op">)</span>, <span class="st">""</span><span class="op">)</span><span class="op">)</span>, hjust <span class="op">=</span> <span class="fl">1</span>, vjust <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  </span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">divorce.resid</span> <span class="op">&gt;</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="va">divorce.resid</span> <span class="op">&lt;=</span> <span class="fl">1.15377608</span>, </span>
<span>                               <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">Loc</span><span class="op">)</span>, <span class="st">""</span><span class="op">)</span><span class="op">)</span>, hjust <span class="op">=</span> <span class="fl">1</span>, vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  </span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">divorce.resid</span> <span class="op">&gt;</span> <span class="op">-</span><span class="fl">1.34199783</span> <span class="op">&amp;</span> <span class="va">divorce.resid</span> <span class="op">&lt;=</span> <span class="op">-</span><span class="fl">1.3</span>, </span>
<span>                               <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">Loc</span><span class="op">)</span>, <span class="st">""</span><span class="op">)</span><span class="op">)</span>, hjust <span class="op">=</span> <span class="fl">1</span>, vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  </span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">divorce.resid</span> <span class="op">&gt;</span> <span class="fl">1.15</span> <span class="op">&amp;</span> <span class="va">divorce.resid</span> <span class="op">&lt;=</span> <span class="fl">1.16</span>, </span>
<span>                               <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">Loc</span><span class="op">)</span>, <span class="st">""</span><span class="op">)</span><span class="op">)</span>, hjust <span class="op">=</span> <span class="fl">1</span>, vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  </span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>label<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">divorce.resid</span> <span class="op">&lt;</span> <span class="op">-</span><span class="fl">4.38753672</span>,<span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">Loc</span><span class="op">)</span>,<span class="st">''</span><span class="op">)</span><span class="op">)</span>, </span>
<span>            hjust <span class="op">=</span> <span class="fl">0</span>, vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  </span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Waffles per capita"</span>, y <span class="op">=</span> <span class="st">"Divorce error"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_minimal</span><span class="op">(</span><span class="op">)</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.14a-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb460"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Average prediction error (residuals) against number of Waffle Houses per capita, with </span></span>
<span><span class="co"># superimposed regression of the two variables.</span></span>
<span><span class="co"># A small positive correlation remains between divorce rate and Waffle House, despite already </span></span>
<span><span class="co"># “controlling” for marriage rate and median age at marriage in each State. This does not mean </span></span>
<span><span class="co"># that the correlation is real. No matter how many predictors you’ve already included in a </span></span>
<span><span class="co"># regression, it’s still possible to find spurious correlations with the remaining variation.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Simulating spurious association</strong></span></span></p>
<p>One way that spurious associations between a predictor and outcome can arise is when a truly causal predictor, call it x<sub>real</sub>, influences both the outcome, y, and a spurious predictor, x<sub>spur</sub>.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb461"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span>                                          <span class="co"># number of cases                       </span></span>
<span></span>
<span><span class="va">x_real</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>                                <span class="co"># x_real as Gaussian with mean 0 and stddev 1</span></span>
<span></span>
<span><span class="va">x_spur</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">x_real</span><span class="op">)</span>                        <span class="co"># x_spur as Gaussian with mean = x_real</span></span>
<span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">x_real</span><span class="op">)</span>                             <span class="co"># y as Gaussian with mean = x_real</span></span>
<span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x_real</span>, <span class="va">x_spur</span><span class="op">)</span>                <span class="co"># bind all together in data frame</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/paired_plot-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb462"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The data frame d has 100 simulated cases. Because x_real influences both y and x_spur, </span></span>
<span><span class="co"># you can think of x_spur as another outcome of x_real, but one which we mistake as a </span></span>
<span><span class="co"># potential predictor of y. As a result, both x_real and x_spur are correlated with y. </span></span>
<span><span class="co"># You can see this in the scatterplots from pairs(d). But when you include both x variables </span></span>
<span><span class="co"># in a linear regression predicting y, the posterior mean for the association between y and</span></span>
<span><span class="co"># x_spur will be close to zero, while the comparable mean for xreal will be closer to 1.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section></section><section id="masked-relationship" class="level2"><h2 class="anchored" data-anchor-id="masked-relationship">Masked relationship</h2>
<p>A second reason to use more than one predictor variable is to measure the direct influences of multiple factors on an outcome, when none of those influences is apparent from bivariate relationships. This kind of problem tends to arise when there are two predictor variables that are correlated with one another. However, one of these is positively correlated with the outcome and the other is negatively correlated with it.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb463"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data on composition of milk across primate species</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">milk</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span> <span class="co">#  29 rows (cases) for 8 variables (columns)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   29 obs. of  8 variables:
 $ clade         : Factor w/ 4 levels "Ape","New World Monkey",..: 4 4 4 4 4 2 2 2 2 2 ...
 $ species       : Factor w/ 29 levels "A palliata","Alouatta seniculus",..: 11 8 9 10 16 2 1 6 28 27 ...
 $ kcal.per.g    : num  0.49 0.51 0.46 0.48 0.6 0.47 0.56 0.89 0.91 0.92 ...
 $ perc.fat      : num  16.6 19.3 14.1 14.9 27.3 ...
 $ perc.protein  : num  15.4 16.9 16.9 13.2 19.5 ...
 $ perc.lactose  : num  68 63.8 69 71.9 53.2 ...
 $ mass          : num  1.95 2.09 2.51 1.62 2.19 5.25 5.37 2.51 0.71 0.68 ...
 $ neocortex.perc: num  55.2 NA NA NA NA ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb465"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## First, simple bivariate regression between kilocalories and neocortex percent</span></span>
<span><span class="co"># Check the neocortex column to see any missing (NA) values</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">neocortex.perc</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] 55.16    NA    NA    NA    NA 64.54 64.54 67.64    NA 68.85 58.85 61.69
[13] 60.32    NA    NA 69.97    NA 70.41    NA 73.40    NA 67.53    NA 71.26
[25] 72.60    NA 70.24 76.30 75.49</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb467"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># If you pass a vector like this to a likelihood function like dnorm, it doesn’t know what to do.</span></span>
<span><span class="co"># After all, what’s the probability of a missing value? Whatever the answer, it isn’t a number, </span></span>
<span><span class="co"># and so dnorm returns a NaN. </span></span>
<span></span>
<span><span class="co"># Manually drop all the cases with missing values</span></span>
<span><span class="va">dcc</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span>, <span class="op">]</span> <span class="co"># gives new data frame with 17 rows</span></span>
<span></span>
<span><span class="va">m5.5</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bn</span><span class="op">*</span><span class="va">neocortex.perc</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">bn</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dcc</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Check precis and add digits=3 to the precis call. The reason is that the posterior mean for </span></span>
<span><span class="co"># bn is very small. Need more digits to see that it’s not exactly zero—a change from the smallest</span></span>
<span><span class="co"># neocortex percent in the data, 55%, to the largest, 76%, would result in an expected change of</span></span>
<span><span class="co"># only: less than 0.1 kilocalories (0.09008296 kcal)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.5</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd         5.5%      94.5%
a     0.353339076 0.47071829 -0.398959668 1.10563782
bn    0.004503203 0.00694034 -0.006588801 0.01559521
sigma 0.165702599 0.02841440  0.120290904 0.21111429</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb469"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m5.5</span><span class="op">)</span><span class="op">[</span><span class="st">"bn"</span><span class="op">]</span> <span class="op">*</span> <span class="op">(</span><span class="fl">75</span> <span class="op">-</span> <span class="fl">55</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>        bn 
0.09006406 </code></pre>
</div>
</div>
<p><br></p>
<p>The kilocalories in the data range from less than 0.5 to more than 0.9 per gram, so this association isn’t so impressive. More importantly, it isn’t very precise. The 89% interval of the parameter extends a good distance on both sides of zero.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb471"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Plot the predicted mean and 89% interval for the mean to see this more easily</span></span>
<span></span>
<span><span class="va">np.seq</span> <span class="op">&lt;-</span> <span class="fl">0</span><span class="op">:</span><span class="fl">100</span></span>
<span><span class="va">pred.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> neocortex.perc<span class="op">=</span><span class="va">np.seq</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.5</span> , data<span class="op">=</span><span class="va">pred.data</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="va">neocortex.perc</span> , data<span class="op">=</span><span class="va">dcc</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.23-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb472"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The MAP line is weakly positive, but it is highly imprecise. A lot of mildly positive </span></span>
<span><span class="co"># and negative slopes are plausible, given this model and these data.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Now consider another predictor variable, adult female body mass, mass in the data frame.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb473"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Use logarithm of mass, log(mass), as a predictor instead of the raw mass in kilograms</span></span>
<span><span class="co"># Taking the log of a measure translates the measure into magnitudes. So by using the </span></span>
<span><span class="co"># logarithm of body mass here, we’re saying that we suspect that the magnitude of a </span></span>
<span><span class="co"># mother’s body mass is related to milk energy, in a linear fashion.</span></span>
<span></span>
<span><span class="co"># Transforms mass first to make a new column in the data</span></span>
<span><span class="va">dcc</span><span class="op">$</span><span class="va">log.mass</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">dcc</span><span class="op">$</span><span class="va">mass</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit the model</span></span>
<span><span class="va">m5.6</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bm</span><span class="op">*</span><span class="va">log.mass</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bm</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">dcc</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.6</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%        94.5%
a      0.70514076 0.04870352  0.62730312 0.7829783950
bm    -0.03167416 0.02028246 -0.06408945 0.0007411225
sigma  0.15685575 0.02689495  0.11387242 0.1998390752</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb475"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot the data</span></span>
<span><span class="va">np.seq</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">4</span><span class="op">:</span><span class="fl">5</span></span>
<span><span class="va">pred.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> log.mass<span class="op">=</span><span class="va">np.seq</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.6</span> , data<span class="op">=</span><span class="va">pred.data</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="va">log.mass</span> , data<span class="op">=</span><span class="va">dcc</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.24-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb476"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># log-mass is negatively correlated with kilocalories. This influence does seem stronger than </span></span>
<span><span class="co"># that of neocortex percent, although in the opposite direction. It is quite uncertain though, </span></span>
<span><span class="co"># with a wide confidence interval that is consistent with a wide range of both weak and </span></span>
<span><span class="co"># stronger relationships.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Now let’s see what happens when we add both predictor variables at the same time to the regression. This is the multivariate model, in math form:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{k}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_n \text{n}_i + \beta_m \text{log}(\text{m}_i)\\
\alpha &amp;\sim \text{Normal}(0, 100)\\
\beta_n &amp;\sim \text{Normal}(0, 1)\\
\beta_m &amp;\sim \text{Normal}(0, 1)\\
\sigma &amp;\sim \text{Uniform}(0, 10)
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>k   = kcal.per.g

n   = neocortex.perc

m   = mass
</code></pre>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb478"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the joint model</span></span>
<span><span class="va">m5.7</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bn</span><span class="op">*</span><span class="va">neocortex.perc</span> <span class="op">+</span> <span class="va">bm</span><span class="op">*</span><span class="va">log.mass</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bn</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bm</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">dcc</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.7</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%       94.5%
a     -1.08440977 0.46756145 -1.83166328 -0.33715626
bn     0.02791699 0.00727271  0.01629379  0.03954018
bm    -0.09634937 0.02245425 -0.13223560 -0.06046314
sigma  0.11479325 0.01968203  0.08333756  0.14624895</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb480"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># By incorporating both predictor variables in the regression, the estimated association </span></span>
<span><span class="co"># of both with the outcome has increased. The posterior mean for the association of </span></span>
<span><span class="co"># neocortex percent has increased more than sixfold, and its 89% interval is now entirely </span></span>
<span><span class="co"># above zero. The posterior mean for log body mass is more strongly negative.</span></span>
<span></span>
<span><span class="co">## Plot the the intervals for the predicted mean kilocalories</span></span>
<span><span class="co">## For necortex.perc</span></span>
<span><span class="co"># Use mean log body mass because they are counterfactual plots showing only how predicted </span></span>
<span><span class="co"># energy varies as a function of neocortex percent</span></span>
<span><span class="va">mean.log.mass</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">dcc</span><span class="op">$</span><span class="va">mass</span><span class="op">)</span> <span class="op">)</span> </span>
<span><span class="va">np.seq</span> <span class="op">&lt;-</span> <span class="fl">0</span><span class="op">:</span><span class="fl">100</span></span>
<span><span class="va">pred.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    neocortex.perc<span class="op">=</span><span class="va">np.seq</span>,</span>
<span>    log.mass<span class="op">=</span><span class="va">mean.log.mass</span></span>
<span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.7</span> , data<span class="op">=</span><span class="va">pred.data</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="va">neocortex.perc</span> , data<span class="op">=</span><span class="va">dcc</span> , type<span class="op">=</span><span class="st">"n"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.26-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb481"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## For log(mass)</span></span>
<span><span class="va">mean.neocortex.perc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">dcc</span><span class="op">$</span><span class="va">neocortex.perc</span><span class="op">)</span></span>
<span><span class="va">np.seq</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">3</span><span class="op">:</span><span class="fl">5</span></span>
<span><span class="va">pred.data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>    neocortex.perc<span class="op">=</span><span class="va">mean.neocortex.perc</span>,</span>
<span>    log.mass<span class="op">=</span><span class="va">np.seq</span></span>
<span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m5.7</span> , data<span class="op">=</span><span class="va">pred.data</span> , n<span class="op">=</span><span class="fl">1e4</span> <span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="va">log.mass</span> , data<span class="op">=</span><span class="va">dcc</span> , type<span class="op">=</span><span class="st">"n"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">np.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.26-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Why did adding neocortex and body mass to the same model lead to larger estimated effects of both?</em></strong></span></p>
<ul>
<li><p>There are two variables correlated with the outcome, but one is positively correlated with it and the other is negatively correlated with it.</p></li>
<li><p>Both of the explanatory variables are positively correlated with one another. As a result, they tend to cancel one another out.</p></li>
<li><p>This is another case in which regression automatically finds the most revealing cases and uses them to produce estimates. What the regression model does is ask if species that have high neocortex percent for their body mass have higher milk energy.</p></li>
<li><p>Likewise, the model asks if species with high body mass for their neocortex percent have higher milk energy. Bigger species, like apes, have milk with less energy. But species with more neocortex tend to have richer milk.</p></li>
<li><p>The fact that these two variables, body size and neocortex, are correlated across species makes it hard to see these relationships, unless we statistically account for both.</p></li>
</ul>
<p><br></p>
<p><span style="color:green"><strong><em>Compound figure for milk energy and neocortex among primates</em></strong></span></p>
<p>In the top two plots, simple bivariate regressions of kilocalories per gram of milk on (left) neocortex percent and (right) log female body mass show weak and uncertain associations.</p>
<p>However, on the bottom, a single regression with both neocortex percent and log body mass suggests strong association with both variables. Both neocortex and body mass are associated with milk energy, but in opposite directions. This masks each variable’s relationship with the outcome, unless both are considered simultaneously.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.7cf-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Simulating a masking relationship</strong></span></span></p>
<p>It may help to simulate data in which two meaningful predictors act to mask one another. Suppose again a single outcome, y, and two predictors, x<sub>pos</sub> and x<sub>neg</sub>. The predictor x<sub>pos</sub> is positively associated with y, while x<sub>neg</sub> is negatively associated with y. Furthermore, the two predictors are positively correlated with one another.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb482"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span>                              <span class="co"># number of cases</span></span>
<span></span>
<span><span class="va">rho</span> <span class="op">&lt;-</span> <span class="fl">0.7</span>                            <span class="co"># correlation btw x_pos and x_neg</span></span>
<span></span>
<span><span class="va">x_pos</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>                     <span class="co"># x_pos Gaussian</span></span>
<span></span>
<span><span class="va">x_neg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">rho</span><span class="op">*</span><span class="va">x_pos</span>,          <span class="co"># x_neg correlated with x_pos</span></span>
<span>               <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">rho</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">x_pos</span> <span class="op">-</span> <span class="va">x_neg</span><span class="op">)</span>          <span class="co"># y equally associated with x_pos, x_neg</span></span>
<span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x_pos</span>, <span class="va">x_neg</span><span class="op">)</span>      <span class="co"># bind all together in data frame</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">d</span>, main <span class="op">=</span> <span class="st">"(a) Rho = 0.7"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.28-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb483"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Predicting y using either x_pos or x_neg gives posterior distributions that underestimate </span></span>
<span><span class="co"># the true association (which should be about 1 or −1, respectively). </span></span>
<span><span class="co"># Fitting a model predicting y using both predictors gives a posterior distribution that </span></span>
<span><span class="co"># better matches the underlying truth.</span></span>
<span></span>
<span><span class="co">## Move rho closer to 0</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span>                              </span>
<span><span class="va">rho</span> <span class="op">&lt;-</span> <span class="fl">0.1</span>                          </span>
<span><span class="va">x_pos</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>                    </span>
<span><span class="va">x_neg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">rho</span><span class="op">*</span><span class="va">x_pos</span>,          </span>
<span>               <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">rho</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">x_pos</span> <span class="op">-</span> <span class="va">x_neg</span><span class="op">)</span>         </span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x_pos</span>, <span class="va">x_neg</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">d</span>, main <span class="op">=</span> <span class="st">"(b) Rho closer to zero"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.28-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb484"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># If you move the value of rho closer to zero, this masking phenomenon will diminish.</span></span>
<span></span>
<span><span class="co">## Make rho closer to 1</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span>                              </span>
<span><span class="va">rho</span> <span class="op">&lt;-</span> <span class="fl">0.99</span>                         </span>
<span><span class="va">x_pos</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>                    </span>
<span><span class="va">x_neg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">rho</span><span class="op">*</span><span class="va">x_pos</span>,          </span>
<span>               <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">rho</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">x_pos</span> <span class="op">-</span> <span class="va">x_neg</span><span class="op">)</span>         </span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x_pos</span>, <span class="va">x_neg</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">d</span>, main <span class="op">=</span> <span class="st">"(c) Rho closer to 1"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.28-3.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb485"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Make rho closer to -1</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span>                              </span>
<span><span class="va">rho</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">0.99</span>                         </span>
<span><span class="va">x_pos</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>                    </span>
<span><span class="va">x_neg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">rho</span><span class="op">*</span><span class="va">x_pos</span>,          </span>
<span>               <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">rho</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">x_pos</span> <span class="op">-</span> <span class="va">x_neg</span><span class="op">)</span>         </span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x_pos</span>, <span class="va">x_neg</span><span class="op">)</span>  </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">d</span>, main <span class="op">=</span> <span class="st">"(d) Rho closer to -1"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.28-4.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb486"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># If you make rho closer to 1 or −1, the masking relationship will magnify. </span></span>
<span><span class="co"># But if rho gets very close to 1 or −1, then the two predictors contain exactly </span></span>
<span><span class="co"># the same information, and there’s no hope for any statistical model to tease out </span></span>
<span><span class="co"># the true underlying association used in the simulation.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Why should two predictors be correlated in this way?</em></strong></span></p>
<ul>
<li><p>They might both be influenced by another, unmeasured variable.</p></li>
<li><p>Or one of them, say x<sub>neg</sub>, is influenced partly by x<sub>pos</sub>, but also by its own unique processes.</p></li>
<li><p>They might both partly influence one another, in a case of reciprocal causation.</p></li>
</ul>
<p><br></p>
</section><section id="when-adding-variables-hurts" class="level2"><h2 class="anchored" data-anchor-id="when-adding-variables-hurts">When adding variables hurts</h2>
<p>It is commonly true that there are many potential predictor variables to add to a regression model. Why not just fit a model that includes all potential predictor variables? There are several good, purely statistical reasons to avoid doing this. Three of them are:</p>
<ul>
<li>Multicollinearity
<ul>
<li>very strong correlation between two or more predictor variables.</li>
<li>The consequence of it is that the posterior distribution will say that a very large range of parameter values are plausible, from tiny associations to massive ones, even if all of the variables are in reality strongly associated with the outcome variable.</li>
</ul>
</li>
</ul>
<ul>
<li>Post-treatment bias
<ul>
<li>statistically controlling for consequences of a causal factor.</li>
</ul>
</li>
</ul>
<ul>
<li>Overfitting
<ul>
<li>a huge and perspective-changing problem</li>
</ul>
</li>
</ul>
<p><br></p>
<section id="multicollinear-legs" class="level3"><h3 class="anchored" data-anchor-id="multicollinear-legs">Multicollinear legs</h3>
<p>The simulation example is predicting an individual’s height using the length of his or her legs as predictor variables. Surely height is positively associated with leg length, or at least the simulation will assume it is. Nevertheless, once you put both leg lengths into the model, something vexing will happen.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb487"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Simulate the heights and leg lengths of 100 individuals</span></span>
<span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span>                           <span class="co"># number of individuals</span></span>
<span></span>
<span><span class="co"># For each, first a height is simulated from a Gaussian distribution</span></span>
<span><span class="va">height</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">10</span>, <span class="fl">2</span><span class="op">)</span>         <span class="co"># sim total height of each</span></span>
<span></span>
<span><span class="co"># Each individual gets a simulated proportion of height for their legs, ranging from 0.4 to 0.5</span></span>
<span><span class="va">leg_prop</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span><span class="op">)</span>    <span class="co"># leg as proportion of height</span></span>
<span></span>
<span><span class="co"># Each leg is salted with a little measurement or developmental error, so the left and right legs </span></span>
<span><span class="co"># are not exactly the same length, as is typical in real populations</span></span>
<span><span class="va">leg_left</span> <span class="op">&lt;-</span> <span class="va">leg_prop</span><span class="op">*</span><span class="va">height</span> <span class="op">+</span>     <span class="co"># sim left leg as proportion + error</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">0</span>, <span class="fl">0.02</span><span class="op">)</span></span>
<span></span>
<span><span class="va">leg_right</span> <span class="op">&lt;-</span> <span class="va">leg_prop</span><span class="op">*</span><span class="va">height</span> <span class="op">+</span>    <span class="co"># sim right leg as proportion + error </span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">0</span>, <span class="fl">0.02</span><span class="op">)</span></span>
<span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">height</span>, <span class="va">leg_left</span>, <span class="co"># combine into data frame</span></span>
<span>                <span class="va">leg_right</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">d</span>, col <span class="op">=</span> <span class="st">"pink"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.29-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>On average, an individual’s legs are 45% of his or her height (in these simulated data). So we should expect the beta coefficient that measures the association of a leg with height to end up around the average height (10) divided by 45% of the average height (4.5). This is 10/4.5 ≈ 2.2. Now let’s see what happens instead:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb488"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m5.8</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bl</span><span class="op">*</span><span class="va">leg_left</span> <span class="op">+</span> <span class="va">br</span><span class="op">*</span><span class="va">leg_right</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">10</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bl</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">2</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">br</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">2</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.8</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%     94.5%
a      1.3103535 0.34034555  0.7664156 1.8542914
bl     2.5789260 2.03113681 -0.6672229 5.8250749
br    -0.6359496 2.02984284 -3.8800305 2.6081313
sigma  0.6404778 0.04529016  0.5680954 0.7128603</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb490"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.8</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.30-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>If both legs have almost identical lengths, and height is so strongly associated with leg length, then why is this posterior distribution so weird? Did the model fitting work correctly? The question for the model to answer is: <em>What is the value of knowing each leg’s length, after already knowing the other leg’s length?</em></p>
<p>The model did fit correctly. The posterior distribution is the answer to this question, considering every possible combination of the parameters and assigning relative plausibilities to every combination, conditional on this model and these data.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb491"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">35</span><span class="op">)</span></span>
<span><span class="co"># Take a look at the bivariate posterior distribution for bl and br</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m5.8</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">bl</span> <span class="op">~</span> <span class="va">br</span> , <span class="va">post</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.1</span><span class="op">)</span> , pch<span class="op">=</span><span class="fl">16</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.32-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb492"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Posterior distribution of the association of each leg with height, from model m5.8. </span></span>
<span><span class="co"># Since both variables contain almost identical information, the posterior is a narrow </span></span>
<span><span class="co"># ridge of negatively correlated values.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>One way to think of this phenomenon is that you have approximated this likelihood:</p>
<p><span class="math display">\[
\begin{align*}
\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i
\end{align*}
\]</span></p>
<pre><code>y   = outcome (height)

x   = single predictor (leg lengths)
</code></pre>
<p>Here x is used twice, which is a perfect example of the problem caused by using the almost-identical leg lengths. From the computer’s perspective, this likelihood is really:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + (\beta_1 + \beta_2) \text{x}_i
\end{align*}\]</span></p>
<p>$$</p>
<p>This means the posterior distribution ends up reporting the practically infinite combinations of <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> that make their sum close to the actual association of x with y.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb494"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute the posterior distribution of the sum of bl and br</span></span>
<span><span class="va">sum_blbr</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">bl</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">br</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">sum_blbr</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd     5.5%    94.5%     histogram
sum_blbr 1.943374 0.07328221 1.825474 2.060206 ▁▁▁▁▂▅▇▇▃▂▁▁▁</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb496"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The posterior mean is in the right neighborhood, around 2, and the standard deviation </span></span>
<span><span class="co"># is much smaller than it is for either component of the sum, bl or br.</span></span>
<span></span>
<span><span class="co"># Plot the posterior distribution </span></span>
<span><span class="fu">dens</span><span class="op">(</span> <span class="va">sum_blbr</span> , col<span class="op">=</span><span class="va">rangi2</span> , lwd<span class="op">=</span><span class="fl">2</span> , xlab<span class="op">=</span><span class="st">"sum of bl and br"</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.33-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb497"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The posterior distribution of the sum of the two parameters is centered on the </span></span>
<span><span class="co"># proper association of either leg with height.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>If you fit a regression with only one of the leg length variables, you’ll get approximately the same posterior mean:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb498"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">36</span><span class="op">)</span></span>
<span><span class="va">m5.9</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bl</span><span class="op">*</span><span class="va">leg_left</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">10</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bl</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">2</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean         sd      5.5%     94.5%
a     1.3105257 0.34055369 0.7662552 1.8547963
bl    1.9430001 0.07316327 1.8260711 2.0599292
sigma 0.6408714 0.04531334 0.5684520 0.7132909</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb500"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 1.94 is almost identical to the mean value of sum_blbr.</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.9</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"Left leg"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## For right leg</span></span>
<span><span class="va">m5.9b</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">br</span><span class="op">*</span><span class="va">leg_right</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">10</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">br</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">2</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.9b</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean         sd      5.5%     94.5%
a     1.3268748 0.34289063 0.7788693 1.8748802
br    1.9396334 0.07367076 1.8218933 2.0573735
sigma 0.6457285 0.04565994 0.5727551 0.7187019</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb502"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.9b</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"Right leg"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.34-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><strong><em>When two predictor variables are very strongly correlated, including both in a model may lead to confusion.</em></strong></p>
<p>The posterior distribution isn’t wrong, in such cases. It’s telling you that the question you asked cannot be answered with these data. And that’s a great thing for a model to say, that it cannot answer your question. And if you are just interested in prediction, you’ll find that this leg model makes fine predictions. It just doesn’t make any claims about which leg is more important.</p>
<p><br></p>
</section><section id="multicollinear-milk" class="level3"><h3 class="anchored" data-anchor-id="multicollinear-milk">Multicollinear milk</h3>
<p>In the leg length example, it’s easy to see that including both legs in the model is a little silly. But the problem that arises in real data sets is that we may not anticipate a clash between highly correlated predictors. And therefore we may mistakenly read the posterior distribution to say that neither predictor is important.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb503"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">### Look at the issue with real data</span></span>
<span></span>
<span><span class="co"># Load milk data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">milk</span></span>
<span></span>
<span><span class="co">## Start by modeling kcal.per.g as a function of perc.fat and perc.lactose, </span></span>
<span><span class="co">## but in two bivariate regressions</span></span>
<span><span class="co"># kcal.per.g regressed on perc.fat</span></span>
<span><span class="va">m5.10</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bf</span><span class="op">*</span><span class="va">perc.fat</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0.6</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bf</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># kcal.per.g regressed on perc.lactose</span></span>
<span><span class="va">m5.11</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bl</span><span class="op">*</span><span class="va">perc.lactose</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0.6</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bl</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">m5.10</span> , digits<span class="op">=</span><span class="fl">3</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean           sd        5.5%      94.5%
a     0.30114097 0.0356389362 0.244183063 0.35809887
bf    0.01002001 0.0009691037 0.008471198 0.01156883
sigma 0.07326269 0.0096140356 0.057897600 0.08862777</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb505"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The posterior mean for bf, the association of percent fat with milk energy, is 0.01, </span></span>
<span><span class="co"># with 89% interval [0.008, 0.012].</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">m5.11</span> , digits<span class="op">=</span><span class="fl">3</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean           sd        5.5%        94.5%
a      1.16642833 0.0427538601  1.09809941  1.234757258
bl    -0.01057740 0.0008302881 -0.01190436 -0.009250441
sigma  0.06175155 0.0081014479  0.04880388  0.074699233</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb507"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The posterior mean in the second model for percent lactose is −0.01, </span></span>
<span><span class="co"># with 89% interval [−0.012, −0.009].</span></span>
<span></span>
<span><span class="co"># These posterior means are essentially mirror images of one another, with the posterior mean </span></span>
<span><span class="co"># of bf being as positive as the mean of bl is negative. Both are narrow posterior </span></span>
<span><span class="co"># distributions that lie almost entirely on one side or the other of zero.</span></span>
<span></span>
<span><span class="co"># Note the parameter values for the slopes bf and bl are small in absolute value.</span></span>
<span><span class="co"># Both predictors are percents, so are potentially large numbers- these associations really </span></span>
<span><span class="co"># have much influence on the outcome, milk energy. Given the strong association of each </span></span>
<span><span class="co"># predictor with the outcome, we might conclude that both variables are reliable predictors </span></span>
<span><span class="co"># of total energy in milk, across species. </span></span>
<span></span>
<span><span class="co">## Place both predictor variables in the same regression model</span></span>
<span><span class="va">m5.12</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>      <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bf</span><span class="op">*</span><span class="va">perc.fat</span> <span class="op">+</span> <span class="va">bl</span><span class="op">*</span><span class="va">perc.lactose</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0.6</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bf</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bl</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">m5.12</span> , digits<span class="op">=</span><span class="fl">3</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>              mean          sd        5.5%        94.5%
a      1.007211317 0.199975023  0.68761261  1.326810026
bf     0.001954457 0.002399120 -0.00187980  0.005788714
bl    -0.008706937 0.002438624 -0.01260433 -0.004809545
sigma  0.061065924 0.008012829  0.04825988  0.073871972</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb509"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now the posterior means of both bf and bl are closer to zero. And the standard deviations </span></span>
<span><span class="co"># for both parameters are twice as large as in the bivariate models (m5.10 and m5.11). </span></span>
<span><span class="co"># In the case of percent fat, the posterior mean is essentially zero.</span></span>
<span></span>
<span><span class="co"># What has happened is that the variables perc.fat and perc.lactose contain much of the </span></span>
<span><span class="co"># same information. They are substitutes for one another. As a result, when you include both </span></span>
<span><span class="co"># in a regression, the posterior distribution ends up describing a long ridge of combinations </span></span>
<span><span class="co"># of bf and bl that are equally plausible.</span></span>
<span></span>
<span><span class="co"># See results with pairs plot</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span> <span class="op">~</span> <span class="va">kcal.per.g</span> <span class="op">+</span> <span class="va">perc.fat</span> <span class="op">+</span> <span class="va">perc.lactose</span> ,</span>
<span>    data<span class="op">=</span><span class="va">d</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.35-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb510"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># A pairs plot of the total energy, percent fat, and percent lactose variables from the primate </span></span>
<span><span class="co"># milk data. Percent fat and percent lactose are strongly negatively correlated with one another, </span></span>
<span><span class="co"># providing mostly the same information- these two variables form essentially a single axis of variation.</span></span>
<span><span class="co"># These two variables are negatively correlated, and so strongly so that they are nearly redundant. </span></span>
<span><span class="co"># Either helps in predicting kcal.per.g, but neither helps much once you already know the other.</span></span>
<span></span>
<span><span class="co"># Compute the correlation between the two variables with cor</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">perc.fat</span> , <span class="va">d</span><span class="op">$</span><span class="va">perc.lactose</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] -0.9416373</code></pre>
</div>
</div>
<p><br></p>
<p>Correlations do have to get pretty high before this problem interferes with your analysis. But, <strong><em>what matters isn’t just the correlation between a pair of variables. Rather, what matters is the correlation that remains after accounting for any other predictors.</em></strong></p>
<p>But with only two predictors here, we can address the correlation question directly. Suppose we have only kcal.per.g and perc.fat:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb512"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Construct a random predictor variable, call it x, that is correlated with perc.fat </span></span>
<span><span class="co"># at some predetermined level</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span></span>
<span><span class="va">rho</span> <span class="op">&lt;-</span> <span class="fl">0.6</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">rho</span><span class="op">*</span><span class="va">milk</span><span class="op">$</span><span class="va">perc.fat</span>, <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">rho</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">kcal.per.g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">milk</span><span class="op">$</span><span class="va">perc.fat</span> <span class="op">-</span> <span class="va">x</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">kcal.per.g</span>, <span class="va">milk</span><span class="op">$</span><span class="va">perc.fat</span>, <span class="va">x</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">d</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.10a-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb513"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the regression model that tries to predict kcal.per.g using both perc.fat </span></span>
<span><span class="co"># and our random fake variable x</span></span>
<span><span class="va">m5.10a</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bf</span><span class="op">*</span><span class="va">milk</span><span class="op">$</span><span class="va">perc.fat</span> <span class="op">+</span> <span class="va">bx</span><span class="op">*</span><span class="va">x</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0.4</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">bf</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">bx</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.10a</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
a      0.1167787 0.5866545 -0.8208086  1.0543659
bf     1.0746174 0.1491246  0.8362875  1.3129474
bx    -1.1247141 0.2447117 -1.5158106 -0.7336176
sigma  1.2061145 0.1594012  0.9513607  1.4608683</code></pre>
</div>
</div>
<p>Now repeat this procedure many times, at different levels of correlation between perc.fat and x:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb515"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">milk</span></span>
<span><span class="va">sim.coll</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span> <span class="va">r</span><span class="op">=</span><span class="fl">0.9</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">d</span><span class="op">$</span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span> , mean<span class="op">=</span><span class="va">r</span><span class="op">*</span><span class="va">d</span><span class="op">$</span><span class="va">perc.fat</span> ,</span>
<span>        sd<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">r</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">perc.fat</span><span class="op">)</span> <span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="va">perc.fat</span> <span class="op">+</span> <span class="va">x</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span> <span class="op">)</span> <span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="co"># stddev of parameter</span></span>
<span><span class="op">}</span></span>
<span><span class="va">rep.sim.coll</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span> <span class="va">r</span><span class="op">=</span><span class="fl">0.9</span> , <span class="va">n</span><span class="op">=</span><span class="fl">100</span> <span class="op">)</span> <span class="op">{</span> <span class="co"># 100 regressions</span></span>
<span>    <span class="va">stddev</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">replicate</a></span><span class="op">(</span> <span class="va">n</span> , <span class="fu">sim.coll</span><span class="op">(</span><span class="va">r</span><span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">stddev</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">r.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fl">0</span>,to<span class="op">=</span><span class="fl">0.99</span>,by<span class="op">=</span><span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">stddev</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">r.seq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span> <span class="fu">rep.sim.coll</span><span class="op">(</span>r<span class="op">=</span><span class="va">z</span>,n<span class="op">=</span><span class="fl">100</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">stddev</span> <span class="op">~</span> <span class="va">r.seq</span> , type<span class="op">=</span><span class="st">"l"</span> , col<span class="op">=</span><span class="va">rangi2</span>, lwd<span class="op">=</span><span class="fl">2</span> , xlab<span class="op">=</span><span class="st">"correlation"</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5.40-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb516"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The effect of correlated predictor variables on the narrowness of the posterior distribution. </span></span>
<span><span class="co"># The vertical axis shows the standard deviation of the posterior distribution of the slope. </span></span>
<span><span class="co"># The horizontal axis is the correlation between the predictor of interest (perc.fat) and another</span></span>
<span><span class="co"># predictor (x) added to the model. As the correlation increases, the standard deviation inflates.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>What can be done about multicollinearity</em></strong></span></p>
<ul>
<li><p>Be aware of it.</p></li>
<li>
<p>Check the predictor variables against one another in a pairs plot.</p>
<ul>
<li>Any pair or cluster of variables with very large correlations, over about 0.9, may be problematic, once included as main effects in the same model.</li>
<li>However, it isn’t always true that highly correlated variables are completely redundant— other predictors might be correlated with only one of the pair, and so help extract the unique information each predictor provides.</li>
<li>So, you can’t know just from a table of correlations nor from a matrix of scatterplots whether multicollinearity will prevent you from including sets of variables in the same model.</li>
<li>Still, you can usually diagnose the problem by looking for a big inflation of standard deviation, when both variables are included in the same model.</li>
</ul>
</li>
</ul>
<ul>
<li>Principle components or Factor analysis
<ul>
<li>A data reduction procedure, and then to use the components/factors as predictor variables</li>
<li>may be considered voodoo</li>
</ul>
</li>
</ul>
<ul>
<li><strong><em>It’s usually helpful to check the covariation among parameters, especially when intervals are extremely wide, so you don’t misinterpret what the model is trying to tell you.</em></strong></li>
</ul>
<p><br></p>
</section><section id="post-treatment-bias" class="level3"><h3 class="anchored" data-anchor-id="post-treatment-bias">Post-treatment bias</h3>
<ul>
<li>Omitted variable bias
<ul>
<li>mistaken inferences that arise from omitting predictor variables</li>
</ul>
</li>
</ul>
<ul>
<li>Post-treatment bias
<ul>
<li>mistaken inferences arising from including variables that are consequences of other variables</li>
</ul>
</li>
</ul>
<p><br></p>
<p>Simulate post-treatment bias in plant growth vs.&nbsp;different anti-fungal soil treatments model. There are four variables of interest here: initial height, final height, treatment, and presence of fungus. Final height is the outcome of interest. But which of the other variables should be in the model? If your goal is to make a causal inference about the treatment, you shouldn’t include the presence of fungus, because it is a post-treatment effect.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb517"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">54</span><span class="op">)</span></span>
<span><span class="co"># number of plants</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span></span>
<span><span class="co"># simulate initial heights</span></span>
<span><span class="va">h0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>,<span class="fl">10</span>,<span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># assign treatments and simulate fungus and growth</span></span>
<span><span class="va">treatment</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span> , each<span class="op">=</span><span class="va">N</span><span class="op">/</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="va">fungus</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span> <span class="va">N</span> , size<span class="op">=</span><span class="fl">1</span> , prob<span class="op">=</span><span class="fl">0.5</span> <span class="op">-</span> <span class="va">treatment</span><span class="op">*</span><span class="fl">0.4</span> <span class="op">)</span></span>
<span><span class="va">h1</span> <span class="op">&lt;-</span> <span class="va">h0</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="fl">5</span> <span class="op">-</span> <span class="fl">3</span><span class="op">*</span><span class="va">fungus</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compose a clean data frame</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> h0<span class="op">=</span><span class="va">h0</span> , h1<span class="op">=</span><span class="va">h1</span> , treatment<span class="op">=</span><span class="va">treatment</span> , fungus<span class="op">=</span><span class="va">fungus</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   100 obs. of  4 variables:
 $ h0       : num  13.77 10.99 9.27 13.24 12.33 ...
 $ h1       : num  15.6 13 11.3 14.2 15.6 ...
 $ treatment: int  0 0 0 0 0 0 0 0 0 0 ...
 $ fungus   : int  1 1 1 1 1 1 0 0 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb519"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># fit the model that includes all of the available variables</span></span>
<span><span class="va">m5.13</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">h1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>,<span class="va">sigma</span><span class="op">)</span>,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bh</span><span class="op">*</span><span class="va">h0</span> <span class="op">+</span> <span class="va">bt</span><span class="op">*</span><span class="va">treatment</span> <span class="op">+</span> <span class="va">bf</span><span class="op">*</span><span class="va">fungus</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bh</span>,<span class="va">bt</span>,<span class="va">bf</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.13</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%       94.5%
a      5.0760895 0.50330524  4.2717105  5.88046847
bh     0.9888748 0.04630184  0.9148755  1.06287404
bt    -0.2940410 0.20805340 -0.6265505  0.03846852
bf    -3.0766366 0.21338337 -3.4176644 -2.73560873
sigma  0.9437399 0.06673229  0.8370888  1.05039100</code></pre>
</div>
</div>
<p>The marginal posterior for bt, the effect of treatment, is actually negative here. But it mainly had very little effect. The other two predictors, h0 and fungus, have important effects. Given that we know the treatment matters, because we built the simulation that way, what happened here? The problem is that fungus is mostly a consequence of treatment- fungus is a post-treatment variable. When we control for fungus, the soil treatment doesn’t matter because soil treatment has its effects on growth through reducing fungus.</p>
<p><em>Model m5.13 misleads because it asks the wrong question, not because it would make poor predictions- the model that includes fungus both fits the sample better and would make better out-of-sample predictions. No statistical procedure can substitute for scientific knowledge and attention to it.</em></p>
<p>What we actually want to know, based on the design of the experiment, is the impact of treatment on growth. To measure this properly, we should omit the post-treatment variable fungus.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb521"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">43</span><span class="op">)</span></span>
<span><span class="va">m5.14</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">h1</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>,<span class="va">sigma</span><span class="op">)</span>,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bh</span><span class="op">*</span><span class="va">h0</span> <span class="op">+</span> <span class="va">bt</span><span class="op">*</span><span class="va">treatment</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">bh</span>,<span class="va">bt</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.14</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean         sd      5.5%    94.5%
a     3.1447927 0.85123728 1.7843511 4.505234
bh    1.0035258 0.08123017 0.8737043 1.133347
bt    0.9410028 0.33255187 0.4095207 1.472485
sigma 1.6561506 0.11710267 1.4689979 1.843303</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb523"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now the impact of treatment is strong and positive, as it should be. It makes sense to </span></span>
<span><span class="co"># control for pre-treatment differences, like the initial height h0, that might mask the </span></span>
<span><span class="co"># causal influence of treatment. But including post-treatment variables can actually mask </span></span>
<span><span class="co"># the treatment itself.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="categorical-variables" class="level2"><h2 class="anchored" data-anchor-id="categorical-variables">Categorical variables</h2>
<p>A common question for statistical methods is to what extent an outcome changes as a result of presence or absence of a category. Common examples of categorical variables (factors) include:</p>
<ul>
<li><p>Sex: male, female</p></li>
<li><p>Developmental status: infant, juvenile, adult</p></li>
<li><p>Geographic region: Africa, Europe, Melanesia</p></li>
<li><p>Taxonomic group: Ape, Monkeys</p></li>
</ul>
<p><br></p>
<section id="binary-categories" class="level3"><h3 class="anchored" data-anchor-id="binary-categories">Binary categories</h3>
<p>In the simplest case, the variable of interest has only two categories, like male and female.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb524"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data Howell1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Howell1</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Howell1</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   544 obs. of  4 variables:
 $ height: num  152 140 137 157 145 ...
 $ weight: num  47.8 36.5 31.9 53 41.3 ...
 $ age   : num  63 63 65 41 51 35 32 27 19 54 ...
 $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb526"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The male variable is our new predictor, an example of a dummy variable.</span></span>
<span><span class="co"># Dummy variables are devices for encoding categories into quantitative models.</span></span>
<span><span class="co"># e.g. 1 for male, 0 for female</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The effect of a dummy variable is to turn a parameter on for those cases in the category. Simultaneously, the variable turns the same parameter off for those cases in another category. The model to fit is:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{h}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_m \text{m}_i\\
\alpha &amp;\sim \text{Normal}(178, 100)\\
\beta_m &amp;\sim \text{Normal}(0, 10)\\
\sigma &amp;\sim \text{Uniform}(0, 50)
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>h   = height

m   = dummy variable indicating a male individual
</code></pre>
<p>The parameter <span class="math inline">\(\beta_m\)</span> influences prediction only for those cases where <span class="math inline">\(\text{m}_i\)</span> = 1. When <span class="math inline">\(\text{m}_i\)</span> = 0, it has no effect on prediction, because it is multiplied by zero inside the linear model, <span class="math inline">\(\alpha + \beta_m \text{m}_i\)</span>, canceling it out, whatever its value.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb528"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the model</span></span>
<span><span class="va">m5.15</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bm</span><span class="op">*</span><span class="va">male</span> , </span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bm</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.15</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%     94.5%
a     134.830478 1.5918746 132.286355 137.37460
bm      7.279393 2.2833451   3.630166  10.92862
sigma  27.309193 0.8279734  25.985931  28.63245</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb530"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The parameter α (a) is now the average height among females. Because when mi = 0, </span></span>
<span><span class="co"># indicating a female, the predicted mean height is just μi = α + βm(0) = α. </span></span>
<span><span class="co"># So the estimate says that the expected average female height is 135 cm. </span></span>
<span><span class="co"># The parameter βm then tells us the average difference between males and females, 7.3 cm. </span></span>
<span><span class="co"># So to compute the average male height, you just add these two estimates: 135 + 7.3 = 142.3.</span></span>
<span></span>
<span><span class="co"># You’ll also need to consider the width of the posterior distribution. And because the </span></span>
<span><span class="co"># parameters α and βm are correlated with one another, you can’t just add together </span></span>
<span><span class="co"># the boundaries in the precis output and get correct boundaries for their sum. </span></span>
<span></span>
<span><span class="co"># Sample from the posterior to derive a percentile interval for average male height</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m5.15</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add samples of a and bm together to get the posterior distribution of their sum</span></span>
<span><span class="va">mu.male</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">bm</span></span>
<span><span class="fu">PI</span><span class="op">(</span><span class="va">mu.male</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      5%      94% 
139.3918 144.7775 </code></pre>
</div>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Re-parameterizing the model</strong></span></span></p>
<p>Instead of using a parameter for the difference between males and females, we can make parameters specific to males and females:</p>
<p><span class="math display">\[
\begin{align*}
\text{h}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha_f(1 - \text{m}_i) + \alpha_m \text{m}_i\\
\end{align*}
\]</span></p>
<pre><code>alpha_f   = average female height

alpha_m   = average male height
</code></pre>
<p>Plug in <span class="math inline">\(\text{m}_i\)</span> = 0 and <span class="math inline">\(\text{m}_i\)</span> = 1 to verify that either <span class="math inline">\(\alpha_f\)</span> or <span class="math inline">\(\alpha_m\)</span>, but never both, is turned on for any individual case i.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb533"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the model</span></span>
<span><span class="va">m5.15b</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">height</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">af</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">male</span><span class="op">)</span> <span class="op">+</span> <span class="va">am</span><span class="op">*</span><span class="va">male</span> ,</span>
<span>        <span class="va">af</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">am</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">178</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">50</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.15b</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean        sd      5.5%     94.5%
af    134.64103 1.6117398 132.06516 137.21690
am    142.32902 1.7031888 139.60699 145.05104
sigma  27.30819 0.8278877  25.98506  28.63131</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb535"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The results are inferentially equivalent to the original m5.15.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The mathematical model can be rearranged where the old <span class="math inline">\(\beta_m\)</span> as the difference between the average male and female, <span class="math inline">\(\alpha_m - \alpha_f\)</span>:</p>
<p><span class="math display">\[\mu_i = \alpha_f + (\alpha_m - \alpha_f) \text{m}_i \]</span></p>
<p><br></p>
</section><section id="many-categories" class="level3"><h3 class="anchored" data-anchor-id="many-categories">Many categories</h3>
<p>When there are more than two categories, you’ll need more than one dummy variable. To include k categories in a linear model, you require k − 1 dummy variables. Each dummy variable indicates, with the value 1, a unique category. The category with no dummy variable assigned to it ends up again as the “intercept” category.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb536"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load milk data and extract clade variable</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">milk</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">clade</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] Strepsirrhine    New World Monkey Old World Monkey Ape             
Levels: Ape New World Monkey Old World Monkey Strepsirrhine</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb538"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># There are more than two categories and none of them have yet been coded into dummy variables.</span></span>
<span></span>
<span><span class="co"># Create a dummy for the New World Monkey category</span></span>
<span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">clade.NWM</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">clade</span><span class="op">==</span><span class="st">"New World Monkey"</span> , <span class="fl">1</span> , <span class="fl">0</span> <span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb540"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Only those rows (cases) where clade is New World Monkey get a 1 for this new variable.</span></span>
<span></span>
<span><span class="co"># Make two more dummy variables with the same strategy</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">clade.OWM</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">clade</span><span class="op">==</span><span class="st">"Old World Monkey"</span> , <span class="fl">1</span> , <span class="fl">0</span> <span class="op">)</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">clade.S</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">clade</span><span class="op">==</span><span class="st">"Strepsirrhine"</span> , <span class="fl">1</span> , <span class="fl">0</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>The category <code>Ape</code> will be the default “intercept” category. In fact, if you try to include a dummy variable for apes, you’ll up with a non-identifiable model.</p>
<p>The model we aim to fit to the data is kcal.per.g regressed on the dummy variables for clade:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{k}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_{NWM} \text{NWM}_i + \beta_{OWM} \text{OWM}_i + \beta_S \text{S}_i\\
\alpha &amp;\sim \text{Normal}(0.6, 10)\\
\beta_{NWM} &amp;\sim \text{Normal}(0, 1)\\
\beta_{OWM} &amp;\sim \text{Normal}(0, 1)\\
\beta_S &amp;\sim \text{Normal}(0, 1)\\
\sigma &amp;\sim \text{Uniform}(0, 10)
\end{align*}\]</span></p>
<p>$$</p>
<p>A linear model like this really defines four different linear models, each corresponding to a different category.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb541"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Fit the model</span></span>
<span><span class="va">m5.16</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b.NWM</span><span class="op">*</span><span class="va">clade.NWM</span> <span class="op">+</span> <span class="va">b.OWM</span><span class="op">*</span><span class="va">clade.OWM</span> <span class="op">+</span> <span class="va">b.S</span><span class="op">*</span><span class="va">clade.S</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0.6</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b.NWM</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b.OWM</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">b.S</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.16</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd       5.5%     94.5%
a      0.54609803 0.03808579  0.4852296 0.6069665
b.NWM  0.16810149 0.05386157  0.0820203 0.2541827
b.OWM  0.24170706 0.06020619  0.1454859 0.3379282
b.S   -0.03799841 0.06370576 -0.1398125 0.0638157
sigma  0.11450632 0.01503123  0.0904835 0.1385291</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb543"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The estimate a is the average milk energy for apes, and the estimates for the other </span></span>
<span><span class="co"># categories are differences from apes.</span></span>
<span></span>
<span><span class="co">## Use samples to get posterior distributions of the average milk energy in each category</span></span>
<span><span class="co"># sample posterior</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m5.16</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute averages for each category</span></span>
<span><span class="va">mu.ape</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span></span>
<span><span class="va">mu.NWM</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b.NWM</span></span>
<span><span class="va">mu.OWM</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b.OWM</span></span>
<span><span class="va">mu.S</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b.S</span></span>
<span></span>
<span><span class="co"># summarize using precis</span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mu.ape</span>,<span class="va">mu.NWM</span>,<span class="va">mu.OWM</span>,<span class="va">mu.S</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd      5.5%     94.5% histogram
mu.ape 0.5453054 0.03812854 0.4843704 0.6075089   ▁▁▂▇▇▁▁
mu.NWM 0.7144030 0.03848309 0.6530230 0.7762385   ▁▁▅▇▂▁▁
mu.OWM 0.7880187 0.04677242 0.7129501 0.8618181  ▁▁▃▇▅▂▁▁
mu.S   0.5093351 0.05115477 0.4280024 0.5910291  ▁▁▂▇▇▃▁▁</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb545"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The most plausible (conditional on data and model) average milk energies in each category </span></span>
<span><span class="co"># are 0.55, 0.71, 0.79, and 0.51.</span></span>
<span></span>
<span><span class="co">## Re-parameterize model after fitting it to data to know the estimate difference between</span></span>
<span><span class="co">## two monkey groups- rather than a difference from apes. </span></span>
<span><span class="co"># Substract the estimated means to get a difference</span></span>
<span><span class="va">diff.NWM.OWM</span> <span class="op">&lt;-</span> <span class="va">mu.NWM</span> <span class="op">-</span> <span class="va">mu.OWM</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span> <span class="va">diff.NWM.OWM</span> , probs<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>,<span class="fl">0.5</span>,<span class="fl">0.975</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       2.5%         50%       97.5% 
-0.19357941 -0.07361547  0.04409290 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb547"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The values are the posterior lower 95% boundary, the median, and the upper 95% boundary </span></span>
<span><span class="co"># for the difference between New World and Old World monkeys.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="adding-regular-predictor-variables" class="level3"><h3 class="anchored" data-anchor-id="adding-regular-predictor-variables">Adding regular predictor variables</h3>
<p>Just add the predictor variables to the equation for the mean, as you normally would. For example, to add the influence of perc.fat to the model with dummies for the clades:</p>
<p><span class="math display">\[\mu_i = \alpha + \beta_{NWM} \text{NWM}_i + \beta_{OWM} \text{OWM}_i + \beta_S \text{S}_i + \beta_F \text{F}_i\]</span></p>
<pre><code>Fi    = the percent fat for the i-th case in the data 

βF    = the slope that measures the influence of F on predictions about the mean milk energy.
</code></pre>
<p><br></p>
</section><section id="another-approach-unique-intercepts" class="level3"><h3 class="anchored" data-anchor-id="another-approach-unique-intercepts">Another approach: Unique intercepts</h3>
<p>Another way to conceptualize categorical variables is to construct a vector of intercept parameters, one parameter for each category. Then you can create an <strong><em>index variable</em></strong> in your data frame that says which parameter goes with each case.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb549"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Make an index variable for clade in the primate milk data</span></span>
<span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">clade_id</span> <span class="op">&lt;-</span> <span class="fu">coerce_index</span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">clade</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1] 4 4 4 4 4 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb551"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This variable just gives the number of each unique clade value. There are four different clades, </span></span>
<span><span class="co"># and it doesn’t matter which is “1” or “4,” because they are unordered.</span></span>
<span></span>
<span><span class="co"># Use map to make a vector of intercepts, one intercept for each unique value in clade_id</span></span>
<span><span class="va">m5.16_alt</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span><span class="op">[</span><span class="va">clade_id</span><span class="op">]</span> ,</span>
<span>        <span class="va">a</span><span class="op">[</span><span class="va">clade_id</span><span class="op">]</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0.6</span> , <span class="fl">10</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span> <span class="va">m5.16_alt</span> , depth<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean         sd       5.5%     94.5%
a[1]  0.5455549 0.03816863 0.48455402 0.6065557
a[2]  0.7144430 0.03816863 0.65344211 0.7754438
a[3]  0.7883283 0.04674666 0.71361806 0.8630385
a[4]  0.5080034 0.05120829 0.42616265 0.5898441
sigma 0.1145067 0.01503132 0.09048377 0.1385297</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb553"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Same averages for each clade as earlier (m5.16), but this time directly from the fit model.</span></span>
<span><span class="co"># Need to add depth=2 to the precis call in order to print out vector parameters like these.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="ordinary-least-squares-and-lm" class="level2"><h2 class="anchored" data-anchor-id="ordinary-least-squares-and-lm">Ordinary least squares and <code>lm</code>
</h2>
<p>Gaussian regression models or ordinary least squares regression (OLS) is a way of estimating the parameters of a linear regression. Instead of searching for the combination of parameter values that maximizes the posterior probability, OLS instead solves for the parameter values that minimize the sum of the squared residuals. This procedure is often functionally equivalent to maximizing the posterior probability or maximizing the likelihood. <em>Provided you are happy with flat priors, you’ll get the same estimates with <code>lm</code> that you got with <code>map</code>.</em></p>
<p><br></p>
<section id="design-formulas" class="level3"><h3 class="anchored" data-anchor-id="design-formulas">Design formulas</h3>
<p>Design formulas (input format for models) take the expression for <span class="math inline">\(\mu_i\)</span> in the detailed mathematical form of a model and strip out the parameters, leaving only a series of predictor names, separated by + signs. These formulas are sufficient to describe the model’s design, provided all priors are flat.</p>
<p>The linear regression model:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta \text{x}_i
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>The corresponding design formula with the leading 1 on the right-hand side indicates the intercept, <span class="math inline">\(\alpha\)</span>:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{y} \sim 1 + \text{x}
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>The linear regression model with three predictors:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_x \text{x}_i + \beta_z \text{Z}_i + \beta_w \text{W}_i
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>The corresponding design formula:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{y} \sim 1 + \text{x} + \text{z} + \text{w}
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
</section><section id="using-lm" class="level3"><h3 class="anchored" data-anchor-id="using-lm">Using <code>lm</code>
</h3>
<p>To fit a linear regression using OLS, just provide the design formula and the name of the data frame.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb554"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="fl">4</span>,<span class="fl">4</span>,<span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x</span>, <span class="va">z</span>, <span class="va">w</span><span class="op">)</span></span>
<span><span class="co"># For first example above</span></span>
<span><span class="va">m5.17</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span> <span class="co"># assume data are in a frame named d</span></span>
<span></span>
<span><span class="co"># For second example above</span></span>
<span><span class="va">m5.18</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x</span> <span class="op">+</span> <span class="va">z</span> <span class="op">+</span> <span class="va">w</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="co"># The parameter estimates will be named after the predictors, since you didn’t provide any </span></span>
<span><span class="co"># explicit parameter names. You can sample from the posterior and process estimates as usual.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<section id="intercepts-are-optional" class="level4"><h4 class="anchored" data-anchor-id="intercepts-are-optional">Intercepts are optional</h4>
<p>These two model fits return exactly the same estimates:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb555"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m5.17</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="va">m5.19</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Test with milk data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">milk</span></span>
<span><span class="va">m5.17a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">milk</span><span class="op">$</span><span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">milk</span><span class="op">$</span><span class="va">perc.protein</span>, data <span class="op">=</span> <span class="va">d</span><span class="op">)</span></span>
<span><span class="va">m5.18a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">milk</span><span class="op">$</span><span class="va">kcal.per.g</span> <span class="op">~</span>  <span class="va">milk</span><span class="op">$</span><span class="va">perc.protein</span>, data <span class="op">=</span> <span class="va">d</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.17a</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                         mean          sd        5.5%      94.5%
(Intercept)       0.610731119 0.109288176  0.43606751 0.78539473
milk$perc.protein 0.001889421 0.006398289 -0.00833628 0.01211512</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb557"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.18a</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                         mean          sd        5.5%      94.5%
(Intercept)       0.610731119 0.109288176  0.43606751 0.78539473
milk$perc.protein 0.001889421 0.006398289 -0.00833628 0.01211512</code></pre>
</div>
</div>
<p>When you omit the explicit intercept, <code>lm</code> assumes you wanted one. If you really do not want an intercept— equivalent to fixing <span class="math inline">\(\alpha = 0\)</span>— then you can use one of these forms:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb559"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m5.20</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">x</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="va">m5.21</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">-</span> <span class="fl">1</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Test with milk data</span></span>
<span><span class="va">m5.20a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">milk</span><span class="op">$</span><span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">milk</span><span class="op">$</span><span class="va">perc.protein</span><span class="op">)</span></span>
<span><span class="va">m5.21a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">milk</span><span class="op">$</span><span class="va">kcal.per.g</span> <span class="op">~</span> <span class="va">milk</span><span class="op">$</span><span class="va">perc.protein</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.20a</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                        mean          sd       5.5%      94.5%
milk$perc.protein 0.03622675 0.002572682 0.03211511 0.04033839</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb561"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">precis</span><span class="op">(</span><span class="va">m5.21a</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                        mean          sd       5.5%      94.5%
milk$perc.protein 0.03622675 0.002572682 0.03211511 0.04033839</code></pre>
</div>
</div>
<p><br></p>
</section><section id="categorical-variables-1" class="level4"><h4 class="anchored" data-anchor-id="categorical-variables-1">Categorical variables</h4>
<p>Black-box functions like <code>lm</code> will automatically expand categorical factors into the necessary number of dummy variables. But R is not a mind reader, and sometimes the same variable can be treated as categories or rather as continuous. To prevent R from getting confused, and therefore confusing yourself, best to get into the habit of explicitly telling lm when you mean to use a variable as categories.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb563"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># R can think seasons (1,2,3,4) as categorical (different seasons) or </span></span>
<span><span class="co"># continuous variable marking the passage of time</span></span>
<span><span class="va">season</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">3</span>,<span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Tell R to use variable as categories</span></span>
<span><span class="va">m5.22</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">season</span><span class="op">)</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="co"># The function as.factor makes sure that lm knows to treat the values in season </span></span>
<span><span class="co"># as unordered categories.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="transform-variables-first" class="level4"><h4 class="anchored" data-anchor-id="transform-variables-first">Transform variables first</h4>
<p>Black-box functions like <code>lm</code> sometimes have problems understanding the transformations(logarithms, squares, cubes, centering, standardizing), when they are included in the design formula. So it’s best to make new variables that hold the transformed values. Then include those new variables instead.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb564"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Make up a data frame d to run the code</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, y <span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span>, by <span class="op">=</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit a cubic regression of y on x</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">x2</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">x3</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">x</span><span class="op">^</span><span class="fl">3</span></span>
<span><span class="va">m5.23</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x</span> <span class="op">+</span> <span class="va">x2</span> <span class="op">+</span> <span class="va">x3</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Use 'as is' function I() to fit the same cubic model</span></span>
<span><span class="co"># Note that I() can't be used inside map </span></span>
<span><span class="va">m5.24</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="no-estimate-for-sigma" class="level4"><h4 class="anchored" data-anchor-id="no-estimate-for-sigma">No estimate for <span class="math inline">\(\sigma\)</span>
</h4>
<p>Using <code>lm</code> will not provide a posterior distribution for the standard deviation <span class="math inline">\(\sigma\)</span>— it won’t be reported in the table of estimates. If you ask for a summary of the model fit, <code>lm</code> will report the “residual standard error,” which is a slightly different estimate of <span class="math inline">\(\sigma\)</span>, but without any uncertainty information like a standard deviation (or standard error).</p>
<p>Use <code>map</code> if you need <span class="math inline">\(\sigma\)</span>- get some sense of the uncertainty of the estimate. As a bonus, you can use informative priors then, as well.</p>
<p><br></p>
</section></section><section id="building-map-formulas-from-lm-formulas" class="level3"><h3 class="anchored" data-anchor-id="building-map-formulas-from-lm-formulas">Building <code>map</code> formulas from <code>lm</code> formulas</h3>
<p>The <code>rethinking</code> package provides a function, <code>glimmer</code>, that translates design formulas into <code>map</code>-style model formulas.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb565"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">cars</span><span class="op">)</span></span>
<span><span class="fu">glimmer</span><span class="op">(</span> <span class="va">dist</span> <span class="op">~</span> <span class="va">speed</span> , data<span class="op">=</span><span class="va">cars</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>alist(
    dist ~ dnorm( mu , sigma ),
    mu &lt;- Intercept +
        b_speed*speed,
    Intercept ~ dnorm(0,10),
    b_speed ~ dnorm(0,10),
    sigma ~ dcauchy(0,2)
)</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb567"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The function glimmer automatically adds default priors. You can change these to suit your </span></span>
<span><span class="co"># tastes, or remove them all together, if you just want maximum likelihood estimation. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="summary" class="level2"><h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>The defining question of multiple regression is:</p>
<p><span class="math display">\[\text{What is the value of knowing each predictor, once we already know the other predictors?}\]</span></p>
<p>Implicit in this question are:</p>
<ol type="1">
<li><p>a focus on the value of the predictors for description of the sample, instead of forecasting a future sample</p></li>
<li><p>the assumption that the value of each predictor does not depend upon the values of the other predictors</p></li>
</ol>
<p><br></p>
</section><section id="practice-3" class="level2"><h2 class="anchored" data-anchor-id="practice-3">Practice</h2>
<section id="easy-3" class="level3"><h3 class="anchored" data-anchor-id="easy-3">Easy</h3>
<p><br></p>
<blockquote class="blockquote">
<p>5E1. Which of the linear models below are multiple linear regressions?</p>
</blockquote>
<ol start="2" type="1">
<li><span class="math inline">\(\mu_i = \beta_x \text{x}_i + \beta_z \text{Z}_i\)</span></li>
<li><span class="math inline">\(\mu_i = \alpha + \beta_x \text{x}_i + \beta_z \text{Z}_i\)</span></li>
</ol>
<p><br></p>
<blockquote class="blockquote">
<p>5E2. Write down a multiple regression to evaluate the claim: Animal diversity is linearly related to latitude, but only after controlling for plant diversity. You just need to write down the model definition.</p>
</blockquote>
<p>$$ <span class="math display">\[\begin{align*}
\text{AD_i} &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_L \text{L}_i + \beta_D \text{D}_i
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>AD    = Animal diversity

L     = Latitude

D     = Plant diversity
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>5E3. Write down a multiple regression to evaluate the claim: Neither amount of funding nor size of laboratory is by itself a good predictor of time to PhD degree; but together these variables are both positively associated with time to degree. Write down the model definition and indicate which side of zero each slope parameter should be on.</p>
</blockquote>
<p>$$ <span class="math display">\[\begin{align*}
T_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_F \text{F}_i + \beta_S \text{S}_i
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>T   = Time to PhD degree

F   = Amount of funding

S   = Size of laboratory

Both beta_F and beta_S should be on the positive size of zero if considered together.
If considered individually, both will be almost zero. 
</code></pre>
<p><br></p>
<blockquote class="blockquote">
<p>5E4. Suppose you have a single categorical predictor with 4 levels (unique values), labeled A, B, C and D. Let Ai be an indicator variable that is 1 where case i is in category A. Also suppose Bi, Ci, and Di for the other categories. Now which of the following linear models are inferentially equivalent ways to include the categorical variable in a regression? Models are inferentially equivalent when it’s possible to compute one posterior distribution from the posterior distribution of another model.</p>
</blockquote>
<p>I exclude choice 2 as it contains all variables plus one extra unidentified interceptor variable. I use <code>Accident</code> dataset to check the similarity among posterior distributions of the models in choices 1, 3, 4, and 5. As seen below, the mean (<span class="math inline">\(\mu\)</span>) values of dummy variables A, B, C and D are similar across the models 1, 3, 4 and 5. Hence, choice 1, 3, 4 and 5 are the correct answers to the question. The slight difference between model 1,3 and model 4,5 is because I used informative priors for model 4 and 5, and flat priors for model 1 and 3.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb570"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>, mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="fl">4</span>,<span class="fl">4</span>,<span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load data to test the posteriors of each model </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Accident"</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">Accident</span></span>
<span></span>
<span><span class="co"># Extract categorical variables</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">type</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] A B C D E
Levels: A B C D E</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb572"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Remove level E because we only need A, B, C, D</span></span>
<span><span class="va">dn</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">type</span> <span class="op">==</span> <span class="st">"E"</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">dn</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   32 obs. of  5 variables:
 $ type   : Factor w/ 4 levels "A","B","C","D": 1 1 1 1 1 1 1 1 2 2 ...
 $ constr : Factor w/ 4 levels "C6064","C6569",..: 1 1 2 2 3 3 4 4 1 1 ...
 $ operate: Factor w/ 2 levels "O6074","O7579": 1 2 1 2 1 2 1 2 1 2 ...
 $ months : int  127 63 1095 1095 1512 3353 NA 2244 44882 17176 ...
 $ acc    : int  0 0 3 4 6 18 NA 11 39 29 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb574"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract again</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span><span class="op">(</span><span class="va">dn</span><span class="op">$</span><span class="va">type</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] A B C D
Levels: A B C D</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb576"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># I want to see correlation between ship type and number of accident</span></span>
<span><span class="co"># Check if got NA values in accident</span></span>
<span><span class="va">dn</span><span class="op">$</span><span class="va">acc</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1]  0  0  3  4  6 18 NA 11 39 29 58 53 12 44 NA 18  1  1  0  1  6  2 NA  1  0
[26]  0  0  0  2 11 NA  4</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb578"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Drop the 4 NA values</span></span>
<span><span class="va">dnc</span> <span class="op">&lt;-</span> <span class="va">dn</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">dn</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">dnc</span><span class="op">$</span><span class="va">acc</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> [1]  0  0  3  4  6 18 11 39 29 58 53 12 44 18  1  1  0  1  6  2  1  0  0  0  0
[26]  2 11  4</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb580"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Make dummy variables for A, B, C, D</span></span>
<span><span class="co"># The question doesn't specify which label is the intercept one, so I will do all</span></span>
<span><span class="va">dnc</span><span class="op">$</span><span class="va">type.A</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">dnc</span><span class="op">$</span><span class="va">type</span> <span class="op">==</span> <span class="st">"A"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">dnc</span><span class="op">$</span><span class="va">type.B</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">dnc</span><span class="op">$</span><span class="va">type</span> <span class="op">==</span> <span class="st">"B"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">dnc</span><span class="op">$</span><span class="va">type.C</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">dnc</span><span class="op">$</span><span class="va">type</span> <span class="op">==</span> <span class="st">"C"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">dnc</span><span class="op">$</span><span class="va">type.D</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">dnc</span><span class="op">$</span><span class="va">type</span> <span class="op">==</span> <span class="st">"D"</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Model 1</span></span>
<span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">dnc</span><span class="op">$</span><span class="va">acc</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">type.A</span> <span class="op">+</span> <span class="va">type.B</span> <span class="op">+</span> <span class="va">type.D</span>, data <span class="op">=</span> <span class="va">dnc</span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                  mean       sd      5.5%     94.5%
(Intercept)  1.7142857 3.595632 -4.032229  7.460801
type.A       4.2857143 5.084992 -3.841085 12.412513
type.B      34.4285714 5.084992 26.301772 42.555371
type.D       0.7142857 5.084992 -7.412513  8.841085</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb582"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m1</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"Model 1"</span><span class="op">)</span></span>
<span><span class="va">post1</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span>
<span><span class="va">mu.C</span> <span class="op">&lt;-</span> <span class="va">post1</span><span class="op">$</span><span class="va">Intercept</span></span>
<span><span class="va">mu.A</span> <span class="op">&lt;-</span> <span class="va">post1</span><span class="op">$</span><span class="va">Intercept</span> <span class="op">+</span> <span class="va">post1</span><span class="op">$</span><span class="va">type.A</span></span>
<span><span class="va">mu.B</span> <span class="op">&lt;-</span> <span class="va">post1</span><span class="op">$</span><span class="va">Intercept</span> <span class="op">+</span> <span class="va">post1</span><span class="op">$</span><span class="va">type.B</span></span>
<span><span class="va">mu.D</span> <span class="op">&lt;-</span> <span class="va">post1</span><span class="op">$</span><span class="va">Intercept</span> <span class="op">+</span> <span class="va">post1</span><span class="op">$</span><span class="va">type.D</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mu.A</span>, <span class="va">mu.B</span>, <span class="va">mu.C</span>, <span class="va">mu.D</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>          mean       sd       5.5%     94.5%       histogram
mu.A  5.960190 3.602781  0.1860312 11.678597   ▁▁▁▁▃▅▇▇▅▃▁▁▁
mu.B 36.189044 3.626941 30.4553982 41.975739 ▁▁▁▁▂▅▇▇▅▃▁▁▁▁▁
mu.C  1.720013 3.575800 -3.9596172  7.373927  ▁▁▁▁▃▅▇▇▅▂▁▁▁▁
mu.D  2.433794 3.562962 -3.3597146  8.124968         ▁▁▃▇▃▁▁</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb584"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Model 2 is skipped because it contains two intercepts.</span></span>
<span></span>
<span><span class="co"># Model 3</span></span>
<span><span class="va">m3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">dnc</span><span class="op">$</span><span class="va">acc</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">type.B</span> <span class="op">+</span> <span class="va">type.C</span> <span class="op">+</span> <span class="va">type.D</span>, data <span class="op">=</span> <span class="va">dnc</span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m3</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                 mean       sd        5.5%     94.5%
(Intercept)  6.000000 3.595632   0.2534852 11.746515
type.B      30.142857 5.084992  22.0160579 38.269656
type.C      -4.285714 5.084992 -12.4125135  3.841085
type.D      -3.571429 5.084992 -11.6982278  4.555371</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb586"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m3</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"Model 3"</span><span class="op">)</span></span>
<span><span class="va">post3</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m3</span><span class="op">)</span></span>
<span><span class="va">mu.A</span> <span class="op">&lt;-</span> <span class="va">post3</span><span class="op">$</span><span class="va">Intercept</span></span>
<span><span class="va">mu.C</span> <span class="op">&lt;-</span> <span class="va">post3</span><span class="op">$</span><span class="va">Intercept</span> <span class="op">+</span> <span class="va">post3</span><span class="op">$</span><span class="va">type.C</span></span>
<span><span class="va">mu.B</span> <span class="op">&lt;-</span> <span class="va">post3</span><span class="op">$</span><span class="va">Intercept</span> <span class="op">+</span> <span class="va">post3</span><span class="op">$</span><span class="va">type.B</span></span>
<span><span class="va">mu.D</span> <span class="op">&lt;-</span> <span class="va">post3</span><span class="op">$</span><span class="va">Intercept</span> <span class="op">+</span> <span class="va">post3</span><span class="op">$</span><span class="va">type.D</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mu.A</span>, <span class="va">mu.B</span>, <span class="va">mu.C</span>, <span class="va">mu.D</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>          mean       sd       5.5%     94.5%      histogram
mu.A  6.020434 3.577670  0.2764602 11.654928         ▁▁▅▇▂▁
mu.B 36.111900 3.571745 30.5243668 41.835216 ▁▁▁▁▂▅▇▇▅▃▁▁▁▁
mu.C  1.708005 3.595331 -4.0268087  7.481140 ▁▁▁▁▃▇▇▇▅▂▁▁▁▁
mu.D  2.437936 3.585580 -3.3308841  8.154994        ▁▁▃▇▃▁▁</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb588"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Model 4</span></span>
<span><span class="va">m4</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">acc</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">aA</span><span class="op">*</span><span class="va">type.A</span> <span class="op">+</span> <span class="va">aB</span><span class="op">*</span><span class="va">type.B</span> <span class="op">+</span> <span class="va">aC</span><span class="op">*</span><span class="va">type.C</span> <span class="op">+</span> <span class="va">aD</span><span class="op">*</span><span class="va">type.D</span>,</span>
<span>    <span class="va">aA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>    <span class="va">aB</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">30</span>, <span class="fl">9</span><span class="op">)</span>,</span>
<span>    <span class="va">aC</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>    <span class="va">aD</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dnc</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m4</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean       sd      5.5%     94.5%
aA     5.693277 2.773915  1.260026 10.126529
aB    35.399890 3.130481 30.396777 40.403002
aC     1.494998 2.773630 -2.937798  5.927794
aD     2.291341 2.773448 -2.141165  6.723847
sigma  8.818393 1.180839  6.931183 10.705602</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb590"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m4</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"Model 4"</span><span class="op">)</span></span>
<span><span class="va">post4</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m4</span><span class="op">)</span></span>
<span><span class="va">mu.A</span> <span class="op">&lt;-</span> <span class="va">post4</span><span class="op">$</span><span class="va">aA</span></span>
<span><span class="va">mu.B</span> <span class="op">&lt;-</span> <span class="va">post4</span><span class="op">$</span><span class="va">aB</span></span>
<span><span class="va">mu.C</span> <span class="op">&lt;-</span> <span class="va">post4</span><span class="op">$</span><span class="va">aC</span></span>
<span><span class="va">mu.D</span> <span class="op">&lt;-</span> <span class="va">post4</span><span class="op">$</span><span class="va">aD</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mu.A</span>, <span class="va">mu.B</span>, <span class="va">mu.C</span>, <span class="va">mu.D</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>          mean       sd      5.5%     94.5%      histogram
mu.A  5.739789 2.771947  1.271586 10.228388    ▁▁▂▅▇▇▃▁▁▁▁
mu.B 35.453816 3.145570 30.393508 40.394798 ▁▁▁▁▃▅▇▇▃▂▁▁▁▁
mu.C  1.499819 2.762258 -2.887174  5.874566  ▁▁▁▁▂▅▇▇▃▁▁▁▁
mu.D  2.287917 2.797042 -2.201474  6.744880   ▁▁▁▁▃▇▇▅▂▁▁▁</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb592"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Model 5</span></span>
<span><span class="va">m5</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">acc</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">aA</span><span class="op">*</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">type.B</span> <span class="op">-</span> <span class="va">type.C</span> <span class="op">-</span> <span class="va">type.D</span><span class="op">)</span> <span class="op">+</span> <span class="va">aB</span><span class="op">*</span><span class="va">type.B</span> <span class="op">+</span> <span class="va">aC</span><span class="op">*</span><span class="va">type.C</span> <span class="op">+</span> <span class="va">aD</span><span class="op">*</span><span class="va">type.D</span>,</span>
<span>    <span class="va">aA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>    <span class="va">aB</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">30</span>, <span class="fl">9</span><span class="op">)</span>,</span>
<span>    <span class="va">aC</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>    <span class="va">aD</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">5</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>    <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">dnc</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean       sd      5.5%     94.5%
aA     5.692304 2.773707  1.259384 10.125224
aB    35.402444 3.130144 30.399869 40.405018
aC     1.494241 2.773420 -2.938221  5.926703
aD     2.297005 2.773228 -2.135148  6.729159
sigma  8.817423 1.180513  6.930736 10.704111</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb594"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">post5</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m5</span><span class="op">)</span></span>
<span><span class="va">mu.A</span> <span class="op">&lt;-</span> <span class="va">post5</span><span class="op">$</span><span class="va">aA</span></span>
<span><span class="va">mu.B</span> <span class="op">&lt;-</span> <span class="va">post5</span><span class="op">$</span><span class="va">aB</span></span>
<span><span class="va">mu.C</span> <span class="op">&lt;-</span> <span class="va">post5</span><span class="op">$</span><span class="va">aC</span></span>
<span><span class="va">mu.D</span> <span class="op">&lt;-</span> <span class="va">post5</span><span class="op">$</span><span class="va">aD</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mu.A</span>, <span class="va">mu.B</span>, <span class="va">mu.C</span>, <span class="va">mu.D</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>          mean       sd      5.5%     94.5%    histogram
mu.A  5.679909 2.773976  1.216623 10.108590  ▁▁▁▂▅▇▇▃▁▁▁
mu.B 35.403833 3.120270 30.436795 40.420675 ▁▁▁▂▅▇▇▃▂▁▁▁
mu.C  1.438555 2.744457 -3.000749  5.826422  ▁▁▁▂▅▇▇▃▁▁▁
mu.D  2.356144 2.762407 -2.076153  6.772363 ▁▁▁▁▃▇▇▅▂▁▁▁</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb596"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">precis</span><span class="op">(</span><span class="va">m5</span><span class="op">)</span>, main <span class="op">=</span> <span class="st">"Model 5"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5E4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
</section><section id="medium-3" class="level3"><h3 class="anchored" data-anchor-id="medium-3">Medium</h3>
<p><br></p>
<blockquote class="blockquote">
<p>5M1. Invent your own example of a spurious correlation. An outcome variable should be correlated with both predictor variables. But when both predictors are entered in the same model, the correlation between the outcome and one of the predictors should mostly vanish (or at least be greatly reduced).</p>
</blockquote>
<p>I invented a data set that contains rate of rainfall (rain.ppt), percent probability of seeing stars in the night sky (chance.star) and percent increase in sales of umbrella (umbrella.sales). The outcome variable <code>chance.star</code> and predictor variable <code>rain.ppt</code> were fitted in model <code>m.rs</code>, and the model predicts the chance of seeing stars would be decreased by 1.4% for every inch of increased rainfall.</p>
<p>Another predictor variable <code>umbrella.sales</code> was fitted to the same outcome variable in model <code>m.us</code>, and the model showed the chance of seeing star would be decreased by approximate 1.5% for every percent increase in umbrella sales. So, the correlation between chance of seeing stars and umbrella sales was stronger by about 0.1% when two predictors were put into model separately.</p>
<p>But, when the two predictor variables were fitted together to the outcome variable, the correlation between rate of rain fall and chance of seeing stars remained the same at -1.4%, while the correlation dropped to -0.07% for umbrella sales.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb597"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">rain.ppt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>, <span class="fl">0.6</span>, <span class="fl">0.4</span>, <span class="fl">0.2</span>, <span class="fl">0.27</span>, <span class="fl">0.33</span>, <span class="fl">0.35</span><span class="op">)</span></span>
<span></span>
<span><span class="va">chance.star</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span>, <span class="fl">0.2</span>, <span class="fl">0.28</span>, <span class="fl">0.7</span>, <span class="fl">0.65</span>, <span class="fl">0.55</span>, <span class="fl">0.52</span><span class="op">)</span></span>
<span></span>
<span><span class="va">umbrella.sales</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>, <span class="fl">0.3</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>, <span class="fl">0.13</span>, <span class="fl">0.18</span>, <span class="fl">0.2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">rain.ppt</span>, <span class="va">chance.star</span>, <span class="va">umbrella.sales</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   10 obs. of  3 variables:
 $ rain.ppt      : num  0.25 0.5 0.3 0.1 0.6 0.4 0.2 0.27 0.33 0.35
 $ chance.star   : num  0.6 0.25 0.5 0.9 0.2 0.28 0.7 0.65 0.55 0.52
 $ umbrella.sales: num  0.1 0.05 0.15 0.05 0.3 0.25 0.15 0.13 0.18 0.2</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb599"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Check correlation between rainfall rate and probability of seeing stars</span></span>
<span><span class="va">m.rs</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">d</span><span class="op">$</span><span class="va">chance.star</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span> <span class="op">*</span> <span class="va">d</span><span class="op">$</span><span class="va">rain.ppt</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.rs</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%      94.5%
a      0.98420695 0.04924078  0.90551067  1.0629032
bR    -1.42291313 0.13770880 -1.64299839 -1.2028279
sigma  0.05996239 0.01346928  0.03843587  0.0814889</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb601"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">d1</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">rain.ppt</span>, y <span class="op">=</span> <span class="va">chance.star</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"firebrick3"</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>              color  <span class="op">=</span> <span class="st">"firebrick4"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"firebrick1"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Rate of rainfall"</span>, y <span class="op">=</span> <span class="st">"Chance of seeing stars"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Check correlation between umbrella sales and probability of seeing stars</span></span>
<span><span class="va">m.us</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">d</span><span class="op">$</span><span class="va">chance.star</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bU</span> <span class="op">*</span> <span class="va">d</span><span class="op">$</span><span class="va">umbrella.sales</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">bU</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.us</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%      94.5%
a      0.7383492 0.12351987  0.5409405  0.9357578
bU    -1.4459655 0.71161103 -2.5832574 -0.3086736
sigma  0.1733902 0.03880474  0.1113727  0.2354077</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb603"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">umbrella.sales</span>, y <span class="op">=</span> <span class="va">chance.star</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"#73a5c6"</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>              color  <span class="op">=</span> <span class="st">"#528aae"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"#bcd2e8"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Percent increase in umbrella sales"</span>, y <span class="op">=</span> <span class="st">"Chance of seeing stars"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> </span>
<span> <span class="fu">grid.arrange</span><span class="op">(</span><span class="va">d1</span>, <span class="va">d2</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5M1-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb604"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span> <span class="co"># Consider both predictors to the outcome</span></span>
<span> <span class="va">m.b</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>   <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>     <span class="va">d</span><span class="op">$</span><span class="va">chance.star</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>     <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span> <span class="op">*</span> <span class="va">d</span><span class="op">$</span><span class="va">rain.ppt</span> <span class="op">+</span> <span class="va">bU</span> <span class="op">*</span> <span class="va">d</span><span class="op">$</span><span class="va">umbrella.sales</span>,</span>
<span>     <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>     <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>     <span class="va">bU</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>     <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>   <span class="op">)</span>,</span>
<span>   data <span class="op">=</span> <span class="va">d</span></span>
<span> <span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.b</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>             mean         sd        5.5%       94.5%
a      0.98804733 0.05167185  0.90546573  1.07062893
bR    -1.40013435 0.16710602 -1.66720205 -1.13306666
bU    -0.07280881 0.30075612 -0.55347517  0.40785756
sigma  0.05996844 0.01349129  0.03840675  0.08153013</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb606"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="op">~</span> <span class="va">chance.star</span> <span class="op">+</span> <span class="va">rain.ppt</span> <span class="op">+</span> <span class="va">umbrella.sales</span>, data <span class="op">=</span> <span class="va">d</span>, col <span class="op">=</span> <span class="st">"firebrick"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5M1-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>5M2. Invent your own example of a masked relationship. An outcome variable should be correlated with both predictor variables, but in opposite directions. And the two predictor variables should be correlated with one another.</p>
</blockquote>
<p>Instead of adjusting each data point to get the desired relationship (like in 5M1 which took quite a while to manipulate the data), I used the book’s code to create a data set for simulating a masked relationship. In the example below, the number of trees in the area (<code>tree.number</code>) is positively associated with good air quality (<code>pm.air</code>), while the number of factory in the area (<code>factory.number</code>) is negatively associated with good air quality(<code>pm.air</code>). The <code>factory.number</code> and <code>tree.number</code> have a correlation strength of 0.5.</p>
<p>When the predictors are fitted separately to the model, the <span class="math inline">\(\beta\)</span> coefficients for <code>tree.number</code> and <code>factory.number</code> are 0.52 and -0.47, in relation to the outcome <code>pm.air</code>. But when the predictors are fitted together in the model, stronger associations with outcome variable are seen with each of the predictors (0.99 for <code>tree.number</code> and -0.97 for <code>factory.number</code>).</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb607"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create data set</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1000</span>                             </span>
<span><span class="va">rho</span> <span class="op">&lt;-</span> <span class="fl">0.5</span>                         </span>
<span><span class="va">tree.number</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span>                     </span>
<span><span class="va">factory.number</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">rho</span><span class="op">*</span><span class="va">tree.number</span>, <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">rho</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">pm.air</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">N</span>, <span class="va">tree.number</span> <span class="op">-</span> <span class="va">factory.number</span><span class="op">)</span>        </span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">pm.air</span>, <span class="va">tree.number</span>, <span class="va">factory.number</span><span class="op">)</span>  </span>
<span></span>
<span><span class="co"># Air quality vs. trees</span></span>
<span><span class="va">m.at</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">pm.air</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">tree.number</span>, data <span class="op">=</span> <span class="va">d</span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.at</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                  mean         sd        5.5%      94.5%
(Intercept) 0.02188061 0.04082564 -0.04336665 0.08712787
tree.number 0.50911244 0.04119010  0.44328270 0.57494219</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb609"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">d1</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">tree.number</span>, y <span class="op">=</span> <span class="va">pm.air</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"green3"</span>, <span class="fl">0.2</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>              color  <span class="op">=</span> <span class="st">"green4"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"green"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Trees per hectare (x100)"</span>, y <span class="op">=</span> <span class="st">"Particulate matter (ug/m^3)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Air quality vs. factory</span></span>
<span><span class="va">m.af</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">pm.air</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">factory.number</span>, data <span class="op">=</span> <span class="va">d</span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.af</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                      mean         sd       5.5%       94.5%
(Intercept)    -0.03459464 0.04127023 -0.1005524  0.03136316
factory.number -0.48147728 0.04252136 -0.5494346 -0.41351993</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb611"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">factory.number</span>, y <span class="op">=</span> <span class="va">pm.air</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"red3"</span>, <span class="fl">0.2</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>              color  <span class="op">=</span> <span class="st">"red4"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"red"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Number of factories"</span>, y <span class="op">=</span> <span class="st">"Particulate matter (ug/m^3)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> </span>
<span> <span class="fu">grid.arrange</span><span class="op">(</span><span class="va">d1</span>, <span class="va">d2</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5M2-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb612"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span> <span class="co"># Air quality vs. number of trees and number of factories</span></span>
<span> <span class="va">m.atf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">pm.air</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">tree.number</span> <span class="op">+</span> <span class="va">factory.number</span>, data <span class="op">=</span> <span class="va">d</span><span class="op">)</span></span>
<span> <span class="fu">precis</span><span class="op">(</span><span class="va">m.atf</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                       mean         sd        5.5%       94.5%
(Intercept)    -0.006541906 0.03160906 -0.05705929  0.04397548
tree.number     0.970431754 0.03651750  0.91206974  1.02879377
factory.number -0.965210006 0.03729335 -1.02481198 -0.90560804</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb614"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span> <span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="op">~</span> <span class="va">pm.air</span> <span class="op">+</span> <span class="va">tree.number</span> <span class="op">+</span> <span class="va">factory.number</span>, data <span class="op">=</span> <span class="va">d</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"skyblue"</span>, <span class="fl">0.4</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5M2-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>5M3. It is sometimes observed that the best predictor of fire risk is the presence of firefighters— States and localities with many firefighters also have more fires. Presumably firefighters do not cause fires. Nevertheless, this is not a spurious correlation. Instead fires cause firefighters. Consider the same reversal of causal inference in the context of the divorce and marriage data. How might a high divorce rate cause a higher marriage rate? Can you think of a way to evaluate this relationship, using multiple regression?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb615"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># load data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"WaffleDivorce"</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">WaffleDivorce</span></span>
<span></span>
<span><span class="co">## Try fitting divorce rate vs. marriage.rate first</span></span>
<span><span class="co"># Standardize the variable</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">Divorce.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Divorce</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">)</span><span class="op">)</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Divorce</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># fit model</span></span>
<span><span class="va">m.5m3.a</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Marriage</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">Divorce.s</span>, data <span class="op">=</span> <span class="va">d</span><span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.5m3.a</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                 mean        sd       5.5%    94.5%
(Intercept) 20.114000 0.5033474 19.3095537 20.91845
Divorce.s    1.419397 0.5084576  0.6067832  2.23201</code></pre>
</div>
</div>
<p>So, with every sd increase in divorces, there is 1.42 increase in marriage cases. Since this is not a spurious relationship, a logical explanation of this phenomenon would be people remarry after divorce. In order to analyse this using multiple regression, the marriage data needs to be split into first marriage, second marriage, etc (Divorce rate may not correlate with first marriages but with remarriages). But then, the marriage and divorce data are for the year 2009 only. How likely for the couples to remarry within the same year of divorce? It is possible, but it’s not typically considered a norm. So, that means within the year 2009, it is possible that increased divorce cases did not result in more marriages— more people were actually getting married for the first time. To assume a causal inference between divorce and marriage rate, we need to analyse data for more years (longitudinal data). Even then, the term causal inference sounds quite easy for divorce and remarriage rate. Of course, people can only remarry after divorce, but does divorce cause people to remarry? This is different from the assumption <em>“fire causes firefighters.”</em> Fire can cause an increased in firefighters because firefighters are necessary to put out the fire (a danger). But, is it necessary for people to remarry after divorce? Is being a divorcee a social disadvantage that people must remarry (is remarriage an inevitable consequence of getting divorced)?</p>
<p><br></p>
<blockquote class="blockquote">
<p>5M4. In the divorce data, States with high numbers of Mormons (members of The Church of Jesus Christ of Latter-day Saints, LDS) have much lower divorce rates than the regression models expected. Find a list of LDS population by State and use those numbers as a predictor variable, predicting divorce rate using marriage rate, median age at marriage, and percent LDS population (possibly standardized). You may want to consider transformations of the raw percent LDS variable.</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb617"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># I don't know which states have Mormons, so I copy the data from answer sheet</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">WaffleDivorce</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">WaffleDivorce</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">pct_LDS</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.75</span>, <span class="fl">4.53</span>, <span class="fl">6.18</span>, <span class="fl">1</span>, <span class="fl">2.01</span>, <span class="fl">2.82</span>, <span class="fl">0.43</span>, <span class="fl">0.55</span>, <span class="fl">0.38</span>,</span>
<span>  <span class="fl">0.75</span>, <span class="fl">0.82</span>, <span class="fl">5.18</span>, <span class="fl">26.35</span>, <span class="fl">0.44</span>, <span class="fl">0.66</span>, <span class="fl">0.87</span>, <span class="fl">1.25</span>, <span class="fl">0.77</span>, <span class="fl">0.64</span>, <span class="fl">0.81</span>,</span>
<span>  <span class="fl">0.72</span>, <span class="fl">0.39</span>, <span class="fl">0.44</span>, <span class="fl">0.58</span>, <span class="fl">0.72</span>, <span class="fl">1.14</span>, <span class="fl">4.78</span>, <span class="fl">1.29</span>, <span class="fl">0.61</span>, <span class="fl">0.37</span>, <span class="fl">3.34</span>,</span>
<span>  <span class="fl">0.41</span>, <span class="fl">0.82</span>, <span class="fl">1.48</span>, <span class="fl">0.52</span>, <span class="fl">1.2</span>, <span class="fl">3.85</span>, <span class="fl">0.4</span>, <span class="fl">0.37</span>, <span class="fl">0.83</span>, <span class="fl">1.27</span>, <span class="fl">0.75</span>,</span>
<span>  <span class="fl">1.21</span>, <span class="fl">67.97</span>, <span class="fl">0.74</span>, <span class="fl">1.13</span>, <span class="fl">3.99</span>, <span class="fl">0.92</span>, <span class="fl">0.44</span>, <span class="fl">11.5</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Standardize the variables</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">pct_LDS.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">pct_LDS</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">pct_LDS</span><span class="op">)</span><span class="op">)</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">pct_LDS</span><span class="op">)</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span><span class="op">)</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Marriage</span><span class="op">)</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span><span class="op">)</span><span class="op">)</span><span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Predict divorce rate using marriage rate, median age at marriage, and percent LDS population</span></span>
<span><span class="va">m.5m4.s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">Divorce</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">d</span><span class="op">$</span><span class="va">Marriage.s</span> <span class="op">+</span> <span class="va">d</span><span class="op">$</span><span class="va">MedianAgeMarriage.s</span> <span class="op">+</span> <span class="va">d</span><span class="op">$</span><span class="va">pct_LDS.s</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.5m4.s</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>                              mean        sd       5.5%      94.5%
(Intercept)            9.688000000 0.1975750  9.3722370 10.0037630
d$Marriage.s           0.006657859 0.3001325 -0.4730119  0.4863276
d$MedianAgeMarriage.s -1.375897714 0.2924092 -1.8432241 -0.9085713
d$pct_LDS.s           -0.622803610 0.2357031 -0.9995026 -0.2461046</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb619"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Each standard deviation increase in percent of Mormons, the divorce rate will be reduced by </span></span>
<span><span class="co"># 0.62 divorces per 1000 adults.  </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>5M5. One way to reason through multiple causation hypotheses is to imagine detailed mechanisms through which predictor variables may influence outcomes. For example, it is sometimes argued that the price of gasoline (predictor variable) is positively associated with lower obesity rates (outcome variable). However, there are at least two important mechanisms by which the price of gas could reduce obesity. First, it could lead to less driving and therefore more exercise. Second, it could lead to less driving, which leads to less eating out, which leads to less consumption of huge restaurant meals. Can you outline one or more multiple regressions that address these two mechanisms? Assume you can have any predictor data you need.</p>
</blockquote>
<p><span style="color:navy"><span style="text-decoration:underline"><strong><em>First mechanism</em></strong></span></span></p>
<p>Higher gasoline price leads to people using public transportation more and less driving. That reduces traffic congestion, leading to lower air pollution which can cause people to go out more and exercise during free time (fresh air and more spaces). Those who don’t use public transportation may walk or ride bicycle, resulting in more exercise. This can result in reduce obesity. The assumptions are:</p>
<ul>
<li><p>Gasoline price (G) increases usage of public transportation (T).</p></li>
<li><p>Gasoline price (G) reduces driving (D).</p></li>
<li><p>T and D reduces traffic congestion (C).</p></li>
<li><p>C increases air quality (F) and space (S).</p></li>
<li><p>F, S, T, and D increases exercise (E).</p></li>
<li><p>E reduces obesity (O).</p></li>
</ul>
<p><br></p>
<p><span style="color:navy"><span style="text-decoration:underline"><strong><em>Second mechanism</em></strong></span></span></p>
<p>High gasoline price leads to less driving, which leads to less eating out. Also, high gasoline price increases food food prices (higher cost of food production and transportation), leading to less eating out.</p>
<ul>
<li><p>D reduces eating out at restaurants (R).</p></li>
<li><p>G increases food prices (P).</p></li>
<li><p>P reduces R.</p></li>
<li><p>R reduces O.</p></li>
</ul>
<p><strong><em>Here I included many predictor variables I could think of at the moment. Using all predictors to fit multiple regressions is a bad idea. So, predictor variables need to be thoroughly checked and weeded out before building the regression model.</em></strong></p>
<p><br></p>
</section><section id="hard-3" class="level3"><h3 class="anchored" data-anchor-id="hard-3">Hard</h3>
<blockquote class="blockquote">
<p>5H1. Fit two bivariate Gaussian regressions, using map: (1) body weight as a linear function of territory size (area), and (2) body weight as a linear function of groupsize. Plot the results of these regressions, displaying the MAP regression line and the 95% interval of the mean. Is either variable important for predicting fox body weight?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb620"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">foxes</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">foxes</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   116 obs. of  5 variables:
 $ group    : int  1 1 2 2 3 3 4 4 5 5 ...
 $ avgfood  : num  0.37 0.37 0.53 0.53 0.49 0.49 0.45 0.45 0.74 0.74 ...
 $ groupsize: int  2 2 2 2 2 2 2 2 3 3 ...
 $ area     : num  1.09 1.09 2.05 2.05 2.12 2.12 1.29 1.29 3.78 3.78 ...
 $ weight   : num  5.02 2.84 5.33 6.07 5.85 3.25 4.53 4.09 6.13 5.59 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb622"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#  body weight as a linear function of territory size (area)</span></span>
<span><span class="va">m.ts</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">weight</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bT</span> <span class="op">*</span> <span class="va">area</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">bT</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>, </span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.ts</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%     94.5%
a     4.45195002 0.38834525  3.8312993 5.0726007
bT    0.02451762 0.11757349 -0.1633875 0.2124228
sigma 1.17868459 0.07738421  1.0550097 1.3023595</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb624"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">a.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">7</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m.ts</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>area <span class="op">=</span> <span class="va">a.seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span> , <span class="va">mean</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">weight</span> <span class="op">~</span> <span class="va">area</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown3"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">d</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">a.seq</span>, <span class="va">mu.mean</span>, col <span class="op">=</span> <span class="st">"brown4"</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">a.seq</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown"</span>, alpha <span class="op">=</span> <span class="fl">0.4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># body weight as a linear function of groupsize</span></span>
<span><span class="va">m.gs</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">weight</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bG</span> <span class="op">*</span> <span class="va">groupsize</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">bG</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.gs</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%      94.5%
a      5.0652703 0.32417759  4.5471719  5.5833687
bG    -0.1232802 0.07034753 -0.2357092 -0.0108513
sigma  1.1635297 0.07638923  1.0414449  1.2856144</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb626"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">g.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">10</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m.gs</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>groupsize <span class="op">=</span> <span class="va">g.seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">weight</span> <span class="op">~</span> <span class="va">groupsize</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"slateblue3"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">d</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">g.seq</span>, <span class="va">mu.mean</span>, col <span class="op">=</span> <span class="st">"slateblue4"</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">g.seq</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"slateblue"</span>, alpha <span class="op">=</span> <span class="fl">0.4</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5H1-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb627"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The regression line between area and body weight is almost linear and data points are</span></span>
<span><span class="co"># quite scattered in the plot, showing there's almost no correlation between area and body weight. </span></span>
<span><span class="co"># The effect of group size on body weight seems a bit larger than that of area, but does not show </span></span>
<span><span class="co"># strong association. Both variables are not a strong predictor of the outcome, but group size seems </span></span>
<span><span class="co"># more promising than area. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>5H2. Now fit a multiple linear regression with weight as the outcome and both area and groupsize as predictor variables. Plot the predictions of the model for each predictor, holding the other predictor constant at its mean. What does this model say about the importance of each variable? Why do you get different results than you got in the exercise just above?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb628"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"foxes"</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">foxes</span></span>
<span></span>
<span><span class="co"># Fit model</span></span>
<span><span class="va">m.ag</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">weight</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bT</span> <span class="op">*</span> <span class="va">area</span> <span class="op">+</span> <span class="va">bG</span> <span class="op">*</span> <span class="va">groupsize</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">bT</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">bG</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.ag</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean        sd       5.5%      94.5%
a      4.4736124 0.3688387  3.8841369  5.0630879
bT     0.5863792 0.1953797  0.2741246  0.8986337
bG    -0.4148101 0.1183610 -0.6039738 -0.2256463
sigma  1.1185768 0.0734537  1.0011836  1.2359700</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb630"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## When group size is constant</span></span>
<span><span class="va">a.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">7</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">g.avg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">groupsize</span><span class="op">)</span></span>
<span><span class="va">pred.area</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  area <span class="op">=</span> <span class="va">a.seq</span>,</span>
<span>  groupsize <span class="op">=</span> <span class="va">g.avg</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m.ag</span>, data <span class="op">=</span> <span class="va">pred.area</span><span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">weight</span> <span class="op">~</span> <span class="va">area</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown3"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">d</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">a.seq</span>, <span class="va">mu.mean</span>, col <span class="op">=</span> <span class="st">"brown4"</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">a.seq</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"brown"</span>, alpha <span class="op">=</span> <span class="fl">0.4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"Group size is constant at mean value"</span>, col <span class="op">=</span> <span class="st">"brown"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## When area is held constant</span></span>
<span><span class="va">g.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">10</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">a.avg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">area</span><span class="op">)</span></span>
<span><span class="va">pred.group</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  groupsize <span class="op">=</span> <span class="va">g.seq</span>,</span>
<span>  area <span class="op">=</span> <span class="va">a.avg</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m.ag</span>, data <span class="op">=</span> <span class="va">pred.group</span><span class="op">)</span></span>
<span><span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">mean</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span>, prob <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">weight</span> <span class="op">~</span> <span class="va">groupsize</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"slateblue3"</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">d</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">g.seq</span>, <span class="va">mu.mean</span>, col <span class="op">=</span> <span class="st">"slateblue4"</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">g.seq</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"slateblue"</span>, alpha <span class="op">=</span> <span class="fl">0.4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"Area is constant at mean value"</span>, col <span class="op">=</span> <span class="st">"slateblue"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5H2-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb631"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The correlations become a lot stronger for both predictors. This is an example of </span></span>
<span><span class="co"># masked relationship where predictors are correlated with one another but have opposite </span></span>
<span><span class="co"># correlation with the outcome variable. Both variables are strong predictors of outcome </span></span>
<span><span class="co"># in this model, but the raw (observed) data points don't seem to fit well with the model- </span></span>
<span><span class="co"># maybe because we hold a predictor constant in the model where this is impossible in raw </span></span>
<span><span class="co"># observed data. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<blockquote class="blockquote">
<p>5H3. Finally, consider the avgfood variable. Fit two more multiple regressions: (1) body weight as an additive function of avgfood and groupsize, and (2) body weight as an additive function of all three variables, avgfood and groupsize and area. Compare the results of these models to the previous models you’ve fit, in the first two exercises. (a) Is avgfood or area a better predictor of body weight? If you had to choose one or the other to include in a model, which would it be? Support your assessment with any tables or plots you choose. (b) When both avgfood or area are in the same model, their effects are reduced (closer to zero) and their standard errors are larger than when they are included in separate models. Can you explain this result?</p>
</blockquote>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb632"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">foxes</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">foxes</span></span>
<span></span>
<span><span class="co"># body weight as an additive function of avgfood and groupsize</span></span>
<span><span class="va">m.fg</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">weight</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bF</span> <span class="op">*</span> <span class="va">avgfood</span> <span class="op">+</span> <span class="va">bG</span> <span class="op">*</span> <span class="va">groupsize</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">bF</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">bG</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.fg</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%      94.5%
a      4.1368962 0.43079170  3.4484078  4.8253845
bF     3.7713096 1.20417263  1.8468092  5.6958101
bG    -0.5620985 0.15542950 -0.8105049 -0.3136922
sigma  1.1166213 0.07331186  0.9994548  1.2337878</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb634"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="op">~</span> <span class="va">weight</span> <span class="op">+</span> <span class="va">avgfood</span> <span class="op">+</span> <span class="va">groupsize</span>, data <span class="op">=</span> <span class="va">d</span>, col <span class="op">=</span> <span class="st">"brown3"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5H3-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb635"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># body weight as an additive function of avgfood and groupsize and area</span></span>
<span><span class="va">m.fga</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>    <span class="va">weight</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,</span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bF</span> <span class="op">*</span> <span class="va">avgfood</span> <span class="op">+</span> <span class="va">bG</span> <span class="op">*</span> <span class="va">groupsize</span> <span class="op">+</span> <span class="va">bT</span> <span class="op">*</span> <span class="va">area</span>,</span>
<span>    <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>,</span>
<span>    <span class="va">bG</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">bF</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">bT</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">d</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m.fga</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd         5.5%      94.5%
a      4.0719294 0.42792481  3.388022912  4.7558359
bG    -0.6039440 0.15584589 -0.853015801 -0.3548722
bF     2.4570556 1.43770651  0.159322881  4.7547882
bT     0.3896095 0.23847201  0.008485197  0.7707339
sigma  1.1043532 0.07250485  0.988476477  1.2202300</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb637"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="op">~</span> <span class="va">weight</span> <span class="op">+</span> <span class="va">avgfood</span> <span class="op">+</span> <span class="va">groupsize</span> <span class="op">+</span> <span class="va">area</span>, data <span class="op">=</span> <span class="va">d</span>, col <span class="op">=</span> <span class="st">"slateblue3"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/5H3-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb638"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># (a) Average food because a bit higher increase in weight per unit of average food increase,</span></span>
<span><span class="co"># as seen in the table (model m.fga). </span></span>
<span></span>
<span><span class="co"># (b) It could be because average food and area are highly correlated with each other.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section></section><section id="chapter-6-overfitting-regularization-and-information-criteria" class="level1"><h1>Chapter 6: Overfitting, Regularization, and Information Criteria</h1>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Two fundamental kinds of statistical error:</strong></span></span></p>
<ol type="1">
<li><p><strong><em>Overfitting:</em></strong> leads to poor prediction by learning too much from the data</p></li>
<li><p><strong><em>Underfitting:</em></strong> leads to poor prediction by learning too little from the data</p></li>
</ol>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Two approaches to address the errors:</strong></span></span></p>
<ol type="1">
<li><p><strong><em>Regularizing prior:</em></strong> tells the model not to get too excited by the data (penalized likelihood)</p></li>
<li><p><strong><em>Information criteria:</em></strong> scoring device to model the prediction task and estimate predictive accuracy for some purpose</p></li>
</ol>
<p><em>Both can be— maybe should be— used in combination.</em></p>
<p><br></p>
<section id="the-problem-with-parameters" class="level2"><h2 class="anchored" data-anchor-id="the-problem-with-parameters">The problem with parameters</h2>
<p>There are two principle concerns with just adding variables.</p>
<p>The first is that adding parameters— making the model more complex— nearly always improves the fit of a model to the data. For example, like other measures of fit to sample, <em>R<sup>2</sup></em> increases as more predictor variables are added. This is true even when the variables added to a model are just random numbers, with no relation to the outcome. So it’s no good to choose among models using only fit to the data.</p>
<p>Second, while more complex models fit the data better, they often predict new data worse. Models that have many parameters tend to overfit more than do simpler models. This means that a complex model will be very sensitive to the exact sample used to fit it, leading to potentially large mistakes when future data is not exactly like the past data. But simple models, with too few parameters, tend instead to underfit, systematically over-predicting or under-predicting the data, regardless of how well future data resemble past data. So we can’t always favor either simple models or complex models.</p>
<p><br></p>
</section><section id="more-parameters-always-improve-fit" class="level2"><h2 class="anchored" data-anchor-id="more-parameters-always-improve-fit">More parameters always improve fit</h2>
<p>Overfitting occurs when a model learns too much from the sample. This is a general phenomenon: If you adopt a model family with enough parameters, you can fit the data exactly. But such a model will make rather absurd predictions for yet-to-be-observed cases.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb639"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Create data set for average brain volumes and body masses for seven hominin species</span></span>
<span><span class="va">sppnames</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="st">"afarensis"</span>,<span class="st">"africanus"</span>,<span class="st">"habilis"</span>,<span class="st">"boisei"</span>,</span>
<span>    <span class="st">"rudolfensis"</span>,<span class="st">"ergaster"</span>,<span class="st">"sapiens"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">brainvolcc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fl">438</span> , <span class="fl">452</span> , <span class="fl">612</span>, <span class="fl">521</span>, <span class="fl">752</span>, <span class="fl">871</span>, <span class="fl">1350</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">masskg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fl">37.0</span> , <span class="fl">35.5</span> , <span class="fl">34.5</span> , <span class="fl">41.5</span> , <span class="fl">55.5</span> , <span class="fl">61.0</span> , <span class="fl">53.5</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> species<span class="op">=</span><span class="va">sppnames</span> , brain<span class="op">=</span><span class="va">brainvolcc</span> , mass<span class="op">=</span><span class="va">masskg</span> <span class="op">)</span></span>
<span></span>
<span><span class="co">## Fit model that relates brain size to body size </span></span>
<span><span class="va">m6.1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m6.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = brain ~ mass, data = d)

Residuals:
      1       2       3       4       5       6       7 
 -99.86  -54.83  125.86 -109.96 -168.60 -163.39  470.77 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept) -227.629    439.794  -0.518   0.6268  
mass          20.689      9.436   2.192   0.0798 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 252.1 on 5 degrees of freedom
Multiple R-squared:  0.4902,    Adjusted R-squared:  0.3882 
F-statistic: 4.807 on 1 and 5 DF,  p-value: 0.07985</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb641"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate R^2</span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">resid</a></span><span class="op">(</span><span class="va">m6.1</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">brain</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.490158</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb643"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Same number as 'multipled R-squared' from summary(m6.1)</span></span>
<span></span>
<span><span class="co">## Create other models to compare to the fit of m6.1</span></span>
<span><span class="co"># Second-degree polynomial (parabola) that relates body size to brain size</span></span>
<span><span class="va">m6.2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Third-degree polynomial</span></span>
<span><span class="va">m6.3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Fourth-degree polynomial</span></span>
<span><span class="va">m6.4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">4</span><span class="op">)</span> ,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Fifth-degree polynomial</span></span>
<span><span class="va">m6.5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">4</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">5</span><span class="op">)</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Sixth-degree polynomial</span></span>
<span><span class="va">m6.6</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">4</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">5</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">6</span><span class="op">)</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co">## Plot the data</span></span>
<span></span>
<span><span class="co"># Linear model</span></span>
<span> <span class="va">d1</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">masskg</span>, y <span class="op">=</span> <span class="va">brainvolcc</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span>, shape <span class="op">=</span> <span class="fl">21</span>, stroke <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>               level <span class="op">=</span> <span class="fl">0.89</span>, </span>
<span>              color  <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"grey"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>,</span>
<span>              formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">300</span>, <span class="fl">1500</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">33</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"body mass (kg)"</span>, y <span class="op">=</span> <span class="st">"brain volume (cc)"</span>, title <span class="op">=</span> <span class="st">"R^2 = 0.49"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span> </span>
<span><span class="co"># Second-degree polynomial</span></span>
<span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">masskg</span>, y <span class="op">=</span> <span class="va">brainvolcc</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span>, shape <span class="op">=</span> <span class="fl">21</span>,</span>
<span>             stroke <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>               level <span class="op">=</span> <span class="fl">0.89</span>, </span>
<span>              color  <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"grey"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>,</span>
<span>              formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">300</span>, <span class="fl">1500</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">33</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"body mass (kg)"</span>, y <span class="op">=</span> <span class="st">"brain volume (cc)"</span>, title <span class="op">=</span> <span class="st">"R^2 = 0.54"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span> </span>
<span><span class="co"># Third-degree polynomial</span></span>
<span> <span class="va">d3</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">masskg</span>, y <span class="op">=</span> <span class="va">brainvolcc</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span>, shape <span class="op">=</span> <span class="fl">21</span>, </span>
<span>              stroke <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>                level <span class="op">=</span> <span class="fl">0.89</span>, </span>
<span>               color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>,</span>
<span>               fill <span class="op">=</span> <span class="st">"grey"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>,</span>
<span>               formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">300</span>, <span class="fl">1500</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">33</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"body mass (kg)"</span>, y <span class="op">=</span> <span class="st">"brain volume (cc)"</span>, title <span class="op">=</span> <span class="st">"R^2 = 0.68"</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span> </span>
<span> <span class="co"># Fourth-degree polynomial</span></span>
<span> <span class="va">d4</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">masskg</span>, y <span class="op">=</span> <span class="va">brainvolcc</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span>, shape <span class="op">=</span> <span class="fl">21</span>,</span>
<span>              stroke <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>                level <span class="op">=</span> <span class="fl">0.89</span>, </span>
<span>               color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>,</span>
<span>               fill <span class="op">=</span> <span class="st">"grey"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>,</span>
<span>               formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">300</span>, <span class="fl">1500</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">33</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"body mass (kg)"</span>, y <span class="op">=</span> <span class="st">"brain volume (cc)"</span>, title <span class="op">=</span> <span class="st">"R^2 = 0.81"</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span> </span>
<span><span class="co"># Fifth-degree polynomial</span></span>
<span> <span class="va">d5</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">masskg</span>, y <span class="op">=</span> <span class="va">brainvolcc</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span>, shape <span class="op">=</span> <span class="fl">21</span>, </span>
<span>              stroke <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                level <span class="op">=</span> <span class="fl">0.89</span>, </span>
<span>               color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>,</span>
<span>               fill <span class="op">=</span> <span class="st">"grey"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>,</span>
<span>               formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">150</span>, <span class="fl">1900</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">33</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"body mass (kg)"</span>, y <span class="op">=</span> <span class="st">"brain volume (cc)"</span>, title <span class="op">=</span> <span class="st">"R^2 = 0.99"</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span> </span>
<span> <span class="co"># Sixth-degree polynomial</span></span>
<span> <span class="va">d6</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">masskg</span>, y <span class="op">=</span> <span class="va">brainvolcc</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span>, shape <span class="op">=</span> <span class="fl">21</span>, </span>
<span>              stroke <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>               level <span class="op">=</span> <span class="fl">0.89</span>, </span>
<span>               color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>,</span>
<span>               fill <span class="op">=</span> <span class="st">"grey"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>,</span>
<span>               formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html">poly</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_hline</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"black"</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">300</span>, <span class="fl">1500</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">34</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"body mass (kg)"</span>, y <span class="op">=</span> <span class="st">"brain volume (cc)"</span>, title <span class="op">=</span> <span class="st">"R^2 = 1.00"</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span> </span>
<span> <span class="fu">grid.arrange</span><span class="op">(</span><span class="va">d1</span>, <span class="va">d2</span>, <span class="va">d3</span>, <span class="va">d4</span>, <span class="va">d5</span>, <span class="va">d6</span>, layout_matrix <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span>, </span>
<span>                                                             ncol <span class="op">=</span> <span class="fl">2</span>, </span>
<span>                                                             byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/6.1-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb644"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span> <span class="co"># As the degree of the polynomial defining the mean increases, the fit always improves. </span></span>
<span> <span class="co"># However, you can see from looking at the paths of the predicted means that the </span></span>
<span> <span class="co"># higher-degree polynomials are increasingly absurd. </span></span>
<span> <span class="co"># The sixth-degree polynomial fit perfectly because it has enough parameters to assign</span></span>
<span> <span class="co"># one to each point of data. The model’s equation for the mean has 7 parameters and there </span></span>
<span> <span class="co"># are 7 species to predict brain sizes for.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="too-few-parameters-hurts-too" class="level2"><h2 class="anchored" data-anchor-id="too-few-parameters-hurts-too">Too few parameters hurts, too</h2>
<p>The overfit polynomial models manage to fit the data extremely well, but they suffer for this within-sample accuracy by making nonsensical out-of-sample predictions. In contrast, underfitting produces models that are inaccurate both within and out of sample. They have learned too little, failing to recover regular features of the sample.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb645"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load data </span></span>
<span><span class="va">sppnames</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="st">"afarensis"</span>,<span class="st">"africanus"</span>,<span class="st">"habilis"</span>,<span class="st">"boisei"</span>,</span>
<span>    <span class="st">"rudolfensis"</span>,<span class="st">"ergaster"</span>,<span class="st">"sapiens"</span><span class="op">)</span></span>
<span><span class="va">brainvolcc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fl">438</span> , <span class="fl">452</span> , <span class="fl">612</span>, <span class="fl">521</span>, <span class="fl">752</span>, <span class="fl">871</span>, <span class="fl">1350</span> <span class="op">)</span></span>
<span><span class="va">masskg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fl">37.0</span> , <span class="fl">35.5</span> , <span class="fl">34.5</span> , <span class="fl">41.5</span> , <span class="fl">55.5</span> , <span class="fl">61.0</span> , <span class="fl">53.5</span> <span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> species<span class="op">=</span><span class="va">sppnames</span> , brain<span class="op">=</span><span class="va">brainvolcc</span> , mass<span class="op">=</span><span class="va">masskg</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Consider a model of brain volume where mu = a (no predictor variable, just intercept a)</span></span>
<span><span class="va">m6.7</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="fl">1</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the data</span></span>
<span><span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">masskg</span>, y <span class="op">=</span> <span class="va">brainvolcc</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>, <span class="fl">0.8</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">2</span>, shape <span class="op">=</span> <span class="fl">21</span>, stroke <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_smooth</span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, fullrange <span class="op">=</span> <span class="cn">T</span>,</span>
<span>               level <span class="op">=</span> <span class="fl">0.89</span>, </span>
<span>              color  <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>              fill   <span class="op">=</span> <span class="st">"grey"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">3</span>,</span>
<span>              formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">scale_x_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">30</span>, <span class="fl">65</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"body mass (kg)"</span>, y <span class="op">=</span> <span class="st">"brain volume (cc)"</span>, title <span class="op">=</span> <span class="st">"R^2 = 0"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>size<span class="op">=</span><span class="fl">11</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/6.6-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb646"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># An underfit model of hominin brain volume. This model ignores any association between </span></span>
<span><span class="co"># body mass and brain volume, producing a horizontal line of predictions. As a result, </span></span>
<span><span class="co"># the model fits badly and (presumably) predicts badly.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Another way to conceptualize an underfit model is to notice that it is insensitive to the sample. We could remove any one point from the sample and get pretty much the same regression line. In contrast, the most complex model, m6.6, is very sensitive to the sample. The predicted mean would change course a lot, if we removed any one point from the sample.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb647"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create seven sets of data by dropping a row each time</span></span>
<span><span class="va">d1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">species</span> <span class="op">==</span> <span class="st">"sapiens"</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="va">d2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">species</span> <span class="op">==</span> <span class="st">"ergaster"</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="va">d3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">species</span> <span class="op">==</span> <span class="st">"rudolfensis"</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="va">d4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">species</span> <span class="op">==</span> <span class="st">"boisei"</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="va">d5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">species</span> <span class="op">==</span> <span class="st">"habilis"</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="va">d6</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">species</span> <span class="op">==</span> <span class="st">"africanus"</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="va">d7</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/droplevels.html">droplevels</a></span><span class="op">(</span><span class="va">d</span><span class="op">[</span><span class="op">!</span><span class="va">d</span><span class="op">$</span><span class="va">species</span> <span class="op">==</span> <span class="st">"afarenis"</span>, <span class="op">]</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co">## Fit the models (First- degree polynomials: Underfit example) </span></span>
<span><span class="va">m1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, data <span class="op">=</span> <span class="va">d1</span><span class="op">)</span></span>
<span><span class="va">m2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, data <span class="op">=</span> <span class="va">d2</span><span class="op">)</span></span>
<span><span class="va">m3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, data <span class="op">=</span> <span class="va">d3</span><span class="op">)</span></span>
<span><span class="va">m4</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, data <span class="op">=</span> <span class="va">d4</span><span class="op">)</span></span>
<span><span class="va">m5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, data <span class="op">=</span> <span class="va">d5</span><span class="op">)</span></span>
<span><span class="va">m6</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, data <span class="op">=</span> <span class="va">d6</span><span class="op">)</span></span>
<span><span class="va">m7</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, data <span class="op">=</span> <span class="va">d7</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Plot the data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mass</span>, <span class="va">d</span><span class="op">$</span><span class="va">brain</span>,</span>
<span>      xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mass</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">brain</span><span class="op">)</span>, pch <span class="op">=</span> <span class="fl">1</span>,</span>
<span>     col <span class="op">=</span> <span class="st">"blue"</span>, xlab <span class="op">=</span> <span class="st">"body mass (kg)"</span>, ylab <span class="op">=</span> <span class="st">"brain volume (cc)"</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"My plot"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m6</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m7</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> , <span class="va">d</span> , col<span class="op">=</span><span class="st">"slateblue"</span> , main <span class="op">=</span> <span class="st">"Given example"</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">d.new</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span> <span class="op">-</span><span class="va">i</span> , <span class="op">]</span></span>
<span>    <span class="va">m0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span>, <span class="va">d.new</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span> <span class="va">m0</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>,<span class="fl">0.5</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/f6.5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb648"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">### Use codes from "ajkurz"</span></span>
<span><span class="co"># Create base plot</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">d</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mass</span>, y <span class="op">=</span> <span class="va">brain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"slateblue"</span>, size <span class="op">=</span> <span class="fl">3</span>, shape <span class="op">=</span> <span class="fl">21</span><span class="op">)</span>  <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span><span class="st">"body mass (kg)"</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">33</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">300</span>, <span class="fl">1500</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ylab</span><span class="op">(</span><span class="st">"brain volume (cc)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"(a)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>,</span>
<span>        plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># If drop second row</span></span>
<span><span class="va">d</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="fu">row_number</span><span class="op">(</span><span class="op">)</span> <span class="op">!=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      species brain mass
1   afarensis   438 37.0
2     habilis   612 34.5
3      boisei   521 41.5
4 rudolfensis   752 55.5
5    ergaster   871 61.0
6     sapiens  1350 53.5</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb650"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># We can then extend that logic into a custom function, make_lines(), that will drop a </span></span>
<span><span class="co"># row from d, fit the simple model brain ~ mass, and then use base R predict() to return </span></span>
<span><span class="co"># the model-implied trajectory over new data values.</span></span>
<span></span>
<span><span class="co">## Fit the models (First- degree polynomials: Underfit example) </span></span>
<span><span class="co"># because these lines are straight, we only need new data over two points of `mass`</span></span>
<span><span class="va">nd</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>mass <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">30</span>, <span class="fl">70</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">make_lines</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">row</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">my_fit</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">d</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="fu">row_number</span><span class="op">(</span><span class="op">)</span> <span class="op">!=</span> <span class="va">row</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">my_fit</span>, <span class="va">nd</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">rename</span><span class="op">(</span>brain <span class="op">=</span> <span class="va">value</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">bind_cols</span><span class="op">(</span><span class="va">nd</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Here we’ll make a tibble, lines, which will specify rows 1 through 7 in the row column.</span></span>
<span><span class="co"># We’ll then feed those row numbers into our custom make_lines() function, which will return </span></span>
<span><span class="co"># the predicted values and their corresponding mass values, per model.</span></span>
<span><span class="op">(</span></span>
<span>  <span class="va">lines</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">tibble</span><span class="op">(</span>row <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>p <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">row</span>, <span class="va">make_lines</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">unnest</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code># A tibble: 14 × 3
     row brain  mass
   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
 1     1  436.    30
 2     1 1201.    70
 3     2  421.    30
 4     2 1205.    70
 5     3  323.    30
 6     3 1264.    70
 7     4  423.    30
 8     4 1221.    70
 9     5  376.    30
10     5 1335.    70
11     6  332.    30
12     6 1433.    70
13     7  412.    30
14     7  964.    70</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb652"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot the data</span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">+</span> </span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span>expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">lines</span>, </span>
<span>            <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mass</span>, y <span class="op">=</span> <span class="va">brain</span>, group <span class="op">=</span> <span class="va">row</span><span class="op">)</span>,</span>
<span>            color <span class="op">=</span> <span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Fit the models (Sixth-order polynomials: Overfit example)</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">d</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">mass</span>, y <span class="op">=</span> <span class="va">brain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"slateblue"</span>, size <span class="op">=</span> <span class="fl">3</span>, shape <span class="op">=</span> <span class="fl">21</span><span class="op">)</span>  <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span><span class="st">"body mass (kg)"</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">33</span>, <span class="fl">62</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">300</span>, <span class="fl">1500</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ylab</span><span class="op">(</span><span class="st">"brain volume (cc)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"(b)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>,</span>
<span>        plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We’ll need to increase the number of mass points in our nd data and redefine the </span></span>
<span><span class="co"># make_lines() function to fit the sixth-order-polynomial model.</span></span>
<span><span class="co"># because these lines will be very curvy, we'll need new data over many points of `mass`</span></span>
<span><span class="va">nd</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>mass <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">30</span>, to <span class="op">=</span> <span class="fl">65</span>, length.out <span class="op">=</span> <span class="fl">200</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># redifine the function</span></span>
<span><span class="va">make_lines</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">row</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">my_fit</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">d</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="fu">row_number</span><span class="op">(</span><span class="op">)</span> <span class="op">!=</span> <span class="va">row</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">3</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">4</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">5</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">mass</span><span class="op">^</span><span class="fl">6</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">my_fit</span>, <span class="va">nd</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">rename</span><span class="op">(</span>brain <span class="op">=</span> <span class="va">value</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">bind_cols</span><span class="op">(</span><span class="va">nd</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># make our new tibble</span></span>
<span><span class="va">lines</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">tibble</span><span class="op">(</span>row <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>p <span class="op">=</span> <span class="fu">map</span><span class="op">(</span><span class="va">row</span>, <span class="va">make_lines</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">unnest</span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># plot!</span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="va">p</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>data <span class="op">=</span> <span class="va">lines</span>, </span>
<span>            <span class="fu">aes</span><span class="op">(</span>group <span class="op">=</span> <span class="va">row</span><span class="op">)</span>,</span>
<span>            color <span class="op">=</span> <span class="st">"black"</span>, alpha <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">300</span>, <span class="fl">2000</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">grid.arrange</span><span class="op">(</span><span class="va">p1</span>, <span class="va">p2</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/f6.5a-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb653"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Underfitting and overfitting as under-sensitivity and over-sensitivity to sample. </span></span>
<span><span class="co"># In both plots, a regression is fit to the seven sets of data made by dropping one row </span></span>
<span><span class="co"># from the original data. (a) An underfit model is insensitive to the sample, changing </span></span>
<span><span class="co"># little as individual points are dropped. (b) An overfit model is sensitive to the sample, </span></span>
<span><span class="co"># changing dramatically as points are dropped.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="information-theory-and-model-performance" class="level2"><h2 class="anchored" data-anchor-id="information-theory-and-model-performance">Information theory and model performance</h2>
<p>The information theory provides a common and useful target (criterion of model performance), the <em>out-of-sample deviance</em> to navigate between overfitting and underfitting. The steps to out-of-sample deviance:</p>
<ul>
<li><p>First, we need to establish that joint probability, not average probability, is the right way to judge model accuracy.</p></li>
<li><p>Second, we need to establish a measurement scale for distance from perfect accuracy. This will require a little <em>information theory</em>, as it will provide a natural measurement scale for the distance between two probability distributions.</p></li>
<li><p>Third, we need to establish deviance as an approximation of relative distance from perfect accuracy.</p></li>
<li><p>Finally, we must establish that it is only deviance out-of-sample that is of interest.</p></li>
</ul>
<p>Once you have deviance in hand as a measure model performance, both regularizing priors and information criteria help you improve and estimate the out-of-sample deviance of a model.</p>
<p><br></p>
<section id="firing-the-weatherperson" class="level3"><h3 class="anchored" data-anchor-id="firing-the-weatherperson">Firing the weatherperson</h3>
<p>Accuracy depends upon the definition of the target, and there is no unique best target. In defining a target, there are two major dimensions to worry about:</p>
<ol type="1">
<li><p><strong><em>Cost-benefit analysis</em></strong> - How much does it cost when we’re wrong? How much do we win when we’re right?</p></li>
<li><p><strong><em>Accuracy in context</em></strong> - Some prediction tasks are inherently easier than others. So even if we ignore costs and benefits, we still need a way to judge “accuracy” that accounts for how much a model could possibly improve prediction.</p></li>
</ol>
<p><br></p>
</section><section id="information-and-uncertainty" class="level3"><h3 class="anchored" data-anchor-id="information-and-uncertainty">Information and uncertainty</h3>
<p>The information theory provides a solution to the problem of how to measure distance of a model’s accuracy from a target. The basic insight is to ask: <em>How much is our uncertainty reduced by learning an outcome?</em></p>
<p><span class="math display">\[\textit{Information:}~\text{The reduction in uncertainty derived from learning an outcome.}\]</span></p>
<p>To use this definition, what we need is a principled way to quantify the uncertainty inherent in a probability distribution. There are many possible ways to measure uncertainty. The most common way begins by naming some properties a measure of uncertainty should possess. These are the three intuitive desiderata:</p>
<ol type="1">
<li><p>The measure of uncertainty should be continuous.</p></li>
<li><p>The measure of uncertainty should increase as the number of possible events increases.</p></li>
<li><p>The measure of uncertainty should be additive.</p></li>
</ol>
<p>Only one function <strong><em>Information Theory</em></strong> satisfies these desiderata. If there are <em>n</em> different possible events and each event <em>i</em> has probability <em>p<sub>i</sub></em>, and we call the list of probabilities <em>p</em>, then the unique measure of uncertainty we seek is:</p>
<p><span class="math display">\[H(p) = ~- \text{E log}(p_i) = -\sum_{i=1}^{n} p_i ~\text{log}(p_i)\]</span></p>
<pre><code>
The uncertainty contained in a probability distribution is the average log-probability of an event.
</code></pre>
<p>To compute the information entropy for the weather, suppose the true probabilities of rain and shine are p<sub>1</sub> = 0.3 and p<sub>2</sub> = 0.7, respectively. Then:</p>
<p><span class="math display">\[H(p) = ~-(p_1 ~\text{log}(p_1) ~+~ p_2 ~\text{log}(p_2)) \approx 0.61 \]</span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb655"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># In R calculation for the value of entropy:</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fl">0.3</span> , <span class="fl">0.7</span> <span class="op">)</span></span>
<span></span>
<span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">p</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6108643</code></pre>
</div>
</div>
<p><br></p>
<p>The entropy values by themselves don’t mean much to us, though. Instead we can use them to build a measure of accuracy. The information entropy is the average log-probability. But there’s also a −1 in the definition. Multiplying the average log-probability by −1 just makes the entropy H increase from zero, rather than decrease from zero.</p>
<p>The logarithms above are natural logs (base <em>e</em>), but changing the base rescales without any effect on inference. Binary logarithms, base 2, are just as common. As long as all of the entropies you compare use the same base, you’ll be fine.</p>
<p>The only trick in computing <em>H</em> is to deal with the inevitable question of what to do when <em>p<sub>i</sub></em> = 0. The log(0) = −<span class="math inline">\(\infty\)</span>, which won’t do. So just assume that 0 log(0) = 0, when you compute <em>H</em>. In other words, events that never happen drop out. It may make more sense to just remember that when an event never happens, there’s no point in keeping it in the model.</p>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>The benefits of maximizing uncertainty</strong></span></span></p>
<p><strong>Maximum entropy</strong>, also known as <strong>maxent</strong>, is a family of techniques for finding probability distributions that are most consistent with states of knowledge. In other words, given what we know, what is the <em>least surprising</em> distribution? It turns out that one answer to this question maximizes the information entropy, using the prior knowledge as constraint.</p>
<p><br></p>
</section><section id="from-entropy-to-accuracy" class="level3"><h3 class="anchored" data-anchor-id="from-entropy-to-accuracy">From entropy to accuracy</h3>
<p>How can we use information entropy to say how far a model is from the target? The key lies in divergence:</p>
<p><span class="math display">\[\textit{Divergence:} ~\text{The additional uncertainty induced by using probabilities from one distribution to describe another distribution.}\]</span></p>
<p>Suppose for example that the true distribution of events is <em>p<sub>1</sub></em> = 0.3, <em>p<sub>2</sub></em> = 0.7. If we believe instead that these events happen with probabilities <em>q<sub>1</sub></em> = 0.25, <em>q<sub>2</sub></em> = 0.75, how much additional uncertainty have we introduced, as a consequence of using <em>q</em> = {<em>q<sub>1</sub></em>, <em>q<sub>2</sub></em>} to approximate <em>p</em> = {<em>p<sub>1</sub></em>, <em>p<sub>2</sub></em>}? The formal answer to this question is based upon <em>H</em>, and has a similarly simple formula:</p>
<p><span class="math display">\[D_{KL} (p, q) = \sum_i~ p_i ~(~\text{log}(p_i) - \text{log}(q_i)) = \sum_i~p_i ~\text{log} \left(\frac{p_i}{q_i}\right)\]</span></p>
<p>In plainer language, the divergence is <em>the average difference in log probability between the target (p) and model (q)</em>. This divergence is just the difference between two entropies: The entropy of the target distribution <em>p</em> and the cross entropy arising from using <em>q</em> to predict <em>p</em>. When <em>p</em> = <em>q</em>, we know the actual probabilities of the events. In that case:</p>
<p><span class="math display">\[D_{KL} (p, q) = D_{KL} (p, p) = \sum_i ~p_i  ~(~\text{log} (p_i) - \text{log}(p_i)) = 0\]</span></p>
<p>There is no additional uncertainty induced when we use a probability distribution to represent itself. But more importantly, as <em>q</em> grows more different from <em>p</em>, the divergence <span class="math inline">\(D_{KL}\)</span> also grows. Suppose the true target distribution is p = {0.3, 0.7}. Suppose the approximating distribution <em>q</em> can be anything from <em>q</em> = {0.01, 0.99} to <em>q</em> = {0.99, 0.01}. The first of these probabilities, <em>q<sub>1</sub></em>, is displayed on the horizontal axis, and the vertical displays the divergence <span class="math inline">\(D_{KL}\)</span>(<em>p</em>, <em>q</em>). Only exactly where <em>q</em> = <em>p</em>, at <em>q<sub>1</sub></em> = 0.3, does the divergence achieve a value of zero. Everyplace else, it grows.</p>
<p>Divergence can help us contrast different approximations to <em>p</em>. As an approximating function <em>q</em> becomes more accurate, <span class="math inline">\(D_{KL}\)</span>(<em>p</em>, <em>q</em>) will shrink. So if we have a pair of candidate distributions, then the candidate that minimizes the divergence will be closest to the target. Since predictive models specify probabilities of events (observations), we can use divergence to compare the accuracy of models.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb657"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create dataframe for figure 6.6</span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fl">0.3</span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fl">0.7</span></span>
<span><span class="va">q1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0.01</span>, to <span class="op">=</span> <span class="fl">0.99</span>, by <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="va">q2</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">-</span><span class="va">q1</span></span>
<span><span class="va">dkl</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">p1</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">p1</span><span class="op">/</span><span class="va">q1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="va">p2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">p2</span><span class="op">/</span><span class="va">q2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p1</span>, <span class="va">p2</span>, <span class="va">q1</span>, <span class="va">q2</span>, <span class="va">dkl</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   99 obs. of  5 variables:
 $ p1 : num  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 ...
 $ p2 : num  0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 0.7 ...
 $ q1 : num  0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 ...
 $ q2 : num  0.99 0.98 0.97 0.96 0.95 0.94 0.93 0.92 0.91 0.9 ...
 $ dkl: num  0.778 0.577 0.462 0.383 0.324 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb659"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plot data for true p at 0.3</span></span>
<span><span class="va">f1</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">q1</span>, y <span class="op">=</span> <span class="va">dkl</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">.3</span>, color <span class="op">=</span> <span class="st">"black"</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span> <span class="fu">geom_hline</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>, <span class="fl">0.4</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"slateblue"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span>geom <span class="op">=</span> <span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">.4</span>, y <span class="op">=</span> <span class="fl">1.5</span>, label <span class="op">=</span> <span class="st">"q = p"</span>,</span>
<span>           color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"True target distribution p = 0.3"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"q[1]"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Divergence of q from p"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>,</span>
<span>         plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot data for true p at 0.7</span></span>
<span><span class="va">f2</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">d</span>, <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">q2</span>, y <span class="op">=</span> <span class="va">dkl</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">.7</span>, color <span class="op">=</span> <span class="st">"black"</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu">geom_hline</span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"black"</span>, <span class="fl">0.4</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span>color <span class="op">=</span> <span class="st">"slateblue"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">annotate</span><span class="op">(</span>geom <span class="op">=</span> <span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">.8</span>, y <span class="op">=</span> <span class="fl">1.5</span>, label <span class="op">=</span> <span class="st">"q = p"</span>,</span>
<span>           color <span class="op">=</span> <span class="st">"black"</span>, size <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggtitle</span><span class="op">(</span><span class="st">"True target distribution p = 0.7"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"q[2]"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Divergence of q from p"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>,</span>
<span>         plot.title <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">grid.arrange</span><span class="op">(</span><span class="va">f1</span>, <span class="va">f2</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/f6.6-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb660"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Information divergence of an approximating distribution q from a true distribution p. </span></span>
<span><span class="co"># Divergence can only equal zero when q = p (dashed line). Otherwise, the divergence is </span></span>
<span><span class="co"># positive and grows as q becomes more dissimilar from p. When we have more than one </span></span>
<span><span class="co"># candidate approximation q, the q with the smallest divergence is the most accurate </span></span>
<span><span class="co"># approximation, in the sense that it induces the least additional uncertainty.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Cross entropy and divergence</strong></span></span></p>
<ul>
<li>
<strong><em>Cross entropy:</em></strong>
<ul>
<li>The use of a probability distribution <em>q</em> to predict events from another distribution <em>p</em>
</li>
<li><span class="math inline">\(H(p, q) = ~-\sum_i p_i ~\text{log}(q_i)\)</span></li>
<li>Events arise according to the <em>p’</em>s, but they are expected according to the <em>q’</em>s, so the entropy is inflated, depending upon how different <em>p</em> and <em>q</em> are</li>
</ul>
</li>
</ul>
<ul>
<li>
<strong><em>Divergence:</em></strong>
<ul>
<li>The <em>additional</em> entropy induced by using <em>q</em> (measuring how far <em>q</em> is from the target <em>p</em>, in units of entropy)</li>
<li>Divergence depends upon direction: <span class="math inline">\(H(p, q)\)</span> does not in general equal <span class="math inline">\(H(q, p)\)</span>
</li>
<li>It’s just the difference between <span class="math inline">\(H(p)\)</span>, the actual entropy of events, and <span class="math inline">\(H(p, q)\)</span>:</li>
</ul>
</li>
</ul>
<p>$$ <span class="math display">\[\begin{align*}
\ D_{KL} (p, q) &amp;= H(p, q) ~- ~ H(p)\\
&amp;= ~- \sum_i p_i ~\text{log}(q_i) ~-~ \left(- \sum_i p_i ~\text{log}(p_i) \right)\\
&amp;= ~- \sum_i p_i ~\left( \text{log}(q_i) ~-~ \text{log}(p_i) \right)
\end{align*}\]</span></p>
<p>$$</p>
<p><strong><em>If we use a distribution with high entropy to approximate an unknown true distribution of events, we will reduce the distance to the truth and therefore the error.</em></strong></p>
<p><br></p>
</section><section id="from-divergence-to-deviance" class="level3"><h3 class="anchored" data-anchor-id="from-divergence-to-deviance">From divergence to deviance</h3>
<p>The point of all the preceding material about information theory and divergence is to establish both:</p>
<ol type="1">
<li><p>How to measure the distance of a model from our target. Information theory gives us the distance measure we need, the K-L divergence.</p></li>
<li><p>How to estimate the divergence. Having identified the right measure of distance, we now need a way to estimate it in real statistical modeling tasks— a measure of model fit known as <strong><em>deviance</em></strong> which is defined as:</p></li>
</ol>
<p><span class="math display">\[D(q) = ~-2 \sum_i \text{log}(q_i)\]</span></p>
<pre><code>i   = indexes each observation (case)

q_i =  the likelihood of case i
</code></pre>
<p><br></p>
<p>In examples of divergence, p is known. In real world, p is unknown, but we can still estimate which models (q or r, etc.) is a better fit by using deviance— like we don’t know how far each archer is from hitting the target, but we can know which archer is closer and how far apart they are from each other.</p>
<p>You can compute the deviance for any model you’ve fit already in this book, just by using the <code>MAP</code> estimates to compute a log-probability of the observed data for each row. These probabilities are the <em>q</em> values. Then you add these log-probabilities together and multiply by −2. Most of the standard model fitting functions support <code>logLik</code>, which will do the hard part: compute the sum of log-probabilities, usually known as the log-likelihood of the data. For example:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb662"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Reload data</span></span>
<span><span class="va">sppnames</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="st">"afarensis"</span>,<span class="st">"africanus"</span>,<span class="st">"habilis"</span>,<span class="st">"boisei"</span>,</span>
<span>    <span class="st">"rudolfensis"</span>,<span class="st">"ergaster"</span>,<span class="st">"sapiens"</span><span class="op">)</span></span>
<span><span class="va">brainvolcc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fl">438</span> , <span class="fl">452</span> , <span class="fl">612</span>, <span class="fl">521</span>, <span class="fl">752</span>, <span class="fl">871</span>, <span class="fl">1350</span> <span class="op">)</span></span>
<span><span class="va">masskg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fl">37.0</span> , <span class="fl">35.5</span> , <span class="fl">34.5</span> , <span class="fl">41.5</span> , <span class="fl">55.5</span> , <span class="fl">61.0</span> , <span class="fl">53.5</span> <span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span> species<span class="op">=</span><span class="va">sppnames</span> , brain<span class="op">=</span><span class="va">brainvolcc</span> , mass<span class="op">=</span><span class="va">masskg</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># fit model with lm</span></span>
<span><span class="va">m6.1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">brain</span> <span class="op">~</span> <span class="va">mass</span> , <span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># compute deviance by cheating</span></span>
<span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">m6.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' 94.92499 (df=3)</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb664"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Note that, because there is uncertainty about the parameters, there is also uncertainty about </span></span>
<span><span class="co"># the deviance of a model. For any specific parameter values, deviance is defined exactly. </span></span>
<span><span class="co"># But since we have a posterior distribution of parameter values, there is also a posterior </span></span>
<span><span class="co"># distribution of the deviance.</span></span>
<span></span>
<span><span class="co">## Raw calculation</span></span>
<span><span class="co"># standardize the mass before fitting</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">mass.s</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mass</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mass</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mass</span><span class="op">)</span></span>
<span><span class="va">m6.8</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">brain</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">mass.s</span></span>
<span><span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d</span> , </span>
<span>start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">brain</span><span class="op">)</span>,b<span class="op">=</span><span class="fl">0</span>,sigma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">brain</span><span class="op">)</span><span class="op">)</span> ,</span>
<span>method<span class="op">=</span><span class="st">"Nelder-Mead"</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># extract MAP estimates</span></span>
<span><span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m6.8</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute deviance</span></span>
<span><span class="va">dev</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span></span>
<span>            <span class="va">d</span><span class="op">$</span><span class="va">brain</span> ,</span>
<span>            mean<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">+</span><span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">*</span><span class="va">d</span><span class="op">$</span><span class="va">mass.s</span> ,</span>
<span>            sd<span class="op">=</span><span class="va">theta</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> ,</span>
<span>            log<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">dev</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 94.92499</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb666"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The same result you’d get with -2*logLik(m6.8). All that’s really required is to plug the </span></span>
<span><span class="co"># MAP estimates into the likelihood function. You compute the log-likelihood for each observation. </span></span>
<span><span class="co"># Then you add them all together. Finally, multiply the sum by −2. That yields the deviance. </span></span>
<span><span class="co"># R’s logLik function does everything except multiply by −2.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="from-deviance-to-out-of-sample" class="level3"><h3 class="anchored" data-anchor-id="from-deviance-to-out-of-sample">From deviance to out-of-sample</h3>
<p>When we usually have data and use it to fit a statistical model, the data comprise a <em>training sample</em>. Parameters are estimated from it, and then we can imagine using those estimates to predict outcomes in a new sample, called the <em>test sample</em>. R is going to do all of this for you. But here’s the full procedure, in outline:</p>
<ol type="1">
<li><p>Suppose there’s a training sample of size <em>N</em>.</p></li>
<li><p>Fit a model to the training sample, and compute the deviance on the training sample. Call this deviance D<sub>train</sub>.</p></li>
<li><p>Suppose another sample of size <em>N</em> from the same process. This is the test sample.</p></li>
<li><p>Compute the deviance on the test sample. This means using the MAP estimates from step (2) to compute the deviance for the data in the test sample. Call this deviance D<sub>test</sub>.</p></li>
</ol>
<p>The above is a thought experiment. It allows us to explore the distinction between deviance measured in and out of sample, using a simple prediction scenario.</p>
<p>To visualize the results of the thought experiment, what we’ll do now is conduct the above thought experiment 10,000 times, for each of five different linear regression models. The model that generates the data is:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{y}_i &amp;\sim \text{Normal}(\mu_i, 1)\\
\mu_i &amp;\sim (0.15)\text{x}_{1,i} ~-~ (0.4)\text{x}_{2,i}
\end{align*}\]</span></p>
<p>$$</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb667"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## sim.train.test is run 10,000 (1e4) times for each of the 5 models</span></span>
<span><span class="co"># I will change to 1000 to load faster</span></span>
<span></span>
<span><span class="co">## For N = 20</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">kseq</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span></span>
<span><span class="va">dev</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">kseq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span>;</span>
<span>        <span class="co">#r &lt;- replicate( 1000 , sim.train.test( N=N, k=k ) ); </span></span>
<span><span class="co"># If you are Mac or Linux, you can parallelize the simulations by replacing the replicate line with:</span></span>
<span>        <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">mcreplicate</span><span class="op">(</span><span class="fl">1000</span>, <span class="fu">sim.train.test</span><span class="op">(</span>N<span class="op">=</span><span class="va">N</span>, k<span class="op">=</span><span class="va">k</span><span class="op">)</span>, mc.cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>;</span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set mc.cores to the number of processor cores you want to use for the simulations. </span></span>
<span><span class="co"># Once the simulations complete, dev will be a 4-by-5 matrix of means and standard deviations. </span></span>
<span><span class="co"># By altering this code, you can simulate many different train-test scenarios.</span></span>
<span><span class="co"># See ?sim.train.test for additional options.</span></span>
<span></span>
<span><span class="co">## To reproduce the plot:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span> , <span class="va">dev</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">dev</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span><span class="op">-</span><span class="fl">5</span> , <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">dev</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span><span class="op">+</span><span class="fl">10</span> <span class="op">)</span> ,</span>
<span>    xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">5.1</span><span class="op">)</span> , xlab<span class="op">=</span><span class="st">"number of parameters"</span> , ylab<span class="op">=</span><span class="st">"deviance"</span> ,</span>
<span>        pch<span class="op">=</span><span class="fl">16</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span> <span class="fu">concat</span><span class="op">(</span> <span class="st">"N = "</span>,<span class="va">N</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">+</span><span class="fl">0.1</span> , <span class="va">dev</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> <span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="va">kseq</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">pts_in</span> <span class="op">&lt;-</span> <span class="va">dev</span><span class="op">[</span><span class="fl">1</span>,<span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">dev</span><span class="op">[</span><span class="fl">3</span>,<span class="va">i</span><span class="op">]</span></span>
<span>    <span class="va">pts_out</span> <span class="op">&lt;-</span> <span class="va">dev</span><span class="op">[</span><span class="fl">2</span>,<span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">dev</span><span class="op">[</span><span class="fl">4</span>,<span class="va">i</span><span class="op">]</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">i</span>,<span class="va">i</span><span class="op">)</span> , <span class="va">pts_in</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">i</span>,<span class="va">i</span><span class="op">)</span><span class="op">+</span><span class="fl">0.1</span> , <span class="va">pts_out</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">1.8</span>, <span class="fl">55</span>, <span class="st">"in"</span>, col <span class="op">=</span> <span class="va">rangi2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">2.42</span>, <span class="fl">59</span>, <span class="st">"out"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">2.42</span>, <span class="fl">51</span>, <span class="st">"-1SD"</span>, cex <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">2.42</span>, <span class="fl">66</span>, <span class="st">"+1SD"</span>, cex <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## For N = 100</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">kseq</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span></span>
<span><span class="va">dev</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="va">kseq</span> , <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span>;</span>
<span>        <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">mcreplicate</span><span class="op">(</span><span class="fl">1000</span>, <span class="fu">sim.train.test</span><span class="op">(</span>N<span class="op">=</span><span class="va">N</span>, k<span class="op">=</span><span class="va">k</span><span class="op">)</span>, mc.cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>;</span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">)</span> , <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span> , <span class="va">dev</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">dev</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span><span class="op">-</span><span class="fl">10</span> , <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">dev</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span><span class="op">+</span><span class="fl">12</span> <span class="op">)</span> ,</span>
<span>    xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">5.1</span><span class="op">)</span> , xlab<span class="op">=</span><span class="st">"number of parameters"</span> , ylab<span class="op">=</span><span class="st">"deviance"</span> ,</span>
<span>        pch<span class="op">=</span><span class="fl">16</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span> <span class="fu">concat</span><span class="op">(</span> <span class="st">"N = "</span>,<span class="va">N</span> <span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span> <span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span><span class="op">+</span><span class="fl">0.1</span> , <span class="va">dev</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> <span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="va">kseq</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">pts_in</span> <span class="op">&lt;-</span> <span class="va">dev</span><span class="op">[</span><span class="fl">1</span>,<span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">dev</span><span class="op">[</span><span class="fl">3</span>,<span class="va">i</span><span class="op">]</span></span>
<span>    <span class="va">pts_out</span> <span class="op">&lt;-</span> <span class="va">dev</span><span class="op">[</span><span class="fl">2</span>,<span class="va">i</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">dev</span><span class="op">[</span><span class="fl">4</span>,<span class="va">i</span><span class="op">]</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">i</span>,<span class="va">i</span><span class="op">)</span> , <span class="va">pts_in</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">i</span>,<span class="va">i</span><span class="op">)</span><span class="op">+</span><span class="fl">0.1</span> , <span class="va">pts_out</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">1.8</span>, <span class="fl">280.1</span>, <span class="st">"in"</span>, col <span class="op">=</span> <span class="va">rangi2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">2.42</span>, <span class="fl">284</span>, <span class="st">"out"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Deviance in and out of sample. In each plot, models with different numbers of predictor variables </span></span>
<span><span class="co"># are shown on the horizontal axis. Deviance across 10,000 simulations is shown on the vertical. </span></span>
<span><span class="co"># Blue shows deviance in-sample, the training data. Black shows deviance out-of-sample, the test data. </span></span>
<span><span class="co"># Points show means, and the line segments show ±1 standard deviation.</span></span>
<span></span>
<span><span class="co"># Moving left to right with increasing numbers of parameters, the average deviance declines. </span></span>
<span><span class="co"># A smaller deviance means a better fit. So this decline with increasing model complexity.</span></span>
<span><span class="co"># While deviance keeps improving (declining) in the training sample, it gets worse on average in </span></span>
<span><span class="co"># the test sample.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="regularization" class="level2"><h2 class="anchored" data-anchor-id="regularization">Regularization</h2>
<p>The root of overfitting is a model’s tendency to get overexcited by the training sample. One way to prevent a model from getting too excited by the training sample is to give it a skeptical prior. By “skeptical,” I mean a prior that slows the rate of learning from the sample. The most common skeptical prior is a <strong><em>regularizing prior</em></strong>, which is applied to a beta-coefficient, a “slope” in a linear model.</p>
<p>The regularizing prior, when <em>tuned properly</em>, reduces overfitting while still allowing the model to learn the regular features of a sample. If the prior is too skeptical, however, then regular features will be missed, resulting in underfitting. For example, consider this Gaussian model:</p>
<p>$$ <span class="math display">\[\begin{align*}
\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta \text{x}_i\\
\alpha &amp;\sim \text{Normal}(0, 100)\\
\beta &amp;\sim \text{Normal}(0, 1)\\
\sigma &amp;\sim \text{Uniform}(0, 10)
\end{align*}\]</span></p>
<p>$$</p>
<p>Assume, as is good practice, that the predictor x is standardized so that its standard deviation is 1 and its mean is zero. Then the prior on <span class="math inline">\(\alpha\)</span> is a nearly flat prior that has no practical effect on inference.</p>
<p>But the prior on <span class="math inline">\(\beta\)</span> is narrower and is meant to regularize. The prior <span class="math inline">\(\beta\)</span> ∼ Normal(0, 1) says that, before seeing the data, the machine should be very skeptical of values above 2 and below −2, as a Gaussian prior with a standard deviation of 1 assigns only 5% plausibility to values above and below 2 standard deviations. Because the predictor variable x is standardized, you can interpret this as meaning that a change of 1 standard deviation in x is very unlikely to produce 2 units of change in the outcome.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb668"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tibble</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span> <span class="fl">3.5</span>, </span>
<span>               to   <span class="op">=</span> <span class="fl">3.5</span>, </span>
<span>               by   <span class="op">=</span> <span class="fl">.01</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, ymin <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>ymax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span><span class="op">)</span>, </span>
<span>               fill <span class="op">=</span> <span class="st">"transparent"</span>, col <span class="op">=</span> <span class="st">"black"</span>,linetype <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>ymax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>, </span>
<span>              fill <span class="op">=</span> <span class="st">"transparent"</span>, col <span class="op">=</span> <span class="st">"black"</span>, linetype <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_ribbon</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>ymax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>, </span>
<span>              fill <span class="op">=</span> <span class="st">"transparent"</span>, col <span class="op">=</span> <span class="st">"black"</span>, linetype <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2.2</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">xlab</span><span class="op">(</span><span class="st">"parameter value"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ylab</span><span class="op">(</span><span class="st">"Density"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, expand <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>panel.grid.major <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span>, panel.grid.minor <span class="op">=</span> <span class="fu">element_blank</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/f6.8-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb669"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Regularizing priors, weak and strong. Three Gaussian priors of varying standard deviation. </span></span>
<span><span class="co"># These priors reduce overfitting, but with different strength. </span></span>
<span><span class="co"># Dashed: Normal(0, 1). Thin solid: Normal(0, 0.5). Thick solid: Normal(0, 0.2).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>How strong or weak these skeptical priors will be in practice depends upon the data and model. So let’s explore a train-test example again, but this time we’ll use the regularizing priors.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb670"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Use Ajkurz's codes</span></span>
<span><span class="va">n</span>       <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">kseq</span>    <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span></span>
<span><span class="co"># I've reduced this number by one order of magnitude to reduce computation time</span></span>
<span><span class="va">n_sim</span>   <span class="op">&lt;-</span> <span class="fl">1e3</span></span>
<span><span class="va">n_cores</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span></span>
<span><span class="co"># here's our dev object based on `N &lt;- 20`</span></span>
<span><span class="va">dev_20</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">kseq</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span>;</span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">mcreplicate</span><span class="op">(</span><span class="va">n_sim</span>, <span class="fu">sim.train.test</span><span class="op">(</span>N <span class="op">=</span> <span class="va">n</span>, k <span class="op">=</span> <span class="va">k</span><span class="op">)</span>,</span>
<span>                     mc.cores <span class="op">=</span> <span class="va">n_cores</span><span class="op">)</span>;</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># here's our dev object based on N &lt;- 100</span></span>
<span><span class="va">n</span>       <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">dev_100</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">kseq</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span>;</span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">mcreplicate</span><span class="op">(</span><span class="va">n_sim</span>, <span class="fu">sim.train.test</span><span class="op">(</span>N <span class="op">=</span> <span class="va">n</span>, k <span class="op">=</span> <span class="va">k</span><span class="op">)</span>, </span>
<span>                     mc.cores <span class="op">=</span> <span class="va">n_cores</span><span class="op">)</span>;</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dev_tibble</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">dev_20</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">bind_rows</span><span class="op">(</span></span>
<span>    <span class="va">dev_100</span> <span class="op">%&gt;%</span></span>
<span>      <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>n         <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"n = 20"</span>, <span class="st">"n = 100"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>         statistic <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mean"</span>, <span class="st">"sd"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">.</span>, times <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>         sample    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"in"</span>, <span class="st">"out"</span><span class="op">)</span>, times <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">.</span>, times <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span><span class="va">n_par</span>, <span class="va">value</span>, <span class="op">-</span><span class="va">n</span>, <span class="op">-</span><span class="va">statistic</span>, <span class="op">-</span><span class="va">sample</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">spread</span><span class="op">(</span>key <span class="op">=</span> <span class="va">statistic</span>, value <span class="op">=</span> <span class="va">value</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>n     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">n</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"n = 20"</span>, <span class="st">"n = 100"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         n_par <span class="op">=</span> <span class="fu">str_remove</span><span class="op">(</span><span class="va">n_par</span>, <span class="st">"V"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>n_par <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">sample</span> <span class="op">==</span> <span class="st">"in"</span>, <span class="va">n_par</span> <span class="op">-</span> <span class="fl">.075</span>, <span class="va">n_par</span> <span class="op">+</span> <span class="fl">.075</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">dev_tibble</span><span class="op">)</span></span>
<span></span>
<span><span class="va">make_sim</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">n</span>, <span class="va">b_sigma</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">kseq</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span>;</span>
<span>    <span class="co"># this is an augmented line of code</span></span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">mcreplicate</span><span class="op">(</span><span class="va">n_sim</span>, <span class="fu">sim.train.test</span><span class="op">(</span>N <span class="op">=</span> <span class="va">n</span>, k <span class="op">=</span> <span class="va">k</span>, b_sigma <span class="op">=</span> <span class="va">b_sigma</span><span class="op">)</span>,</span>
<span>                     mc.cores <span class="op">=</span> <span class="va">n_cores</span><span class="op">)</span>;</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">}</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    </span>
<span>    <span class="co"># this is a new line of code</span></span>
<span>    <span class="fu">as_tibble</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">tibble</span><span class="op">(</span>n       <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">20</span>, <span class="fl">100</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>         b_sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">.5</span>, <span class="fl">.2</span><span class="op">)</span>, times <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sim     <span class="op">=</span> <span class="fu">map2</span><span class="op">(</span><span class="va">n</span>, <span class="va">b_sigma</span>, <span class="va">make_sim</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">unnest</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># wrangle the simulation data</span></span>
<span><span class="va">s</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>statistic <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"mean"</span>, <span class="st">"sd"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">.</span>, times <span class="op">=</span> <span class="fl">3</span> <span class="op">*</span> <span class="fl">2</span><span class="op">)</span>,</span>
<span>         sample    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"in"</span>, <span class="st">"out"</span><span class="op">)</span>, times <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">.</span>, times <span class="op">=</span> <span class="fl">3</span> <span class="op">*</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span><span class="va">n_par</span>, <span class="va">value</span>, <span class="op">-</span><span class="va">n</span>, <span class="op">-</span><span class="va">b_sigma</span>, <span class="op">-</span><span class="va">statistic</span>, <span class="op">-</span><span class="va">sample</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">spread</span><span class="op">(</span>key <span class="op">=</span> <span class="va">statistic</span>, value <span class="op">=</span> <span class="va">value</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>n     <span class="op">=</span> <span class="fu">str_c</span><span class="op">(</span><span class="st">"n = "</span>, <span class="va">n</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">.</span>, levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"n = 20"</span>, <span class="st">"n = 100"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         n_par <span class="op">=</span> <span class="fu">str_remove</span><span class="op">(</span><span class="va">n_par</span>, <span class="st">"V"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>  <span class="op">%&gt;%</span> </span>
<span>  </span>
<span>  <span class="co"># now plot</span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">n_par</span>, y <span class="op">=</span> <span class="va">mean</span>,</span>
<span>             group <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/interaction.html">interaction</a></span><span class="op">(</span><span class="va">sample</span>, <span class="va">b_sigma</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>color <span class="op">=</span> <span class="va">sample</span>, size <span class="op">=</span> <span class="va">b_sigma</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># this function contains the data from the previous simulation</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>data <span class="op">=</span> <span class="va">dev_tibble</span>, </span>
<span>             <span class="fu">aes</span><span class="op">(</span>group <span class="op">=</span> <span class="va">sample</span>, fill <span class="op">=</span> <span class="va">sample</span><span class="op">)</span>,</span>
<span>             color <span class="op">=</span> <span class="st">"black"</span>, shape <span class="op">=</span> <span class="fl">21</span>, size <span class="op">=</span> <span class="fl">2.5</span>, stroke <span class="op">=</span> <span class="fl">.1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_fill_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"slateblue"</span>, <span class="st">"black"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"slateblue"</span>, <span class="st">"black"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_size_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">.5</span>, <span class="fl">.2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"number of parameters"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"deviance"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>text             <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>family <span class="op">=</span> <span class="st">"serif"</span><span class="op">)</span>,</span>
<span>        legend.position  <span class="op">=</span> <span class="st">"none"</span>,</span>
<span>        strip.background <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>fill <span class="op">=</span> <span class="fu">alpha</span><span class="op">(</span><span class="st">"purple"</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span>,</span>
<span>        panel.background <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>fill <span class="op">=</span> <span class="fu">alpha</span><span class="op">(</span><span class="st">"white"</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">n</span>, scale <span class="op">=</span> <span class="st">"free_y"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Regularizing priors and out-of-sample deviance. The points in both plots are the same as 6.12. </span></span>
<span><span class="co"># The lines show training (blue) and testing (black) deviance for the three regularizing priors in f6.8. </span></span>
<span><span class="co"># Thin solid: Each beta-coefficient is given a Normal(0, 1) prior. </span></span>
<span><span class="co"># Thick solid: Normal(0, 0.5). </span></span>
<span><span class="co"># Bold solid: Normal(0, 0.2).</span></span>
<span></span>
<span><span class="co">## For left-hand plot</span></span>
<span><span class="co"># The training deviance always increases—gets worse—with tighter priors. The thick blue trend </span></span>
<span><span class="co"># is substantially larger than the others, and this is because the skeptical prior prevents </span></span>
<span><span class="co"># the model from adapting completely to the sample. But the test deviances, out-of-sample, </span></span>
<span><span class="co"># improve (get smaller) with the tighter priors. The model with three parameters is still the </span></span>
<span><span class="co"># best model out-of-sample, and the regularizing priors have little impact on its deviance.</span></span>
<span></span>
<span><span class="co"># But also notice that as the prior gets more skeptical, the harm done by an overly complex model </span></span>
<span><span class="co"># is greatly reduced. For the Normal(0, 0.2) prior (thick line), the models with 4 and 5 parameters </span></span>
<span><span class="co"># are barely worse than the correct model with 3 parameters. If you can tune the regularizing prior </span></span>
<span><span class="co"># right, then overfitting can be greatly reduced.</span></span>
<span></span>
<span><span class="co">## For right hand plot</span></span>
<span><span class="co"># The priors have much less of an effect here, because there is so much more evidence. </span></span>
<span><span class="co"># The priors do help. But overfitting was less of a concern to begin with, and there is </span></span>
<span><span class="co"># enough information in the data to overwhelm even the Normal(0, 0.2) prior (thick line).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Regularizing priors are great, because they reduce overfitting. But if they are too skeptical, they prevent the model from learning from the data. If you have enough data, you can split into “train” and “test” samples and then try different priors and select the one that provides the smallest deviance on the test sample. That is the essence of cross-validation, a common technique for reducing overfitting. But if you need to use all of the data to train the model, tuning the prior may not be so easy.</p>
<p><br></p>
</section><section id="information-criteria" class="level2"><h2 class="anchored" data-anchor-id="information-criteria">Information criteria</h2>
<p>We’ve used simulations in which a model is fit to one sample, the training sample, and then used to predict a second sample of the same size, the testing sample. Let’s look at one of those thought experiments again, but now annotated with the difference between the training deviance (in-sample) and the testing deviance (out-of-sample).</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb671"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Use ajkurz's codes</span></span>
<span><span class="co"># The data from our initial simulation isn’t formatted well to plot Figure 6.10. </span></span>
<span><span class="co"># We’ll have to wrangle a little.</span></span>
<span><span class="va">dev_tibble1</span> <span class="op">&lt;-</span> <span class="va">dev_tibble</span><span class="op">[</span>, <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">dev_tibble</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="st">"sd"</span><span class="op">]</span></span>
<span><span class="co"># He used select() to remove sd column but the function is not working for me</span></span>
<span><span class="co"># So, I use !name instead of select(-sd)</span></span>
<span><span class="op">(</span></span>
<span>  <span class="va">dev_tibble2</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">dev_tibble1</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">mutate</span><span class="op">(</span>n_par  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">sample</span> <span class="op">==</span> <span class="st">"in"</span>, <span class="va">n_par</span> <span class="op">+</span> <span class="fl">0.075</span>, <span class="va">n_par</span> <span class="op">-</span> <span class="fl">0.075</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">spread</span><span class="op">(</span>key <span class="op">=</span> <span class="va">sample</span>, value <span class="op">=</span> <span class="va">mean</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">mutate</span><span class="op">(</span>height <span class="op">=</span> <span class="op">(</span><span class="va">out</span> <span class="op">-</span> <span class="va">`in`</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>           dash   <span class="op">=</span> <span class="va">`in`</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">n_par</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># Plot</span></span>
<span><span class="va">dev_tibble2</span>  <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">n_par</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="va">dash</span><span class="op">)</span>,</span>
<span>            linetype <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="va">`in`</span><span class="op">)</span>,</span>
<span>             color <span class="op">=</span> <span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">7</span><span class="op">]</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="va">out</span><span class="op">)</span>,</span>
<span>             color <span class="op">=</span> <span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_errorbar</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">n_par</span> <span class="op">+</span> <span class="fl">.15</span>,</span>
<span>                    ymin <span class="op">=</span> <span class="va">`in`</span>, ymax <span class="op">=</span> <span class="va">out</span><span class="op">)</span>,</span>
<span>                width <span class="op">=</span> <span class="fl">.1</span>, color <span class="op">=</span> <span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">6</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_text</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">n_par</span> <span class="op">+</span> <span class="fl">.4</span>,</span>
<span>                y <span class="op">=</span> <span class="op">(</span><span class="va">out</span> <span class="op">+</span> <span class="va">`in`</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2</span>,</span>
<span>                label <span class="op">=</span> <span class="va">height</span><span class="op">)</span>,</span>
<span>            family <span class="op">=</span> <span class="st">"Courier"</span>, size <span class="op">=</span> <span class="fl">3</span>, color <span class="op">=</span> <span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">6</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>x <span class="op">=</span> <span class="st">"number of parameters"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"deviance"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>text             <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>family <span class="op">=</span> <span class="st">"Courier"</span><span class="op">)</span>,</span>
<span>        strip.background <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>fill <span class="op">=</span> <span class="fu">alpha</span><span class="op">(</span><span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span>,</span>
<span>        panel.background <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>fill <span class="op">=</span> <span class="fu">alpha</span><span class="op">(</span><span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">n</span>, scale <span class="op">=</span> <span class="st">"free_y"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Deviance in (dark red) and out (red) of sample, using flat priors. The vertical segments </span></span>
<span><span class="co"># measure the distance between each pair of deviances. For both N = 20 and N = 100, this distance </span></span>
<span><span class="co"># is approximately twice the number of parameters. The dashed lines show exactly the deviance </span></span>
<span><span class="co"># in-sample (training) plus twice the number of parameters on the horizontal axis. </span></span>
<span><span class="co"># These lines therefore show AIC for each model, an approximation of the out-of-sample deviance.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>This is the phenomenon behind <strong><em>information criteria</em></strong>. The most known information criterion is the <strong><em>Akaike information criterion</em></strong>, abbreviated <strong>AIC</strong>. AIC provides a surprisingly simple estimate of the average out-of-sample deviance:</p>
<p><span class="math display">\[\text{AIC} = D_{train} ~+~ 2p \]</span></p>
<pre><code>p   = the number of free parameters to be estimated in the model

This definition reflects the relationship between training and testing deviance in f6.10. 
The dashed lines in f6.10 trace out the AIC values of the models.
</code></pre>
<p><br></p>
<p>AIC provides an approximation of predictive accuracy, as measured by out-of-sample deviance. AIC is an approximation that is reliable only when:</p>
<ol type="1">
<li><p>The priors are flat or overwhelmed by the likelihood.</p></li>
<li><p>The posterior distribution is approximately multivariate Gaussian.</p></li>
<li><p>The sample size N is much greater than the number of parameters k.</p></li>
</ol>
<p>Since flat priors are hardly ever the best priors, we’ll want something more general.</p>
<p><br></p>
<p><span style="color:purple"><strong><em>Two common and more-general criteria</em></strong></span></p>
<ul>
<li>
<strong><em>Deviance Information Criterion (DIC)</em></strong>
<ul>
<li>accommodates informative priors, but still assumes that the posterior is multivariate Gaussian and that <span class="math inline">\(N \gg k\)</span>
</li>
</ul>
</li>
</ul>
<ul>
<li>
<strong><em>Widely Applicable Information Criterion (WAIC)</em></strong>
<ul>
<li>more general yet, making no assumption about the shape of the posterior</li>
</ul>
</li>
</ul>
<p><br></p>
<section id="deviance-information-criterion-dic" class="level3"><h3 class="anchored" data-anchor-id="deviance-information-criterion-dic">Deviance Information Criterion (DIC)</h3>
<p>DIC is essentially a version of AIC that is aware of informative priors. Like AIC, it assumes a multivariate Gaussian posterior distribution. This means if any parameter in the posterior is substantially skewed, and also has a substantial effect on prediction, then DIC like AIC can go horribly wrong.</p>
<p>DIC is calculated from the posterior distribution of the training deviance. So define D now as the posterior distribution of deviance. This means we compute deviance (on the training sample) for each set of sampled parameter values in the posterior distribution. So if we draw 10,000 samples from the posterior, we compute 10,000 deviance values.</p>
<p>DIC is calculated as:</p>
<p><span class="math display">\[\text{DIC} = D^{\overline{}} + (D^{\overline{}} - D\hat{}) = D^{\overline{}} + p_D \]</span></p>
<pre><code>D ̄ = the average of D

Dˆ = the deviance calculated at the posterior mean

p_D = the expected distance between the deviance in-sample and the deviance out-of-sample 

The difference D ̄ − Dˆ = p_D is analogous to the number of parameters used in computing AIC.
</code></pre>
<p><br></p>
</section><section id="widely-applicable-information-criterionwaic" class="level3"><h3 class="anchored" data-anchor-id="widely-applicable-information-criterionwaic">Widely Applicable Information Criterion(WAIC)</h3>
<p>WAIC is also calculated by taking averages of log-likelihood over the posterior distribution. And it is also just an estimate of out-of-sample deviance. But it does not require a multivariate Gaussian posterior, and it is often more accurate than DIC.</p>
<p>The distinguishing feature of WAIC is that it is <em>pointwise</em>. This means that uncertainty in prediction is considered case-by-case, or point-by-point, in the data. WAIC assesses flexibility of a model with respect to fitting each observation, and then sums up across all observations.</p>
<p>We compute the likelihood of <span class="math inline">\(y_i\)</span> for each set of parameters sampled from the posterior distribution. Then we average the likelihoods for each observation i and finally sum over all observations. This produces the first part of WAIC, the log-pointwise-predictive-density, lppd:</p>
<p><span class="math display">\[\text{lppd} = \sum_{i=1}^N ~\text{log Pr}(y_i)\]</span></p>
<pre><code>Pr(y_i)   =  the average likelihood of observation i in the training sample

The log-pointwise-predictive-density is the total across observations of the logarithm of 
the average likelihood of each observation.

The lppd is just a pointwise analog of deviance, averaged over the posterior distribution. 
If you multiplied it by −2, it’d be similar to the deviance, in fact.
</code></pre>
<p><br></p>
<p>The second piece of WAIC is the effective number of parameters <span class="math inline">\(p_{WAIC}\)</span>.</p>
<p><span class="math display">\[p_{WAIC} = \sum_{i=1}^N ~V(y_i)\]</span></p>
<pre><code>p_WAIC    = the effective number of parameters

V(y_i)    = the variance in log-likelihood for observation i in the training sample
</code></pre>
<p><br></p>
<p>Now WAIC is defined as:</p>
<p><span class="math display">\[\text{WAIC} = ~-2 (\text{lppd}~-~ p_{WAIC})\]</span></p>
<p>Because WAIC requires splitting up the data into independent observations i = 1…N, it is sometimes hard to define. Consider for example a model in which each prediction depends upon a previous observation. This happens, for example, in a <em>time series</em>. In a time series, a previous observation becomes a predictor variable for the next observation. So it’s not easy to think of each observation as independent of, or exchangeable with, the others. In such a case, you can of course compute WAIC as if each observation were independent of the others, but it’s not clear what the resulting value means.</p>
<p><br></p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>WAIC calculations</strong></span></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb676"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">615</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># To see how the WAIC calculations actually work, consider a simple regression fit with map:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">cars</span><span class="op">)</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">dist</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>,<span class="va">sigma</span><span class="op">)</span>,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">speed</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>        <span class="va">b</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">30</span><span class="op">)</span></span>
<span>    <span class="op">)</span> , data<span class="op">=</span><span class="va">cars</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span><span class="va">m</span>,n<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We’ll need the log-likelihood of each observation i at each sample s from the posterior:</span></span>
<span><span class="va">n_samples</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">ll</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_samples</span> ,</span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">s</span><span class="op">)</span> <span class="op">{</span></span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">a</span><span class="op">[</span><span class="va">s</span><span class="op">]</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">b</span><span class="op">[</span><span class="va">s</span><span class="op">]</span><span class="op">*</span><span class="va">cars</span><span class="op">$</span><span class="va">speed</span></span>
<span>        <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">cars</span><span class="op">$</span><span class="va">dist</span> , <span class="va">mu</span> , <span class="va">post</span><span class="op">$</span><span class="va">sigma</span><span class="op">[</span><span class="va">s</span><span class="op">]</span> , log<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">ll</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:50, 1:1000] -3.66 -3.81 -3.81 -3.85 -3.66 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb678"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># You end up with a 50-by-1000 matrix of log-likelihoods, with observations in rows </span></span>
<span><span class="co"># and samples in columns.</span></span>
<span></span>
<span><span class="co"># Now to compute lppd, the Bayesian deviance, we average the samples in each row, </span></span>
<span><span class="co"># take the log, and add all of the logs together. However, to do this with precision, </span></span>
<span><span class="co"># we need to do all of the averaging on the log scale. This is made easy with a </span></span>
<span><span class="co"># function log_sum_exp, which computes the log of a sum of exponentiated terms. </span></span>
<span><span class="co"># Then we can just subtract the log of the number of samples. </span></span>
<span><span class="co"># This computes the log of the average.</span></span>
<span><span class="va">n_cases</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">cars</span><span class="op">)</span></span>
<span><span class="va">lppd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_cases</span> , <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu">log_sum_exp</span><span class="op">(</span><span class="va">ll</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">n_samples</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">lppd</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] -206.5176</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb680"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now for the effective number of parameters, pWAIC. This is more straightforward, as </span></span>
<span><span class="co"># we just compute the variance across samples for each observation, then add these together:</span></span>
<span><span class="va">pWAIC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_cases</span> , <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">ll</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">pWAIC</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 3.804683</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb682"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># To compute WAIC:</span></span>
<span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">lppd</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">pWAIC</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 420.6446</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb684"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># You can compute the standard error by computing the square root of number of cases </span></span>
<span><span class="co"># multiplied by the variance over the individual observation terms in WAIC:</span></span>
<span><span class="va">waic_vec</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="op">(</span> <span class="va">lppd</span> <span class="op">-</span> <span class="va">pWAIC</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">waic_vec</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> num [1:50] 7.47 8.11 7.51 8.05 7.35 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb686"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span> <span class="va">n_cases</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">waic_vec</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 14.04329</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb688"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The variance remains much smaller than the standard error of WAIC itself. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="dic-and-waic-as-estimates-of-deviance" class="level3"><h3 class="anchored" data-anchor-id="dic-and-waic-as-estimates-of-deviance">DIC and WAIC as estimates of deviance</h3>
<p>Let’s visualize the estimates of out-of-sample deviance that DIC and WAIC provide, in the same familiar context as earlier sections.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb689"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Use akjurz's codes</span></span>
<span></span>
<span><span class="va">n_sim</span> <span class="op">&lt;-</span> <span class="fl">1e3</span></span>
<span></span>
<span><span class="va">make_sim</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">b_sigma</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">kseq</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span>;</span>
<span>    <span class="va">r</span> <span class="op">&lt;-</span> <span class="fu">mcreplicate</span><span class="op">(</span><span class="va">n_sim</span>, </span>
<span>                     <span class="fu">sim.train.test</span><span class="op">(</span>N         <span class="op">=</span> <span class="fl">20</span>,</span>
<span>                                    k         <span class="op">=</span> <span class="va">k</span>,</span>
<span>                                    b_sigma   <span class="op">=</span> <span class="va">b_sigma</span>,</span>
<span>                                    DIC       <span class="op">=</span> <span class="cn">T</span>,</span>
<span>                                    WAIC      <span class="op">=</span> <span class="cn">T</span>, </span>
<span>                                    devbar    <span class="op">=</span> <span class="cn">T</span>, </span>
<span>                                    devbarout <span class="op">=</span> <span class="cn">T</span><span class="op">)</span>,</span>
<span>                     mc.cores <span class="op">=</span> <span class="va">n_cores</span><span class="op">)</span>;</span>
<span>    </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>dev_in    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span>,</span>
<span>      dev_out   <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span>,</span>
<span>      DIC       <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">3</span>, <span class="op">]</span><span class="op">)</span>, </span>
<span>      WAIC      <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">4</span>, <span class="op">]</span><span class="op">)</span>, </span>
<span>      devbar    <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">5</span>, <span class="op">]</span><span class="op">)</span>, </span>
<span>      devbarout <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">r</span><span class="op">[</span><span class="fl">6</span>, <span class="op">]</span><span class="op">)</span><span class="op">)</span> </span>
<span>  <span class="op">}</span></span>
<span>  <span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">rownames_to_column</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>    <span class="fu">rename</span><span class="op">(</span>statistic <span class="op">=</span> <span class="va">rowname</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">s</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">tibble</span><span class="op">(</span>b_sigma <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">.5</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>sim <span class="op">=</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">b_sigma</span>, <span class="va">make_sim</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">unnest</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Wrangle and plot</span></span>
<span><span class="va">s</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span><span class="va">n_par</span>, <span class="va">value</span>, <span class="op">-</span><span class="va">b_sigma</span>, <span class="op">-</span><span class="va">statistic</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>n_par <span class="op">=</span> <span class="fu">str_remove</span><span class="op">(</span><span class="va">n_par</span>, <span class="st">"X"</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">statistic</span> <span class="op">!=</span> <span class="st">"devbar"</span> <span class="op">&amp;</span> <span class="va">statistic</span> <span class="op">!=</span> <span class="st">"devbarout"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">spread</span><span class="op">(</span>key <span class="op">=</span> <span class="va">statistic</span>, value <span class="op">=</span> <span class="va">value</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span><span class="va">ic</span>, <span class="va">value</span>, <span class="op">-</span><span class="va">b_sigma</span>, <span class="op">-</span><span class="va">n_par</span>, <span class="op">-</span><span class="va">dev_in</span>, <span class="op">-</span><span class="va">dev_out</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">gather</span><span class="op">(</span><span class="va">sample</span>, <span class="va">deviance</span>, <span class="op">-</span><span class="va">b_sigma</span>, <span class="op">-</span><span class="va">n_par</span>, <span class="op">-</span><span class="va">ic</span>, <span class="op">-</span><span class="va">value</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">sample</span> <span class="op">==</span> <span class="st">"dev_out"</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">mutate</span><span class="op">(</span>b_sigma <span class="op">=</span> <span class="va">b_sigma</span> <span class="op">%&gt;%</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  </span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">n_par</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="va">deviance</span>, color <span class="op">=</span> <span class="va">b_sigma</span><span class="op">)</span>,</span>
<span>             size <span class="op">=</span> <span class="fl">2.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y <span class="op">=</span> <span class="va">value</span>, group <span class="op">=</span> <span class="va">b_sigma</span>, color <span class="op">=</span> <span class="va">b_sigma</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_color_manual</span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">7</span><span class="op">]</span>, <span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># scale_color_manual(values = c("steelblue", "black")) +</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>subtitle <span class="op">=</span> <span class="st">"n = 20"</span>,</span>
<span>       x <span class="op">=</span> <span class="st">"number of parameters"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"deviance"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_classic</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme</span><span class="op">(</span>text             <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>family <span class="op">=</span> <span class="st">"Courier"</span><span class="op">)</span>,</span>
<span>        strip.background <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>fill <span class="op">=</span> <span class="fu">alpha</span><span class="op">(</span><span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span>,</span>
<span>        panel.background <span class="op">=</span> <span class="fu">element_rect</span><span class="op">(</span>fill <span class="op">=</span> <span class="fu">alpha</span><span class="op">(</span><span class="fu">carto_pal</span><span class="op">(</span><span class="fl">7</span>, <span class="st">"BurgYl"</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">4</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        legend.position  <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span><span class="va">ic</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co"># Out-of-sample deviance as estimated by DIC and WAIC. Points are average out-of-sample </span></span>
<span><span class="co"># deviance over 1000 simulations. The lines are average DIC (top) and WAIC (bottom) </span></span>
<span><span class="co"># computed from the same simulations. </span></span>
<span><span class="co"># The red (top) points and lines come from simulations with a nearly flat Normal(0, 100) prior. </span></span>
<span><span class="co"># The brown (bottom) points and lines used a regularizing Normal(0, 0.5) prior.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In the above figure, both DIC and WAIC are accurate on average, being within 1 point of deviance of the actual average in most cases. Both are useful estimates of the deviance, but WAIC is more accurate in this context.</p>
<p>Also notice that the regularizing prior (brown) still helps, and that DIC and WAIC do track this help. This suggests that using both regularization and information criteria will always beat using only one or the other alone. Regularization, as long as it’s not too strong, reduces overfitting for any particular model. Information criteria instead help us measure overfitting across models fit to the same data.</p>
<p><br></p>
</section></section><section id="using-information-criteria" class="level2"><h2 class="anchored" data-anchor-id="using-information-criteria">Using information criteria</h2>
<p>Once we have DIC or WAIC calculated for each plausible model, how do we use these values?</p>
<ul>
<li>
<strong><em>Model comparison</em></strong> - means using DIC/WAIC in combination with the estimates and posterior predictive checks from each model - It is just as important to understand why a model outperforms another as it is to measure the performance difference. - DIC/WAIC alone says very little about such details. But in combination with other information, DIC/WAIC is a big help.</li>
</ul>
<ul>
<li>
<strong><em>Model averaging</em></strong> - means using DIC/WAIC to construct a posterior predictive distribution that exploits what we know about relative accuracy of the models - This helps guard against overconfidence in model structure, in the same way that using the entire posterior distribution helps guard against overconfidence in parameter values. - What model averaging does not mean is averaging parameter estimates, because parameters in different models have different meanings and should not be averaged, unless you are sure you are in a special case in which it is safe to do so. - So it is better to think of model averaging as prediction averaging, because that’s what is actually being done.</li>
</ul>
<p><br></p>
<section id="model-comparison" class="level3"><h3 class="anchored" data-anchor-id="model-comparison">Model comparison</h3>
<p>As an example, we’ll repeat the analysis of predicting kilocalories per gram of milk (kcal.per.g) with the two predictor variables neocortex and the logarithm of mass. But now we’ll fit four different models, corresponding to the four simple combinations of linear models with these two predictor variables:</p>
<ol type="1">
<li><p>a model with both neocortex and log mass</p></li>
<li><p>a model with only neocortex</p></li>
<li><p>a model with only log mass</p></li>
<li><p>a model with neither predictor (just an intercept)</p></li>
</ol>
<p>Fitting the four models, using map, is straightforward. The only thing that differs among these models is the equation for <span class="math inline">\(\mu_i\)</span> (mu).</p>
<p>A way to constrain the standard deviation of the outcome, <span class="math inline">\(\sigma\)</span>, to be positive is to estimate the logarithm of <span class="math inline">\(\sigma\)</span>, which can be any real number. Then inside the likelihood function we just exponentiate it. Since <span class="math inline">\(exp(x) &gt; 0\)</span> for any real number <span class="math inline">\(x\)</span>, this effectively bounds <span class="math inline">\(\sigma\)</span> to positive reals.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb690"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the primate milk data, remove the NAs, and rescale one of the explanatory variables</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">milk</span><span class="op">[</span> <span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">milk</span><span class="op">)</span> , <span class="op">]</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">neocortex</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">neocortex.perc</span> <span class="op">/</span> <span class="fl">100</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 17  9</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb692"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># data frame now have 17 rows (cases) and 9 columns (variables)</span></span>
<span></span>
<span><span class="co">## Constrain sigma to be positive and fit the models</span></span>
<span><span class="va">a.start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">kcal.per.g</span><span class="op">)</span></span>
<span><span class="va">sigma.start</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">kcal.per.g</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The priors are all flat which is clearly not the best idea. But this will let you get </span></span>
<span><span class="co"># a sense of what the sample alone says, in the absence of regularization, and </span></span>
<span><span class="co"># how WAIC measures overfitting. </span></span>
<span></span>
<span><span class="co"># Model with neither predictor (just intercept)</span></span>
<span><span class="va">m6.11</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">a</span> , <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">log.sigma</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> , start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="va">a.start</span>,log.sigma<span class="op">=</span><span class="va">sigma.start</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Model with only neocortex</span></span>
<span><span class="va">m6.12</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">log.sigma</span><span class="op">)</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bn</span><span class="op">*</span><span class="va">neocortex</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> , start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="va">a.start</span>,bn<span class="op">=</span><span class="fl">0</span>,log.sigma<span class="op">=</span><span class="va">sigma.start</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Model with only log mass</span></span>
<span><span class="va">m6.13</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">log.sigma</span><span class="op">)</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bm</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">mass</span><span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> , start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="va">a.start</span>,bm<span class="op">=</span><span class="fl">0</span>,log.sigma<span class="op">=</span><span class="va">sigma.start</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Model with both neocortex and log mass</span></span>
<span><span class="va">m6.14</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">log.sigma</span><span class="op">)</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bn</span><span class="op">*</span><span class="va">neocortex</span> <span class="op">+</span> <span class="va">bm</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">mass</span><span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d</span> , start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="va">a.start</span>,bn<span class="op">=</span><span class="fl">0</span>,bm<span class="op">=</span><span class="fl">0</span>,log.sigma<span class="op">=</span><span class="va">sigma.start</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Fitting these four models provides answers to questions about how and how much prediction changes when we include either or both predictor variables. With the four sets of estimates, and four deviances, in hand, we’ll look quickly at both (1) comparing the models on the basis of WAIC values and (2) on the basis of parameter estimates. These are complementary approaches, aimed at understanding the best model by understanding how predictions and estimates change as predictors are added and subtracted from a model.</p>
<p><br></p>
<section id="comparing-waic-values" class="level4"><h4 class="anchored" data-anchor-id="comparing-waic-values">Comparing WAIC values</h4>
<p>To compare models using an information criterion, you first compute the criterion. Then you can rank the models from lowest (best) to highest (worst) and also calculate weights, which provide a more interpretable measure of the relative distances among the models.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb693"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/WAIC.html">WAIC</a></span><span class="op">(</span> <span class="va">m6.14</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       WAIC     lppd  penalty  std_err
1 -15.46516 12.35631 4.623733 7.602267</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb695"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Note that WAIC value is negative in this case. That’s fine. There’s nothing </span></span>
<span><span class="co"># preventing deviance from being negative. Smaller values are still better.</span></span>
<span></span>
<span><span class="co"># The third value is pWAIC. If you subtract pWAIC from lppd and then multiply that </span></span>
<span><span class="co"># difference by −2, you’ll get the WAIC value.</span></span>
<span></span>
<span><span class="co"># The standard error (std_err) provides rough guidance to the uncertainty in WAIC </span></span>
<span><span class="co"># that arises from sampling. It can be very rough guidance, when the sample size is small. </span></span>
<span><span class="co"># Still, always remember that WAIC is an estimate.</span></span>
<span></span>
<span><span class="co">## Calculate WAIC for other models</span></span>
<span><span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/WAIC.html">WAIC</a></span><span class="op">(</span> <span class="va">m6.13</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       WAIC     lppd  penalty  std_err
1 -8.586509 6.978118 2.684863 5.366012</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb697"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/WAIC.html">WAIC</a></span><span class="op">(</span> <span class="va">m6.12</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      WAIC     lppd  penalty std_err
1 -6.40718 6.045217 2.841627 4.26487</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb699"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/WAIC.html">WAIC</a></span><span class="op">(</span> <span class="va">m6.11</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       WAIC    lppd  penalty  std_err
1 -8.440587 5.93748 1.717186 4.357663</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb701"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Order the models by their WAIC values using compare()</span></span>
<span><span class="op">(</span> <span class="va">milk.models</span> <span class="op">&lt;-</span> <span class="fu">compare</span><span class="op">(</span> <span class="va">m6.11</span> , <span class="va">m6.12</span> , <span class="va">m6.13</span> , <span class="va">m6.14</span> <span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            WAIC       SE    dWAIC      dSE    pWAIC      weight
m6.14 -15.888725 7.218042 0.000000       NA 4.366503 0.952142746
m6.11  -8.627326 4.415365 7.261398 6.986071 1.652923 0.025229546
m6.13  -7.489048 5.804589 8.399677 5.177669 3.253759 0.014280236
m6.12  -6.415212 4.205845 9.473512 7.274884 2.811785 0.008347473</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb703"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The function `compare` takes fit models as input. It returns a table in which </span></span>
<span><span class="co"># models are ranked from best to worst, with six columns of information.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ol type="1">
<li><p>WAIC is obviously WAIC for each model. Smaller WAIC indicates better estimated out-of-sample deviance, so model m6.14 is ranked first.</p></li>
<li><p>pWAIC is the estimated effective number of parameters. This provides a clue as to how flexible each model is in fitting the sample.</p></li>
<li><p>dWAIC is the difference between each WAIC and the lowest WAIC. Since only relative deviance matters, this column shows the differences in relative fashion.</p></li>
<li><p>weight is the Akaike weight for each model. These values are transformed information criterion values.</p></li>
<li><p>SE is the standard error of the WAIC estimate. WAIC is an estimate, and provided the sample size N is large enough, its uncertainty will be well approximated by its standard error. So this SE value isn’t necessarily very precise, but it does provide a check against overconfidence in differences between WAIC values.</p></li>
<li><p>dSE is the standard error of the difference in WAIC between each model and the top-ranked model. So it is missing for the top model. If you want the full set of pairwise model differences, you can extract milk.models@dSE.</p></li>
</ol>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb704"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">milk.models</span><span class="op">@</span><span class="va">dSE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>         m6.11    m6.12    m6.13    m6.14
m6.11       NA 1.389250 3.308216 6.986071
m6.12 1.389250       NA 4.254929 7.274884
m6.13 3.308216 4.254929       NA 5.177669
m6.14 6.986071 7.274884 5.177669       NA</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb706"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Plot the values, to provide a possibly more-intuitive presentation</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">milk.models</span> , SE<span class="op">=</span><span class="cn">TRUE</span> , dSE<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/6.25-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb707"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Each row is a model, ordered by WAIC. </span></span>
<span></span>
<span><span class="co"># The filled points are the in-sample deviance of each model, which for WAIC is </span></span>
<span><span class="co"># calculated as −2 × lppd, which is 2pWAIC from the corresponding WAIC value. </span></span>
<span></span>
<span><span class="co"># The open points are WAIC. The standard error of each WAIC is shown by the dark line </span></span>
<span><span class="co"># segment that passes through each open point. </span></span>
<span></span>
<span><span class="co"># The standard error of the difference between each WAIC and the top-ranked WAIC is shown </span></span>
<span><span class="co"># by the gray triangles and line segments between the rows. The triangle just above each</span></span>
<span><span class="co"># WAIC point is the difference between that model and the top model. The gray line segment </span></span>
<span><span class="co"># is the standard deviation of that difference.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>Akaike weights help by rescaling. A total weight of 1 is partitioned among the considered models, making it easier to compare their relative predictive accuracy. The weight for a model <span class="math inline">\(i\)</span> in a set of <span class="math inline">\(m\)</span> models is given by:</p>
<p><span class="math display">\[ w_i = \frac{exp \left(- \frac{1}{2}dWAIC_i \right)}{\sum_{j=1}^m exp\left(- \frac{1}{2}dWAIC_j \right)}\]</span></p>
<p>The Akaike weight formula might look rather odd, but really all it is doing is putting WAIC on a probability scale, so it just undoes the multiplication by −2 and then exponentiates to reverse the log transformation. Then it standardizes by dividing by the total. So each weight will be a number from 0 to 1, and the weights together always sum to 1. <strong><em>Now larger values are better.</em></strong></p>
<p><br></p>
<p><span style="color:purple"><strong><em>Akaike’s interpretation of the Akaike weight</em></strong></span></p>
<p>A model’s weight is an estimate of the probability that the model will make the best predictions on new data, conditional on the set of models considered.</p>
<p><br></p>
<p><span style="color:purple"><strong><em>Heuristic explanation of the Akaike weight</em></strong></span></p>
<ul>
<li><p>First, regard WAIC as the expected deviance of a model on future data. That is to say that WAIC gives us an estimate of E(<span class="math inline">\(D_{test}\)</span>).</p></li>
<li><p>Akaike weights convert these deviance values, which are log-likelihoods, to plain likelihoods and then standardize them all. This is just like Bayes’ theorem uses a sum in the denominator to standardize the product of the likelihood and prior.</p></li>
<li><p>Therefore the Akaike weights are analogous to posterior probabilities of models, conditional on expected future data.</p></li>
<li><p>Remember, a probability is a standardized count of all the ways some particular thing might happen, according to our assumptions, among all the things that could happen, also according to our assumptions.</p></li>
<li><p>So you can heuristically read each weight as an estimated probability that each model will perform best on future data. In simulation at least, interpreting weights in this way turns out to be appropriate. However, given all the strong assumptions about repeat sampling that go into calculating WAIC, you can’t take this heuristic too seriously. The future is unlikely to be exactly like the past, after all.</p></li>
<li><p>In this analysis, the best model has more than 90% of the model weight. But with only 12 cases, the error on the WAIC estimates is substantial, and of course that uncertainty should propagate to the Akaike weights. If we take the standard error of the difference from the <code>compare</code> table literally, you can think of the difference as Gaussian distribution centered (for the difference between models m6.14 and m6.11) on 7.4 with a standard deviation of 7.16. If you feel hesitant that you know how to calculate from that the probability that the difference is negative, and so reversed, you can just simulate it:</p></li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb708"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">diff</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span> <span class="fl">1e5</span> , <span class="fl">7.4</span> , <span class="fl">7.16</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">diff</span><span class="op">&lt;</span><span class="fl">0</span><span class="op">)</span><span class="op">/</span><span class="fl">1e5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.15104</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb710"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># This is only of heuristic value, especially with only 12 cases. On the other hand, </span></span>
<span><span class="co"># for having only 12 cases, this is more than we might have reasonably hoped for.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Interpreting differences in information criteria</em></strong></span></p>
<p>Akaike weights are conditional upon the set of models considered. If you add another model, or take one away, all of the weights will change. How you interpret differences in information criteria always depend upon context:</p>
<ul>
<li><p>sample size</p></li>
<li><p>past research</p></li>
<li><p>nature of measurements</p></li>
</ul>
<p><br></p>
</section><section id="comparing-estimates" class="level4"><h4 class="anchored" data-anchor-id="comparing-estimates">Comparing estimates</h4>
<p>Comparing estimates helps in at least two major ways:</p>
<ul>
<li><p><em>It is useful to understand why a particular model or models have lower WAIC values.</em> Changes in posterior distributions, across models, provide useful hints.</p></li>
<li><p><em>Regardless of WAIC values, we often want to know whether some parameter’s posterior distribution is stable across models.</em> For example, to know whether a predictor remains important as other predictors are added and subtracted from the model, one typically looks for a parameter’s posterior distribution to remain stable across models, as well as for all models that contain that parameter to have lower WAIC than those models without it.</p></li>
</ul>
<p>In the primate milk example, comparing estimates confirms that the model with both predictors does much better, because each predictor masks the other. Looking at a consolidated table of the MAP estimates makes the comparison a lot easier. The <code>coeftab</code> function takes a series of fit models as input and builds such a table:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb711"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">coeftab</span><span class="op">(</span><span class="va">m6.11</span>,<span class="va">m6.12</span>,<span class="va">m6.13</span>,<span class="va">m6.14</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>          m6.11   m6.12   m6.13   m6.14  
a            0.66    0.35    0.71   -1.09
log.sigma   -1.79   -1.80   -1.85   -2.16
bn             NA    0.45      NA    2.79
bm             NA      NA   -0.03   -0.10
nobs           17      17      17      17</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb713"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The nobs at the bottom are the number of observations, just there to help you make sure </span></span>
<span><span class="co"># you fit each model to the same observations.</span></span>
<span></span>
<span><span class="co"># Estimates for both bn and bm get farther from zero when they are both present in the model.</span></span>
<span><span class="co"># But standard errors aren’t represented here, and seeing how the uncertainty changes is </span></span>
<span><span class="co"># just as important as seeing how the location changes.</span></span>
<span></span>
<span><span class="co">## Plot the estimates </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="fu">coeftab</span><span class="op">(</span><span class="va">m6.11</span>,<span class="va">m6.12</span>,<span class="va">m6.13</span>,<span class="va">m6.14</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/6.27-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb714"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Comparing the posterior densities of parameters for the four models fit to the </span></span>
<span><span class="co"># primate milk data. Each point is a MAP estimate, and each black line segment is </span></span>
<span><span class="co"># a 89% percentile interval. Estimates are grouped by parameter identity, and </span></span>
<span><span class="co"># each row in a group is a model.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="model-averaging" class="level3"><h3 class="anchored" data-anchor-id="model-averaging">Model averaging</h3>
<p>Treating model weights as heuristic plausibilities that each model will perform best in testing, it makes sense to try to preserve these relative plausibilities when generating predictions. And doing so is mechanically very similar to the procedure with a single model.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb715"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## simulate and plot counterfactual predictions for the minimum-WAIC model, m6.14</span></span>
<span><span class="co"># compute counterfactual predictions</span></span>
<span><span class="co"># neocortex from 0.5 to 0.8</span></span>
<span><span class="va">nc.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="fl">0.5</span>,to<span class="op">=</span><span class="fl">0.8</span>,length.out<span class="op">=</span><span class="fl">30</span><span class="op">)</span></span>
<span><span class="va">d.predict</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    kcal.per.g <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">30</span><span class="op">)</span>, <span class="co"># empty outcome</span></span>
<span>    neocortex <span class="op">=</span> <span class="va">nc.seq</span>,     <span class="co"># sequence of neocortex</span></span>
<span>    mass <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">4.5</span>,<span class="fl">30</span><span class="op">)</span>      <span class="co"># average mass</span></span>
<span><span class="op">)</span></span>
<span><span class="va">pred.m6.14</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m6.14</span> , data<span class="op">=</span><span class="va">d.predict</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">pred.m6.14</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">pred.m6.14</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot it all</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">kcal.per.g</span> <span class="op">~</span> <span class="va">neocortex</span> , <span class="va">d</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">nc.seq</span> , <span class="va">mu</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">nc.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">nc.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="co"># Focus on the dashed regression line and the dashed 89% percentile interval of the mean. </span></span>
<span></span>
<span><span class="co"># Now let’s compute and add model averaged posterior predictions. </span></span>
<span><span class="co"># What we’re going to compute is an ensemble of posterior predictions.</span></span>
<span><span class="va">milk.ensemble</span> <span class="op">&lt;-</span> <span class="fu">ensemble</span><span class="op">(</span> <span class="va">m6.11</span> , <span class="va">m6.12</span> , <span class="va">m6.13</span> , <span class="va">m6.14</span> , data<span class="op">=</span><span class="va">d.predict</span> <span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">milk.ensemble</span><span class="op">$</span><span class="va">link</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">milk.ensemble</span><span class="op">$</span><span class="va">link</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">nc.seq</span> , <span class="va">mu</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">nc.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/6.29-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb716"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Model averaged posterior predictive distribution for the primate milk analysis. </span></span>
<span><span class="co"># The dashed regression line and dashed 89% percentile interval correspond to the </span></span>
<span><span class="co"># minimum-WAIC model, m6.14. The solid line and shaded 89% percentile region correspond </span></span>
<span><span class="co"># to the model averaged predictions.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The conceptual procedure behind the calculation of an ensemble of posterior predictions:</p>
<ol type="1">
<li><p>Compute WAIC (or another information criterion) for each model.</p></li>
<li><p>Compute the weight for each model.</p></li>
<li><p>Compute linear model and simulated outcomes for each model.</p></li>
<li><p>Combine these values into an ensemble of predictions, using the model weights as proportions.</p></li>
</ol>
<p><br></p>
</section></section><section id="practice-4" class="level2"><h2 class="anchored" data-anchor-id="practice-4">Practice</h2>
<section id="easy-4" class="level3"><h3 class="anchored" data-anchor-id="easy-4">Easy</h3>
<blockquote class="blockquote">
<p>6E1. State the three motivating criteria that define information entropy. Try to express each in your own words.</p>
</blockquote>
<p><br></p>
</section></section></section><section id="chapter-7-interactions" class="level1"><h1>Chapter 7: Interactions</h1>
<p>To model deeper conditionality— where the importance of one predictor depends upon another predictor— we need interaction. Interaction is a kind of conditioning, a way of allowing parameters (really their posterior distributions) to be conditional on further aspects of the data.</p>
<p><br></p>
<section id="building-an-interaction" class="level2"><h2 class="anchored" data-anchor-id="building-an-interaction">Building an interaction</h2>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb717"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Terrain ruggedness aganist economic performance inside and outside of Africa</span></span>
<span><span class="co"># Load data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">rugged</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">rugged</span></span>
<span></span>
<span><span class="co"># make log version of outcome</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">log_gdp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span> <span class="va">d</span><span class="op">$</span><span class="va">rgdppc_2000</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># extract countries with GDP data</span></span>
<span><span class="va">dd</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span> <span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">rgdppc_2000</span><span class="op">)</span> , <span class="op">]</span></span>
<span></span>
<span><span class="co"># split countries into Africa and not-Africa</span></span>
<span><span class="va">d.A1</span> <span class="op">&lt;-</span> <span class="va">dd</span><span class="op">[</span> <span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span><span class="op">==</span><span class="fl">1</span> , <span class="op">]</span> <span class="co"># Africa</span></span>
<span><span class="va">d.A0</span> <span class="op">&lt;-</span> <span class="va">dd</span><span class="op">[</span> <span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span><span class="op">==</span><span class="fl">0</span> , <span class="op">]</span> <span class="co"># not Africa</span></span>
<span></span>
<span><span class="co"># Fit the regression models</span></span>
<span><span class="co"># African nations</span></span>
<span><span class="va">m7.1</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span>  <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">rugged</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">8</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d.A1</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># non-African nations</span></span>
<span><span class="va">m7.2</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">rugged</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">8</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">d.A0</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the posterior</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># African countries</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">log_gdp</span> <span class="op">~</span> <span class="va">rugged</span>, <span class="va">d.A1</span>, col <span class="op">=</span> <span class="st">"slateblue"</span>, main <span class="op">=</span> <span class="st">"Africa"</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"log(rgdppc_2000)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m7.1</span><span class="op">)</span></span>
<span><span class="va">rugged.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>, to <span class="op">=</span> <span class="fl">7</span>, length.out <span class="op">=</span> <span class="fl">40</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m7.1</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>rugged <span class="op">=</span> <span class="va">rugged.seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">rugged.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Non-african countries</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">log_gdp</span> <span class="op">~</span> <span class="va">rugged</span>, <span class="va">d.A0</span>, col <span class="op">=</span> <span class="st">"black"</span>, main <span class="op">=</span> <span class="st">"not Africa"</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"log(rgdppc_2000)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="va">m7.2</span><span class="op">)</span></span>
<span><span class="va">rugged.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="op">-</span><span class="fl">1</span>, to <span class="op">=</span> <span class="fl">6</span>, length.out <span class="op">=</span> <span class="fl">40</span><span class="op">)</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span><span class="va">m7.2</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>rugged <span class="op">=</span> <span class="va">rugged.seq</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span><span class="va">mu</span>, <span class="fl">2</span>, <span class="va">PI</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.PI</span>, <span class="va">rugged.seq</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/7.1-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb718"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Separate linear regressions inside and outside of Africa, for log-GDP against terrain ruggedness. </span></span>
<span><span class="co"># The slope is positive inside Africa, but negative outside. How can we recover this reversal of </span></span>
<span><span class="co"># the slope, using the combined data?</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>How do we discover and describe such a reversal in the context of a regression model?</em></strong></span></p>
<p>The plots above cheat, because they split the data into two data frames. But it’s not a good idea to split the data in this way. Here are four, of many, reasons.</p>
<ul>
<li><p>There are usually some parameters, such as <span class="math inline">\(\sigma\)</span>, that the model says do not depend in any way upon an African identity for each nation. By splitting the data table, you are hurting the accuracy of the estimates for these parameters, because you are essentially making two less-accurate estimates instead of pooling all of the evidence into one estimate. In effect, you have accidentally assumed that variance differs between African and non-African nations. Now, there’s nothing wrong with that sort of assumption. But you want to avoid accidental assumptions.</p></li>
<li><p>In order to acquire probability statements about the variable you used to split the data, <code>cont_africa</code> in this case, you need to include it in the model. Otherwise, you have only the weakest sort of statistical argument. Isn’t there uncertainty about the predictive value of distinguishing between African and non-African nations? Of course there is. Unless you analyze all of the data in a single model, you can’t easily quantify that uncertainty. If you just let the posterior distribution do the work for you, you’ll have a useful measure of that uncertainty.</p></li>
<li><p>We may want to use information criteria or another method to compare models. In order to compare a model that treats all continents the same way to a model that allows different slopes in different continents, we need models that use all of the same data. This means we can’t split the data, but have to make the model split the data.</p></li>
<li><p>There are advantages to borrowing information across categories like “Africa” and “not Africa.” This is especially true when sample sizes vary across categories, such that overfitting risk is higher within some categories. In other words, what we learn about ruggedness outside of Africa should have some effect on our estimate within Africa, and visa versa.</p></li>
</ul>
<p><br></p>
<section id="adding-a-dummy-variable-doesnt-work" class="level3"><h3 class="anchored" data-anchor-id="adding-a-dummy-variable-doesnt-work">Adding a dummy variable doesn’t work</h3>
<p>The first thing to realize is that just including the categorical variable (dummy variable) <code>cont_africa</code> won’t reveal the reversed slope. The question is to what extent singling out African nations changes predictions.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb719"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># First model: simple linear regression of log-GDP on ruggedness for entire data set</span></span>
<span><span class="va">m7.3</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">rugged</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">8</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">dd</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Second model: the model that includes a dummy variable for African nations</span></span>
<span><span class="va">m7.4</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">rugged</span> <span class="op">+</span> <span class="va">bA</span><span class="op">*</span><span class="va">cont_africa</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">8</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">dd</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare the two models using WAIC</span></span>
<span><span class="fu">compare</span><span class="op">(</span> <span class="va">m7.3</span> , <span class="va">m7.4</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>         WAIC       SE    dWAIC     dSE    pWAIC       weight
m7.4 476.1611 15.23279  0.00000      NA 4.247216 1.000000e+00
m7.3 539.5781 13.24052 63.41701 14.9871 2.714210 1.695009e-14</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb721"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># While the standard error of the difference in WAIC is 15, the difference itself is 63, </span></span>
<span><span class="co"># implying a 95% interval of 63 ± 30. So the continent predictor variable seems to be picking </span></span>
<span><span class="co"># up something important to the sample, even accounting for expected overfitting.</span></span>
<span></span>
<span><span class="co">## Now let’s plot the posterior predictions for m7.4, so you can see how, despite it’s plausible </span></span>
<span><span class="co">## superiority to m7.3, it still doesn’t manage different slopes inside and outside of Africa.</span></span>
<span><span class="co"># To sample from the posterior and compute the predicted means and intervals for </span></span>
<span><span class="co"># both African and non-African nations</span></span>
<span><span class="va">rugged.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="op">-</span><span class="fl">1</span>,to<span class="op">=</span><span class="fl">8</span>,by<span class="op">=</span><span class="fl">0.25</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute mu over samples, fixing cont_africa=0</span></span>
<span><span class="va">mu.NotAfrica</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.4</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>cont_africa<span class="op">=</span><span class="fl">0</span>,rugged<span class="op">=</span><span class="va">rugged.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># compute mu over samples, fixing cont_africa=1</span></span>
<span><span class="va">mu.Africa</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.4</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>cont_africa<span class="op">=</span><span class="fl">1</span>,rugged<span class="op">=</span><span class="va">rugged.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># summarize to means and intervals</span></span>
<span><span class="va">mu.NotAfrica.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.NotAfrica</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.NotAfrica.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.NotAfrica</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span><span class="va">mu.Africa.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.Africa</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.Africa.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.Africa</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the posterior</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mu.Africa.mean</span> <span class="op">~</span> <span class="va">rugged.seq</span>, type <span class="op">=</span> <span class="st">"l"</span>, col <span class="op">=</span> <span class="st">"#446CCF"</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6</span>, <span class="fl">11</span><span class="op">)</span>, </span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">6</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="st">"Terrain Ruggedness Index"</span>, ylab <span class="op">=</span> <span class="st">"log GDP year 2000"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span><span class="va">mu.NotAfrica.mean</span> <span class="op">~</span> <span class="va">rugged.seq</span>, type <span class="op">=</span> <span class="st">"l"</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.Africa.PI</span>, <span class="va">rugged.seq</span>, col <span class="op">=</span> <span class="fu">col.alpha</span><span class="op">(</span><span class="st">"#446CCF"</span>, <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span><span class="va">mu.NotAfrica.PI</span>, <span class="va">rugged.seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add data points for log_gdp ~ rugged</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">rugged</span><span class="op">[</span><span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span>, <span class="va">dd</span><span class="op">$</span><span class="va">log_gdp</span><span class="op">[</span><span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"#446CCF"</span>, pch <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">rugged</span><span class="op">[</span><span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span>, <span class="va">dd</span><span class="op">$</span><span class="va">log_gdp</span><span class="op">[</span><span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span>, col <span class="op">=</span> <span class="st">"black"</span>, pch <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add text</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">6.5</span>, <span class="st">"Africa"</span>, col <span class="op">=</span> <span class="st">"#446CCF"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">9.4</span>, <span class="st">"not Africa"</span>, col <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/7.3-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb722"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Including a dummy variable for African nations has no effect on the slope. African nations </span></span>
<span><span class="co"># are shown in blue. Non-African nations are shown in gray. Regression means for each subset </span></span>
<span><span class="co"># of nations are shown in corresponding colors, along with 97% intervals shown by shading.</span></span>
<span><span class="co">## The fact that WAIC tells you that the model with the dummy variable is hugely better only</span></span>
<span><span class="co">## indicates that African nations on average do have lower GDP.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="adding-a-linear-interaction-does-work" class="level3"><h3 class="anchored" data-anchor-id="adding-a-linear-interaction-does-work">Adding a linear interaction does work</h3>
<p>A proper interaction effect is needed to recover the change in slope you saw at the start of this section. The likelihood for the model you just plotted, in math form, is:</p>
<p>$$ <span class="math display">\[\begin{align*}
\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_R R_i + \beta_A A_i
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>Y   = log(rgdppc_2000)

A   = cont_africa

R   = rugged
</code></pre>
<p><br></p>
<p>Now you want to allow the relationship between Y and R to vary as a function of A. Within the model, this relationship is measured by the slope <span class="math inline">\(\beta_R\)</span>. Following the same strategy of replacing parameters with linear models, the most straightforward way to make <span class="math inline">\(\beta_R\)</span> depend upon <span class="math inline">\(A\)</span> is just to define the slope <span class="math inline">\(\beta_R\)</span> as a linear model itself, one that includes <span class="math inline">\(A\)</span>.</p>
<p><br></p>
<p>$$ <span class="math display">\[\begin{align*}
\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{[likelihood]}\\
\mu_i &amp;= \alpha + \gamma_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{[linear model of}~\mu]\\
\gamma_i &amp;= \beta_R + \beta_{AR} A_i &amp;&amp;&amp;    \text{[linear model of slope]}
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>By defining the relationship between GDP and ruggedness in this way, you are explicitly modeling the hypothesis that the slope between GDP and ruggedness depends— is <em>conditional</em>— upon whether or not a nation is in Africa. The parameter <span class="math inline">\(\beta_{AR}\)</span> defines the strength of this dependency. If you set <span class="math inline">\(\beta_{AR}\)</span> = 0, then you get the previous model back. If instead <span class="math inline">\(\beta_{AR}\)</span> &gt; 0, then African nations have a more positive slope between GDP and ruggedness. If <span class="math inline">\(\beta_{AR}\)</span> &lt; 0, African nations have a more negative slope. For any nation not in Africa, <span class="math inline">\(A_i\)</span> = 0 and so the interaction parameter <span class="math inline">\(\beta_{AR}\)</span> has no effect on prediction for that nation.</p>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb724"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the model that includes an interaction between ruggedness and being in Africa</span></span>
<span><span class="va">m7.5</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">gamma</span><span class="op">*</span><span class="va">rugged</span> <span class="op">+</span> <span class="va">bA</span><span class="op">*</span><span class="va">cont_africa</span> ,</span>
<span>        <span class="va">gamma</span> <span class="op">&lt;-</span> <span class="va">bR</span> <span class="op">+</span> <span class="va">bAR</span><span class="op">*</span><span class="va">cont_africa</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">8</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bAR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">dd</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m7.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%       94.5%
a      9.1837197 0.13641212  8.9657068  9.40173267
bA    -1.8462574 0.21847502 -2.1954226 -1.49709209
bR    -0.1844038 0.07568555 -0.3053639 -0.06344368
bAR    0.3483651 0.12749618  0.1446016  0.55212867
sigma  0.9332274 0.05066755  0.8522508  1.01420390</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb726"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare the new model to the previous two using WAIC</span></span>
<span><span class="fu">compare</span><span class="op">(</span><span class="va">m7.3</span>, <span class="va">m7.4</span>, <span class="va">m7.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>         WAIC       SE     dWAIC       dSE    pWAIC       weight
m7.5 469.6027 15.15680  0.000000        NA 5.277048 9.672387e-01
m7.4 476.3731 15.35690  6.770393  6.154507 4.411896 3.276133e-02
m7.3 539.6247 13.28416 70.021933 15.197414 2.721043 6.032038e-16</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb728"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The modicum of weight given to m7.4 suggests that the posterior means for the slopes in m7.5 </span></span>
<span><span class="co"># are a little overfit. And the standard error of the difference in WAIC between the top two </span></span>
<span><span class="co"># models is almost the same as the difference itself. </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:purple"><strong><em>Conventional form of interaction</em></strong></span></p>
<p>Instead of a model definition with more than one linear model, as you saw above, it’s conventional to multiply out any interaction effects, so that there is only one linear model. The equation for <span class="math inline">\(\gamma\)</span> can be substituted into the second line and expanded.</p>
<p>$$ <span class="math display">\[\begin{align*}
\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{[likelihood]}\\
\mu_i &amp;= \alpha + \beta_R R_i + \beta_{AR} A_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{[linear model of}~\mu]
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb729"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m7.5b</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">rugged</span> <span class="op">+</span> <span class="va">bAR</span><span class="op">*</span><span class="va">rugged</span><span class="op">*</span><span class="va">cont_africa</span> <span class="op">+</span> <span class="va">bA</span><span class="op">*</span><span class="va">cont_africa</span>,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">8</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bAR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">1</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">10</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">dd</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m7.5b</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%       94.5%
a      9.1835676 0.13641586  8.9655488  9.40158655
bA    -1.8460959 0.21848086 -2.1952705 -1.49692126
bR    -0.1843470 0.07568751 -0.3053103 -0.06338378
bAR    0.3483085 0.12749938  0.1445398  0.55207712
sigma  0.9332502 0.05067070  0.8522687  1.01423178</code></pre>
</div>
</div>
<p><br></p>
</section><section id="plotting-the-interaction" class="level3"><h3 class="anchored" data-anchor-id="plotting-the-interaction">Plotting the interaction</h3>
<p>The goal is to make two plots. In the first, we’ll display nations in Africa and overlay the posterior mean (MAP) regression line and the 97% interval of that line. In the second, we’ll display nations outside of Africa instead.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb731"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate the necessary posterior mean line and interval, for both plots</span></span>
<span><span class="va">rugged.seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from<span class="op">=</span><span class="op">-</span><span class="fl">1</span>,to<span class="op">=</span><span class="fl">8</span>,by<span class="op">=</span><span class="fl">0.25</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu.Africa</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.5b</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>cont_africa<span class="op">=</span><span class="fl">1</span>,rugged<span class="op">=</span><span class="va">rugged.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.Africa.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.Africa</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.Africa.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.Africa</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">mu.NotAfrica</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.5b</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>cont_africa<span class="op">=</span><span class="fl">0</span>,rugged<span class="op">=</span><span class="va">rugged.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.NotAfrica.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.NotAfrica</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.NotAfrica.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.NotAfrica</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># plot African nations with regression</span></span>
<span><span class="va">d.A1</span> <span class="op">&lt;-</span> <span class="va">dd</span><span class="op">[</span><span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span><span class="op">==</span><span class="fl">1</span>,<span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">rgdppc_2000</span><span class="op">)</span> <span class="op">~</span> <span class="va">rugged</span> , data<span class="op">=</span><span class="va">d.A1</span> ,</span>
<span>    col<span class="op">=</span><span class="va">rangi2</span> , ylab<span class="op">=</span><span class="st">"log GDP year 2000"</span> ,</span>
<span>    xlab<span class="op">=</span><span class="st">"Terrain Ruggedness Index"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span> <span class="st">"African nations"</span> , <span class="fl">3</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">rugged.seq</span> , <span class="va">mu.Africa.mean</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.Africa.PI</span> , <span class="va">rugged.seq</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.3</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot non-African nations with regression</span></span>
<span><span class="va">d.A0</span> <span class="op">&lt;-</span> <span class="va">dd</span><span class="op">[</span><span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span><span class="op">==</span><span class="fl">0</span>,<span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">rgdppc_2000</span><span class="op">)</span> <span class="op">~</span> <span class="va">rugged</span> , data<span class="op">=</span><span class="va">d.A0</span> ,</span>
<span>    col<span class="op">=</span><span class="st">"black"</span> , ylab<span class="op">=</span><span class="st">"log GDP year 2000"</span> ,</span>
<span>    xlab<span class="op">=</span><span class="st">"Terrain Ruggedness Index"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span> <span class="st">"Non-African nations"</span> , <span class="fl">3</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">rugged.seq</span> , <span class="va">mu.NotAfrica.mean</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.NotAfrica.PI</span> , <span class="va">rugged.seq</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/7.10-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb732"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Posterior predictions for the terrain ruggedness model,including the interaction between </span></span>
<span><span class="co"># Africa and ruggedness. Shaded regions are 97% posterior intervals of the mean.</span></span>
<span><span class="co">## Finally, the slope reverses direction inside and outside of Africa.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="interpreting-an-interaction-estimate" class="level3"><h3 class="anchored" data-anchor-id="interpreting-an-interaction-estimate">Interpreting an interaction estimate</h3>
<p>There are two basic reasons to be wary of interpreting tables of posterior means and standard deviations as a way to understanding interactions.</p>
<ol type="1">
<li><p>When you add an interaction to a model, this changes the meanings of the parameters. A “main effect” coefficient in an interaction model does not mean the same thing as a coefficient of the same name in a model without an interaction. Their distributions cannot usually be directly compared.</p></li>
<li><p>Tables of numbers don’t make it easy to fully incorporate uncertainty in our thinking, since covariance among parameters isn’t usually shown. And this gets much harder once the influence of a predictor depends upon multiple parameters.</p></li>
</ol>
<p><br></p>
<section id="parameters-change-meaning" class="level4"><h4 class="anchored" data-anchor-id="parameters-change-meaning">Parameters change meaning</h4>
<p>Unlike in the simple linear regression models, you can no longer read the influence of either predictor from the table of estimates in interaction models:</p>
<p>$$ <span class="math display">\[\begin{align*}
\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{[likelihood]}\\
\mu_i &amp;= \alpha + \gamma_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{[linear model of}~\mu]\\
\gamma_i &amp;= \beta_R + \beta_{AR} A_i &amp;&amp;&amp;    \text{[linear model of slope]}
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>Now the change in <span class="math inline">\(\mu_i\)</span> that results from a unit change in <span class="math inline">\(R_i\)</span> is given by <span class="math inline">\(\gamma_i\)</span>. And since <span class="math inline">\(\gamma_i\)</span> is a function of three things— <span class="math inline">\(\beta_R\)</span>, <span class="math inline">\(\beta_{AR}\)</span>, and <span class="math inline">\(A_i\)</span>— we have to know all three in order to know the influence of <span class="math inline">\(R_i\)</span> on the outcome. The only time the slope <span class="math inline">\(\beta_R\)</span> has its old meaning is when <span class="math inline">\(A_i = 0\)</span>, which makes <span class="math inline">\(\gamma_i = \beta_R\)</span>. Otherwise, to compute the influence of <span class="math inline">\(R_i\)</span> on the outcome, we have to simultaneously consider two parameters and another predictor variable.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb733"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">precis</span><span class="op">(</span><span class="va">m7.5</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%       94.5%
a      9.1837197 0.13641212  8.9657068  9.40173267
bA    -1.8462574 0.21847502 -2.1954226 -1.49709209
bR    -0.1844038 0.07568555 -0.3053639 -0.06344368
bAR    0.3483651 0.12749618  0.1446016  0.55212867
sigma  0.9332274 0.05066755  0.8522508  1.01420390</code></pre>
</div>
</div>
<p>Since <span class="math inline">\(\gamma\)</span> (gamma) doesn’t appear in this table— it wasn’t estimated— we have to compute it ourselves.</p>
<p>For example, the <strong><em>MAP</em></strong> slope relating ruggedness to log-GDP within Africa is:</p>
<p><span class="math display">\[\gamma = \beta_R + \beta_{AR}(1) = −0.18 + 0.35 = 0.17\]</span> <br></p>
<p>And outside of Africa:</p>
<p><span class="math display">\[\gamma = \beta_R + \beta_{AR}(0) = -0.18\]</span></p>
<p>So the relationship between ruggedness and log-GDP is essentially reversed inside and out-side of Africa.</p>
<p><br></p>
</section><section id="incorporating-uncertainty" class="level4"><h4 class="anchored" data-anchor-id="incorporating-uncertainty">Incorporating uncertainty</h4>
<p>Anything calculated using parameters has a distribution. Since <span class="math inline">\(\gamma\)</span> depends upon parameters, and those parameters have a posterior distribution, <span class="math inline">\(\gamma\)</span> must also have a posterior distribution.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb735"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compute the posterior distribution of γ using samples from posterior</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">m7.5</span> <span class="op">)</span></span>
<span><span class="va">gamma.Africa</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">bR</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">bAR</span><span class="op">*</span><span class="fl">1</span></span>
<span><span class="va">gamma.notAfrica</span> <span class="op">&lt;-</span> <span class="va">post</span><span class="op">$</span><span class="va">bR</span> <span class="op">+</span> <span class="va">post</span><span class="op">$</span><span class="va">bAR</span><span class="op">*</span><span class="fl">0</span></span>
<span></span>
<span><span class="co"># Calculate means of the distributions</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">gamma.Africa</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.1638082</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb737"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">gamma.notAfrica</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] -0.1839249</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb739"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Nearly identical to the MAP values, of course.</span></span>
<span><span class="co"># Now we have full distributions of the slopes within and outside of Africa. </span></span>
<span></span>
<span><span class="co"># Plot the distributions on the same axis</span></span>
<span><span class="fu">dens</span><span class="op">(</span> <span class="va">gamma.Africa</span> , xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>,<span class="fl">0.6</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">5.5</span><span class="op">)</span> ,</span>
<span>    xlab<span class="op">=</span><span class="st">"gamma"</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu">dens</span><span class="op">(</span> <span class="va">gamma.notAfrica</span> , add<span class="op">=</span><span class="cn">TRUE</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"topright"</span>, legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Africa"</span>, <span class="st">"Not Africa"</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"blue"</span>, <span class="st">"black"</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/7.13-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb740"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Posterior distributions of the slope relating terrain ruggedness to log-GDP. </span></span>
<span><span class="co"># Blue: African nations. Black: non-African nations.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>From here, you could use the samples to ask a bunch of questions, depending upon your interest. For example, what’s the probability (according to this model and these data) that the slope within Africa is less than the slope outside of Africa? All we need to do is compute the difference between the slopes, for each sample from the posterior, and then ask what proportion of these differences is below zero.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb741"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">diff</span> <span class="op">&lt;-</span> <span class="va">gamma.Africa</span> <span class="op">-</span> <span class="va">gamma.notAfrica</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">diff</span> <span class="op">&lt;</span> <span class="fl">0</span> <span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span> <span class="va">diff</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0033</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb743"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># So conditional on this model and these data, it’s highly implausible that the slope </span></span>
<span><span class="co"># association ruggedness with log-GDP is lower inside Africa than outside it.</span></span>
<span></span>
<span><span class="co"># Let's try the reverse</span></span>
<span><span class="va">diff</span> <span class="op">&lt;-</span> <span class="va">gamma.notAfrica</span> <span class="op">-</span> <span class="va">gamma.Africa</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">diff</span> <span class="op">&lt;</span> <span class="fl">0</span> <span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span> <span class="va">diff</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9967</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb745"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># So, it's highly plausible that the slope association ruggedness with log-GDP is </span></span>
<span><span class="co"># lower outside Africa than inside it.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Also note that this probability, 0.004, is very tiny compared to the visual overlap of the two distributions in the figure. The distributions in the figure are marginal, like silhouettes of each distribution, ignoring all of the other dimensions in the posterior. The calculation above is the distribution of the difference between the two. The distribution of their difference is not the same as the visual overlap of their marginal distributions. This is also the reason we can’t use overlap in confidence intervals of different parameters as an informal test of “significance” of the difference. If you care about the difference, you must compute the distribution of the difference directly.</p>
<p><br></p>
</section></section></section><section id="symmetry-of-the-linear-interaction" class="level2"><h2 class="anchored" data-anchor-id="symmetry-of-the-linear-interaction">Symmetry of the linear interaction</h2>
<p>The linear interaction contains two symmetrical interpretations. Absent some other information, outside the model, there’s no logical basis for preferring one over the other.</p>
<p><br></p>
<section id="buridans-interaction" class="level3"><h3 class="anchored" data-anchor-id="buridans-interaction">Buridan’s interaction</h3>
<p>We’ll plot the ruggedness and GDP example again, but with the reverse phrasing— the influence of Africa depends upon ruggedness.</p>
<p>Consider yet again the mathematical form of the likelihood:</p>
<p>$$ <span class="math display">\[\begin{align*}
\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{[likelihood]}\\
\mu_i &amp;= \alpha + \gamma_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{[linear model of}~\mu]\\
\gamma_i &amp;\sim \beta_R + \beta_{AR} A_i &amp;&amp;&amp;   \text{[linear model of slope]}
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>Let’s expand <span class="math inline">\(\gamma_i\)</span> into the expression for <span class="math inline">\(\mu_i\)</span>:</p>
<p>$$ <span class="math display">\[\begin{align*}
\mu_i &amp;= \alpha + (\beta_R + \beta_{AR} A_i) R_i + \beta_A A_i\\
&amp;= \alpha + \beta_R R_i + \beta_{AR} A_i R_i + \beta_A A_i
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>Now factor together the terms with <span class="math inline">\(A_i\)</span> in them:</p>
<p>$$ <span class="math display">\[\begin{align*}
\mu_i &amp;= \alpha + \beta_R R_i + \underbrace{(\beta_A + \beta_{AR}R_i)}_G A_i
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>The term labeled <span class="math inline">\(G\)</span> looks a lot like <span class="math inline">\(\gamma_i\)</span> in the original form. This is the same model of <span class="math inline">\(\mu_i\)</span>, but re-expressed so that the linear interaction applies to <span class="math inline">\(A_i\)</span>— prove that linear interactions are symmetric. Within the model, there’s no basis to prefer one interpretation over the other, because in fact they are the same interpretation. But when we reason causally about models, our minds tend to prefer one interpretation over the other, because it’s usually easier to imagine manipulating one of the predictor variables instead of the other— hard to imagine manipulating which continent a nation is on, but it’s easy to imagine manipulating terrain ruggedness.</p>
<p><br></p>
</section><section id="africa-depends-upon-ruggedness" class="level3"><h3 class="anchored" data-anchor-id="africa-depends-upon-ruggedness">Africa depends upon ruggedness</h3>
<p>It’ll be helpful to plot the reverse interpretation: <em>The influence of being in Africa depends upon terrain ruggedness</em>.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb746"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># get minimum and maximum rugged values</span></span>
<span><span class="va">q.rugged</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">rugged</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute lines and confidence intervals</span></span>
<span><span class="va">mu.ruggedlo</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.5b</span> ,</span>
<span>    data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>rugged<span class="op">=</span><span class="va">q.rugged</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,cont_africa<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.ruggedlo.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.ruggedlo</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.ruggedlo.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.ruggedlo</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">mu.ruggedhi</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.5b</span> ,</span>
<span>    data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>rugged<span class="op">=</span><span class="va">q.rugged</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,cont_africa<span class="op">=</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="va">mu.ruggedhi.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.ruggedhi</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span><span class="va">mu.ruggedhi.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu.ruggedhi</span> , <span class="fl">2</span> , <span class="va">PI</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># plot it all, splitting points at median</span></span>
<span><span class="va">med.r</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">rugged</span><span class="op">)</span></span>
<span><span class="va">ox</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span> <span class="va">dd</span><span class="op">$</span><span class="va">rugged</span> <span class="op">&gt;</span> <span class="va">med.r</span> , <span class="fl">0.05</span> , <span class="op">-</span><span class="fl">0.05</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">dd</span><span class="op">$</span><span class="va">cont_africa</span> <span class="op">+</span> <span class="va">ox</span> , <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">rgdppc_2000</span><span class="op">)</span> ,</span>
<span>    col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">dd</span><span class="op">$</span><span class="va">rugged</span><span class="op">&gt;</span><span class="va">med.r</span>,<span class="va">rangi2</span>,<span class="st">"black"</span><span class="op">)</span> ,</span>
<span>    xlim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.25</span>,<span class="fl">1.25</span><span class="op">)</span> , xaxt<span class="op">=</span><span class="st">"n"</span> , ylab<span class="op">=</span><span class="st">"log GDP year 2000"</span> ,</span>
<span>    xlab<span class="op">=</span><span class="st">"Continent"</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span> <span class="fl">1</span> , at<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span> , labels<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"other"</span>,<span class="st">"Africa"</span><span class="op">)</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span> , <span class="va">mu.ruggedlo.mean</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.ruggedlo.PI</span> , <span class="fl">0</span><span class="op">:</span><span class="fl">1</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span> , <span class="va">mu.ruggedhi.mean</span> , col<span class="op">=</span><span class="va">rangi2</span> <span class="op">)</span></span>
<span><span class="fu">shade</span><span class="op">(</span> <span class="va">mu.ruggedhi.PI</span> , <span class="fl">0</span><span class="op">:</span><span class="fl">1</span> , col<span class="op">=</span><span class="fu">col.alpha</span><span class="op">(</span><span class="va">rangi2</span>,<span class="fl">0.25</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/7.17-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb747"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The other side of the interaction between ruggedness and continent. </span></span>
<span><span class="co"># Blue points are nations with above-median ruggedness. </span></span>
<span><span class="co"># Black points are below the median. </span></span>
<span><span class="co"># Dashed black line: relationship between continent and log-GDP, for an </span></span>
<span><span class="co"># imaginary nation with minimum observed ruggedness (0.003). </span></span>
<span><span class="co"># Blue line: an imaginary nation with maximum observed ruggedness (6.2).</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="continuous-interactions" class="level2"><h2 class="anchored" data-anchor-id="continuous-interactions">Continuous interactions</h2>
<p>A third reason to be wary of using only tables of numbers to interpret interactions is that interactions among continuous variables are especially opaque. It’s one thing to make a slope conditional upon a <em>category</em>, as in the previous example of ruggedness and being in Africa. In such a context, the model reduces to estimating a different slope for each category. But, it’s quite a lot harder to understand that a slope varies in a continuous fashion with a continuous variable.</p>
<p><span style="color:brown"><span style="text-decoration:underline"><strong>Two common benefits of centering prediction variables</strong></span></span></p>
<ul>
<li><p>Centering the prediction variables can make it much easier to lean on the coefficients alone in understanding the model, especially when you want to compare the estimates from models with and without an interaction.</p></li>
<li><p>Sometimes model fitting has a hard time with uncentered variables. Centering (and possibly also standardizing) the data before fitting the model can help you achieve a faster and more reliable set of estimates.</p></li>
</ul>
<p><br></p>
<section id="the-data-1" class="level3"><h3 class="anchored" data-anchor-id="the-data-1">The data</h3>
<p>The data in this example are sizes of blooms from beds of tulips grown in greenhouses, under different soil and light conditions.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb748"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">tulips</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">tulips</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   27 obs. of  4 variables:
 $ bed   : Factor w/ 3 levels "a","b","c": 1 1 1 1 1 1 1 1 1 2 ...
 $ water : int  1 1 1 2 2 2 3 3 3 1 ...
 $ shade : int  1 2 3 1 2 3 1 2 3 1 ...
 $ blooms: num  0 0 111 183.5 59.2 ...</code></pre>
</div>
</div>
<p>The <code>blooms</code> column will be our outcome. The <code>water</code> and <code>shade</code> columns will be our predictor variables. Independent effects of sunlight (<code>shade</code>) and <code>water</code> will produce bigger blooms. We are also interested in the interaction between these two variables. How will the <code>water</code> help in the absence of light, or will sunlight helps the blooms in the absence of water? One way to model such an interdependency is to use an interaction effect.</p>
<p><br></p>
</section><section id="the-un-centered-models" class="level3"><h3 class="anchored" data-anchor-id="the-un-centered-models">The un-centered models</h3>
<p>Example focusing on just two models:</p>
<ol type="1">
<li><p>the model with both <code>water</code> and <code>shade</code> but no interaction</p></li>
<li><p>the model with both main effects and the interaction of <code>water</code> with <code>shade</code></p></li>
</ol>
<p><br></p>
<p>The main effect likelihood is:</p>
<p>$$ <span class="math display">\[\begin{align*}
\ B_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_W W_i + \beta_S S_i
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<p>And the full interaction likelihood is:</p>
<p>$$ <span class="math display">\[\begin{align*}
\ B_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_W W_i + \beta_S S_i + \beta_{WS} W_i S_i
\end{align*}\]</span></p>
<p>$$</p>
<pre><code>B_i    = the value of bloom on row i 

W_i    = the value of water

S_i    = the value of shade.
</code></pre>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb751"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">717</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m7.6</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">blooms</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bW</span><span class="op">*</span><span class="va">water</span> <span class="op">+</span> <span class="va">bS</span><span class="op">*</span><span class="va">shade</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bW</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">m7.7</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">blooms</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bW</span><span class="op">*</span><span class="va">water</span> <span class="op">+</span> <span class="va">bS</span><span class="op">*</span><span class="va">shade</span> <span class="op">+</span> <span class="va">bWS</span><span class="op">*</span><span class="va">water</span><span class="op">*</span><span class="va">shade</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bW</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bWS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="co"># The model fitting engine, R’s optim, searched for a very long time. It searched so long </span></span>
<span><span class="co"># that it reached the time limit, the “maximum iterations.” As a result, the estimates are </span></span>
<span><span class="co"># unreliable and should not be used, unless you are sure they are okay.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p><span style="color:gray"><strong><em>Fix the maximum iterations problem.</em></strong></span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb752"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">719</span><span class="op">)</span></span>
<span><span class="co"># Use  Nelder-Mead method of optimization</span></span>
<span><span class="va">m7.6</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">blooms</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bW</span><span class="op">*</span><span class="va">water</span> <span class="op">+</span> <span class="va">bS</span><span class="op">*</span><span class="va">shade</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bW</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span><span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> <span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">d</span> ,</span>
<span>    method<span class="op">=</span><span class="st">"Nelder-Mead"</span> ,</span>
<span>    control<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>maxit<span class="op">=</span><span class="fl">1e4</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">m7.7</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">blooms</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bW</span><span class="op">*</span><span class="va">water</span> <span class="op">+</span> <span class="va">bS</span><span class="op">*</span><span class="va">shade</span> <span class="op">+</span> <span class="va">bWS</span><span class="op">*</span><span class="va">water</span><span class="op">*</span><span class="va">shade</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bW</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bWS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d</span> , method<span class="op">=</span><span class="st">"Nelder-Mead"</span> , control<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>maxit<span class="op">=</span><span class="fl">1e4</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># Use coeftab function to check the estimates</span></span>
<span><span class="fu">coeftab</span><span class="op">(</span><span class="va">m7.6</span>,<span class="va">m7.7</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      m7.6    m7.7   
a       52.25 -102.09
bW      76.83  158.51
bS     -38.69   42.61
sigma   57.54   45.69
bWS        NA  -42.73
nobs       27      27</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb754"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># In main-effects-only model (m7.6), for every additional level of soil moisture, </span></span>
<span><span class="co"># blooms increase by 76, on average. For every addition unit of shade, </span></span>
<span><span class="co"># blooms decrease by 42, on average. </span></span>
<span></span>
<span><span class="co"># In interaction model (m7.7), both main effects are positive, but the new interaction</span></span>
<span><span class="co"># posterior mean is negative.</span></span>
<span></span>
<span><span class="co"># WAIC values assure that the interaction model is indeed a much better model</span></span>
<span><span class="fu">compare</span><span class="op">(</span> <span class="va">m7.6</span> , <span class="va">m7.7</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>         WAIC        SE    dWAIC      dSE    pWAIC      weight
m7.7 295.7057 10.205077 0.000000       NA 6.111885 0.992893528
m7.6 305.5850  8.842373 9.879235 6.731572 5.126106 0.007106472</code></pre>
</div>
</div>
<p><br></p>
</section><section id="center-and-re-estimate" class="level3"><h3 class="anchored" data-anchor-id="center-and-re-estimate">Center and re-estimate</h3>
<p>To <em>center</em> a variable means to create a new variable that contains the same information as the original, but has a new mean of zero. Centering can help with two things in this analysis:</p>
<ul>
<li><p>fix our previous problem with maximum iterations</p></li>
<li><p>make the estimates easier to interpret</p></li>
</ul>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb756"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Make centered versions of shade and water by subtracting the mean of the original from each value</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">shade.c</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">shade</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">shade</span><span class="op">)</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">water.c</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">water</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">water</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Re-estimate m7.6 and m7.7 using centered variables</span></span>
<span><span class="va">m7.8</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">blooms</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bW</span><span class="op">*</span><span class="va">water.c</span> <span class="op">+</span> <span class="va">bS</span><span class="op">*</span><span class="va">shade.c</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">130</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bW</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d</span> , start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">blooms</span><span class="op">)</span>,bW<span class="op">=</span><span class="fl">0</span>,bS<span class="op">=</span><span class="fl">0</span>,sigma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">blooms</span><span class="op">)</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="va">m7.9</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">blooms</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bW</span><span class="op">*</span><span class="va">water.c</span> <span class="op">+</span> <span class="va">bS</span><span class="op">*</span><span class="va">shade.c</span> <span class="op">+</span> <span class="va">bWS</span><span class="op">*</span><span class="va">water.c</span><span class="op">*</span><span class="va">shade.c</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">130</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bW</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">bWS</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span> ,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span> <span class="fl">0</span> , <span class="fl">100</span> <span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>data<span class="op">=</span><span class="va">d</span> , start<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">blooms</span><span class="op">)</span>,bW<span class="op">=</span><span class="fl">0</span>,bS<span class="op">=</span><span class="fl">0</span>,bWS<span class="op">=</span><span class="fl">0</span>,sigma<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">blooms</span><span class="op">)</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="co"># Check estimates</span></span>
<span><span class="fu">coeftab</span><span class="op">(</span><span class="va">m7.8</span>,<span class="va">m7.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      m7.8    m7.9   
a      129.00  129.01
bW      74.22   74.96
bS     -40.74  -41.14
sigma   57.35   45.22
bWS        NA  -51.87
nobs       27      27</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb758"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Now when we compare the posterior means across the two models, the main effects are the same. </span></span>
<span><span class="co"># Unlike before, the direction of the association for shade has not changed. More water appears </span></span>
<span><span class="co"># to directly increase blooms, while more shade directly decreases them. Meanwhile, the </span></span>
<span><span class="co"># interaction posterior mean has remained the same as it was in the non-centered model.</span></span>
<span><span class="co">## Centering has these effects because: Estimation worked better, Estimates changed less across models.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<section id="estimation-worked-better" class="level4"><h4 class="anchored" data-anchor-id="estimation-worked-better">Estimation worked better</h4>
<p>Estimation failed with the un-centered predictor variables, because there was a long way to go from the <code>start</code> values you provided to map and the <code>MAP</code> values it was seeking. When the predictors are centered, the MAP value for <span class="math inline">\(\alpha\)</span> is just the empirical mean for the outcome. That is also the <code>start</code> value given to <code>map</code>. With un-centered predictors, the MAP value for <span class="math inline">\(\alpha\)</span> lies a long way from the empirical mean. Hence, the long search that failed.</p>
<p><br></p>
</section><section id="estimates-changed-less-across-models" class="level4"><h4 class="anchored" data-anchor-id="estimates-changed-less-across-models">Estimates changed less across models</h4>
<p>In the un-centered models, the interaction effect is applied to every case, and so none of the parameters in <span class="math inline">\(\mu\)</span> makes sense alone. This is because neither of the predictors in those models, <code>shade</code> and <code>water</code>, are ever zero. As a result the interaction parameter always factors into generating a prediction. Consider for example a tulip at the average moisture and shade levels, 2 in each case. The expected blooms for such a tulip is:</p>
<p><span class="math display">\[\mu_i|_{S_i=2, W_i=2} = \alpha + \beta_W(2) + \beta_S (2) + \beta_{WS}(2 \times 2)\]</span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb759"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Plugging in the MAP values for the un-centered interaction model, m7.7</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m7.7</span><span class="op">)</span></span>
<span><span class="va">k</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">k</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span> <span class="va">k</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">*</span><span class="fl">2</span> <span class="op">+</span> <span class="va">k</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">*</span><span class="fl">2</span><span class="op">*</span><span class="fl">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>       a 
129.2586 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb761"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Same prediction from the centered interaction model, m7.9,</span></span>
<span><span class="co"># also using the mean values of both predictors</span></span>
<span><span class="va">k</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m7.9</span><span class="op">)</span></span>
<span><span class="va">k</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">k</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">*</span><span class="fl">0</span> <span class="op">+</span> <span class="va">k</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">*</span><span class="fl">0</span> <span class="op">+</span> <span class="va">k</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">*</span><span class="fl">0</span><span class="op">*</span><span class="fl">0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>      a 
129.008 </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb763"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">precis</span><span class="op">(</span><span class="va">m7.9</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>           mean        sd      5.5%     94.5%
a     129.00797  8.670768 115.15041 142.86553
bW     74.95946 10.602006  58.01540  91.90351
bS    -41.14054 10.600305 -58.08188 -24.19921
bWS   -51.87265 12.948117 -72.56625 -31.17906
sigma  45.22497  6.152983  35.39132  55.05863</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb765"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The estimate a,α, is the expected value of blooms when both water and shade are at </span></span>
<span><span class="co"># their average values. Their average values are both zero (0), because they were centered </span></span>
<span><span class="co"># before fitting the model.</span></span>
<span></span>
<span><span class="co"># The estimate bW, βW, is the expected change in blooms when water increases by one unit </span></span>
<span><span class="co"># and shade is at its average value (of zero). This parameter does not tell you the expected </span></span>
<span><span class="co"># rate of change for any other value of shade. This estimate suggests that when shade is at </span></span>
<span><span class="co"># its average value, increasing water is highly beneficial to blooms.</span></span>
<span></span>
<span><span class="co"># The estimate bS, βS, is the expected change in blooms when shade increases by one unit and </span></span>
<span><span class="co"># water is at its average value (of zero). This parameter does not tell you the expected rate </span></span>
<span><span class="co"># of change for any other value of water. This estimate suggests that when water is at its </span></span>
<span><span class="co"># average value, increasing shade is highly detrimental to blooms.</span></span>
<span></span>
<span><span class="co"># The estimate bWS, βWS, is the interaction effect. Like all linear interactions, it can be </span></span>
<span><span class="co"># explained in more than one way. First, the estimate tells us the expected change in the </span></span>
<span><span class="co"># influence of water on blooms when increasing shade by one unit. Second, it tells us the </span></span>
<span><span class="co"># expected change in the influence of shade on blooms when increasing water by one unit.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="plotting-implied-predictions" class="level3"><h3 class="anchored" data-anchor-id="plotting-implied-predictions">Plotting implied predictions</h3>
<p>There were no interactions in the models in previous chapters. As a result, when plotting model predictions as a function of any one predictor, you could hold the other predictors constant at any value you liked. So the choice of which values to set the un-viewed predictor variables to hardly mattered.</p>
<p>Once there are interactions in a model, the effect of changing a predictor depends upon the values of the other predictors. Maybe the simplest way to go about plotting such interdependency is to make a frame of multiple bivariate plots. In each plot, you choose different values for the un-viewed variables. Then by comparing the plots to one another, you can see how big of a difference the changes make.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb766"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># make a plot window with three panels in a single row</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span>, mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span> <span class="co"># 2 row, 3 columns</span></span>
<span></span>
<span><span class="co">## Without interaction</span></span>
<span><span class="co"># loop over values of water.c and plot predictions</span></span>
<span><span class="va">shade.seq</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">w</span> <span class="kw">in</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">dt</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">water.c</span><span class="op">==</span><span class="va">w</span>,<span class="op">]</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">blooms</span> <span class="op">~</span> <span class="va">shade.c</span> , data<span class="op">=</span><span class="va">dt</span> , col<span class="op">=</span><span class="va">rangi2</span> ,</span>
<span>        main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"water.c ="</span>,<span class="va">w</span><span class="op">)</span> , xaxp<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">362</span><span class="op">)</span> ,</span>
<span>        xlab<span class="op">=</span><span class="st">"shade (centered)"</span> <span class="op">)</span></span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.8</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>water.c<span class="op">=</span><span class="va">w</span>,shade.c<span class="op">=</span><span class="va">shade.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span>    <span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">shade.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">shade.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">shade.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co">## With interaction</span></span>
<span><span class="co"># loop over values of water.c and plot predictions</span></span>
<span><span class="va">shade.seq</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">w</span> <span class="kw">in</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">dt</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">water.c</span><span class="op">==</span><span class="va">w</span>,<span class="op">]</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">blooms</span> <span class="op">~</span> <span class="va">shade.c</span> , data<span class="op">=</span><span class="va">dt</span> , col<span class="op">=</span><span class="va">rangi2</span> ,</span>
<span>        main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"water.c ="</span>,<span class="va">w</span><span class="op">)</span> , xaxp<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">362</span><span class="op">)</span> ,</span>
<span>        xlab<span class="op">=</span><span class="st">"shade (centered)"</span> <span class="op">)</span></span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.9</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>water.c<span class="op">=</span><span class="va">w</span>,shade.c<span class="op">=</span><span class="va">shade.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span>    <span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">shade.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">shade.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">shade.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/7.28-1.png" class="img-fluid" width="768"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb767"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Triptych plot of predicted blooms across water treatments, without (top row) and </span></span>
<span><span class="co"># with (bottom row) an interaction effect. Blue points in each plot are data- individual </span></span>
<span><span class="co"># cases that match the water value displayed at the top of each plot.</span></span>
<span><span class="co"># The solid line is the posterior mean and the dashed lines give 97% interval of the mean.</span></span>
<span></span>
<span><span class="co"># Top row: Without the interaction, model m7.8. Each of the three plots of blooms against </span></span>
<span><span class="co"># shade level is for a different water level. The slope of the regression line in each case </span></span>
<span><span class="co"># is exactly the same, because there is no interaction in this model. </span></span>
<span></span>
<span><span class="co"># Bottom row: With the interaction, model m7.9. Now the slope of blooms against shade has </span></span>
<span><span class="co"># a different value in each plot.At low water levels, shade can’t have much of an effect, </span></span>
<span><span class="co"># because the tulips don’t have enough water to produce blooms anyway. At higher water levels, </span></span>
<span><span class="co"># shade can matter more, because the tulips have enough water to produce some blooms. </span></span>
<span><span class="co"># At very high water levels, water is no longer limiting the blooms very much, and so shade </span></span>
<span><span class="co"># can have a much more dramatic impact on the outcome.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb768"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Water on the horizontal axes and shade level varied from left to right</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span>, mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## Without interaction</span></span>
<span><span class="co"># loop over values of shade.c and plot predictions</span></span>
<span><span class="va">water.seq</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">s</span> <span class="kw">in</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">dt</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">shade.c</span><span class="op">==</span><span class="va">s</span>,<span class="op">]</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">blooms</span> <span class="op">~</span> <span class="va">water.c</span> , data<span class="op">=</span><span class="va">dt</span> , col<span class="op">=</span><span class="va">rangi2</span> ,</span>
<span>        main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"shade.c ="</span>,<span class="va">s</span><span class="op">)</span> , xaxp<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">362</span><span class="op">)</span> ,</span>
<span>        xlab<span class="op">=</span><span class="st">"water (centered)"</span> <span class="op">)</span></span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.8</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>shade.c<span class="op">=</span><span class="va">s</span>,water.c<span class="op">=</span><span class="va">water.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span>    <span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">water.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">water.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">water.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co">## With interaction</span></span>
<span><span class="co"># loop over values of shade.c and plot predictions</span></span>
<span><span class="va">water.seq</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">s</span> <span class="kw">in</span> <span class="op">-</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">dt</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span><span class="va">d</span><span class="op">$</span><span class="va">shade.c</span><span class="op">==</span><span class="va">s</span>,<span class="op">]</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span> <span class="va">blooms</span> <span class="op">~</span> <span class="va">water.c</span> , data<span class="op">=</span><span class="va">dt</span> , col<span class="op">=</span><span class="va">rangi2</span> ,</span>
<span>        main<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"shade.c ="</span>,<span class="va">s</span><span class="op">)</span> , xaxp<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span> , ylim<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">362</span><span class="op">)</span> ,</span>
<span>        xlab<span class="op">=</span><span class="st">"water (centered)"</span> <span class="op">)</span></span>
<span>    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu">link</span><span class="op">(</span> <span class="va">m7.9</span> , data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>shade.c<span class="op">=</span><span class="va">s</span>,water.c<span class="op">=</span><span class="va">water.seq</span><span class="op">)</span> <span class="op">)</span></span>
<span>    <span class="va">mu.mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">mean</span> <span class="op">)</span></span>
<span>    <span class="va">mu.PI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="fl">2</span> , <span class="va">PI</span> , prob<span class="op">=</span><span class="fl">0.97</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">water.seq</span> , <span class="va">mu.mean</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">water.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="va">water.seq</span> , <span class="va">mu.PI</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span> , lty<span class="op">=</span><span class="fl">2</span> <span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/7.28a-1.png" class="img-fluid" width="768"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb769"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># If there isn’t enough light, then more water hardly helps.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section></section><section id="interactions-in-design-formulas" class="level2"><h2 class="anchored" data-anchor-id="interactions-in-design-formulas">Interactions in design formulas</h2>
<p>To specify interaction models using design formulas, like those used by <code>lm</code> and other automated model fitting functions, you just strip out the parameters from the linear model.</p>
<p>For example, here’s a model with an interaction between <span class="math inline">\(x\)</span> and <span class="math inline">\(z\)</span>:</p>
<p>$$ <span class="math display">\[\begin{align*}
\ y_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_x x_i + \beta_z z_i + \beta_{xz} x_i z_i
\end{align*}\]</span></p>
<p>$$</p>
<p><br></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb770"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># As a design formula, this is:</span></span>
<span><span class="va">m7.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">z</span> <span class="op">+</span> <span class="va">x</span><span class="op">*</span><span class="va">z</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span></span>
<span><span class="co"># You can also omit the pure x and z terms, the main effects, and still get the same model.</span></span>
<span><span class="va">m7.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">*</span><span class="va">z</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>If you do not want the main effects in the model, you must explicitly subtract them from the formula. For example, here’s a model with an interaction, but without one of the main effects (when you know a priori that there is no direct effect of <span class="math inline">\(z\)</span> on the outcome, when <span class="math inline">\(\beta_z\)</span> = 0 by assumption):</p>
<p>$$ <span class="math display">\[\begin{align*}
\ y_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_x x_i + \beta_{xz} x_i z_i
\end{align*}\]</span></p>
<p>$$</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb771"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># As a design formula, this model is:</span></span>
<span><span class="va">m7.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">x</span><span class="op">*</span><span class="va">z</span> <span class="op">-</span> <span class="va">z</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
<p>For higher-order interactions, just multiply more predictors together. The design formula always implies all of the lower-order interactions, even though you don’t explicitly state them. For example, this model has a three-way interaction between <span class="math inline">\(x\)</span>, <span class="math inline">\(z\)</span>, and <span class="math inline">\(w\)</span>, as well as three two-way interactions and all three main effects:</p>
<p><span class="math display">\[
\begin{align*}
y_i &amp;\sim \text{Normal}(\mu_i, \sigma)\\
\mu_i &amp;= \alpha + \beta_x x_i + \beta_z z_i + \beta_w w_i + \beta_{xz} x_i z_i + \beta_{xw} x_i w_i + \beta_{zw} z_i w_i + \beta_{xzw} x_i z_i w_i
\end{align*}
\]</span></p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb772"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># create mock data set to solve "error:variable lengths differ (found for 'w')"</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">40</span><span class="op">)</span>,</span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">40</span><span class="op">)</span>,</span>
<span>  z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">40</span><span class="op">)</span>,</span>
<span>  w <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">40</span><span class="op">)</span></span>
<span><span class="op">)</span> </span>
<span></span>
<span><span class="co">## In design formula:</span></span>
<span><span class="va">m7.x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="va">x</span><span class="op">*</span><span class="va">z</span><span class="op">*</span><span class="va">w</span> , data<span class="op">=</span><span class="va">d</span> <span class="op">)</span></span>
<span><span class="co"># And you can explicitly subtract any lower-order interactions or main effects to </span></span>
<span><span class="co"># construct a reduced model.</span></span>
<span></span>
<span><span class="co">## Expand the design formula to see how it works</span></span>
<span><span class="co"># Expand a three-way interaction into a full set of terms:</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">z</span> <span class="op">&lt;-</span> <span class="va">w</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="co"># any number would do here</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="va">x</span><span class="op">*</span><span class="va">z</span><span class="op">*</span><span class="va">w</span><span class="op">)</span> <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] "(Intercept)" "x"           "z"           "w"           "x:z"        
[6] "x:w"         "z:w"         "x:z:w"      </code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb774"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># That function takes the design formula, absent the outcome variable, and expands it </span></span>
<span><span class="co"># into a full set of variables for a linear model. This expanded set is the model matrix. </span></span>
<span><span class="co"># ":" symbols stand for multiplication.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="practice-5" class="level2"><h2 class="anchored" data-anchor-id="practice-5">Practice</h2>
<p><br></p>
</section></section><section id="chapter-8-markov-chain-monte-carlo" class="level1"><h1>Chapter 8: Markov Chain Monte Carlo</h1>
<p><strong><em>Markov chain Monte Carlo (MCMC) estimation</em></strong> is the estimation of posterior probability distributions using a stochastic process. It has the ability to directly estimate models, such as the generalized linear and multilevel models, which routinely produce non-Gaussian posterior distributions.</p>
<p><br></p>
<section id="good-king-markov-and-his-island-kingdom" class="level2"><h2 class="anchored" data-anchor-id="good-king-markov-and-his-island-kingdom">Good King Markov and his island kingdom</h2>
<p>King Markov was a benevolent autocrat of an island kingdom,a circular archipelago, with 10 islands. Each island was neighbored by two others, and the entire archipelago formed a ring. The islands were of different sizes, and so had different sized populations living on them. The second island was about twice as populous as the first, the third about three times as populous as the first, and so on, up to the largest island, which was 10 times as populous as the smallest.</p>
<p>The king should visit each island in proportion to its population size, visiting the largest island 10 times as often as the smallest, for example. Also, since the archipelago was a ring, the King insisted that he only move among adjacent islands, to minimize time spent on the water.</p>
<p>The king’s advisor, a Mr Metropolis, engineered a clever solution to these demands. We’ll call this solution the <strong><em>Metropolis algorithm</em></strong>. Here’s how it works.</p>
<ol type="1">
<li><p>Wherever the King is, each week he decides between staying put for another week or moving to one of the two adjacent islands. To decide his next move, he flips a coin.</p></li>
<li><p>If the coin turns up heads, the King considers moving to the adjacent island clockwise around the archipelago. If the coin turns up tails, he considers instead moving counterclockwise. Call the island the coin nominates the <em>proposal</em> island.</p></li>
<li><p>Now, to see whether or not he moves to the proposal island, King Markov counts out a number of seashells equal to the relative population size of the proposal island. So for example, if the proposal island is number 9, then he counts out 9 seashells. Then he also counts out a number of stones equal to the relative population of the current island. So for example, if the current island is number 10, then King Markov ends up holding 10 stones, in addition to the 9 seashells.</p></li>
<li><p>When there are more seashells than stones, King Markov always moves to the proposal island. But if there are fewer shells than stones, he discards a number of stones equal to the number of shells. So for example, if there are 4 shells and 6 stones, he ends up with 4 shells and 6 − 4 = 2 stones. Then he places the shells and the remaining stones in a bag. He reaches in and randomly pulls out one object. If it is a shell, he moves to the proposal island. Otherwise, he stays put another week. As a result, the probability that he moves is equal to the number of shells divided by the original number of stones.</p></li>
</ol>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb775"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Simulate King Markov’s journey</span></span>
<span></span>
<span><span class="co"># Set number of weeks to simulate</span></span>
<span><span class="va">num_weeks</span> <span class="op">&lt;-</span> <span class="fl">1e5</span></span>
<span></span>
<span><span class="co"># Define an empty history vector</span></span>
<span><span class="va">positions</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="va">num_weeks</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define a starting island position (the biggest island, number 10)</span></span>
<span><span class="va">current</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span> <span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">num_weeks</span> <span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># record current position</span></span>
<span>    <span class="va">positions</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">current</span></span>
<span>    </span>
<span>    <span class="co"># flip coin to generate proposal</span></span>
<span>    <span class="va">proposal</span> <span class="op">&lt;-</span> <span class="va">current</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span> , size<span class="op">=</span><span class="fl">1</span> <span class="op">)</span></span>
<span>    </span>
<span>    <span class="co"># now make sure he loops around the archipelago</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span> <span class="va">proposal</span> <span class="op">&lt;</span> <span class="fl">1</span> <span class="op">)</span> <span class="va">proposal</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span> <span class="va">proposal</span> <span class="op">&gt;</span> <span class="fl">10</span> <span class="op">)</span> <span class="va">proposal</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span>    </span>
<span>    <span class="co"># move?</span></span>
<span>    <span class="va">prob_move</span> <span class="op">&lt;-</span> <span class="va">proposal</span><span class="op">/</span><span class="va">current</span></span>
<span>    <span class="va">current</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="op">&lt;</span> <span class="va">prob_move</span> , <span class="va">proposal</span> , <span class="va">current</span> <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Plot the data (follow ajkurz's codes)</span></span>
<span><span class="fu">tibble</span><span class="op">(</span>week   <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1e5</span>,</span>
<span>       island <span class="op">=</span> <span class="va">positions</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span></span>
<span>  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">week</span>, y <span class="op">=</span> <span class="va">island</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">geom_point</span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_x_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">100</span>, by <span class="op">=</span> <span class="fl">20</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">scale_y_continuous</span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">10</span>, by <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">coord_cartesian</span><span class="op">(</span>xlim <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">100</span>,</span>
<span>                  ylim <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">labs</span><span class="op">(</span>title    <span class="op">=</span> <span class="st">"Behold: The Metropolis algorithm in action!"</span>,</span>
<span>       subtitle <span class="op">=</span> <span class="st">"The dots show the king's path over the first 100 weeks."</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">theme_bw</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span></span>
<span></span>
<span></span>
<span></span>
<span></span>
<span></span>
<span><span class="co"># Results of the king following the Metropolis algorithm. The left-hand plot shows </span></span>
<span><span class="co"># the king’s position (vertical axis) across first 100 weeks (horizontal axis). </span></span>
<span><span class="co"># In any particular week, it’s nearly impossible to say where the king will be. </span></span>
<span></span>
<span><span class="co"># The right-hand plot shows the long-run behavior of the algorithm, as the time spent on </span></span>
<span><span class="co"># each island turns out to be proportional to its population size.</span></span>
<span></span>
<span><span class="co"># The algorithm will still work in this way, even if we allow the king to be equally likely </span></span>
<span><span class="co"># to propose a move to any island from any island, not just among neighbors. The algorithm </span></span>
<span><span class="co"># would also work for any size archipelago, even if the king didn’t know how many islands </span></span>
<span><span class="co"># were in it. All he needs to know at any point in time is the population of the current </span></span>
<span><span class="co"># island and the population of the proposal island.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="markov-chain-monte-carlo-1" class="level2"><h2 class="anchored" data-anchor-id="markov-chain-monte-carlo-1">Markov chain Monte Carlo</h2>
<p>The goal of general <strong>Metropolis Algorithm</strong>, an example of Markov chain Monte Carlo, is to draw samples from an unknown and usually complex target distribution, like a posterior probability distribution.</p>
<ul>
<li><p>The “islands” in our objective are parameter values, and they need not be discrete, but can instead take on a continuous range of values as usual.</p></li>
<li><p>The “population sizes” in our objective are the posterior probabilities at each parameter value.</p></li>
<li><p>The “weeks” in our objective are samples taken from the joint posterior of the parameters in the model.</p></li>
</ul>
<p>Provided the way we choose our proposed parameter values at each step is symmetric— so that there is an equal chance of proposing from A to B and from B to A— then the Metropolis algorithm will eventually give us a collection of samples from the joint posterior.</p>
<p><br></p>
<p><spans style="color:brown"><span style="text-decoration:underline"><strong>Two of the most important in contemporary Bayesian inference</strong></span></spans></p>
<ul>
<li><p>Gibbs sampling</p></li>
<li><p>Hamiltonian (aka Hybrid, aka HMC) Monte Carlo</p></li>
</ul>
<p><br></p>
<section id="gibbs-sampling" class="level3"><h3 class="anchored" data-anchor-id="gibbs-sampling">Gibbs sampling</h3>
<p>The Metropolis algorithm works whenever the probability of proposing a jump to B from A is equal to the probability of proposing A from B, when the proposal distribution is symmetric. There is a more general method, known as Metropolis-Hastings, that allows asymmetric proposals.</p>
<p>An algorithm that allows asymmetric proposals is useful because:</p>
<ul>
<li><p>it makes it easier to handle parameters, like standard deviations, that have boundaries at zero</p></li>
<li><p>we can acquire an equally good image of the posterior distribution in fewer steps</p></li>
</ul>
<p>Gibbs sampling is a variant of the Metropolis-Hastings algorithm that uses clever proposals and is therefore more efficient— you can get a good estimate of the posterior from Gibbs sampling with many fewer samples than a comparable Metropolis approach. The improvement arises from <strong><em>adaptive proposals</em></strong> in which the distribution of proposed parameter values adjusts itself intelligently, depending upon the parameter values at the moment. Gibbs sampling computes these adaptive proposals using particular combinations of prior distributions and likelihoods known as <em>conjugate pairs</em>.</p>
<p>Some limitations of Gibbs sampling:</p>
<ul>
<li><p>Some conjugate priors seem silly, and choosing a prior so that the model fits efficiently isn’t really a strong argument from a scientific perspective.</p></li>
<li><p>As models become more complex and contain hundreds or thousands or tens of thousands of parameters, Gibbs sampling becomes shockingly inefficient.</p></li>
</ul>
<p><br></p>
</section><section id="hamiltonian-monte-carlo" class="level3"><h3 class="anchored" data-anchor-id="hamiltonian-monte-carlo">Hamiltonian Monte Carlo</h3>
<p>Hamiltonian Monte Carlo (or Hybrid Monte Carlo, HMC) adopts Jaynes’ principle that, <em>“whenever there is a randomized way of doing something, then there is a non-randomized way that delivers better performance but requires more thought.”</em></p>
<p>HMC is much more computationally costly than are Metropolis or Gibbs sampling— both highly random procedures. But its proposals are typically much more efficient— doesn’t need as many samples to describe the posterior distribution, outshine other algorithms as models become more complex (thousands or tens of thousands of parameters). HMC outperforms Metropolis and Gibbs sampling, but it is not a universal solution to all MCMC problems.</p>
<p>Monty’s kingdom is not a discrete set of islands. Instead, it is a continuous territory stretched out along a narrow valley. Monty’s advisor, Hamilton realized that a much more efficient way to visit the citizens in the continuous Kingdom is to travel back and forth along its length. In order to spend more time in densely settled areas, they should slow the royal vehicle down when houses grow more dense. Likewise, they should speed up when houses grow more sparse. This strategy requires knowing how quickly population density is changing, at their current location. But it doesn’t require remembering where they’ve been or knowing the population distribution anyplace else. And a major benefit of this strategy compared to that of Metropolis is that the King makes a full sweep of the kingdom before revisiting anyone.</p>
<p>In statistical applications, the royal vehicle is the current vector of parameter values. Let’s consider the single parameter case, just to keep things simple. In that case, the log-posterior is like a bowl, with the MAP at its nadir. Then the job is to sweep across the surface of the bowl, adjusting speed in proportion to how high up we are. In cases where ordinary Metropolis or Gibbs sampling wander slowly through parameter space, Hamiltonian Monte Carlo remains efficient.</p>
<p>Some limitations of HMC:</p>
<ul>
<li><p>HMC requires continuous parameters. It can’t glide through a discrete parameter.</p></li>
<li><p>it needs to be tuned to a particular model and its data. That’s where an engine like Stan (mc-stan.org) comes in. Stan automates much of that tuning.</p></li>
</ul>
<p><br></p>
</section></section><section id="easy-hmc-map2stan" class="level2"><h2 class="anchored" data-anchor-id="easy-hmc-map2stan">Easy HMC: <code>map2stan</code>
</h2>
<p><code>map2stan</code> compiles lists of formulas, like the lists you’ve been using so far to construct map estimates, into Stan HMC code. To use <code>map2stan</code>, you need to preprocess any variable transformations, and you need to construct a clean data frame with only the variables you will use.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb776"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># load the data and reduce it down to cases (nations) that have the outcome variable of interest</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">rugged</span><span class="op">)</span></span>
<span><span class="va">d</span> <span class="op">&lt;-</span> <span class="va">rugged</span></span>
<span><span class="va">d</span><span class="op">$</span><span class="va">log_gdp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">rgdppc_2000</span><span class="op">)</span></span>
<span><span class="va">dd</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">[</span> <span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html">complete.cases</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">rgdppc_2000</span><span class="op">)</span> , <span class="op">]</span></span>
<span></span>
<span><span class="co"># Fit the interaction model which  aims to predict log-GDP with terrain ruggedness, </span></span>
<span><span class="co"># continent, and the interaction of the two</span></span>
<span><span class="va">m8.1</span> <span class="op">&lt;-</span> <span class="fu">rethinking</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">rugged</span> <span class="op">+</span> <span class="va">bA</span><span class="op">*</span><span class="va">cont_africa</span> <span class="op">+</span> <span class="va">bAR</span><span class="op">*</span><span class="va">rugged</span><span class="op">*</span><span class="va">cont_africa</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">bA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">bAR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">dunif</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span>,</span>
<span>    data<span class="op">=</span><span class="va">dd</span> <span class="op">)</span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m8.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%       94.5%
a      9.2227689 0.13798206  9.0022469  9.44329088
bR    -0.2026479 0.07646937 -0.3248607 -0.08043504
bA    -1.9469342 0.22450149 -2.3057309 -1.58813747
bAR    0.3929195 0.13004840  0.1850770  0.60076196
sigma  0.9326834 0.05058191  0.8518438  1.01352311</code></pre>
</div>
</div>
<p><br></p>
<section id="preparation" class="level3"><h3 class="anchored" data-anchor-id="preparation">Preparation</h3>
<p>But now we’ll also fit this model using Hamiltonian Monte Carlo. This means there will be no more quadratic approximation— if the posterior distribution is non-Gaussian, then we’ll get whatever non-Gaussian shape it has. You can use exactly the same formula list as before, but you need to do two additional things.</p>
<ol type="1">
<li>Preprocess all variable transformations. - If the outcome is transformed somehow, like by taking the logarithm, then do this before fitting the model by constructing a new variable in the data frame. - Likewise, if any predictor variables are transformed, including squaring and cubing and such to build polynomial models, then compute these transformed values before fitting the model.</li>
</ol>
<ol start="2" type="1">
<li>Once you’ve got all the variables ready, make a new trimmed down data frame that contains only the variables you will actually use to fit the model. Technically, you don’t have to do this. But doing so avoids common problems. For example, if any of the unused variables have missing values, NA, then Stan will refuse to work.</li>
</ol>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb778"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">dd.trim</span> <span class="op">&lt;-</span> <span class="va">dd</span><span class="op">[</span> , <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"log_gdp"</span>,<span class="st">"rugged"</span>,<span class="st">"cont_africa"</span><span class="op">)</span> <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">dd.trim</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   170 obs. of  3 variables:
 $ log_gdp    : num  7.49 8.22 9.93 9.41 7.79 ...
 $ rugged     : num  0.858 3.427 0.769 0.775 2.688 ...
 $ cont_africa: int  1 0 0 0 0 0 0 0 0 1 ...</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb780"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The data frame dd.trim contains only the three variables we’re using.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="estimation" class="level3"><h3 class="anchored" data-anchor-id="estimation">Estimation</h3>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb781"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Get samples from the posterior distribution using HMC</span></span>
<span><span class="va">output</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/capture.output.html">capture.output</a></span><span class="op">(</span><span class="va">m8.1stan</span> <span class="op">&lt;-</span> <span class="fu">ulam</span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span></span>
<span>        <span class="va">log_gdp</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span> <span class="va">mu</span> , <span class="va">sigma</span> <span class="op">)</span> ,</span>
<span>        <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">bR</span><span class="op">*</span><span class="va">rugged</span> <span class="op">+</span> <span class="va">bA</span><span class="op">*</span><span class="va">cont_africa</span> <span class="op">+</span> <span class="va">bAR</span><span class="op">*</span><span class="va">rugged</span><span class="op">*</span><span class="va">cont_africa</span> ,</span>
<span>        <span class="va">a</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">100</span><span class="op">)</span>,</span>
<span>        <span class="va">bR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">bA</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">bAR</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">10</span><span class="op">)</span>,</span>
<span>        <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Cauchy.html">dcauchy</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">2</span><span class="op">)</span> <span class="co"># a weakly regularizing prior for standard deviations</span></span>
<span></span>
<span><span class="co"># The uniform prior on sigma has been changed to a half-Cauchy prior. </span></span>
<span><span class="co"># The Cauchy distribution is a useful thick-tailed probability distribution </span></span>
<span><span class="co"># related to the Student t distribution.</span></span>
<span></span>
<span><span class="op">)</span>, data<span class="op">=</span><span class="va">dd.trim</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m8.1stan</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%       94.5%      rhat ess_bulk
a      9.2280350 0.13860503  8.9945226  9.43780500 0.9980571 238.5230
bR    -0.2035494 0.07893781 -0.3256216 -0.07026252 1.0201593 224.9284
bA    -1.9453052 0.20582810 -2.2689997 -1.59567685 1.0011520 176.0479
bAR    0.3921922 0.12998521  0.1777728  0.59327326 0.9986397 204.6634
sigma  0.9510219 0.05181543  0.8722903  1.03583580 1.0010535 528.0297</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb783"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># The interval boundaries in the table are highest posterior density intervals (HPDI), </span></span>
<span><span class="co"># not ordinary percentile intervals (PI).</span></span>
<span></span>
<span><span class="co"># n_eff and Rhat provide MCMC diagnostic criteria, to help you tell how well estimation worked.</span></span>
<span><span class="co"># n_eff is a crude estimate of the number of independent samples you managed to get.</span></span>
<span><span class="co"># Rhat is a complicated estimate of the convergence of the Markov chains to the target </span></span>
<span><span class="co"># distribution. It should approach 1.00 from above, when all is well.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="sampling-agian-in-parallel" class="level3"><h3 class="anchored" data-anchor-id="sampling-agian-in-parallel">Sampling agian, in parallel</h3>
<p>Once you have compiled your Stan model, you can draw more samples from it anytime, running as many independent Markov chains as you like. And you can easily parallelize those chains, as well. To run four independent Markov chains for the model above, and to distribute them across separate processors in your computer, just pass the previous fit back to map2stan:</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb784"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">output</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/capture.output.html">capture.output</a></span><span class="op">(</span><span class="va">m8.1stan_4chains</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span> <span class="va">m8.1stan</span> , chains<span class="op">=</span><span class="fl">4</span> , cores<span class="op">=</span><span class="fl">4</span> <span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># map2stan doesn't work anymore- use update() here. </span></span>
<span><span class="fu">precis</span><span class="op">(</span><span class="va">m8.1stan_4chains</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>            mean         sd       5.5%       94.5%     rhat  ess_bulk
a      9.2241197 0.13742913  9.0092163  9.45199630 1.003929  744.3310
bR    -0.2021915 0.07797400 -0.3221467 -0.07975606 1.001958  827.3747
bA    -1.9523866 0.22351867 -2.3133557 -1.59445150 1.000339  792.7215
bAR    0.3941635 0.13270682  0.1909733  0.61095014 1.002317  851.0328
sigma  0.9517694 0.05485316  0.8668621  1.04373580 1.004684 1354.3185</code></pre>
</div>
</div>
<p><br></p>
</section><section id="visualization" class="level3"><h3 class="anchored" data-anchor-id="visualization">Visualization</h3>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb786"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Pull out the samples</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span> <span class="fu">extract.samples</span><span class="op">(</span> <span class="va">m8.1stan</span> <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>List of 5
 $ a    : num [1:500, 1] 9.07 9.06 9.19 9.24 9.37 ...
 $ bR   : num [1:500, 1] -0.235 -0.238 -0.152 -0.148 -0.327 ...
 $ bA   : num [1:500, 1] -1.93 -1.96 -1.97 -1.97 -1.74 ...
 $ bAR  : num [1:500, 1] 0.545 0.56 0.176 0.213 0.46 ...
 $ sigma: num [1:500, 1] 0.933 0.925 0.949 0.969 0.914 ...
 - attr(*, "source")= chr "ulam posterior from object"</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb788"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Samples are in a list- not in a data.frame (useful for multilevel models)</span></span>
<span></span>
<span><span class="co"># For now, if it doesn’t behave like you expect it to, you can coerce it to a data frame </span></span>
<span><span class="va">post</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># To plot all these samples at once, provided there aren’t too many parameters</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/8.8-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb789"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># To display parameter names and parameter correlations</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html">pairs</a></span><span class="op">(</span><span class="va">m8.1stan</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="Statistical_Rethinking_RM_files/figure-html/8.8-2.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb790"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Pairs plot of the samples produced by Stan. The diagonal shows a density estimate for </span></span>
<span><span class="co"># each parameter. Below the diagonal, correlations between parameters are shown.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><br></p>
</section><section id="using-the-samples" class="level3"><h3 class="anchored" data-anchor-id="using-the-samples">Using the samples</h3>
<p>If you have the samples from the posterior and you know the model, you can do anything: simulate predictions, compute differences between parameters, and calculate DIC and WAIC.</p>
<div class="cell">
<details><summary>Code</summary><div class="sourceCode" id="cb791"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">show</span><span class="op">(</span><span class="va">m8.1stan</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>Hamiltonian Monte Carlo approximation
500 samples from 1 chain

Sampling durations (seconds):
  chain_id warmup sampling total
1        1   0.05     0.04  0.09

Formula:
log_gdp ~ dnorm(mu, sigma)
mu &lt;- a + bR * rugged + bA * cont_africa + bAR * rugged * cont_africa
a ~ dnorm(0, 100)
bR ~ dnorm(0, 10)
bA ~ dnorm(0, 10)
bAR ~ dnorm(0, 10)
sigma ~ dcauchy(0, 2)</code></pre>
</div>
<details><summary>Code</summary><div class="sourceCode" id="cb793"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># map2stan does not work anymore and ulam doesn't compute WAIC and DIC </span></span>
<span></span>
<span><span class="co">## Use brms (copy Akjurz's codes)</span></span>
<span><span class="co"># Run HMC model</span></span>
<span><span class="va">output</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/capture.output.html">capture.output</a></span><span class="op">(</span><span class="va">b8.1</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu">brm</span><span class="op">(</span>data <span class="op">=</span> <span class="va">dd</span>, family <span class="op">=</span> <span class="va">gaussian</span>,</span>
<span>      <span class="va">log_gdp</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">rugged</span> <span class="op">+</span> <span class="va">cont_africa</span> <span class="op">+</span> <span class="va">rugged</span><span class="op">:</span><span class="va">cont_africa</span>,</span>
<span>      prior <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu">prior</span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">Intercept</span><span class="op">)</span>,</span>
<span>                <span class="fu">prior</span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span>,</span>
<span>                <span class="fu">prior</span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span><span class="op">)</span>,</span>
<span>      seed <span class="op">=</span> <span class="fl">8</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">b8.1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code> Family: gaussian 
  Links: mu = identity; sigma = identity 
Formula: log_gdp ~ 1 + rugged + cont_africa + rugged:cont_africa 
   Data: dd (Number of observations: 170) 
  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
         total post-warmup draws = 4000

Population-Level Effects: 
                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
Intercept              9.22      0.14     8.95     9.50 1.00     3047     3348
rugged                -0.20      0.08    -0.36    -0.05 1.00     2841     2935
cont_africa           -1.95      0.23    -2.42    -1.50 1.00     2525     2653
rugged:cont_africa     0.39      0.14     0.13     0.66 1.00     2423     2693

Family Specific Parameters: 
      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
sigma     0.95      0.05     0.85     1.06 1.00     4311     3151

Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
and Tail_ESS are effective sample size measures, and Rhat is the potential
scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
</div>
<hr>
<!-- -->
</section></section></section></main><!-- /main column --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb795" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb795-1"><a href="#cb795-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb795-2"><a href="#cb795-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Statistical_Rethinking_RM"</span></span>
<span id="cb795-3"><a href="#cb795-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "SM"</span></span>
<span id="cb795-4"><a href="#cb795-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "`r format(Sys.time(), '%B %d, %Y')`"</span></span>
<span id="cb795-5"><a href="#cb795-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb795-6"><a href="#cb795-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb795-7"><a href="#cb795-7" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb795-8"><a href="#cb795-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc_float: true</span></span>
<span id="cb795-9"><a href="#cb795-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: "Contents"</span></span>
<span id="cb795-10"><a href="#cb795-10" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 5</span></span>
<span id="cb795-11"><a href="#cb795-11" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-location: left</span></span>
<span id="cb795-12"><a href="#cb795-12" aria-hidden="true" tabindex="-1"></a><span class="co">    number_sections: true</span></span>
<span id="cb795-13"><a href="#cb795-13" aria-hidden="true" tabindex="-1"></a><span class="co">    fig_caption: true</span></span>
<span id="cb795-14"><a href="#cb795-14" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb795-15"><a href="#cb795-15" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb795-16"><a href="#cb795-16" aria-hidden="true" tabindex="-1"></a><span class="co">    code-summary: 'Show code'</span></span>
<span id="cb795-17"><a href="#cb795-17" aria-hidden="true" tabindex="-1"></a><span class="co">    code-link: true</span></span>
<span id="cb795-18"><a href="#cb795-18" aria-hidden="true" tabindex="-1"></a><span class="co">    code_highlight: tango</span></span>
<span id="cb795-19"><a href="#cb795-19" aria-hidden="true" tabindex="-1"></a><span class="co">    code_download: true</span></span>
<span id="cb795-20"><a href="#cb795-20" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: sandstone</span></span>
<span id="cb795-21"><a href="#cb795-21" aria-hidden="true" tabindex="-1"></a><span class="co">    highlight: tango</span></span>
<span id="cb795-22"><a href="#cb795-22" aria-hidden="true" tabindex="-1"></a><span class="co">    smooth-scroll: true</span></span>
<span id="cb795-23"><a href="#cb795-23" aria-hidden="true" tabindex="-1"></a><span class="co">    markdown: kramdown</span></span>
<span id="cb795-24"><a href="#cb795-24" aria-hidden="true" tabindex="-1"></a><span class="an">kramdown:</span></span>
<span id="cb795-25"><a href="#cb795-25" aria-hidden="true" tabindex="-1"></a><span class="co">    math_engine: katex</span></span>
<span id="cb795-26"><a href="#cb795-26" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb795-27"><a href="#cb795-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-28"><a href="#cb795-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-29"><a href="#cb795-29" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, include=FALSE, message  = FALSE, warning = F}</span></span>
<span id="cb795-30"><a href="#cb795-30" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">echo =</span> <span class="cn">TRUE</span>,  <span class="at">message =</span> <span class="cn">FALSE</span>,  <span class="at">warning =</span> <span class="cn">FALSE</span>,  <span class="at">tidy =</span> <span class="cn">TRUE</span>)</span>
<span id="cb795-31"><a href="#cb795-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rethinking)</span>
<span id="cb795-32"><a href="#cb795-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb795-33"><a href="#cb795-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb795-34"><a href="#cb795-34" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb795-35"><a href="#cb795-35" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb795-36"><a href="#cb795-36" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb795-37"><a href="#cb795-37" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Ecdat)</span>
<span id="cb795-38"><a href="#cb795-38" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb795-39"><a href="#cb795-39" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(grid)</span>
<span id="cb795-40"><a href="#cb795-40" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rcartocolor)</span>
<span id="cb795-41"><a href="#cb795-41" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb795-42"><a href="#cb795-42" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstan)</span>
<span id="cb795-43"><a href="#cb795-43" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cmdstanr)</span>
<span id="cb795-44"><a href="#cb795-44" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(brms)</span>
<span id="cb795-45"><a href="#cb795-45" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-46"><a href="#cb795-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-47"><a href="#cb795-47" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 1: The Golem of Prague</span></span>
<span id="cb795-48"><a href="#cb795-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-49"><a href="#cb795-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-50"><a href="#cb795-50" aria-hidden="true" tabindex="-1"></a>Chapter 1 urged us to rethink the "popular statistical and scientific philosophy" by pointing out the flaws in classical statistical tools and reasoning. </span>
<span id="cb795-51"><a href="#cb795-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-52"><a href="#cb795-52" aria-hidden="true" tabindex="-1"></a>According to the author, "classical tools are not diverse enough to handle many common research questions...And if we keep adding new types of tools, soon there will be far too many to keep track of." I agree with these statements. The author also talked about how Fisher's exact test is used "whenever the cell counts are small" and he had "never seen it used appropriately" except Fisher's original use of the test. It would be nice if the author gave some examples and explanations of those inappropriate uses- I can't decide whether to accept without more information. </span>
<span id="cb795-53"><a href="#cb795-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-54"><a href="#cb795-54" aria-hidden="true" tabindex="-1"></a>The author mentioned why deductive falsification is impossible in scientific context:</span>
<span id="cb795-55"><a href="#cb795-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-56"><a href="#cb795-56" aria-hidden="true" tabindex="-1"></a>(1) "Hypotheses are not models. The relations among hypotheses and different kinds of models are complex. Many models correspond to the same hypothesis, and many hypotheses correspond to a single model. This makes strict falsification impossible.</span>
<span id="cb795-57"><a href="#cb795-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-58"><a href="#cb795-58" aria-hidden="true" tabindex="-1"></a>(2) Measurement matters. Even when we think the data falsify a model, another observer will debate our methods and measures. They don’t trust the data. Sometimes they are right.</span>
<span id="cb795-59"><a href="#cb795-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-60"><a href="#cb795-60" aria-hidden="true" tabindex="-1"></a>For both of these reasons, deductive falsification never works. The scientific method cannot be reduced to a statistical procedure, and so our statistical methods should not pretend." </span>
<span id="cb795-61"><a href="#cb795-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-62"><a href="#cb795-62" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-63"><a href="#cb795-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-64"><a href="#cb795-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hypotheses are not models</span></span>
<span id="cb795-65"><a href="#cb795-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-66"><a href="#cb795-66" aria-hidden="true" tabindex="-1"></a>He gave an example of the first statement in evolutionary context. His conclusion was:</span>
<span id="cb795-67"><a href="#cb795-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-68"><a href="#cb795-68" aria-hidden="true" tabindex="-1"></a>(1) "Any given statistical model (M) may correspond to more than one process model (P).</span>
<span id="cb795-69"><a href="#cb795-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-70"><a href="#cb795-70" aria-hidden="true" tabindex="-1"></a>(2) Any given hypothesis (H) may correspond to more than one process model (P). </span>
<span id="cb795-71"><a href="#cb795-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-72"><a href="#cb795-72" aria-hidden="true" tabindex="-1"></a>(3) Any given statistical model (M) may correspond to more than one hypothesis (H)."</span>
<span id="cb795-73"><a href="#cb795-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-74"><a href="#cb795-74" aria-hidden="true" tabindex="-1"></a>In other words, it doesn't matter whether we reject or fail to reject the null. It won't have "much inferential power" or give any useful insights due to possible existence of models- other than the ones under study- which can also align with the null or alternative hypotheses. The author gave a solution to this dilemma- "explicitly compare predictions of more than one model." This is a very nice solution, as I think it will allow analysis of hypothesis or whatever you want to study in real-world conditions. And that is much more powerful than any classical tests. </span>
<span id="cb795-75"><a href="#cb795-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-76"><a href="#cb795-76" aria-hidden="true" tabindex="-1"></a>In that case, should we disregard all studies that rely on NHST? Should we reject all findings made by rejecting the null hypothesis as senseless? And are the multiple process models the only way to go? The frequentists' way to solve this problem is to control the conditions of the experiment/study. In nutrition studies, this can be in the form of inclusion or exclusion criteria and strict control of test subjects (and conditions) throughout the duration of the study. This is to ensure the observed effect (or lack of) is caused by (or related to) the variables of interest and not by uncontrolled confounders. If a NHST research was done well with proper control, then we could 'more or less' have confidence in the research's findings. </span>
<span id="cb795-77"><a href="#cb795-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-78"><a href="#cb795-78" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-79"><a href="#cb795-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-80"><a href="#cb795-80" aria-hidden="true" tabindex="-1"></a><span class="fu">## *Measurement matters*</span></span>
<span id="cb795-81"><a href="#cb795-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-82"><a href="#cb795-82" aria-hidden="true" tabindex="-1"></a>In the section "measurement matters," the author reinforced the first statement, and explained the fallacy of falsification principle, stating two reasons:</span>
<span id="cb795-83"><a href="#cb795-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-84"><a href="#cb795-84" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>"Observations are prone to error, especially at the boundaries of scientific knowledge. </span>
<span id="cb795-85"><a href="#cb795-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-86"><a href="#cb795-86" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Most hypotheses are quantitative, concerning the degrees of existence, rather than discrete, concerning total presence or absence."</span>
<span id="cb795-87"><a href="#cb795-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-88"><a href="#cb795-88" aria-hidden="true" tabindex="-1"></a><span class="fu">### *Observation error*</span></span>
<span id="cb795-89"><a href="#cb795-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-90"><a href="#cb795-90" aria-hidden="true" tabindex="-1"></a>The author gave two examples of observation error. The first example pointed out possible bias or errors in observations, and potential type 1 and type 2 errors (false positives and false negatives) in classical frequentist researches. And the second example talked about errors in measurements (or studies/ experiments). Both are valid concerns and those errors are not uncommon in frequentist researches. </span>
<span id="cb795-91"><a href="#cb795-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-92"><a href="#cb795-92" aria-hidden="true" tabindex="-1"></a>There are several ways to overcome these shortcomings, depending on research design. For example, we can increase sample size or run more tests to reduce type 1 and type 2 errors. Errors in measurements can be avoided by following protocols- taking at least two measurements for each sample, consistency in measurements, etc. However, there is no guarantee that any particular researcher or research group will follow a strict protocol without compromising, and that can lead to observation error. To prevent this, we usually avoid using finding from a single research, and wait till the findings are backed by systematic reviews and made into guidelines. </span>
<span id="cb795-93"><a href="#cb795-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-94"><a href="#cb795-94" aria-hidden="true" tabindex="-1"></a>In both woodpecker and neutrino examples, the author's key concerns were "whether falsification is real or spurious," and that "both true-detection and false-detection plausible." The null hypothesis in the woodpecker example was "The Ivory-billed Woodpecker is extinct." According to the author, it will only take a single woodpecker to falsify this theory, and that the 2005 evidence on existence of a woodpecker was doubted by many. Since no other evidences emerged, the question remained unresolved. That means finding was not conclusive yet, and research was still ongoing. As I mentioned above, we don't accept findings from a single research as concrete or irrefutable evidence. Thus, the dilemma over falsification and type 1 or type 2 error in the woodpecker case was not really a concern- we would just need to conduct more surveys (wider location for longer period?) or simply wait for new evidences. However, I think this is not a good case to use the null hypothesis testing. The falsification of hypothesis in this case will be simply the result of patience or luck, rather than proper research design or statistical tests. In the neutrino example, the problem was the human error which they solved by replication of experiments. This is not unusual in frequentist research. Replicating or reconducting experiment is a common occurrence, especially when lab analyses are involved. It may be an inconvenience, but it does not imply the utter failure of the theory of falsification or the null hypothesis testing. </span>
<span id="cb795-95"><a href="#cb795-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-96"><a href="#cb795-96" aria-hidden="true" tabindex="-1"></a><span class="fu">### *Continuous hypotheses*</span></span>
<span id="cb795-97"><a href="#cb795-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-98"><a href="#cb795-98" aria-hidden="true" tabindex="-1"></a>The author noted "...it is a good practice to design experiments and observations that can differentiate competing hypotheses. But in many cases, the comparison must be probabilistic, a matter of degree, not kind." Two examples of null hypotheses that support the above statement were given: "80% of swans are white" and "Black swans are rare." The author pointed out the *modus tollens* swan story would not be applicable in this case, since the problem is not to prove or disprove the hypothesis but to estimate the distribution of swan coloration. He added "You might object that the hypothesis above is just not a good scientific hypothesis, because it isn’t easy to disprove. But if that’s the case, then most of the important questions about the world are not good scientific hypotheses."</span>
<span id="cb795-99"><a href="#cb795-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-100"><a href="#cb795-100" aria-hidden="true" tabindex="-1"></a>In my opinion, it is not difficult to disprove both hypotheses. The two hypothese are not good hypotheses simply because they are not specific and fail to form sensible research question or outcome- not because it is "a matter of degree." Let's break down the two hypotheses. First, we think about the possible research question for the hypothesis "80% of swan are white." The research question could be "Are 80% of swan white?" or "Do 80% of swan have white feathers?" In this case, this hypothesis would be disprove if survey found any percent of white swan other than 80%. It wouldn't matter if the actual percent was 90 or 95- we could stop the research once the number passed the threshold of 80%. Now it is clear that the problem with this hypothesis is the pointless outcome. What are we trying to achieve knowing whether 80% of swan are white, or 40% or any percentage of swan are white in color? A more sensible hypothesis would be "White coloration is the dominant trait in swan." We can falsify this hypothesis by conducting surveys- like the author suggested- or genetic analysis, etc. Still, it is not a good hypothesis for an original research since the scope is too broad. The hypothesis only specify swan- not a particular speices or geographical location, meaning all swan species in the world are included in the research. That would be a hard task for any single researcher or research group. Hence, this hypothesis is more suitable at review level- not original research level. For original research, we can specify the species of swan and extent of study area based on the available funding.</span>
<span id="cb795-101"><a href="#cb795-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-102"><a href="#cb795-102" aria-hidden="true" tabindex="-1"></a>The second hypothesis "Black swans are rare" has the similar problem- lack of specificity. We need to determine what is considered rare- 1 in 100 or 1 in a million? Once we have that specification, it is not difficult to tackle the second hypothesis. But we need to be aware that the second hypothesis also includes all swan species in the world- or even universe or parallel universes. </span>
<span id="cb795-103"><a href="#cb795-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-104"><a href="#cb795-104" aria-hidden="true" tabindex="-1"></a>Another thing is the *modus tollens* swan story was merely to explain a theory- not a definitive example of how we should write hypothesis. I have yet to see a research with hypothesis written like the one in *modus tollens* swan story. All hypotheses that I have seen so far address "the degree, not kind"-like the author suggested. Hence, the author's concern over hypotheses is somehow invalid. </span>
<span id="cb795-105"><a href="#cb795-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-106"><a href="#cb795-106" aria-hidden="true" tabindex="-1"></a><span class="fu">### *Falsification is consensual*</span></span>
<span id="cb795-107"><a href="#cb795-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-108"><a href="#cb795-108" aria-hidden="true" tabindex="-1"></a>The author said "falsification is always consensual, not logical," and "evidence often— but not always— has something to do with such falsification." He also highlighted the arguments towards "consensus about meaning of evidence" and the danger of "historical revisionism." I think the author is right. We hold such reverence towards the famous scientists in history, that their formulas are still widely applied to this day, without contesting their suitability in this age. Many researches were done following the same mould, that they gave similar results, which became our gold-standard- the guidelines. And those guidelines are not set in stone. They are regularly updated- albeit minor changes. Occasionally, some guidelines are completely proven false and replaced by new ones. These occasions are rare that they are called groundbreaking discovery. I remembered the day everyone at the department was talking about the guideline change on egg consumption- may seem insignificant to outsiders but we were really excited! It could be that such new discoveries are rare because we are doing the same thing over and over again, and are content when our findings (even vaguely) agree the current consensus- we seek validation from previous works by researchers more venerable than us. And that is dangerous to our patients and the public. We may be feeling relaxed because we think the worst that can happen from such findings is "the treatment is ineffective but not harmful." We pour scorn on some of the treatments given by the healthcare providers some hundred years ago as harmful and ineffective. We can do so because we now have the knowledge collected over time. It is very possible our best guidelines may seem 'folly' to the researchers in the next hundred years. Thus, I agree with the author that it's time we should do things differently. </span>
<span id="cb795-109"><a href="#cb795-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-110"><a href="#cb795-110" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-111"><a href="#cb795-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-112"><a href="#cb795-112" aria-hidden="true" tabindex="-1"></a><span class="fu">## Three tools for golem engineering </span></span>
<span id="cb795-113"><a href="#cb795-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-114"><a href="#cb795-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-115"><a href="#cb795-115" aria-hidden="true" tabindex="-1"></a>The author gave alternative to falsification- that is to build models. According to the author, "Models can be made into testing procedures— all statistical tests are also models—but they can also be used to measure, forecast, and argue." He also mentioned three models that are "in demand in both the social and biological sciences."</span>
<span id="cb795-116"><a href="#cb795-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-117"><a href="#cb795-117" aria-hidden="true" tabindex="-1"></a>(1) Bayesian data analysis</span>
<span id="cb795-118"><a href="#cb795-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-119"><a href="#cb795-119" aria-hidden="true" tabindex="-1"></a>(2) Multilevel models</span>
<span id="cb795-120"><a href="#cb795-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-121"><a href="#cb795-121" aria-hidden="true" tabindex="-1"></a>(3) Model comparison using information criteria</span>
<span id="cb795-122"><a href="#cb795-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-123"><a href="#cb795-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-124"><a href="#cb795-124" aria-hidden="true" tabindex="-1"></a><span class="fu">### *Bayesian data analysis*</span></span>
<span id="cb795-125"><a href="#cb795-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-126"><a href="#cb795-126" aria-hidden="true" tabindex="-1"></a>As explained by the author, Bayesian data analysis uses uncertainty or chance to "describe plausibility of different possibilities," and "...we can use probability theory as a general way to represent plausibility, whether in reference to countable events in the world or rather theoretical constructs like parameters." The author then compared this approach to frequentist approach- "Bayesian probability is a very general approach to probability...The frequentist approach requires that all probabilities be defined by connection to countable events and their frequencies in very large samples." And the author pointed out "...This leads to frequentist uncertainty being premised on imaginary resampling of data— if we were to repeat the measurement many many times, we would end up collecting a list of values that will have some pattern to it. It means also that parameters and models cannot have probability distributions, only measurements can. The distribution of these measurements is called a sampling distribution. This resampling is never done, and in general it doesn’t even make sense..." </span>
<span id="cb795-127"><a href="#cb795-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-128"><a href="#cb795-128" aria-hidden="true" tabindex="-1"></a>He also quoted "one of the most important frequentist statisticians of the 20^th^ century," Sir Ronald Fisher:</span>
<span id="cb795-129"><a href="#cb795-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-130"><a href="#cb795-130" aria-hidden="true" tabindex="-1"></a>"<span class="co">[</span><span class="ot">...</span><span class="co">]</span> the only populations that can be referred to in a test of significance have no objective reality, being exclusively the product of the statistician’s imagination <span class="co">[</span><span class="ot">...</span><span class="co">]</span>"</span>
<span id="cb795-131"><a href="#cb795-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-132"><a href="#cb795-132" aria-hidden="true" tabindex="-1"></a>But, Fisher's criticism was already rebuked by his contemporary Professor Egon Pearson in his <span class="co">[</span><span class="ot">"Statistical Concepts in Their Relation to Reality"</span><span class="co">](https://errorstatistics.files.wordpress.com/2021/02/pearson_1955-stat-concepts-reality.pdf)</span>. Pearson said:</span>
<span id="cb795-133"><a href="#cb795-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-134"><a href="#cb795-134" aria-hidden="true" tabindex="-1"></a>"...If probability is to be justly applied to the analysis of data, it follows that a random process must have been introduced or been naturally present at some stage in the collection of these data. Is there not then an appeal to the imagination in taking as the hypothetical population of samples that which would have been generated by repetition of this random process?..."</span>
<span id="cb795-135"><a href="#cb795-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-136"><a href="#cb795-136" aria-hidden="true" tabindex="-1"></a>According to Pearson, Fisher was "often tilting at views which those whom he attacks have never held." And I can use Pearson's argument to address the "telescope" example given by the author.</span>
<span id="cb795-137"><a href="#cb795-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-138"><a href="#cb795-138" aria-hidden="true" tabindex="-1"></a>"...Since the telescope was primitive, it couldn’t really focus the image very well. Saturn always appeared blurred. This is a statistical problem, of a sort. There’s uncertainty about the planet’s shape, but notice that none of the uncertainty is a result of variation in repeat measurements. We could look through the telescope a thousand times, and it will always give the same blurred image (for any given position of the Earth and Saturn). So the sampling distribution of any measurement is constant, because the measurement is deterministic— there’s nothing “random” about it. Frequentist statistical inference has a lot of trouble getting started here..."</span>
<span id="cb795-139"><a href="#cb795-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-140"><a href="#cb795-140" aria-hidden="true" tabindex="-1"></a>I think, like Fisher, the author is also "tilting at views" which frequentists have never held. The problem with the telescope example is that repeated measurements were done on "ONE" sample only. That's why he made assumption that "...none of the uncertainty is a result of variation in repeat measurements...So the sampling distribution of any measurement is constant, because the measurement is deterministic— there’s nothing “random” about it." I have yet to see a research that only measures "one" sample repeatedly to solve a research question at population level or in real-world situations. It would be akin to asking a single child- using different sets of questions- repeatedly about what the child eats in a day to know the dietary pattern of all the children in the region. It makes no sense. Furthermore, sample representativeness play a major role in such researches. The author representation of a frequentist research has no place for sample representativeness- there is only one sample and nothing else. </span>
<span id="cb795-141"><a href="#cb795-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-142"><a href="#cb795-142" aria-hidden="true" tabindex="-1"></a>The author also criticized about "imagined repeat sampling." If taken out of context, such idea can be quite preposterous. But, it can actually be logical if we explain it in terms of sample representativeness. We are not imagining repeated sampling- beyond our chosen sample sets- to justify the results from our samples are applicable to the population. For example, if we were to study the dietary pattern of an ethnic group reside in the mountain, we do not need to ask dietary-related questions to every individual in the group. We select a fraction of the group- chosen at random- to infer the dietary pattern of the whole group. Such fraction (samples) should be high enough in number and have traits similar to the whole group. If results obtained from samples said "fish constitutes only a small part of their diet," then we can assume that we will have the same result if we did the same survey repeatedly with different sample sets obtained from the group. In this case, the so-called "imagined repeat sampling" can work because samples are representative of the population.  </span>
<span id="cb795-143"><a href="#cb795-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-144"><a href="#cb795-144" aria-hidden="true" tabindex="-1"></a>The author continued in the next paragraph that "..even when a Bayesian procedure and frequentist procedure give exactly the same answer, our Bayesian golems aren’t justifying their inferences with imagined repeat sampling." Such narrative can give a result totally opposite of what the author wants. The author wants the readers to "rethinking statistics," by pointing out flaws in the classical statistic tests and research methodology. However, all the examples given by the author can be easily rebuked. More rebuttals will come if such narrative is introduced in a frequestist community- like academics in the nutrition field. But, these academics are not really protecting Karl Popper or E.S. Pearson. They are not defensive about the theories postulated years ago by scientists in the past. They are simply protecting their works- their findings. Majority- if not all- of these academics will not "rethink statistics" if Bayesian approach begins with denouncing the frequentist approach, especially when counter-arguments can easily be made. It will be similar to the author stabbing them with a knife first before offering a treatment. All or most of them will not accept the treatment. They will run away- either scared or hateful. Some may even stab him back. Even if they were forced to accept it, the acceptance would be superficial. Instead, we should offer them beautiful roses with exquisite scent- meaning we should focus on what Bayesian analysis can offer which frequentist apporach can't, rather than attacking them. The thorns may still prick their fingers, but they will not be able to resist the charm of the roses. And we can offer them balm to soothe their fingers. They will be thankful, and meaningful collaborations will be made.   </span>
<span id="cb795-145"><a href="#cb795-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-146"><a href="#cb795-146" aria-hidden="true" tabindex="-1"></a><span class="fu">### *Multilevel models*</span></span>
<span id="cb795-147"><a href="#cb795-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-148"><a href="#cb795-148" aria-hidden="true" tabindex="-1"></a>The author introduced the concept of multilevel model in this section. Statistical models "contain parameters. And parameters support inference. Upon what do parameters themselves stand? Sometimes, in some of the most powerful models, it’s parameters all the way down. What this means is that any particular parameter can be usefully regarded as a placeholder for a missing model. Given some model of how the parameter gets its value, it is simple enough to embed the new model inside the old one. This results in a model with multiple levels of uncertainty, each feeding into the next—a multilevel model."</span>
<span id="cb795-149"><a href="#cb795-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-150"><a href="#cb795-150" aria-hidden="true" tabindex="-1"></a>The author also mentioned "four typical and complementary reasons to sue multilevel models:"</span>
<span id="cb795-151"><a href="#cb795-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-152"><a href="#cb795-152" aria-hidden="true" tabindex="-1"></a>(1) ***To adjust estimates for repeat sampling.*** When more than one observation arises from the same individual, location, or time, then traditional, single-level models may mislead us.</span>
<span id="cb795-153"><a href="#cb795-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-154"><a href="#cb795-154" aria-hidden="true" tabindex="-1"></a>(2) ***To adjust estimates for imbalance in sampling.*** When some individuals,locations,or times are sampled more than others, we may also be misled by single-level models.</span>
<span id="cb795-155"><a href="#cb795-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-156"><a href="#cb795-156" aria-hidden="true" tabindex="-1"></a>(3) ***To study variation.*** If our research questions include variation among individuals or other groups within the data, then multilevel models are a big help, because they model variation explicitly.</span>
<span id="cb795-157"><a href="#cb795-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-158"><a href="#cb795-158" aria-hidden="true" tabindex="-1"></a>(4) ***To avoid averaging.*** Frequently, scholars pre-average some data to construct variables for a regression analysis. This can be dangerous, because averaging removes variation. It therefore manufactures false confidence. Multilevel models allow us to preserve the uncertainty in the original, pre-averaged values, while still using the average to make predictions.</span>
<span id="cb795-159"><a href="#cb795-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-160"><a href="#cb795-160" aria-hidden="true" tabindex="-1"></a>And there are also "diverse model types that turn out to be multilevel: models for missing data (imputation), measurement error, factor analysis, some time series models, types of spatial and network regression, and phylogenetic regressions all are special applications of the multilevel strategy."</span>
<span id="cb795-161"><a href="#cb795-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-162"><a href="#cb795-162" aria-hidden="true" tabindex="-1"></a>The author added "this is why grasping the concept of multilevel modeling may lead to a perspective shift. Suddenly single- level models end up looking like mere components of multilevel models. The multilevel strategy provides an engineering principle to help us to introduce these components into a particular analysis, exactly where we think we need them."</span>
<span id="cb795-163"><a href="#cb795-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-164"><a href="#cb795-164" aria-hidden="true" tabindex="-1"></a>Based on the author's explanation, multilevel models sound really promising, and I'm eager to learn more about them.</span>
<span id="cb795-165"><a href="#cb795-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-166"><a href="#cb795-166" aria-hidden="true" tabindex="-1"></a><span class="fu">### *Model comparison and information criteria*</span></span>
<span id="cb795-167"><a href="#cb795-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-168"><a href="#cb795-168" aria-hidden="true" tabindex="-1"></a>Information criteria were developed to compare "structurally different models based upon future predictive accuracy, using different approximations for different model types."</span>
<span id="cb795-169"><a href="#cb795-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-170"><a href="#cb795-170" aria-hidden="true" tabindex="-1"></a>Popular information criterion AIC, and related metrics- such as DIC and WAIC- "explicitly build a model of the prediction task and use that model to estimate performance of each model you might wish to compare. Because the prediction is modeled, it depends upon assumptions. So information criteria do not in fact achieve the impossible, by seeing the future. They are still golems." The author also mentioned that they are known as "information criteria, because they develop their measure of model accuracy from information theory."</span>
<span id="cb795-171"><a href="#cb795-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-172"><a href="#cb795-172" aria-hidden="true" tabindex="-1"></a>These criteria can help researchers with two common difficulties in model comparison:</span>
<span id="cb795-173"><a href="#cb795-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-174"><a href="#cb795-174" aria-hidden="true" tabindex="-1"></a>(1)  ***Overfitting.*** Future data will not be exactly like past data, and so any model that is unaware of this fact tends to make worse predictions than it could. So if we wish to make good predictions, we cannot judge our models simply on how well they fit our data. Information criteria provide estimates of predictive accuracy, rather than merely fit. So they compare models where it matters.</span>
<span id="cb795-175"><a href="#cb795-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-176"><a href="#cb795-176" aria-hidden="true" tabindex="-1"></a>(2) ***Comparison of multiple non-null models to the same data.*** Frequently, several plausible models of a phenomenon are known to us. In some empirical contexts, like social networks and evolutionary phylogenies, there are no reasonable or uniquely “null” models. This was also true of the neutral evolution example. In such cases, it’s not only a good idea to explicitly compare models. It’s also mandatory. Information criteria aren’t the only way to conduct the comparison. But they are an accessible and widely used way.</span>
<span id="cb795-177"><a href="#cb795-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-178"><a href="#cb795-178" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-179"><a href="#cb795-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-180"><a href="#cb795-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-181"><a href="#cb795-181" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 2: Small Worlds and Large Worlds</span></span>
<span id="cb795-182"><a href="#cb795-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-183"><a href="#cb795-183" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-184"><a href="#cb795-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-185"><a href="#cb795-185" aria-hidden="true" tabindex="-1"></a><span class="fu">## The garden of forking data</span></span>
<span id="cb795-186"><a href="#cb795-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-187"><a href="#cb795-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-188"><a href="#cb795-188" aria-hidden="true" tabindex="-1"></a>"In order to make good inference about what actually happened, it helps to consider everything that could have happened. A Bayesian analysis is a garden of forking data, in which alternative sequences of events are cultivated. As we learn about what did happen, some of these alternative sequences are pruned. In the end, what remains is only what is logically consistent with our knowledge."</span>
<span id="cb795-189"><a href="#cb795-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-190"><a href="#cb795-190" aria-hidden="true" tabindex="-1"></a><span class="fu">### Counting possibilities</span></span>
<span id="cb795-191"><a href="#cb795-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-192"><a href="#cb795-192" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:green"</span><span class="kw">&gt;</span>***A bag of avocado and pear (total 8)***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-193"><a href="#cb795-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-194"><a href="#cb795-194" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Conjectures: (a,a,a,a,a,a,a,a); (p,a,a,a,a,a,a,a); (p,p,a,a,a,a,a,a); (p,p,p,a,a,a,a,a); (p,p,p,p,a,a,a,a);</span>
<span id="cb795-195"><a href="#cb795-195" aria-hidden="true" tabindex="-1"></a>               (p,p,p,p,p,a,a,a); (p,p,p,p,p,p,a,a); (p,p,p,p,p,p,p,a); (p,p,p,p,p,p,p,p)</span>
<span id="cb795-196"><a href="#cb795-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-197"><a href="#cb795-197" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:green"</span><span class="kw">&gt;</span>***Shake the bag to give equal chance and pick 4 fruits; replace the fruit after each pick***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-198"><a href="#cb795-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-199"><a href="#cb795-199" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data: (a,p,a,a)</span>
<span id="cb795-200"><a href="#cb795-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-201"><a href="#cb795-201" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:green"</span><span class="kw">&gt;</span>***Count the possible ways to have that exact data sequence for each conjecture***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-202"><a href="#cb795-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-203"><a href="#cb795-203" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(a,a,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>    8 * 0 * 8 * 8 = 0</span>
<span id="cb795-204"><a href="#cb795-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-205"><a href="#cb795-205" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,a,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>    7 * 1 * 7 * 7 = 343         </span>
<span id="cb795-206"><a href="#cb795-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-207"><a href="#cb795-207" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>    6 * 2 * 6 * 6 = 432</span>
<span id="cb795-208"><a href="#cb795-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-209"><a href="#cb795-209" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>    5 * 3 * 5 * 5 = 375</span>
<span id="cb795-210"><a href="#cb795-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-211"><a href="#cb795-211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,a,a,a,a)       <span class="dv">&amp;rarr;</span>    4 * 4 * 4 * 4 = 256</span>
<span id="cb795-212"><a href="#cb795-212" aria-hidden="true" tabindex="-1"></a>               </span>
<span id="cb795-213"><a href="#cb795-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,a,a,a)       <span class="dv">&amp;rarr;</span>    3 * 5 * 3 * 3 = 135</span>
<span id="cb795-214"><a href="#cb795-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-215"><a href="#cb795-215" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,a,a)       <span class="dv">&amp;rarr;</span>    2 * 6 * 2 * 2 = 48</span>
<span id="cb795-216"><a href="#cb795-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-217"><a href="#cb795-217" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,p,a)       <span class="dv">&amp;rarr;</span>    1 * 7 * 1 * 1 = 7</span>
<span id="cb795-218"><a href="#cb795-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-219"><a href="#cb795-219" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,p,p)       <span class="dv">&amp;rarr;</span>    0 * 8 * 0 * 0 = 0</span>
<span id="cb795-220"><a href="#cb795-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-221"><a href="#cb795-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-222"><a href="#cb795-222" aria-hidden="true" tabindex="-1"></a>"So what good are these counts? By comparing these counts, we have part of a solution for a way to rate the relative plausibility of each conjectured bag composition. But it’s only a part of a solution, because in order to compare these counts we first have to decide how many ways each conjecture could itself be realized. We might argue that when we have no reason to assume otherwise, we can just consider each conjecture equally plausible and compare the counts directly. But often we do have reason to assume otherwise."</span>
<span id="cb795-223"><a href="#cb795-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-224"><a href="#cb795-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-225"><a href="#cb795-225" aria-hidden="true" tabindex="-1"></a><span class="fu">### Using prior information </span></span>
<span id="cb795-226"><a href="#cb795-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-227"><a href="#cb795-227" aria-hidden="true" tabindex="-1"></a>Two possible choices to incorporate prior information: add a new layer to the garden or multiply prior count by the new count. "It turns out that these two methods are mathematically identical, as long as the new observation is logically independent of the previous observations."</span>
<span id="cb795-228"><a href="#cb795-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-229"><a href="#cb795-229" aria-hidden="true" tabindex="-1"></a>"First we count the numbers of ways each conjecture could produce the new observation. Then we multiply each of these new counts by the previous numbers of ways for each conjecture."</span>
<span id="cb795-230"><a href="#cb795-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-231"><a href="#cb795-231" aria-hidden="true" tabindex="-1"></a>We select one more fruit from the bag. Now the data sequence is "a,p,a,a,p"</span>
<span id="cb795-232"><a href="#cb795-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-233"><a href="#cb795-233" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(a,a,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>       0 * 0 = 0</span>
<span id="cb795-234"><a href="#cb795-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-235"><a href="#cb795-235" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,a,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>     343 * 1 = 343            </span>
<span id="cb795-236"><a href="#cb795-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-237"><a href="#cb795-237" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>     432 * 2 = 864</span>
<span id="cb795-238"><a href="#cb795-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-239"><a href="#cb795-239" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>     375 * 3 = 1125</span>
<span id="cb795-240"><a href="#cb795-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-241"><a href="#cb795-241" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,a,a,a,a)       <span class="dv">&amp;rarr;</span>     256 * 4 = 1024</span>
<span id="cb795-242"><a href="#cb795-242" aria-hidden="true" tabindex="-1"></a>               </span>
<span id="cb795-243"><a href="#cb795-243" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,a,a,a)       <span class="dv">&amp;rarr;</span>     135 * 5 = 675</span>
<span id="cb795-244"><a href="#cb795-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-245"><a href="#cb795-245" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,a,a)       <span class="dv">&amp;rarr;</span>      48 * 6 = 288</span>
<span id="cb795-246"><a href="#cb795-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-247"><a href="#cb795-247" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,p,a)       <span class="dv">&amp;rarr;</span>       7 * 7 = 49</span>
<span id="cb795-248"><a href="#cb795-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-249"><a href="#cb795-249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,p,p)       <span class="dv">&amp;rarr;</span>       0 * 8 = 0</span>
<span id="cb795-250"><a href="#cb795-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-251"><a href="#cb795-251" aria-hidden="true" tabindex="-1"></a>"This updating approach amounts to nothing more than asserting that (1) when we have previous information suggesting there are W~prior~ ways for a conjecture to produce a previous observation D~prior~ and (2) we acquire new observations D~new~ that the same conjecture can produce in W~new~ ways, then (3) the number of ways the conjecture can account for both D~prior~ as well as D~new~ is just the product W~prior~ × W~new~."</span>
<span id="cb795-252"><a href="#cb795-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-253"><a href="#cb795-253" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-254"><a href="#cb795-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-255"><a href="#cb795-255" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Incorporating new data types different from prior data**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-256"><a href="#cb795-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-257"><a href="#cb795-257" aria-hidden="true" tabindex="-1"></a>*New information: There are fewer pears than avocados. For every bag containing 5 pears and 3 avocados, there are two bags containing 4 pears and 4 avocados, three bags containing 5 avocados and 3 pears, and four bags containing 2 pears and 6 avocados. Each bag contains at least 2 pears and 2 avocados.*</span>
<span id="cb795-258"><a href="#cb795-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-259"><a href="#cb795-259" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(a,a,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>       0 * 0 = 0</span>
<span id="cb795-260"><a href="#cb795-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-261"><a href="#cb795-261" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,a,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>     343 * 0 = 0            </span>
<span id="cb795-262"><a href="#cb795-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-263"><a href="#cb795-263" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,a,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>     864 * 4 = 3456</span>
<span id="cb795-264"><a href="#cb795-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-265"><a href="#cb795-265" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,a,a,a,a,a)       <span class="dv">&amp;rarr;</span>    1125 * 3 = 3375</span>
<span id="cb795-266"><a href="#cb795-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-267"><a href="#cb795-267" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,a,a,a,a)       <span class="dv">&amp;rarr;</span>    1024 * 2 = 2048</span>
<span id="cb795-268"><a href="#cb795-268" aria-hidden="true" tabindex="-1"></a>               </span>
<span id="cb795-269"><a href="#cb795-269" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,a,a,a)       <span class="dv">&amp;rarr;</span>     675 * 1 = 675</span>
<span id="cb795-270"><a href="#cb795-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-271"><a href="#cb795-271" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,a,a)       <span class="dv">&amp;rarr;</span>     288 * 0 = 0</span>
<span id="cb795-272"><a href="#cb795-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-273"><a href="#cb795-273" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,p,a)       <span class="dv">&amp;rarr;</span>      49 * 0 = 0</span>
<span id="cb795-274"><a href="#cb795-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-275"><a href="#cb795-275" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(p,p,p,p,p,p,p,p)       <span class="dv">&amp;rarr;</span>       0 * 0 = 0</span>
<span id="cb795-276"><a href="#cb795-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-277"><a href="#cb795-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-278"><a href="#cb795-278" aria-hidden="true" tabindex="-1"></a>I made a mental note in the beginning that the bag contained 4 pears and 4 avocados. Now, using the counting method has gotten me nearer to the truth, but it makes no difference since I will get the wrong answer anyway. The author asked "Is there a threshold difference in these counts at which we can safely decide that one of the conjectures is the correct one?", when one conjecture is barely more possible than the other. I think the answer is no (correct answer is in chapter 3). </span>
<span id="cb795-279"><a href="#cb795-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-280"><a href="#cb795-280" aria-hidden="true" tabindex="-1"></a>"Which assumption should we use, when there is no previous information about the conjectures? The most common solution is to assign an equal number of ways that each conjecture could be correct, before seeing any data. This is sometimes known as the *principle of indifference*: When there is no reason to say that one conjecture is more plausible than another, weigh all of the conjectures equally. The issue of choosing a representation of “ignorance” is surprisingly complicated. The issue will arise again in later chapters. For the sort of problems we examine in this book, the principle of indifference results in inferences very comparable to mainstream non-Bayesian approaches, most of which contain implicit equal weighting of possibilities. For example a typical non-Bayesian confidence interval weighs equally all of the possible values a parameter could take, regardless of how implausible some of them are. Many non-Bayesian procedures have moved away from this, through the use of penalized likelihood and other methods."</span>
<span id="cb795-281"><a href="#cb795-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-282"><a href="#cb795-282" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-283"><a href="#cb795-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-284"><a href="#cb795-284" aria-hidden="true" tabindex="-1"></a><span class="fu">### From counts to probability</span></span>
<span id="cb795-285"><a href="#cb795-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-286"><a href="#cb795-286" aria-hidden="true" tabindex="-1"></a>*If p is the proportion of pear and D~new~ = {a,p,a,a}*</span>
<span id="cb795-287"><a href="#cb795-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-288"><a href="#cb795-288" aria-hidden="true" tabindex="-1"></a>plausibility of p after D~new~ $∝$ ways p can produce D~new~ × prior plausibility of p</span>
<span id="cb795-289"><a href="#cb795-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-290"><a href="#cb795-290" aria-hidden="true" tabindex="-1"></a>"The above just means that for any value p can take, we judge the plausibility of that value p as proportional to the number of ways it can get through the garden of forking data. This expression just summarizes the calculations you did in the tables of the previous section.</span>
<span id="cb795-291"><a href="#cb795-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-292"><a href="#cb795-292" aria-hidden="true" tabindex="-1"></a>Finally, we construct probabilities by standardizing the plausibility so that the sum of the plausibilities for all possible conjectures will be one. All you need to do in order to standardize is to add up all of the products, one for each value p can take, and then divide each product by the sum of products:"</span>
<span id="cb795-293"><a href="#cb795-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-294"><a href="#cb795-294" aria-hidden="true" tabindex="-1"></a>plausibility of p after D~new~ = $\frac{ways~p~can~produce~D~new~ x~ prior~plausibility~p}{sum~of~products}$</span>
<span id="cb795-295"><a href="#cb795-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-296"><a href="#cb795-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-297"><a href="#cb795-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{r table, tidy=FALSE, include=TRUE, echo=FALSE}</span></span>
<span id="cb795-298"><a href="#cb795-298" aria-hidden="true" tabindex="-1"></a>data2 <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">sep=</span><span class="st">"/"</span>, <span class="at">text =</span></span>
<span id="cb795-299"><a href="#cb795-299" aria-hidden="true" tabindex="-1"></a><span class="st">'Possible_composition/ p/ Ways_to_produce_data/ Plausibility</span></span>
<span id="cb795-300"><a href="#cb795-300" aria-hidden="true" tabindex="-1"></a><span class="st"> (a,a,a,a,a,a,a,a)/ 0.00/ 0.00/ 0.00</span></span>
<span id="cb795-301"><a href="#cb795-301" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,a,a,a,a,a,a,a)/ 0.125/ 343/ 0.21         </span></span>
<span id="cb795-302"><a href="#cb795-302" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,p,a,a,a,a,a,a)/ 0.25/ 432/ 0.27</span></span>
<span id="cb795-303"><a href="#cb795-303" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,p,p,a,a,a,a,a)/ 0.375/ 375/ 0.23</span></span>
<span id="cb795-304"><a href="#cb795-304" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,p,p,p,a,a,a,a)/ 0.5/ 256/ 0.16</span></span>
<span id="cb795-305"><a href="#cb795-305" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,p,p,p,p,a,a,a)/ 0.625/ 135/ 0.08</span></span>
<span id="cb795-306"><a href="#cb795-306" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,p,p,p,p,p,a,a)/ 0.75/ 48/ 0.03</span></span>
<span id="cb795-307"><a href="#cb795-307" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,p,p,p,p,p,p,a)/ 0.875/ 7/ 0.004</span></span>
<span id="cb795-308"><a href="#cb795-308" aria-hidden="true" tabindex="-1"></a><span class="st"> (p,p,p,p,p,p,p,p)/ 1/ 0/ 0'</span></span>
<span id="cb795-309"><a href="#cb795-309" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-310"><a href="#cb795-310" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>((data2), <span class="at">booktabs =</span> <span class="cn">TRUE</span>)</span>
<span id="cb795-311"><a href="#cb795-311" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-312"><a href="#cb795-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-313"><a href="#cb795-313" aria-hidden="true" tabindex="-1"></a>OR</span>
<span id="cb795-314"><a href="#cb795-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-317"><a href="#cb795-317" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb795-318"><a href="#cb795-318" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">343</span>, <span class="dv">432</span>, <span class="dv">375</span>, <span class="dv">256</span>, <span class="dv">135</span>, <span class="dv">48</span>, <span class="dv">7</span>, <span class="dv">0</span>)</span>
<span id="cb795-319"><a href="#cb795-319" aria-hidden="true" tabindex="-1"></a>ways<span class="sc">/</span><span class="fu">sum</span>(ways)</span>
<span id="cb795-320"><a href="#cb795-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-321"><a href="#cb795-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-322"><a href="#cb795-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-323"><a href="#cb795-323" aria-hidden="true" tabindex="-1"></a>"These plausibilities are also probabilities— they are non-negative (zero or positive) real numbers that sum to one. And all of the mathematical things you can do with probabilities you can also do with these values. Specifically, each piece of the calculation has a direct partner in applied probability theory. These partners have stereotyped names, so it’s worth learning them, as you’ll see them again and again.</span>
<span id="cb795-324"><a href="#cb795-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-325"><a href="#cb795-325" aria-hidden="true" tabindex="-1"></a>• A conjectured proportion of pears, p, is usually called a parameter value. It’s just a way of indexing possible explanations of the data.</span>
<span id="cb795-326"><a href="#cb795-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-327"><a href="#cb795-327" aria-hidden="true" tabindex="-1"></a>• The relative number of ways that a value p can produce the data is usually called a likelihood. It is derived by enumerating all the possible data sequences that could have happened and then eliminating those sequences inconsistent with the data.</span>
<span id="cb795-328"><a href="#cb795-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-329"><a href="#cb795-329" aria-hidden="true" tabindex="-1"></a>• The prior plausibility of any specific p is usually called the prior probability.</span>
<span id="cb795-330"><a href="#cb795-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-331"><a href="#cb795-331" aria-hidden="true" tabindex="-1"></a>• The new, updated plausibility of any specific p is usually called the posterior</span>
<span id="cb795-332"><a href="#cb795-332" aria-hidden="true" tabindex="-1"></a>probability.</span>
<span id="cb795-333"><a href="#cb795-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-334"><a href="#cb795-334" aria-hidden="true" tabindex="-1"></a>*If we really have shuffled a deck of cards enough to erase any prior knowledge of the ordering- in randomization process-, then the order the cards end up in is very likely to be one of the many orderings with high information entropy.*"</span>
<span id="cb795-335"><a href="#cb795-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-336"><a href="#cb795-336" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-337"><a href="#cb795-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-338"><a href="#cb795-338" aria-hidden="true" tabindex="-1"></a><span class="fu">## Building a model</span></span>
<span id="cb795-339"><a href="#cb795-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-340"><a href="#cb795-340" aria-hidden="true" tabindex="-1"></a>"Designing a simple Bayesian model benefits from a design loop with three steps.</span>
<span id="cb795-341"><a href="#cb795-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-342"><a href="#cb795-342" aria-hidden="true" tabindex="-1"></a>(1) Data story: Motivate the model by narrating how the data might arise.</span>
<span id="cb795-343"><a href="#cb795-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-344"><a href="#cb795-344" aria-hidden="true" tabindex="-1"></a>(2) Update: Educate your model by feeding it the data.</span>
<span id="cb795-345"><a href="#cb795-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-346"><a href="#cb795-346" aria-hidden="true" tabindex="-1"></a>(3) Evaluate: All statistical models require supervision, leading possibly to model revision."</span>
<span id="cb795-347"><a href="#cb795-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-348"><a href="#cb795-348" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-349"><a href="#cb795-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-350"><a href="#cb795-350" aria-hidden="true" tabindex="-1"></a><span class="fu">### A data story</span></span>
<span id="cb795-351"><a href="#cb795-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-352"><a href="#cb795-352" aria-hidden="true" tabindex="-1"></a>"Bayesian data analysis usually means producing a story for how the data came to be. This story may be descriptive, specifying associations that can be used to predict outcomes, given observations. Or it may be causal, a theory of how some events produce other events. Typically, any story you intend to be causal may also be descriptive. But many descriptive stories are hard to interpret causally. But all data stories are complete, in the sense that they are sufficient for specifying an algorithm for simulating new data. </span>
<span id="cb795-353"><a href="#cb795-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-354"><a href="#cb795-354" aria-hidden="true" tabindex="-1"></a>You can motivate your data story by trying to explain how each piece of data is born. This usually means describing aspects of the underlying reality as well as the sampling process.</span>
<span id="cb795-355"><a href="#cb795-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-356"><a href="#cb795-356" aria-hidden="true" tabindex="-1"></a>The data story is then translated into a formal probability model. This probability model is easy to build, because the construction process can be usefully broken down into a series of component decisions."</span>
<span id="cb795-357"><a href="#cb795-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-358"><a href="#cb795-358" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-359"><a href="#cb795-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-360"><a href="#cb795-360" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bayesian updating</span></span>
<span id="cb795-361"><a href="#cb795-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-362"><a href="#cb795-362" aria-hidden="true" tabindex="-1"></a>"A Bayesian model begins with one set of plausibilities assigned to each of these possibilities. These are the prior plausibilities. Then it updates them in light of the data, to produce the posterior plausibilities. This updating process is a kind of learning, called Bayesian updating.</span>
<span id="cb795-363"><a href="#cb795-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-364"><a href="#cb795-364" aria-hidden="true" tabindex="-1"></a>Notice that every updated set of plausibilities becomes the initial plausibilities for the next observation. Every conclusion is the starting point for future inference. However, this updating process works backwards, as well as forwards. Knowing the final observation, it is possible to mathematically divide out the observation, to infer the previous plausibility curve. So the data could be presented to your model in any order, or all at once even. In most cases, you will present the data all at once, for the sake of convenience. But it’s important to realize that this merely represents abbreviation of an iterated learning process.</span>
<span id="cb795-365"><a href="#cb795-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-366"><a href="#cb795-366" aria-hidden="true" tabindex="-1"></a>Bayesian estimates are valid for any sample size. This does not mean that more data isn’t helpful—it certainly is. Rather, the estimates have a clear and valid interpretation, no matter the sample size. But the price for this power is dependency upon the initial estimates, the prior. If the prior is a bad one, then the resulting inference will be misleading."</span>
<span id="cb795-367"><a href="#cb795-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-368"><a href="#cb795-368" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-369"><a href="#cb795-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-370"><a href="#cb795-370" aria-hidden="true" tabindex="-1"></a><span class="fu">### Evaluate</span></span>
<span id="cb795-371"><a href="#cb795-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-372"><a href="#cb795-372" aria-hidden="true" tabindex="-1"></a>"If there are important differences between the model and reality, then there is no logical guarantee of large world performance. And even if the two worlds did match, any particular sample of data could still be misleading. So it’s worth keeping in mind at least two cautious principles: (1) the model’s certainty is no guarantee that the model is a good one and (2) it is important to supervise and critique your model’s work.</span>
<span id="cb795-373"><a href="#cb795-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-374"><a href="#cb795-374" aria-hidden="true" tabindex="-1"></a>Note that the goal is not to test the truth value of the model’s assumptions. All manner of small world assumptions about error distributions and the like can be violated in the large world, but a model may still produce a perfectly useful estimate. Instead, the objective is to check the model’s adequacy for some purpose. This usually means asking and answering additional questions, beyond those that originally constructed the model."</span>
<span id="cb795-375"><a href="#cb795-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-376"><a href="#cb795-376" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-377"><a href="#cb795-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-378"><a href="#cb795-378" aria-hidden="true" tabindex="-1"></a><span class="fu">## Components of the model</span></span>
<span id="cb795-379"><a href="#cb795-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-380"><a href="#cb795-380" aria-hidden="true" tabindex="-1"></a>"The usual way we build a statistical model involves choosing distributions and devices for each that represent the relative numbers of ways things can happen. These distributions and devices are </span>
<span id="cb795-381"><a href="#cb795-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-382"><a href="#cb795-382" aria-hidden="true" tabindex="-1"></a>(1) a likelihood function- the number of ways each conjecture could produce an observation</span>
<span id="cb795-383"><a href="#cb795-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-384"><a href="#cb795-384" aria-hidden="true" tabindex="-1"></a>(2) one or more parameters- the accumulated number of ways each conjecture could produce the entire data</span>
<span id="cb795-385"><a href="#cb795-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-386"><a href="#cb795-386" aria-hidden="true" tabindex="-1"></a>(3) a prior- the initial plausibility of each conjectured cause of the data"</span>
<span id="cb795-387"><a href="#cb795-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-388"><a href="#cb795-388" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-389"><a href="#cb795-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-390"><a href="#cb795-390" aria-hidden="true" tabindex="-1"></a><span class="fu">### Likelihood</span></span>
<span id="cb795-391"><a href="#cb795-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-392"><a href="#cb795-392" aria-hidden="true" tabindex="-1"></a>"The likelihood is a mathematical formula that specifies the plausibility of the data. What this means is that the likelihood maps each conjecture onto the relative number of ways the data could occur, given that possibility."</span>
<span id="cb795-393"><a href="#cb795-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-394"><a href="#cb795-394" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Binomial distribution**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-395"><a href="#cb795-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-396"><a href="#cb795-396" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>each event is independent of other events</span>
<span id="cb795-397"><a href="#cb795-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-398"><a href="#cb795-398" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the probability of "an observation" is the same on every event</span>
<span id="cb795-399"><a href="#cb795-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-400"><a href="#cb795-400" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>the common "coin tossing" distribution where there is only two possible answers (e.g., land or water in globe example; failure or success, etc.)</span>
<span id="cb795-401"><a href="#cb795-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-402"><a href="#cb795-402" aria-hidden="true" tabindex="-1"></a>In the given globe example, there are two possible outcomes: either land or water. Out of 9 tosses (n), 6 tosses land on water. The probability of getting water (p) is the same (0.5%) on every toss. Then, we can use binomial distribution formula in R to compute the "likelihood of data w (water)- 6 W's in 9 tosses- under any value of p with":</span>
<span id="cb795-403"><a href="#cb795-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-406"><a href="#cb795-406" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb795-407"><a href="#cb795-407" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>( <span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> <span class="fl">0.5</span>)</span>
<span id="cb795-408"><a href="#cb795-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-409"><a href="#cb795-409" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-410"><a href="#cb795-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-411"><a href="#cb795-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-412"><a href="#cb795-412" aria-hidden="true" tabindex="-1"></a>If probability for getting water is 0.2,</span>
<span id="cb795-413"><a href="#cb795-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-414"><a href="#cb795-414" aria-hidden="true" tabindex="-1"></a><span class="in">``` {r}</span></span>
<span id="cb795-415"><a href="#cb795-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-416"><a href="#cb795-416" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> <span class="fl">0.2</span>)</span>
<span id="cb795-417"><a href="#cb795-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-418"><a href="#cb795-418" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-419"><a href="#cb795-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-420"><a href="#cb795-420" aria-hidden="true" tabindex="-1"></a>*"The job of the likelihood is to tell us the relative number of ways to see the data w, given values for p and n."*</span>
<span id="cb795-421"><a href="#cb795-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-422"><a href="#cb795-422" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-423"><a href="#cb795-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-424"><a href="#cb795-424" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parameters</span></span>
<span id="cb795-425"><a href="#cb795-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-426"><a href="#cb795-426" aria-hidden="true" tabindex="-1"></a>"It is typical to conceive of data and parameters as completely different kinds of entities. Data are measured and known; parameters are unknown and must be estimated from data. Usefully, in the Bayesian framework the distinction between a datum and a parameter is fuzzy. A datum can be recast as a very narrow probability density for a parameter, and a parameter as a datum with uncertainty. This continuity between certainty (data) and uncertainty (parameters) can be exploited (Ch 14) to incorporate measurement error and missing data into your modeling.</span>
<span id="cb795-427"><a href="#cb795-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-428"><a href="#cb795-428" aria-hidden="true" tabindex="-1"></a>In globe tossing example, n and w are data, and p is unknown parameter. Your Bayesian machine can tell you what the data say about any parameter, once you tell it the likelihood and which bits have been observed. In some cases, the golem will just tell you that not much can be learned—Bayesian data analysis isn’t magic, after all. But it is usually an advance to learn that our data don’t discriminate among the possibilities."</span>
<span id="cb795-429"><a href="#cb795-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-430"><a href="#cb795-430" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-431"><a href="#cb795-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-432"><a href="#cb795-432" aria-hidden="true" tabindex="-1"></a><span class="fu">### Prior</span></span>
<span id="cb795-433"><a href="#cb795-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-434"><a href="#cb795-434" aria-hidden="true" tabindex="-1"></a>"A Bayesian machine must have an initial plausibility assignment for each possible value of the parameter. The prior is this initial set of plausibilities. Priors are useful for constraining parameters to reasonable ranges, as well as for expressing any knowledge we have about the parameter, before any data are observed.</span>
<span id="cb795-435"><a href="#cb795-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-436"><a href="#cb795-436" aria-hidden="true" tabindex="-1"></a>Within Bayesian data analysis in the natural and social sciences, the prior is considered to be just part of the model. As such it should be chosen, evaluated, and revised just like all of the other components of the model. In practice, the subjectivist and the non-subjectivist will often analyze data in nearly the same way.</span>
<span id="cb795-437"><a href="#cb795-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-438"><a href="#cb795-438" aria-hidden="true" tabindex="-1"></a>If you don’t have a strong argument for any particular prior, then try different ones. Because the prior is an assumption, it should be interrogated like other assumptions: by altering it and checking how sensitive inference is to the assumption."</span>
<span id="cb795-439"><a href="#cb795-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-440"><a href="#cb795-440" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-441"><a href="#cb795-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-442"><a href="#cb795-442" aria-hidden="true" tabindex="-1"></a><span class="fu">### Posterior</span></span>
<span id="cb795-443"><a href="#cb795-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-444"><a href="#cb795-444" aria-hidden="true" tabindex="-1"></a>"Once you have chosen a likelihood, which parameters are to be estimated, and a prior for each parameter, a Bayesian model treats the estimates as a purely logical consequence of those assumptions. For every unique combination of data, likelihood, parameters, and prior, there is a unique set of estimates. The resulting estimates—the relative plausibility of different parameter values, conditional on the data—are known as the posterior distribution. The posterior distribution takes the form of the probability of the parameters, conditional on the data: <span class="in">`Pr(p|n, w).`</span></span>
<span id="cb795-445"><a href="#cb795-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-446"><a href="#cb795-446" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Bayes Theorem**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-447"><a href="#cb795-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-448"><a href="#cb795-448" aria-hidden="true" tabindex="-1"></a>The mathematical procedure that defines the logic of the posterior distribution is Bayes’ theorem. The joint probability of the data w and any particular value of p is: <span class="in">`Pr(w, p) = Pr(w|p) Pr(p)`</span>- the probability of w and p is the product of likelihood Pr(w|p) and the prior probability Pr(p)."</span>
<span id="cb795-449"><a href="#cb795-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-450"><a href="#cb795-450" aria-hidden="true" tabindex="-1"></a>Example- the probability of mango both sweet and yellow is equal to the probability that mango is sweet given that it is yellow, multiplies by the probability that it is yellow: <span class="in">`Pr(s, y) = Pr(s|y) Pr(y)`</span></span>
<span id="cb795-451"><a href="#cb795-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-452"><a href="#cb795-452" aria-hidden="true" tabindex="-1"></a>OR the probability of mango both sweet and yellow is equal to the probability that mango is yellow given that it is sweet, multiplies by the probability that it is sweet: <span class="in">`Pr(s, y) = Pr(y|s) Pr(s)`</span></span>
<span id="cb795-453"><a href="#cb795-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-454"><a href="#cb795-454" aria-hidden="true" tabindex="-1"></a>Now since both right-hand sides are equal to the same thing, we can set them equal to one another and solve for the posterior probability: Pr(s|y) = $\frac{Pr(y|s)~Pr(s)}{Pr(y)}$</span>
<span id="cb795-455"><a href="#cb795-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-456"><a href="#cb795-456" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;</span>***Bayes' theorem***<span class="kw">&lt;/span&gt;</span>: the probability of any particular value of p, considering the data, is equal to the product of the likelihood and prior, divided by this thing Pr(w), which I’ll call the *average likelihood*. In word form:</span>
<span id="cb795-457"><a href="#cb795-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-458"><a href="#cb795-458" aria-hidden="true" tabindex="-1"></a>$$\text{Posterior =}\frac{\text{Likelihood x Prior}}{\text{Average Likelihood}}$$</span>
<span id="cb795-459"><a href="#cb795-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-460"><a href="#cb795-460" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;</span>***Average Likelihood:***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-461"><a href="#cb795-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-462"><a href="#cb795-462" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>commonly called "evidence" or "probability of the data"</span>
<span id="cb795-463"><a href="#cb795-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-464"><a href="#cb795-464" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Likelihood of the data averaged over the prior</span>
<span id="cb795-465"><a href="#cb795-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-466"><a href="#cb795-466" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>To standardize the posterior, to ensure it sums (integrates) to one </span>
<span id="cb795-467"><a href="#cb795-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-468"><a href="#cb795-468" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-469"><a href="#cb795-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-470"><a href="#cb795-470" aria-hidden="true" tabindex="-1"></a><span class="fu">## Making the model go </span></span>
<span id="cb795-471"><a href="#cb795-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-472"><a href="#cb795-472" aria-hidden="true" tabindex="-1"></a>"Bayesian model is a machine, a figurative golem. It has built-in definitions for the likelihood, the parameters, and the prior. And then at its heart lies a motor that processes data, producing a posterior distribution. The action of this motor can be thought of as conditioning the prior on the data.</span>
<span id="cb795-473"><a href="#cb795-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-474"><a href="#cb795-474" aria-hidden="true" tabindex="-1"></a>Three different conditioning engines, numerical techniques for computing posterior distributions, that can accommodate whichever prior is most useful for inference:</span>
<span id="cb795-475"><a href="#cb795-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-476"><a href="#cb795-476" aria-hidden="true" tabindex="-1"></a>(1) Grid approximation</span>
<span id="cb795-477"><a href="#cb795-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-478"><a href="#cb795-478" aria-hidden="true" tabindex="-1"></a>(2) Quadratic approximation</span>
<span id="cb795-479"><a href="#cb795-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-480"><a href="#cb795-480" aria-hidden="true" tabindex="-1"></a>(3) Markov chain Monte Carlo (MCMC)"</span>
<span id="cb795-481"><a href="#cb795-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-482"><a href="#cb795-482" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-483"><a href="#cb795-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-484"><a href="#cb795-484" aria-hidden="true" tabindex="-1"></a><span class="fu">### Grid approximation</span></span>
<span id="cb795-485"><a href="#cb795-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-486"><a href="#cb795-486" aria-hidden="true" tabindex="-1"></a>While most parameters are continuous, capable of taking on an infinite number of values, it turns out that we can achieve an excellent approximation of the continuous posterior distribution by considering only a finite grid of parameter values. At any particular value of a parameter, p′, it’s a simple matter to compute the posterior probability: just multiply the prior probability of p′ by the likelihood at p′. Repeating this procedure for each value in the grid generates an approximate picture of the exact posterior distribution. This procedure is called grid approximation. </span>
<span id="cb795-487"><a href="#cb795-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-488"><a href="#cb795-488" aria-hidden="true" tabindex="-1"></a>But in most of your real modeling, grid approximation isn’t practical. The reason is that it scales very poorly, as the number of parameters increases. </span>
<span id="cb795-489"><a href="#cb795-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-490"><a href="#cb795-490" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Building a grid approximation**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-491"><a href="#cb795-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-492"><a href="#cb795-492" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Define the grid- decide how many points to use in estimating the posterior, and then make a list of the parameter values on the grid. </span>
<span id="cb795-493"><a href="#cb795-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-494"><a href="#cb795-494" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Compute the value of the prior at each parameter value on the grid.</span>
<span id="cb795-495"><a href="#cb795-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-496"><a href="#cb795-496" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Compute the likelihood at each parameter value.</span>
<span id="cb795-497"><a href="#cb795-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-498"><a href="#cb795-498" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Compute the unstandardized posterior at each parameter value, by multiplying the prior by the likelihood.</span>
<span id="cb795-499"><a href="#cb795-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-500"><a href="#cb795-500" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Finally, standardize the posterior, by dividing each value by the sum of all values.</span>
<span id="cb795-501"><a href="#cb795-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-502"><a href="#cb795-502" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-503"><a href="#cb795-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-504"><a href="#cb795-504" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Building a grid approximation for globe tossing example***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-505"><a href="#cb795-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-506"><a href="#cb795-506" aria-hidden="true" tabindex="-1"></a><span class="in">``` {r globe tossing example}</span></span>
<span id="cb795-507"><a href="#cb795-507" aria-hidden="true" tabindex="-1"></a><span class="co"># define grid</span></span>
<span id="cb795-508"><a href="#cb795-508" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">0</span> , <span class="at">to=</span><span class="dv">1</span> , <span class="at">length.out=</span><span class="dv">20</span> )</span>
<span id="cb795-509"><a href="#cb795-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-510"><a href="#cb795-510" aria-hidden="true" tabindex="-1"></a><span class="co"># define prior</span></span>
<span id="cb795-511"><a href="#cb795-511" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>( <span class="dv">1</span> , <span class="dv">20</span> )</span>
<span id="cb795-512"><a href="#cb795-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-513"><a href="#cb795-513" aria-hidden="true" tabindex="-1"></a><span class="co"># compute likelihood at each value in grid</span></span>
<span id="cb795-514"><a href="#cb795-514" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>( <span class="dv">6</span> , <span class="at">size=</span><span class="dv">9</span> , <span class="at">prob=</span>p_grid )</span>
<span id="cb795-515"><a href="#cb795-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-516"><a href="#cb795-516" aria-hidden="true" tabindex="-1"></a><span class="co"># compute product of likelihood and prior</span></span>
<span id="cb795-517"><a href="#cb795-517" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-518"><a href="#cb795-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-519"><a href="#cb795-519" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior, so it sums to 1</span></span>
<span id="cb795-520"><a href="#cb795-520" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-521"><a href="#cb795-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-522"><a href="#cb795-522" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the posterior distribution </span></span>
<span id="cb795-523"><a href="#cb795-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-524"><a href="#cb795-524" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( p_grid , posterior , <span class="at">type=</span><span class="st">"b"</span> ,</span>
<span id="cb795-525"><a href="#cb795-525" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">"probability of water"</span> , <span class="at">ylab=</span><span class="st">"posterior probability"</span> )</span>
<span id="cb795-526"><a href="#cb795-526" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">"20 points"</span> )</span>
<span id="cb795-527"><a href="#cb795-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-528"><a href="#cb795-528" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-529"><a href="#cb795-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-530"><a href="#cb795-530" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-531"><a href="#cb795-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-532"><a href="#cb795-532" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Try with a 5-point grid***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-533"><a href="#cb795-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-534"><a href="#cb795-534" aria-hidden="true" tabindex="-1"></a><span class="in">``` {r 5-point grid}</span></span>
<span id="cb795-535"><a href="#cb795-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-536"><a href="#cb795-536" aria-hidden="true" tabindex="-1"></a><span class="co"># define grid</span></span>
<span id="cb795-537"><a href="#cb795-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-538"><a href="#cb795-538" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">5</span>)</span>
<span id="cb795-539"><a href="#cb795-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-540"><a href="#cb795-540" aria-hidden="true" tabindex="-1"></a><span class="co"># define prior</span></span>
<span id="cb795-541"><a href="#cb795-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-542"><a href="#cb795-542" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">5</span>) <span class="co"># 1 form a uniform prior distribution, assigning equal probability to each value in the grid. Using a decimal here will mean the same but may assume less degree of uncertainty?</span></span>
<span id="cb795-543"><a href="#cb795-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-544"><a href="#cb795-544" aria-hidden="true" tabindex="-1"></a><span class="co"># compute likelihood at each value in the grid</span></span>
<span id="cb795-545"><a href="#cb795-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-546"><a href="#cb795-546" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-547"><a href="#cb795-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-548"><a href="#cb795-548" aria-hidden="true" tabindex="-1"></a><span class="co"># compute product of likelihood and prior</span></span>
<span id="cb795-549"><a href="#cb795-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-550"><a href="#cb795-550" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-551"><a href="#cb795-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-552"><a href="#cb795-552" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior, so it sums to 1</span></span>
<span id="cb795-553"><a href="#cb795-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-554"><a href="#cb795-554" aria-hidden="true" tabindex="-1"></a>std.posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-555"><a href="#cb795-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-556"><a href="#cb795-556" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-557"><a href="#cb795-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-558"><a href="#cb795-558" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, std.posterior, <span class="at">type =</span> <span class="st">"b"</span>,</span>
<span id="cb795-559"><a href="#cb795-559" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior probability"</span>)</span>
<span id="cb795-560"><a href="#cb795-560" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"5 points"</span>)</span>
<span id="cb795-561"><a href="#cb795-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-562"><a href="#cb795-562" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-563"><a href="#cb795-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-564"><a href="#cb795-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-565"><a href="#cb795-565" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-566"><a href="#cb795-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-567"><a href="#cb795-567" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Try with a 100-point grid***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-568"><a href="#cb795-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-569"><a href="#cb795-569" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 100-point grid}</span></span>
<span id="cb795-570"><a href="#cb795-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-571"><a href="#cb795-571" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-572"><a href="#cb795-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-573"><a href="#cb795-573" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb795-574"><a href="#cb795-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-575"><a href="#cb795-575" aria-hidden="true" tabindex="-1"></a><span class="co"># define a prior</span></span>
<span id="cb795-576"><a href="#cb795-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-577"><a href="#cb795-577" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb795-578"><a href="#cb795-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-579"><a href="#cb795-579" aria-hidden="true" tabindex="-1"></a><span class="co"># compute likelihood at each value in grid</span></span>
<span id="cb795-580"><a href="#cb795-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-581"><a href="#cb795-581" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-582"><a href="#cb795-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-583"><a href="#cb795-583" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the unstandardized posterior</span></span>
<span id="cb795-584"><a href="#cb795-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-585"><a href="#cb795-585" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-586"><a href="#cb795-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-587"><a href="#cb795-587" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior </span></span>
<span id="cb795-588"><a href="#cb795-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-589"><a href="#cb795-589" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-590"><a href="#cb795-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-591"><a href="#cb795-591" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior</span></span>
<span id="cb795-592"><a href="#cb795-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-593"><a href="#cb795-593" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"b"</span>,</span>
<span id="cb795-594"><a href="#cb795-594" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-595"><a href="#cb795-595" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"100 points"</span>)</span>
<span id="cb795-596"><a href="#cb795-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-597"><a href="#cb795-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-598"><a href="#cb795-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-599"><a href="#cb795-599" aria-hidden="true" tabindex="-1"></a>*In this simple example, you can go crazy and use 100,000 points, but there won’t be much change in inference after the first 100.*</span>
<span id="cb795-600"><a href="#cb795-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-601"><a href="#cb795-601" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-602"><a href="#cb795-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-603"><a href="#cb795-603" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Try with a step prior***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-604"><a href="#cb795-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-605"><a href="#cb795-605" aria-hidden="true" tabindex="-1"></a><span class="in">```{r step prior}</span></span>
<span id="cb795-606"><a href="#cb795-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-607"><a href="#cb795-607" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-608"><a href="#cb795-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-609"><a href="#cb795-609" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">40</span>)</span>
<span id="cb795-610"><a href="#cb795-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-611"><a href="#cb795-611" aria-hidden="true" tabindex="-1"></a><span class="co"># define a prior</span></span>
<span id="cb795-612"><a href="#cb795-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-613"><a href="#cb795-613" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(p_grid <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co">#ifelse(test, yes, no)</span></span>
<span id="cb795-614"><a href="#cb795-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-615"><a href="#cb795-615" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the likelihood</span></span>
<span id="cb795-616"><a href="#cb795-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-617"><a href="#cb795-617" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-618"><a href="#cb795-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-619"><a href="#cb795-619" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardized posterior</span></span>
<span id="cb795-620"><a href="#cb795-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-621"><a href="#cb795-621" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-622"><a href="#cb795-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-623"><a href="#cb795-623" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-624"><a href="#cb795-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-625"><a href="#cb795-625" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-626"><a href="#cb795-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-627"><a href="#cb795-627" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior</span></span>
<span id="cb795-628"><a href="#cb795-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-629"><a href="#cb795-629" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"o"</span>,</span>
<span id="cb795-630"><a href="#cb795-630" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-631"><a href="#cb795-631" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"40 points"</span>)</span>
<span id="cb795-632"><a href="#cb795-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-633"><a href="#cb795-633" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-634"><a href="#cb795-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-635"><a href="#cb795-635" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-636"><a href="#cb795-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-637"><a href="#cb795-637" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Try with a peaked prior***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-638"><a href="#cb795-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-639"><a href="#cb795-639" aria-hidden="true" tabindex="-1"></a><span class="in">```{r peaked prior}</span></span>
<span id="cb795-640"><a href="#cb795-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-641"><a href="#cb795-641" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-642"><a href="#cb795-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-643"><a href="#cb795-643" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">40</span>)</span>
<span id="cb795-644"><a href="#cb795-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-645"><a href="#cb795-645" aria-hidden="true" tabindex="-1"></a><span class="co"># define a prior</span></span>
<span id="cb795-646"><a href="#cb795-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-647"><a href="#cb795-647" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="dv">5</span><span class="sc">*</span><span class="fu">abs</span>(p_grid <span class="sc">-</span> <span class="fl">0.5</span>))</span>
<span id="cb795-648"><a href="#cb795-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-649"><a href="#cb795-649" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the likelihood</span></span>
<span id="cb795-650"><a href="#cb795-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-651"><a href="#cb795-651" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-652"><a href="#cb795-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-653"><a href="#cb795-653" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardised posterior</span></span>
<span id="cb795-654"><a href="#cb795-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-655"><a href="#cb795-655" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-656"><a href="#cb795-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-657"><a href="#cb795-657" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-658"><a href="#cb795-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-659"><a href="#cb795-659" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-660"><a href="#cb795-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-661"><a href="#cb795-661" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-662"><a href="#cb795-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-663"><a href="#cb795-663" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"b"</span>,</span>
<span id="cb795-664"><a href="#cb795-664" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-665"><a href="#cb795-665" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"40 points"</span>)</span>
<span id="cb795-666"><a href="#cb795-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-667"><a href="#cb795-667" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-668"><a href="#cb795-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-669"><a href="#cb795-669" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-670"><a href="#cb795-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-671"><a href="#cb795-671" aria-hidden="true" tabindex="-1"></a><span class="fu">### Quadratic approximation</span></span>
<span id="cb795-672"><a href="#cb795-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-673"><a href="#cb795-673" aria-hidden="true" tabindex="-1"></a>Under quite general conditions, the region near the peak of the posterior distribution will be nearly Gaussian—or “normal”—in shape. This means the posterior distribution can be usefully approximated by a Gaussian distribution. A Gaussian distribution is convenient, because it can be completely described by only two numbers: the location of its center (mean) and its spread (variance).</span>
<span id="cb795-674"><a href="#cb795-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-675"><a href="#cb795-675" aria-hidden="true" tabindex="-1"></a>A Gaussian approximation is called “quadratic approximation” because the logarithm of a Gaussian distribution forms a parabola. And a parabola is a quadratic function. So this approximation essentially represents any log-posterior with a parabola.</span>
<span id="cb795-676"><a href="#cb795-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-677"><a href="#cb795-677" aria-hidden="true" tabindex="-1"></a>The procedure to carry out quadratic approximation in R contains two steps:</span>
<span id="cb795-678"><a href="#cb795-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-679"><a href="#cb795-679" aria-hidden="true" tabindex="-1"></a>(1) Find the posterior mode. This is usually accomplished by some optimization algorithm, a procedure that virtually “climbs” the posterior distribution, as if it were a mountain. The golem doesn’t know where the peak is, but it does know the slope under its feet. There are many well-developed optimization procedures, most of them more clever than simple hill climbing. But all of them try to find peaks.</span>
<span id="cb795-680"><a href="#cb795-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-681"><a href="#cb795-681" aria-hidden="true" tabindex="-1"></a>(2) Once you find the peak of the posterior, you must estimate the curvature near the peak. This curvature is sufficient to compute a quadratic approximation of the entire posterior distribution. In some cases, these calculations can be done analytically, but usually your computer uses some numerical technique instead.</span>
<span id="cb795-682"><a href="#cb795-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-683"><a href="#cb795-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-684"><a href="#cb795-684" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Compute the quadratic approximation to the globe tossing data***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-685"><a href="#cb795-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-686"><a href="#cb795-686" aria-hidden="true" tabindex="-1"></a><span class="in">```{r quadratic approximation}</span></span>
<span id="cb795-687"><a href="#cb795-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-688"><a href="#cb795-688" aria-hidden="true" tabindex="-1"></a>globe.qa <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(           <span class="co">#  map is maximum a posteriori- the mode of the posterior distribution</span></span>
<span id="cb795-689"><a href="#cb795-689" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-690"><a href="#cb795-690" aria-hidden="true" tabindex="-1"></a>        w <span class="sc">~</span> <span class="fu">dbinom</span>(<span class="dv">9</span>,p) ,  <span class="co"># binomial likelihood</span></span>
<span id="cb795-691"><a href="#cb795-691" aria-hidden="true" tabindex="-1"></a>        p <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">1</span>)     <span class="co"># uniform prior</span></span>
<span id="cb795-692"><a href="#cb795-692" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span><span class="fu">list</span>(<span class="at">w=</span><span class="dv">6</span>) )</span>
<span id="cb795-693"><a href="#cb795-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-694"><a href="#cb795-694" aria-hidden="true" tabindex="-1"></a><span class="co"># display summary of quadratic approximation</span></span>
<span id="cb795-695"><a href="#cb795-695" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( globe.qa )</span>
<span id="cb795-696"><a href="#cb795-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-697"><a href="#cb795-697" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-698"><a href="#cb795-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-699"><a href="#cb795-699" aria-hidden="true" tabindex="-1"></a>*To use map, you provide a formula, a list of data, and a list of start values for the parameters. The formula defines the likelihood and prior.*</span>
<span id="cb795-700"><a href="#cb795-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-701"><a href="#cb795-701" aria-hidden="true" tabindex="-1"></a>The function precis presents a brief summary of the quadratic approximation. In this case, it shows a MAP value of p = 0.67, which it calls the “Mean.” The curvature is labeled “Std- Dev” This stands for standard deviation. This value is the standard deviation of the posterior distribution, while the mean value is its peak. Finally, the last two values in the precis output show the 89% percentile interval. You can read this kind of approximation like: Assuming the posterior is Gaussian, it is maximized at 0.67, and its standard deviation is 0.16.</span>
<span id="cb795-702"><a href="#cb795-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-703"><a href="#cb795-703" aria-hidden="true" tabindex="-1"></a>Since we already know the posterior, let’s compare to see how good the approximation is. I’ll use the analytical approach here, which uses dbeta.</span>
<span id="cb795-704"><a href="#cb795-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-705"><a href="#cb795-705" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dbeta}</span></span>
<span id="cb795-706"><a href="#cb795-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-707"><a href="#cb795-707" aria-hidden="true" tabindex="-1"></a><span class="co"># analytical calculation</span></span>
<span id="cb795-708"><a href="#cb795-708" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="dv">6</span></span>
<span id="cb795-709"><a href="#cb795-709" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">9</span></span>
<span id="cb795-710"><a href="#cb795-710" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dbeta</span>( x , w<span class="sc">+</span><span class="dv">1</span> , n<span class="sc">-</span>w<span class="sc">+</span><span class="dv">1</span> ) , <span class="at">from=</span><span class="dv">0</span> , <span class="at">to=</span><span class="dv">1</span> ) </span>
<span id="cb795-711"><a href="#cb795-711" aria-hidden="true" tabindex="-1"></a><span class="co"># Use Laplace's rule of succession- add one to both w and n-w to avoid assigning zero probability, </span></span>
<span id="cb795-712"><a href="#cb795-712" aria-hidden="true" tabindex="-1"></a><span class="co"># ensure at least there's one w and one n-w, even if none have been observed yet</span></span>
<span id="cb795-713"><a href="#cb795-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-714"><a href="#cb795-714" aria-hidden="true" tabindex="-1"></a><span class="co"># quadratic approximation</span></span>
<span id="cb795-715"><a href="#cb795-715" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dnorm</span>( x , <span class="fl">0.67</span> , <span class="fl">0.16</span> ) , <span class="at">lty=</span><span class="dv">2</span> , <span class="at">add=</span><span class="cn">TRUE</span> )</span>
<span id="cb795-716"><a href="#cb795-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-717"><a href="#cb795-717" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-718"><a href="#cb795-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-719"><a href="#cb795-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-720"><a href="#cb795-720" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Double the sample size***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-721"><a href="#cb795-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-722"><a href="#cb795-722" aria-hidden="true" tabindex="-1"></a><span class="in">```{r quadratic approximation1}</span></span>
<span id="cb795-723"><a href="#cb795-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-724"><a href="#cb795-724" aria-hidden="true" tabindex="-1"></a>globe.qa1 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(           <span class="co">#  map is maximum a posteriori- the mode of the posterior distribution</span></span>
<span id="cb795-725"><a href="#cb795-725" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-726"><a href="#cb795-726" aria-hidden="true" tabindex="-1"></a>        w <span class="sc">~</span> <span class="fu">dbinom</span>(<span class="dv">18</span>,p) ,  <span class="co"># binomial likelihood</span></span>
<span id="cb795-727"><a href="#cb795-727" aria-hidden="true" tabindex="-1"></a>        p <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">1</span>)     <span class="co"># uniform prior</span></span>
<span id="cb795-728"><a href="#cb795-728" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span><span class="fu">list</span>(<span class="at">w=</span><span class="dv">12</span>) )</span>
<span id="cb795-729"><a href="#cb795-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-730"><a href="#cb795-730" aria-hidden="true" tabindex="-1"></a><span class="co"># display summary of quadratic approximation</span></span>
<span id="cb795-731"><a href="#cb795-731" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( globe.qa1 )</span>
<span id="cb795-732"><a href="#cb795-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-733"><a href="#cb795-733" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-734"><a href="#cb795-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-735"><a href="#cb795-735" aria-hidden="true" tabindex="-1"></a><span class="in">```{r increase tosses1}</span></span>
<span id="cb795-736"><a href="#cb795-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-737"><a href="#cb795-737" aria-hidden="true" tabindex="-1"></a><span class="co"># analytical calculation</span></span>
<span id="cb795-738"><a href="#cb795-738" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb795-739"><a href="#cb795-739" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">18</span></span>
<span id="cb795-740"><a href="#cb795-740" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dbeta</span>( x , w<span class="sc">+</span><span class="dv">1</span> , n<span class="sc">-</span>w<span class="sc">+</span><span class="dv">1</span> ) , <span class="at">from=</span><span class="dv">0</span> , <span class="at">to=</span><span class="dv">1</span> )</span>
<span id="cb795-741"><a href="#cb795-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-742"><a href="#cb795-742" aria-hidden="true" tabindex="-1"></a><span class="co"># quadratic approximation</span></span>
<span id="cb795-743"><a href="#cb795-743" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dnorm</span>( x , <span class="fl">0.67</span> , <span class="fl">0.11</span> ) , <span class="at">lty=</span><span class="dv">2</span> , <span class="at">add=</span><span class="cn">TRUE</span> )</span>
<span id="cb795-744"><a href="#cb795-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-745"><a href="#cb795-745" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-746"><a href="#cb795-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-747"><a href="#cb795-747" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Quadruple the sample size***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-748"><a href="#cb795-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-749"><a href="#cb795-749" aria-hidden="true" tabindex="-1"></a><span class="in">```{r quadratic approximation2}</span></span>
<span id="cb795-750"><a href="#cb795-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-751"><a href="#cb795-751" aria-hidden="true" tabindex="-1"></a>globe.qa2 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(           <span class="co">#  map is maximum a posteriori- the mode of the posterior distribution</span></span>
<span id="cb795-752"><a href="#cb795-752" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-753"><a href="#cb795-753" aria-hidden="true" tabindex="-1"></a>        w <span class="sc">~</span> <span class="fu">dbinom</span>(<span class="dv">36</span>,p) ,  <span class="co"># binomial likelihood</span></span>
<span id="cb795-754"><a href="#cb795-754" aria-hidden="true" tabindex="-1"></a>        p <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">1</span>)     <span class="co"># uniform prior</span></span>
<span id="cb795-755"><a href="#cb795-755" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span><span class="fu">list</span>(<span class="at">w=</span><span class="dv">24</span>) )</span>
<span id="cb795-756"><a href="#cb795-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-757"><a href="#cb795-757" aria-hidden="true" tabindex="-1"></a><span class="co"># display summary of quadratic approximation</span></span>
<span id="cb795-758"><a href="#cb795-758" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( globe.qa2 )</span>
<span id="cb795-759"><a href="#cb795-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-760"><a href="#cb795-760" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-761"><a href="#cb795-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-762"><a href="#cb795-762" aria-hidden="true" tabindex="-1"></a><span class="in">```{r increase tosses2}</span></span>
<span id="cb795-763"><a href="#cb795-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-764"><a href="#cb795-764" aria-hidden="true" tabindex="-1"></a><span class="co"># analytical calculation</span></span>
<span id="cb795-765"><a href="#cb795-765" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="dv">24</span></span>
<span id="cb795-766"><a href="#cb795-766" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">36</span></span>
<span id="cb795-767"><a href="#cb795-767" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dbeta</span>( x , w<span class="sc">+</span><span class="dv">1</span> , n<span class="sc">-</span>w<span class="sc">+</span><span class="dv">1</span> ) , <span class="at">from=</span><span class="dv">0</span> , <span class="at">to=</span><span class="dv">1</span> )</span>
<span id="cb795-768"><a href="#cb795-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-769"><a href="#cb795-769" aria-hidden="true" tabindex="-1"></a><span class="co"># quadratic approximation</span></span>
<span id="cb795-770"><a href="#cb795-770" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>( <span class="fu">dnorm</span>( x , <span class="fl">0.67</span> , <span class="fl">0.078</span> ) , <span class="at">lty=</span><span class="dv">2</span> , <span class="at">add=</span><span class="cn">TRUE</span> )</span>
<span id="cb795-771"><a href="#cb795-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-772"><a href="#cb795-772" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-773"><a href="#cb795-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-774"><a href="#cb795-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-775"><a href="#cb795-775" aria-hidden="true" tabindex="-1"></a>This phenomenon, where the quadratic approximation improves with the amount of data, is very common. It’s one of the reasons that so many classical statistical procedures are nervous about small samples: Those procedures use quadratic (or other) approximations that are only known to be safe with infinite data. Often, these approximations are useful with less than infinite data, obviously. But the rate of improvement as sample size increases varies greatly depending upon the details. In some model types, the quadratic approximation can remain terrible even with thousands of samples.</span>
<span id="cb795-776"><a href="#cb795-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-777"><a href="#cb795-777" aria-hidden="true" tabindex="-1"></a>***Maximum likelihood estimation:*** The quadratic approximation, either with a uniform prior or with a lot of data, is usually equivalent to a maximum likelihood estimate (MLE) and its standard error. The MLE is a very common non-Bayesian parameter estimate. This equivalence between a Bayesian approximation and a common non-Bayesian estimator is both a blessing and a curse. It is a blessing, because it allows us to re-interpret a wide range of published non-Bayesian model fits in Bayesian terms. It is a curse, because maximum likelihood estimates have some curious drawbacks.</span>
<span id="cb795-778"><a href="#cb795-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-779"><a href="#cb795-779" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-780"><a href="#cb795-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-781"><a href="#cb795-781" aria-hidden="true" tabindex="-1"></a><span class="fu">### Markov chain Monte Carlo</span></span>
<span id="cb795-782"><a href="#cb795-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-783"><a href="#cb795-783" aria-hidden="true" tabindex="-1"></a>The conceptual challenge with MCMC lies in its highly non-obvious strategy. Instead of attempting to compute or approximate the posterior distribution directly, MCMC techniques merely draw samples from the posterior. You end up with a collection of parameter values, and the frequencies of these values correspond to the posterior plausibilities. You can then build a picture of the posterior from the histogram of these samples.</span>
<span id="cb795-784"><a href="#cb795-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-785"><a href="#cb795-785" aria-hidden="true" tabindex="-1"></a>We nearly always work directly with these samples, rather than first constructing some mathematical estimate from them. And the samples are in many ways more convenient than having the posterior, because they are easier to think with.</span>
<span id="cb795-786"><a href="#cb795-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-787"><a href="#cb795-787" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-788"><a href="#cb795-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-789"><a href="#cb795-789" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice</span></span>
<span id="cb795-790"><a href="#cb795-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-791"><a href="#cb795-791" aria-hidden="true" tabindex="-1"></a><span class="fu">### Easy</span></span>
<span id="cb795-792"><a href="#cb795-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-793"><a href="#cb795-793" aria-hidden="true" tabindex="-1"></a>2E1. (2), (4)</span>
<span id="cb795-794"><a href="#cb795-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-795"><a href="#cb795-795" aria-hidden="true" tabindex="-1"></a>2E2. (3)</span>
<span id="cb795-796"><a href="#cb795-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-797"><a href="#cb795-797" aria-hidden="true" tabindex="-1"></a>2E3. (1), (4)</span>
<span id="cb795-798"><a href="#cb795-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-799"><a href="#cb795-799" aria-hidden="true" tabindex="-1"></a>2E4. In the context of the globe tossing example, "the probability of water is 0.7" means we estimates there is 70% chance of landing on water in the next toss, based on the observed data (the previous tosses). We may as well say 70% of the earth is water. This is a probability, but the "probability does not exist-" our best guess is 70% of earth is water based on previously observed data, but it may or may not reflect reality. If the next toss fell on land, the probability of water would be less than 70% for the subsequent toss. We can get a consistent probability of water after enough tosses, but we cannot say for sure this is the actual distribution of water on earth. Therefore, it remains as a probability. Once we have a concrete measurement of actual percentage of earth covered by water, it becomes an objective reality- a factual statement. At that point, the need for probability ceases.</span>
<span id="cb795-800"><a href="#cb795-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-801"><a href="#cb795-801" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-802"><a href="#cb795-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-803"><a href="#cb795-803" aria-hidden="true" tabindex="-1"></a><span class="fu">### Medium</span></span>
<span id="cb795-804"><a href="#cb795-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-805"><a href="#cb795-805" aria-hidden="true" tabindex="-1"></a>2M1. </span>
<span id="cb795-806"><a href="#cb795-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-807"><a href="#cb795-807" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span> <span class="st">"color: blue"</span><span class="kw">&gt;</span>*(1) W, W, W*<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-808"><a href="#cb795-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-809"><a href="#cb795-809" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 2M11}</span></span>
<span id="cb795-810"><a href="#cb795-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-811"><a href="#cb795-811" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-812"><a href="#cb795-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-813"><a href="#cb795-813" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)  </span>
<span id="cb795-814"><a href="#cb795-814" aria-hidden="true" tabindex="-1"></a><span class="co"># choose 100 coz chapter says not much difference after 100</span></span>
<span id="cb795-815"><a href="#cb795-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-816"><a href="#cb795-816" aria-hidden="true" tabindex="-1"></a><span class="co"># define a uniform prior</span></span>
<span id="cb795-817"><a href="#cb795-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-818"><a href="#cb795-818" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">100</span>) </span>
<span id="cb795-819"><a href="#cb795-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-820"><a href="#cb795-820" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate likelihood</span></span>
<span id="cb795-821"><a href="#cb795-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-822"><a href="#cb795-822" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">3</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-823"><a href="#cb795-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-824"><a href="#cb795-824" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardized posterior</span></span>
<span id="cb795-825"><a href="#cb795-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-826"><a href="#cb795-826" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-827"><a href="#cb795-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-828"><a href="#cb795-828" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-829"><a href="#cb795-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-830"><a href="#cb795-830" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-831"><a href="#cb795-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-832"><a href="#cb795-832" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-833"><a href="#cb795-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-834"><a href="#cb795-834" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb795-835"><a href="#cb795-835" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-836"><a href="#cb795-836" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="st">"100 points"</span>)</span>
<span id="cb795-837"><a href="#cb795-837" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-838"><a href="#cb795-838" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-839"><a href="#cb795-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-840"><a href="#cb795-840" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-841"><a href="#cb795-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-842"><a href="#cb795-842" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span> <span class="st">"color: blue"</span><span class="kw">&gt;</span>*(2) W, W, W, L*<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-843"><a href="#cb795-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-844"><a href="#cb795-844" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 2M12}</span></span>
<span id="cb795-845"><a href="#cb795-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-846"><a href="#cb795-846" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-847"><a href="#cb795-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-848"><a href="#cb795-848" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb795-849"><a href="#cb795-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-850"><a href="#cb795-850" aria-hidden="true" tabindex="-1"></a><span class="co"># define a uniform prior</span></span>
<span id="cb795-851"><a href="#cb795-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-852"><a href="#cb795-852" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">100</span>) </span>
<span id="cb795-853"><a href="#cb795-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-854"><a href="#cb795-854" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate likelihood</span></span>
<span id="cb795-855"><a href="#cb795-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-856"><a href="#cb795-856" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">3</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-857"><a href="#cb795-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-858"><a href="#cb795-858" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardized posterior</span></span>
<span id="cb795-859"><a href="#cb795-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-860"><a href="#cb795-860" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-861"><a href="#cb795-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-862"><a href="#cb795-862" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-863"><a href="#cb795-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-864"><a href="#cb795-864" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-865"><a href="#cb795-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-866"><a href="#cb795-866" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-867"><a href="#cb795-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-868"><a href="#cb795-868" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb795-869"><a href="#cb795-869" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-870"><a href="#cb795-870" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="st">"100 points"</span>)</span>
<span id="cb795-871"><a href="#cb795-871" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-872"><a href="#cb795-872" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-873"><a href="#cb795-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-874"><a href="#cb795-874" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-875"><a href="#cb795-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-876"><a href="#cb795-876" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span> <span class="st">"color: blue"</span><span class="kw">&gt;</span>*(3) L, W, W, L, W, W, W*<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-877"><a href="#cb795-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-878"><a href="#cb795-878" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 2M13}</span></span>
<span id="cb795-879"><a href="#cb795-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-880"><a href="#cb795-880" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-881"><a href="#cb795-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-882"><a href="#cb795-882" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb795-883"><a href="#cb795-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-884"><a href="#cb795-884" aria-hidden="true" tabindex="-1"></a><span class="co"># define a uniform prior</span></span>
<span id="cb795-885"><a href="#cb795-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-886"><a href="#cb795-886" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">100</span>) </span>
<span id="cb795-887"><a href="#cb795-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-888"><a href="#cb795-888" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate likelihood</span></span>
<span id="cb795-889"><a href="#cb795-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-890"><a href="#cb795-890" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">7</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-891"><a href="#cb795-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-892"><a href="#cb795-892" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardized posterior</span></span>
<span id="cb795-893"><a href="#cb795-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-894"><a href="#cb795-894" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-895"><a href="#cb795-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-896"><a href="#cb795-896" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-897"><a href="#cb795-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-898"><a href="#cb795-898" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-899"><a href="#cb795-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-900"><a href="#cb795-900" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-901"><a href="#cb795-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-902"><a href="#cb795-902" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb795-903"><a href="#cb795-903" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-904"><a href="#cb795-904" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="st">"100 points"</span>)</span>
<span id="cb795-905"><a href="#cb795-905" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-906"><a href="#cb795-906" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-907"><a href="#cb795-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-908"><a href="#cb795-908" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-909"><a href="#cb795-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-910"><a href="#cb795-910" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2M2. Assume a prior for p that is equal to zero when p &lt; 0.5 and is a positive constant when p ≥ 0.5. </span></span>
<span id="cb795-911"><a href="#cb795-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-912"><a href="#cb795-912" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span> <span class="st">"color: blue"</span><span class="kw">&gt;</span>*(1) W, W, W*<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-913"><a href="#cb795-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-914"><a href="#cb795-914" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 2M21}</span></span>
<span id="cb795-915"><a href="#cb795-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-916"><a href="#cb795-916" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-917"><a href="#cb795-917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-918"><a href="#cb795-918" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)  </span>
<span id="cb795-919"><a href="#cb795-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-920"><a href="#cb795-920" aria-hidden="true" tabindex="-1"></a><span class="co"># define a  prior</span></span>
<span id="cb795-921"><a href="#cb795-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-922"><a href="#cb795-922" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(p_grid <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>) </span>
<span id="cb795-923"><a href="#cb795-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-924"><a href="#cb795-924" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate likelihood</span></span>
<span id="cb795-925"><a href="#cb795-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-926"><a href="#cb795-926" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">3</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-927"><a href="#cb795-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-928"><a href="#cb795-928" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardized posterior</span></span>
<span id="cb795-929"><a href="#cb795-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-930"><a href="#cb795-930" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-931"><a href="#cb795-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-932"><a href="#cb795-932" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-933"><a href="#cb795-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-934"><a href="#cb795-934" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-935"><a href="#cb795-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-936"><a href="#cb795-936" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-937"><a href="#cb795-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-938"><a href="#cb795-938" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb795-939"><a href="#cb795-939" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-940"><a href="#cb795-940" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="st">"100 points"</span>)</span>
<span id="cb795-941"><a href="#cb795-941" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-942"><a href="#cb795-942" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-943"><a href="#cb795-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-944"><a href="#cb795-944" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-945"><a href="#cb795-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-946"><a href="#cb795-946" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span> <span class="st">"color: blue"</span><span class="kw">&gt;</span>*(2) W, W, W, L*<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-947"><a href="#cb795-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-948"><a href="#cb795-948" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 2M22}</span></span>
<span id="cb795-949"><a href="#cb795-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-950"><a href="#cb795-950" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-951"><a href="#cb795-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-952"><a href="#cb795-952" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb795-953"><a href="#cb795-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-954"><a href="#cb795-954" aria-hidden="true" tabindex="-1"></a><span class="co"># define a prior</span></span>
<span id="cb795-955"><a href="#cb795-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-956"><a href="#cb795-956" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(p_grid <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>)  </span>
<span id="cb795-957"><a href="#cb795-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-958"><a href="#cb795-958" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate likelihood</span></span>
<span id="cb795-959"><a href="#cb795-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-960"><a href="#cb795-960" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">3</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-961"><a href="#cb795-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-962"><a href="#cb795-962" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardized posterior</span></span>
<span id="cb795-963"><a href="#cb795-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-964"><a href="#cb795-964" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-965"><a href="#cb795-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-966"><a href="#cb795-966" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-967"><a href="#cb795-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-968"><a href="#cb795-968" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-969"><a href="#cb795-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-970"><a href="#cb795-970" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-971"><a href="#cb795-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-972"><a href="#cb795-972" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb795-973"><a href="#cb795-973" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-974"><a href="#cb795-974" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="st">"100 points"</span>)</span>
<span id="cb795-975"><a href="#cb795-975" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-976"><a href="#cb795-976" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-977"><a href="#cb795-977" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-978"><a href="#cb795-978" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-979"><a href="#cb795-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-980"><a href="#cb795-980" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span> <span class="st">"color: blue"</span><span class="kw">&gt;</span>*(3) L, W, W, L, W, W, W*<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-981"><a href="#cb795-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-982"><a href="#cb795-982" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 2M23}</span></span>
<span id="cb795-983"><a href="#cb795-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-984"><a href="#cb795-984" aria-hidden="true" tabindex="-1"></a><span class="co"># define a grid</span></span>
<span id="cb795-985"><a href="#cb795-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-986"><a href="#cb795-986" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb795-987"><a href="#cb795-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-988"><a href="#cb795-988" aria-hidden="true" tabindex="-1"></a><span class="co"># define a prior</span></span>
<span id="cb795-989"><a href="#cb795-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-990"><a href="#cb795-990" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(p_grid <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>) </span>
<span id="cb795-991"><a href="#cb795-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-992"><a href="#cb795-992" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate likelihood</span></span>
<span id="cb795-993"><a href="#cb795-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-994"><a href="#cb795-994" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">5</span>, <span class="at">size =</span> <span class="dv">7</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-995"><a href="#cb795-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-996"><a href="#cb795-996" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate unstandardized posterior</span></span>
<span id="cb795-997"><a href="#cb795-997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-998"><a href="#cb795-998" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-999"><a href="#cb795-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1000"><a href="#cb795-1000" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the posterior</span></span>
<span id="cb795-1001"><a href="#cb795-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1002"><a href="#cb795-1002" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-1003"><a href="#cb795-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1004"><a href="#cb795-1004" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the posterior distribution</span></span>
<span id="cb795-1005"><a href="#cb795-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1006"><a href="#cb795-1006" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_grid, posterior, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb795-1007"><a href="#cb795-1007" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">"probability of water"</span>, <span class="at">ylab =</span> <span class="st">"posterior distribution"</span>)</span>
<span id="cb795-1008"><a href="#cb795-1008" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtext</span>(<span class="st">"100 points"</span>)</span>
<span id="cb795-1009"><a href="#cb795-1009" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-1010"><a href="#cb795-1010" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1011"><a href="#cb795-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1012"><a href="#cb795-1012" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1013"><a href="#cb795-1013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1014"><a href="#cb795-1014" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2M3. Suppose there are two globes, one for Earth and one for Mars. The Earth globe is 70% covered in water. The Mars globe is 100% land. Further suppose that one of these globes—you don’t know which—was tossed in the air and produced a “land” observation. Assume that each globe was equally likely to be tossed. Show that the posterior probability that the globe was the Earth, conditional on seeing “land” (Pr(Earth|land)), is 0.23.</span></span>
<span id="cb795-1015"><a href="#cb795-1015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1016"><a href="#cb795-1016" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1017"><a href="#cb795-1017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1018"><a href="#cb795-1018" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability land on earth, given that 70% of earth is water</span></span>
<span id="cb795-1019"><a href="#cb795-1019" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(land|earth) = 0.3</span></span>
<span id="cb795-1020"><a href="#cb795-1020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1021"><a href="#cb795-1021" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of land on mars</span></span>
<span id="cb795-1022"><a href="#cb795-1022" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(land|mars) = 1 </span></span>
<span id="cb795-1023"><a href="#cb795-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1024"><a href="#cb795-1024" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that earth is tossed</span></span>
<span id="cb795-1025"><a href="#cb795-1025" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(earth) = 0.5</span></span>
<span id="cb795-1026"><a href="#cb795-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1027"><a href="#cb795-1027" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that mars is tossed</span></span>
<span id="cb795-1028"><a href="#cb795-1028" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(mars) = 0.5</span></span>
<span id="cb795-1029"><a href="#cb795-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1030"><a href="#cb795-1030" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that it is both land and earth</span></span>
<span id="cb795-1031"><a href="#cb795-1031" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(land, earth) = Pr(land|earth) * Pr(earth)</span></span>
<span id="cb795-1032"><a href="#cb795-1032" aria-hidden="true" tabindex="-1"></a><span class="in">                = 0.3 * 0.5</span></span>
<span id="cb795-1033"><a href="#cb795-1033" aria-hidden="true" tabindex="-1"></a><span class="in">                = 0.15</span></span>
<span id="cb795-1034"><a href="#cb795-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1035"><a href="#cb795-1035" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that it is both land and mars</span></span>
<span id="cb795-1036"><a href="#cb795-1036" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(land, mars) = Pr(land|mars) * Pr(mars)</span></span>
<span id="cb795-1037"><a href="#cb795-1037" aria-hidden="true" tabindex="-1"></a><span class="in">               = 1 * 0.5</span></span>
<span id="cb795-1038"><a href="#cb795-1038" aria-hidden="true" tabindex="-1"></a><span class="in">               = 0.5</span></span>
<span id="cb795-1039"><a href="#cb795-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1040"><a href="#cb795-1040" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability of land in all possible scenarios (both on earth and mars)</span></span>
<span id="cb795-1041"><a href="#cb795-1041" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(land) = Pr(land, earth) + Pr(land, mars)</span></span>
<span id="cb795-1042"><a href="#cb795-1042" aria-hidden="true" tabindex="-1"></a><span class="in">         = 0.15 + 0.5</span></span>
<span id="cb795-1043"><a href="#cb795-1043" aria-hidden="true" tabindex="-1"></a><span class="in">         = 0.65</span></span>
<span id="cb795-1044"><a href="#cb795-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1045"><a href="#cb795-1045" aria-hidden="true" tabindex="-1"></a><span class="in"># Find the probability of earth, conditional on seeing land</span></span>
<span id="cb795-1046"><a href="#cb795-1046" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(earth|land) = (Pr(land|earth) * Pr(earth))/ Pr(land)</span></span>
<span id="cb795-1047"><a href="#cb795-1047" aria-hidden="true" tabindex="-1"></a><span class="in">               = (0.3 * 0.5)/ 0.65</span></span>
<span id="cb795-1048"><a href="#cb795-1048" aria-hidden="true" tabindex="-1"></a><span class="in">               = 0.2307692</span></span>
<span id="cb795-1049"><a href="#cb795-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1050"><a href="#cb795-1050" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1051"><a href="#cb795-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1052"><a href="#cb795-1052" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1053"><a href="#cb795-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1054"><a href="#cb795-1054" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2M4. Suppose you have a deck with only three cards. Each card has two sides, and each side is either black or white. One card has two black sides. The second card has one black and one white side. The third card has two white sides. Now suppose all three cards are placed in a bag and shuffled. Someone reaches into the bag and pulls out a card and places it flat on a table. A black side is shown facing up, but you don’t know the color of the side facing down. Show that the probability that the other side is also black is 2/3. Use the counting method (Section 2 of the chapter) to approach this problem. This means counting up the ways that each card could produce the observed data (a black side facing up on the table).</span></span>
<span id="cb795-1055"><a href="#cb795-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1056"><a href="#cb795-1056" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1057"><a href="#cb795-1057" aria-hidden="true" tabindex="-1"></a><span class="in"># First card has two black sides</span></span>
<span id="cb795-1058"><a href="#cb795-1058" aria-hidden="true" tabindex="-1"></a><span class="in">C1 &lt;- b,b</span></span>
<span id="cb795-1059"><a href="#cb795-1059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1060"><a href="#cb795-1060" aria-hidden="true" tabindex="-1"></a><span class="in"># Second card has one black and one white side</span></span>
<span id="cb795-1061"><a href="#cb795-1061" aria-hidden="true" tabindex="-1"></a><span class="in">C2 &lt;- b,w</span></span>
<span id="cb795-1062"><a href="#cb795-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1063"><a href="#cb795-1063" aria-hidden="true" tabindex="-1"></a><span class="in"># Third card has two white sides</span></span>
<span id="cb795-1064"><a href="#cb795-1064" aria-hidden="true" tabindex="-1"></a><span class="in">C3 &lt;- w,w</span></span>
<span id="cb795-1065"><a href="#cb795-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1066"><a href="#cb795-1066" aria-hidden="true" tabindex="-1"></a><span class="in"># Possible conjectures </span></span>
<span id="cb795-1067"><a href="#cb795-1067" aria-hidden="true" tabindex="-1"></a><span class="in">conjectures &lt;- (b,b), (b,w), (w,w)</span></span>
<span id="cb795-1068"><a href="#cb795-1068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1069"><a href="#cb795-1069" aria-hidden="true" tabindex="-1"></a><span class="in"># One card is drawn with black side facing up</span></span>
<span id="cb795-1070"><a href="#cb795-1070" aria-hidden="true" tabindex="-1"></a><span class="in">data &lt;- b</span></span>
<span id="cb795-1071"><a href="#cb795-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1072"><a href="#cb795-1072" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways to have the observe data for each conjecture (data: b)</span></span>
<span id="cb795-1073"><a href="#cb795-1073" aria-hidden="true" tabindex="-1"></a><span class="in">(b,b) -&gt; 2  </span></span>
<span id="cb795-1074"><a href="#cb795-1074" aria-hidden="true" tabindex="-1"></a><span class="in">(b,w) -&gt; 1</span></span>
<span id="cb795-1075"><a href="#cb795-1075" aria-hidden="true" tabindex="-1"></a><span class="in">(w,w) -&gt; 0</span></span>
<span id="cb795-1076"><a href="#cb795-1076" aria-hidden="true" tabindex="-1"></a><span class="in">total ways to see a black side up -&gt; 3</span></span>
<span id="cb795-1077"><a href="#cb795-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1078"><a href="#cb795-1078" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways that the other side is also black (data: b,b)</span></span>
<span id="cb795-1079"><a href="#cb795-1079" aria-hidden="true" tabindex="-1"></a><span class="in">(b,b) -&gt; 2 x 1 -&gt; 2</span></span>
<span id="cb795-1080"><a href="#cb795-1080" aria-hidden="true" tabindex="-1"></a><span class="in">(b,w) -&gt; 1 x 0 -&gt; 0</span></span>
<span id="cb795-1081"><a href="#cb795-1081" aria-hidden="true" tabindex="-1"></a><span class="in">(w,w) -&gt; 0 x 0 -&gt; 0</span></span>
<span id="cb795-1082"><a href="#cb795-1082" aria-hidden="true" tabindex="-1"></a><span class="in">total ways to see another side also black -&gt; 2</span></span>
<span id="cb795-1083"><a href="#cb795-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1084"><a href="#cb795-1084" aria-hidden="true" tabindex="-1"></a><span class="in"># Possible ways to get both side black</span></span>
<span id="cb795-1085"><a href="#cb795-1085" aria-hidden="true" tabindex="-1"></a><span class="in">(b,b) -&gt; total ways to see another side also black / total ways to see a black side up</span></span>
<span id="cb795-1086"><a href="#cb795-1086" aria-hidden="true" tabindex="-1"></a><span class="in">      -&gt; 2/3</span></span>
<span id="cb795-1087"><a href="#cb795-1087" aria-hidden="true" tabindex="-1"></a><span class="in">      </span></span>
<span id="cb795-1088"><a href="#cb795-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1089"><a href="#cb795-1089" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1090"><a href="#cb795-1090" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>***If we calculate probability as shown in chapter 2***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1091"><a href="#cb795-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1092"><a href="#cb795-1092" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 2M4}</span></span>
<span id="cb795-1093"><a href="#cb795-1093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1094"><a href="#cb795-1094" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb795-1095"><a href="#cb795-1095" aria-hidden="true" tabindex="-1"></a>ways<span class="sc">/</span> <span class="fu">sum</span>(ways)</span>
<span id="cb795-1096"><a href="#cb795-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1097"><a href="#cb795-1097" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1098"><a href="#cb795-1098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1099"><a href="#cb795-1099" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1100"><a href="#cb795-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1101"><a href="#cb795-1101" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2M5. Now suppose there are four cards: B/B, B/W, W/W, and another B/B. Again suppose a card is drawn from the bag and a black side appears face up. Again calculate the probability that the other side is black.</span></span>
<span id="cb795-1102"><a href="#cb795-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1103"><a href="#cb795-1103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1104"><a href="#cb795-1104" aria-hidden="true" tabindex="-1"></a><span class="in"># Possible conjectures</span></span>
<span id="cb795-1105"><a href="#cb795-1105" aria-hidden="true" tabindex="-1"></a><span class="in">conjectures: (B/B), (B/W), (W/W), (B/B)</span></span>
<span id="cb795-1106"><a href="#cb795-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1107"><a href="#cb795-1107" aria-hidden="true" tabindex="-1"></a><span class="in"># First observation</span></span>
<span id="cb795-1108"><a href="#cb795-1108" aria-hidden="true" tabindex="-1"></a><span class="in">data: B</span></span>
<span id="cb795-1109"><a href="#cb795-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1110"><a href="#cb795-1110" aria-hidden="true" tabindex="-1"></a><span class="in"># Possible ways to get the observed data for each conjecture</span></span>
<span id="cb795-1111"><a href="#cb795-1111" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 2</span></span>
<span id="cb795-1112"><a href="#cb795-1112" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) -&gt; 1</span></span>
<span id="cb795-1113"><a href="#cb795-1113" aria-hidden="true" tabindex="-1"></a><span class="in">(W/W) -&gt; 0</span></span>
<span id="cb795-1114"><a href="#cb795-1114" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 2</span></span>
<span id="cb795-1115"><a href="#cb795-1115" aria-hidden="true" tabindex="-1"></a><span class="in">Total ways to get initial black side -&gt; 5</span></span>
<span id="cb795-1116"><a href="#cb795-1116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1117"><a href="#cb795-1117" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability to see black on second observation (data: B/B)</span></span>
<span id="cb795-1118"><a href="#cb795-1118" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 2 x 1 = 2</span></span>
<span id="cb795-1119"><a href="#cb795-1119" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) -&gt; 1 x 0 = 0</span></span>
<span id="cb795-1120"><a href="#cb795-1120" aria-hidden="true" tabindex="-1"></a><span class="in">(W/W) -&gt; 0 x 0 = 0</span></span>
<span id="cb795-1121"><a href="#cb795-1121" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 2 x 1 = 2</span></span>
<span id="cb795-1122"><a href="#cb795-1122" aria-hidden="true" tabindex="-1"></a><span class="in">Total ways to get another black side -&gt; 4</span></span>
<span id="cb795-1123"><a href="#cb795-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1124"><a href="#cb795-1124" aria-hidden="true" tabindex="-1"></a><span class="in">Hence, the probability of getting a card with both sides black by counting method is 4/5. </span></span>
<span id="cb795-1125"><a href="#cb795-1125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1126"><a href="#cb795-1126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1127"><a href="#cb795-1127" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1128"><a href="#cb795-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1129"><a href="#cb795-1129" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2M6. Imagine that black ink is heavy, and so cards with black sides are heavier than cards with white sides. As a result, it’s less likely that a card with black sides is pulled from the bag. So again assume there are three cards: B/B, B/W, and W/W. After experimenting a number of times, you conclude that for every way to pull the B/B card from the bag, there are 2 ways to pull the B/W card and 3 ways to pull the W/W card. Again suppose that a card is pulled and a black side appears face up. Show that the probability the other side is black is now 0.5. Use the counting method, as before.</span></span>
<span id="cb795-1130"><a href="#cb795-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1131"><a href="#cb795-1131" aria-hidden="true" tabindex="-1"></a><span class="in">``` </span></span>
<span id="cb795-1132"><a href="#cb795-1132" aria-hidden="true" tabindex="-1"></a><span class="in"># Possible conjectures</span></span>
<span id="cb795-1133"><a href="#cb795-1133" aria-hidden="true" tabindex="-1"></a><span class="in">conjectures : (B/B), (B/W), (W/W)</span></span>
<span id="cb795-1134"><a href="#cb795-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1135"><a href="#cb795-1135" aria-hidden="true" tabindex="-1"></a><span class="in"># New information</span></span>
<span id="cb795-1136"><a href="#cb795-1136" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(B/B) &lt; Pr(B/W) &lt; Pr(W/W)</span></span>
<span id="cb795-1137"><a href="#cb795-1137" aria-hidden="true" tabindex="-1"></a><span class="in">1 (B/B) = 2 (B/W) + 3 (W/W)</span></span>
<span id="cb795-1138"><a href="#cb795-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1139"><a href="#cb795-1139" aria-hidden="true" tabindex="-1"></a><span class="in"># Likelihood of drawing each card</span></span>
<span id="cb795-1140"><a href="#cb795-1140" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 1</span></span>
<span id="cb795-1141"><a href="#cb795-1141" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) -&gt; 2</span></span>
<span id="cb795-1142"><a href="#cb795-1142" aria-hidden="true" tabindex="-1"></a><span class="in">(W/W) -&gt; 3</span></span>
<span id="cb795-1143"><a href="#cb795-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1144"><a href="#cb795-1144" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways to get data (B)</span></span>
<span id="cb795-1145"><a href="#cb795-1145" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 2 x 1 = 2</span></span>
<span id="cb795-1146"><a href="#cb795-1146" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) -&gt; 1 x 2 = 2</span></span>
<span id="cb795-1147"><a href="#cb795-1147" aria-hidden="true" tabindex="-1"></a><span class="in">(W/W) -&gt; 0 x 3 = 0</span></span>
<span id="cb795-1148"><a href="#cb795-1148" aria-hidden="true" tabindex="-1"></a><span class="in">Total counts of way to get initial B = 4</span></span>
<span id="cb795-1149"><a href="#cb795-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1150"><a href="#cb795-1150" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways to get data (B/B)</span></span>
<span id="cb795-1151"><a href="#cb795-1151" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 2 x 1 = 2</span></span>
<span id="cb795-1152"><a href="#cb795-1152" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) -&gt; 2 x 0 = 0</span></span>
<span id="cb795-1153"><a href="#cb795-1153" aria-hidden="true" tabindex="-1"></a><span class="in">(W/W) -&gt; 0 x 0 = 0</span></span>
<span id="cb795-1154"><a href="#cb795-1154" aria-hidden="true" tabindex="-1"></a><span class="in">Total counts of way to get B/B = 2</span></span>
<span id="cb795-1155"><a href="#cb795-1155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1156"><a href="#cb795-1156" aria-hidden="true" tabindex="-1"></a><span class="in">Probability the other side is also black = 2/4 = 0.5</span></span>
<span id="cb795-1157"><a href="#cb795-1157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1158"><a href="#cb795-1158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1159"><a href="#cb795-1159" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1160"><a href="#cb795-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1161"><a href="#cb795-1161" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2M7. Assume again the original card problem, with a single card showing a black side face up.Before looking at the other side, we draw another card from the bag and lay it face up on the table. The face that is shown on the new card is white. Show that the probability that the first card, the one showing a black side, has black on its other side is now 0.75. Use the counting method, if you can. Hint: Treat this like the sequence of globe tosses, counting all the ways to see each observation, for each possible first card.</span></span>
<span id="cb795-1162"><a href="#cb795-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1163"><a href="#cb795-1163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1164"><a href="#cb795-1164" aria-hidden="true" tabindex="-1"></a><span class="in"># Possible conjectures</span></span>
<span id="cb795-1165"><a href="#cb795-1165" aria-hidden="true" tabindex="-1"></a><span class="in">conjectures: (B/B), (B/W), (W/W)</span></span>
<span id="cb795-1166"><a href="#cb795-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1167"><a href="#cb795-1167" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways to get data (B)</span></span>
<span id="cb795-1168"><a href="#cb795-1168" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 2 </span></span>
<span id="cb795-1169"><a href="#cb795-1169" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) -&gt; 1 </span></span>
<span id="cb795-1170"><a href="#cb795-1170" aria-hidden="true" tabindex="-1"></a><span class="in">(W/W) -&gt; 0 </span></span>
<span id="cb795-1171"><a href="#cb795-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1172"><a href="#cb795-1172" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways to get data (W)</span></span>
<span id="cb795-1173"><a href="#cb795-1173" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) -&gt; 0</span></span>
<span id="cb795-1174"><a href="#cb795-1174" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) -&gt; 1 </span></span>
<span id="cb795-1175"><a href="#cb795-1175" aria-hidden="true" tabindex="-1"></a><span class="in">(W/W) -&gt; 2 </span></span>
<span id="cb795-1176"><a href="#cb795-1176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1177"><a href="#cb795-1177" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways to get data (B/x, W/x)</span></span>
<span id="cb795-1178"><a href="#cb795-1178" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) , (B/W) -&gt; 2 x 1 = 2</span></span>
<span id="cb795-1179"><a href="#cb795-1179" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) , (W/W) -&gt; 2 x 2 = 4</span></span>
<span id="cb795-1180"><a href="#cb795-1180" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) , (B/B) -&gt; 1 x 0 = 0</span></span>
<span id="cb795-1181"><a href="#cb795-1181" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) , (W/W) -&gt; 1 x 2 = 2</span></span>
<span id="cb795-1182"><a href="#cb795-1182" aria-hidden="true" tabindex="-1"></a><span class="in">Total counts of ways to get data (B/x, W/x) = 8</span></span>
<span id="cb795-1183"><a href="#cb795-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1184"><a href="#cb795-1184" aria-hidden="true" tabindex="-1"></a><span class="in"># Count the possible ways to get data (B/B, W/x)</span></span>
<span id="cb795-1185"><a href="#cb795-1185" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) , (B/W) -&gt; 2 x 1 = 2</span></span>
<span id="cb795-1186"><a href="#cb795-1186" aria-hidden="true" tabindex="-1"></a><span class="in">(B/B) , (W/W) -&gt; 4 x 1 = 4</span></span>
<span id="cb795-1187"><a href="#cb795-1187" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) , (B/B) -&gt; 0 x 0 = 0</span></span>
<span id="cb795-1188"><a href="#cb795-1188" aria-hidden="true" tabindex="-1"></a><span class="in">(B/W) , (W/W) -&gt; 2 x 0 = 0</span></span>
<span id="cb795-1189"><a href="#cb795-1189" aria-hidden="true" tabindex="-1"></a><span class="in">Total counts of ways to get data (B/B, W/x) = 6</span></span>
<span id="cb795-1190"><a href="#cb795-1190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1191"><a href="#cb795-1191" aria-hidden="true" tabindex="-1"></a><span class="in">Probability that the first card has both black sides = 6/8 = 0.75</span></span>
<span id="cb795-1192"><a href="#cb795-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1193"><a href="#cb795-1193" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1194"><a href="#cb795-1194" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1195"><a href="#cb795-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1196"><a href="#cb795-1196" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hard</span></span>
<span id="cb795-1197"><a href="#cb795-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1198"><a href="#cb795-1198" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2H1. Suppose there are two species of panda bear. Both are equally common in the wild and live in the same places. They look exactly alike and eat the same food, and there is yet no genetic assay capable of telling them apart. They differ however in their family sizes. Species A gives birth to twins 10% of the time, otherwise birthing a single infant. Species B births twins 20% of the time, otherwise birthing singleton infants. Assume these numbers are known with certainty, from many years of field research.</span></span>
<span id="cb795-1199"><a href="#cb795-1199" aria-hidden="true" tabindex="-1"></a><span class="at">Now suppose you are managing a captive panda breeding program. You have a new female panda of unknown species, and she has just given birth to twins. What is the probability that her next birth will also be twins?</span></span>
<span id="cb795-1200"><a href="#cb795-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1201"><a href="#cb795-1201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1202"><a href="#cb795-1202" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of species A gives birth to twins</span></span>
<span id="cb795-1203"><a href="#cb795-1203" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twin|SpA) = 0.1</span></span>
<span id="cb795-1204"><a href="#cb795-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1205"><a href="#cb795-1205" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of species B gives birth to twins</span></span>
<span id="cb795-1206"><a href="#cb795-1206" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twin|SpB) = 0.2</span></span>
<span id="cb795-1207"><a href="#cb795-1207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1208"><a href="#cb795-1208" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the new female panda belongs to species A or species B</span></span>
<span id="cb795-1209"><a href="#cb795-1209" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA) = 0.5</span></span>
<span id="cb795-1210"><a href="#cb795-1210" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpB) = 0.5</span></span>
<span id="cb795-1211"><a href="#cb795-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1212"><a href="#cb795-1212" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability of having twins (average likelihood)</span></span>
<span id="cb795-1213"><a href="#cb795-1213" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twins) = (Pr(twins|SpA) * Pr(SpA)) + (Pr(twins|SpB) * Pr(SpB))</span></span>
<span id="cb795-1214"><a href="#cb795-1214" aria-hidden="true" tabindex="-1"></a><span class="in">          = (0.1 * 0.5) + (0.2 * 0.5)</span></span>
<span id="cb795-1215"><a href="#cb795-1215" aria-hidden="true" tabindex="-1"></a><span class="in">          = 0.15</span></span>
<span id="cb795-1216"><a href="#cb795-1216" aria-hidden="true" tabindex="-1"></a><span class="in">          </span></span>
<span id="cb795-1217"><a href="#cb795-1217" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability of having two set of twins (average likelihood)</span></span>
<span id="cb795-1218"><a href="#cb795-1218" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(2twins) = (Pr(2twins|SpA) * Pr(SpA)) + (Pr(2twins|SpB) * Pr(SpB))</span></span>
<span id="cb795-1219"><a href="#cb795-1219" aria-hidden="true" tabindex="-1"></a><span class="in">          = (0.01 * 0.5) + (0.04 * 0.5)</span></span>
<span id="cb795-1220"><a href="#cb795-1220" aria-hidden="true" tabindex="-1"></a><span class="in">          = 0.025</span></span>
<span id="cb795-1221"><a href="#cb795-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1222"><a href="#cb795-1222" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of having another set of twins given that the first set is twin, regardless of species</span></span>
<span id="cb795-1223"><a href="#cb795-1223" aria-hidden="true" tabindex="-1"></a><span class="in">Pr (second_twins|first_twins) = Pr(first_twins, second_twins)/ Pr(twins)</span></span>
<span id="cb795-1224"><a href="#cb795-1224" aria-hidden="true" tabindex="-1"></a><span class="in">                              = Pr(2twins)/ Pr(twins)</span></span>
<span id="cb795-1225"><a href="#cb795-1225" aria-hidden="true" tabindex="-1"></a><span class="in">                              = 0.025/ 0.15 </span></span>
<span id="cb795-1226"><a href="#cb795-1226" aria-hidden="true" tabindex="-1"></a><span class="in">                              = 0.1666667</span></span>
<span id="cb795-1227"><a href="#cb795-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1228"><a href="#cb795-1228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1229"><a href="#cb795-1229" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1230"><a href="#cb795-1230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1231"><a href="#cb795-1231" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2H2. Recall all the facts from the problem above. Now compute the probability that the panda we have is from species A, assuming we have observed only the first birth and that it was twins.</span></span>
<span id="cb795-1232"><a href="#cb795-1232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1233"><a href="#cb795-1233" aria-hidden="true" tabindex="-1"></a><span class="in">``` </span></span>
<span id="cb795-1234"><a href="#cb795-1234" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of panda from species A giving birth to twins</span></span>
<span id="cb795-1235"><a href="#cb795-1235" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twins|SpA) = 0.1</span></span>
<span id="cb795-1236"><a href="#cb795-1236" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twin|SpB)  = 0.2</span></span>
<span id="cb795-1237"><a href="#cb795-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1238"><a href="#cb795-1238" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the new female panda belongs to species A or species B</span></span>
<span id="cb795-1239"><a href="#cb795-1239" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA) = 0.5</span></span>
<span id="cb795-1240"><a href="#cb795-1240" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpB) = 0.5</span></span>
<span id="cb795-1241"><a href="#cb795-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1242"><a href="#cb795-1242" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability of having twins (average likelihood)</span></span>
<span id="cb795-1243"><a href="#cb795-1243" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twins) = (Pr(twins|SpA) * Pr(SpA)) + (Pr(twins|SpB) * Pr(SpB))</span></span>
<span id="cb795-1244"><a href="#cb795-1244" aria-hidden="true" tabindex="-1"></a><span class="in">          = (0.1 * 0.5) + (0.2 * 0.5)</span></span>
<span id="cb795-1245"><a href="#cb795-1245" aria-hidden="true" tabindex="-1"></a><span class="in">          = 0.15</span></span>
<span id="cb795-1246"><a href="#cb795-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1247"><a href="#cb795-1247" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that panda is from species A after observing first birth of twins</span></span>
<span id="cb795-1248"><a href="#cb795-1248" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA|twins) = (Pr(twins|SpA) * Pr(SpA))/ Pr(twins)</span></span>
<span id="cb795-1249"><a href="#cb795-1249" aria-hidden="true" tabindex="-1"></a><span class="in">              = (0.1 * 0.5)/ 0.15</span></span>
<span id="cb795-1250"><a href="#cb795-1250" aria-hidden="true" tabindex="-1"></a><span class="in">              = 0.3333333</span></span>
<span id="cb795-1251"><a href="#cb795-1251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1252"><a href="#cb795-1252" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1253"><a href="#cb795-1253" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1254"><a href="#cb795-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1255"><a href="#cb795-1255" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2H3. Continuing on from the previous problem, suppose the same panda mother has a second birth and that it is not twins, but a singleton infant. Compute the posterior probability that this panda is species A.</span></span>
<span id="cb795-1256"><a href="#cb795-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1257"><a href="#cb795-1257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1258"><a href="#cb795-1258" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the new female panda belongs to species A or species B</span></span>
<span id="cb795-1259"><a href="#cb795-1259" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA) = 0.5</span></span>
<span id="cb795-1260"><a href="#cb795-1260" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpB) = 0.5</span></span>
<span id="cb795-1261"><a href="#cb795-1261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1262"><a href="#cb795-1262" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of panda from species A and B giving birth to twins</span></span>
<span id="cb795-1263"><a href="#cb795-1263" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twins|SpA) = 0.1</span></span>
<span id="cb795-1264"><a href="#cb795-1264" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(twin|SpB)  = 0.2</span></span>
<span id="cb795-1265"><a href="#cb795-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1266"><a href="#cb795-1266" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of panda from species A and B giving birth to singleton</span></span>
<span id="cb795-1267"><a href="#cb795-1267" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton|SpA) = 0.9</span></span>
<span id="cb795-1268"><a href="#cb795-1268" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton|SpB) = 0.8</span></span>
<span id="cb795-1269"><a href="#cb795-1269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1270"><a href="#cb795-1270" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of panda from species A and B having a twin and a singleton </span></span>
<span id="cb795-1271"><a href="#cb795-1271" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton, twins|SpA) = 0.1 * 0.9 = 0.09</span></span>
<span id="cb795-1272"><a href="#cb795-1272" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton, twins|SpB) = 0.2 * 0.8 = 0.16</span></span>
<span id="cb795-1273"><a href="#cb795-1273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1274"><a href="#cb795-1274" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability of having a twin and a singleton (average likelihood)</span></span>
<span id="cb795-1275"><a href="#cb795-1275" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton, twins) = (Pr(singleton, twins|SpA) * Pr(SpA)) + (Pr(singleton, twins|SpB) * Pr(SpB))</span></span>
<span id="cb795-1276"><a href="#cb795-1276" aria-hidden="true" tabindex="-1"></a><span class="in">                     = (0.09 * 0.5) + (0.16 * 0.5)</span></span>
<span id="cb795-1277"><a href="#cb795-1277" aria-hidden="true" tabindex="-1"></a><span class="in">                     = 0.125</span></span>
<span id="cb795-1278"><a href="#cb795-1278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1279"><a href="#cb795-1279" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the new panda is from species A given the birth of a singleton and a twins</span></span>
<span id="cb795-1280"><a href="#cb795-1280" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA|sigleton, twins) = (Pr(singleton, twins|SpA) * Pr(SpA))/ Pr(singleton, twins)</span></span>
<span id="cb795-1281"><a href="#cb795-1281" aria-hidden="true" tabindex="-1"></a><span class="in">                        = (0.09 * 0.5)/ 0.125</span></span>
<span id="cb795-1282"><a href="#cb795-1282" aria-hidden="true" tabindex="-1"></a><span class="in">                        = 0.36</span></span>
<span id="cb795-1283"><a href="#cb795-1283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1284"><a href="#cb795-1284" aria-hidden="true" tabindex="-1"></a><span class="in">OR</span></span>
<span id="cb795-1285"><a href="#cb795-1285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1286"><a href="#cb795-1286" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of the new panda is from species A or B after the first birth of twins</span></span>
<span id="cb795-1287"><a href="#cb795-1287" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA) = 0.33</span></span>
<span id="cb795-1288"><a href="#cb795-1288" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpB) = 0.67</span></span>
<span id="cb795-1289"><a href="#cb795-1289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1290"><a href="#cb795-1290" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability of panda from species A and B giving birth to singleton</span></span>
<span id="cb795-1291"><a href="#cb795-1291" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton|SpA) = 0.9</span></span>
<span id="cb795-1292"><a href="#cb795-1292" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton|SpB) = 0.8</span></span>
<span id="cb795-1293"><a href="#cb795-1293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1294"><a href="#cb795-1294" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability of having singleton after the first birth of twins (average likelihood)</span></span>
<span id="cb795-1295"><a href="#cb795-1295" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(singleton) = (Pr(singleton|SpA) * Pr(SpA)) + (Pr(singleton|SpB) * Pr(SpB))</span></span>
<span id="cb795-1296"><a href="#cb795-1296" aria-hidden="true" tabindex="-1"></a><span class="in">              = (0.9 * 0.33) + (0.8 * 0.67)</span></span>
<span id="cb795-1297"><a href="#cb795-1297" aria-hidden="true" tabindex="-1"></a><span class="in">              = 0.833</span></span>
<span id="cb795-1298"><a href="#cb795-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1299"><a href="#cb795-1299" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the new panda is from species A given the second birth of a singleton</span></span>
<span id="cb795-1300"><a href="#cb795-1300" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA|singleton) = (Pr(singleton|SpA) * Pr(SpA))/ Pr(singleton)</span></span>
<span id="cb795-1301"><a href="#cb795-1301" aria-hidden="true" tabindex="-1"></a><span class="in">                  = (0.9 * 0.33)/ 0.833</span></span>
<span id="cb795-1302"><a href="#cb795-1302" aria-hidden="true" tabindex="-1"></a><span class="in">                  = 0.3565426</span></span>
<span id="cb795-1303"><a href="#cb795-1303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1304"><a href="#cb795-1304" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1305"><a href="#cb795-1305" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1306"><a href="#cb795-1306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1307"><a href="#cb795-1307" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2H4. A common boast of Bayesian statisticians is that Bayesian inference makes it easy to use all of the data, even if the data are of different types.</span></span>
<span id="cb795-1308"><a href="#cb795-1308" aria-hidden="true" tabindex="-1"></a><span class="at">So suppose now that a veterinarian comes along who has a new genetic test that she claims can identify the species of our mother panda. But the test, like all tests, is imperfect. This is the information you have about the test:</span></span>
<span id="cb795-1309"><a href="#cb795-1309" aria-hidden="true" tabindex="-1"></a><span class="at">• The probability it correctly identifies a species A panda is 0.8. </span></span>
<span id="cb795-1310"><a href="#cb795-1310" aria-hidden="true" tabindex="-1"></a><span class="at">• The probability it correctly identifies a species B panda is 0.65.</span></span>
<span id="cb795-1311"><a href="#cb795-1311" aria-hidden="true" tabindex="-1"></a><span class="at">The vet administers the test to your panda and tells you that the test is positive for species A. First ignore your previous information from the births and compute the posterior probability that your panda is species A. Then redo your calculation, now using the birth data as well.</span></span>
<span id="cb795-1312"><a href="#cb795-1312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1313"><a href="#cb795-1313" aria-hidden="true" tabindex="-1"></a><span class="in">``` </span></span>
<span id="cb795-1314"><a href="#cb795-1314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1315"><a href="#cb795-1315" aria-hidden="true" tabindex="-1"></a><span class="in"># Without using birth data</span></span>
<span id="cb795-1316"><a href="#cb795-1316" aria-hidden="true" tabindex="-1"></a><span class="in"># Initital probability of speacies A and B</span></span>
<span id="cb795-1317"><a href="#cb795-1317" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA) = 0.5</span></span>
<span id="cb795-1318"><a href="#cb795-1318" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpB) = 0.5</span></span>
<span id="cb795-1319"><a href="#cb795-1319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1320"><a href="#cb795-1320" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the test correctly identifies a species A or B panda</span></span>
<span id="cb795-1321"><a href="#cb795-1321" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(correct_A|SpA) = 0.8</span></span>
<span id="cb795-1322"><a href="#cb795-1322" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(correct_B|SpB) = 0.65</span></span>
<span id="cb795-1323"><a href="#cb795-1323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1324"><a href="#cb795-1324" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the test wrongly identifies a species A or B panda</span></span>
<span id="cb795-1325"><a href="#cb795-1325" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(wrong_A|SpA) = 0.2</span></span>
<span id="cb795-1326"><a href="#cb795-1326" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(wrong_B|SpB) = 0.35</span></span>
<span id="cb795-1327"><a href="#cb795-1327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1328"><a href="#cb795-1328" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability that the test correctly identifies species A (average likelihood)</span></span>
<span id="cb795-1329"><a href="#cb795-1329" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(correct_A) = (Pr(correct_A|SpA) * Pr(SpA)) + (Pr(wrong_B|SpB) * Pr(SpB))</span></span>
<span id="cb795-1330"><a href="#cb795-1330" aria-hidden="true" tabindex="-1"></a><span class="in">              = (0.8 * 0.5) + (0.35 * 0.5)</span></span>
<span id="cb795-1331"><a href="#cb795-1331" aria-hidden="true" tabindex="-1"></a><span class="in">              = 0.575</span></span>
<span id="cb795-1332"><a href="#cb795-1332" aria-hidden="true" tabindex="-1"></a><span class="in">              </span></span>
<span id="cb795-1333"><a href="#cb795-1333" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the panda is from species A, given the correct test result</span></span>
<span id="cb795-1334"><a href="#cb795-1334" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA|correct_A) = (Pr(correct_A|SpA) * Pr(SpA))/ Pr(correct_A)</span></span>
<span id="cb795-1335"><a href="#cb795-1335" aria-hidden="true" tabindex="-1"></a><span class="in">                  = (0.8 * 0.5)/ 0.575</span></span>
<span id="cb795-1336"><a href="#cb795-1336" aria-hidden="true" tabindex="-1"></a><span class="in">                  = 0.6956522</span></span>
<span id="cb795-1337"><a href="#cb795-1337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1338"><a href="#cb795-1338" aria-hidden="true" tabindex="-1"></a><span class="in"># Using birth data</span></span>
<span id="cb795-1339"><a href="#cb795-1339" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the test correctly identifies a species A or B panda</span></span>
<span id="cb795-1340"><a href="#cb795-1340" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(correct_A|SpA) = 0.8</span></span>
<span id="cb795-1341"><a href="#cb795-1341" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(correct_B|SpB) = 0.65</span></span>
<span id="cb795-1342"><a href="#cb795-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1343"><a href="#cb795-1343" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the test wrongly identifies a species A or B panda</span></span>
<span id="cb795-1344"><a href="#cb795-1344" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(wrong_A|SpA) = 0.2</span></span>
<span id="cb795-1345"><a href="#cb795-1345" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(wrong_B|SpB) = 0.35</span></span>
<span id="cb795-1346"><a href="#cb795-1346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1347"><a href="#cb795-1347" aria-hidden="true" tabindex="-1"></a><span class="in"># Prior probability of species A and B</span></span>
<span id="cb795-1348"><a href="#cb795-1348" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA) = 0.36</span></span>
<span id="cb795-1349"><a href="#cb795-1349" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpB) = 0.64</span></span>
<span id="cb795-1350"><a href="#cb795-1350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1351"><a href="#cb795-1351" aria-hidden="true" tabindex="-1"></a><span class="in"># Total probability that the test correctly identifies species A (average likelihood)</span></span>
<span id="cb795-1352"><a href="#cb795-1352" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(correct_A) = (Pr(correct_A|SpA) * Pr(SpA)) + (Pr(wrong_B|SpB) * Pr(SpB))</span></span>
<span id="cb795-1353"><a href="#cb795-1353" aria-hidden="true" tabindex="-1"></a><span class="in">              = (0.8 * 0.36) + (0.35 * 0.64)</span></span>
<span id="cb795-1354"><a href="#cb795-1354" aria-hidden="true" tabindex="-1"></a><span class="in">              = 0.512</span></span>
<span id="cb795-1355"><a href="#cb795-1355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1356"><a href="#cb795-1356" aria-hidden="true" tabindex="-1"></a><span class="in"># Probability that the panda is from species A, given the test result</span></span>
<span id="cb795-1357"><a href="#cb795-1357" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(SpA|correct_A) = (Pr(correct_A|SpA) * Pr(SpA))/ Pr(correct_A)</span></span>
<span id="cb795-1358"><a href="#cb795-1358" aria-hidden="true" tabindex="-1"></a><span class="in">                  = (0.8 * 0.36)/ 0.512</span></span>
<span id="cb795-1359"><a href="#cb795-1359" aria-hidden="true" tabindex="-1"></a><span class="in">                  = 0.5625</span></span>
<span id="cb795-1360"><a href="#cb795-1360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1361"><a href="#cb795-1361" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1362"><a href="#cb795-1362" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1363"><a href="#cb795-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1364"><a href="#cb795-1364" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 3: Sampling the Imaginary</span></span>
<span id="cb795-1365"><a href="#cb795-1365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1366"><a href="#cb795-1366" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1367"><a href="#cb795-1367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1368"><a href="#cb795-1368" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sampling from a grid-approximate posterior</span></span>
<span id="cb795-1369"><a href="#cb795-1369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1370"><a href="#cb795-1370" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Compute the posterior for the globe tossing model, using grid approximation**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1371"><a href="#cb795-1371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1372"><a href="#cb795-1372" aria-hidden="true" tabindex="-1"></a><span class="in">```{r sampling_from_grid}</span></span>
<span id="cb795-1373"><a href="#cb795-1373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1374"><a href="#cb795-1374" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb795-1375"><a href="#cb795-1375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1376"><a href="#cb795-1376" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb795-1377"><a href="#cb795-1377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1378"><a href="#cb795-1378" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-1379"><a href="#cb795-1379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1380"><a href="#cb795-1380" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-1381"><a href="#cb795-1381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1382"><a href="#cb795-1382" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior<span class="sc">/</span> <span class="fu">sum</span>(posterior)</span>
<span id="cb795-1383"><a href="#cb795-1383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1384"><a href="#cb795-1384" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(posterior)</span>
<span id="cb795-1385"><a href="#cb795-1385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1386"><a href="#cb795-1386" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1387"><a href="#cb795-1387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1388"><a href="#cb795-1388" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Draw the samples**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1389"><a href="#cb795-1389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1390"><a href="#cb795-1390" aria-hidden="true" tabindex="-1"></a>Now we wish to draw 10,000 samples from this posterior. Imagine the posterior is a bucket full of parameter values, numbers such as 0.1, 0.7, 0.5, 1, etc. Within the bucket, each value exists in proportion to its posterior probability, such that values near the peak are much more common than those in the tails. We’re going to scoop out 10,000 values from the bucket. Provided the bucket is well mixed, the resulting samples will have the same proportions as the exact posterior density. Therefore the individual values of p will appear in our samples in proportion to the posterior plausibility of each value.</span>
<span id="cb795-1391"><a href="#cb795-1391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1392"><a href="#cb795-1392" aria-hidden="true" tabindex="-1"></a><span class="in">```{r create_sample}</span></span>
<span id="cb795-1393"><a href="#cb795-1393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1394"><a href="#cb795-1394" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">prob =</span> posterior, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb795-1395"><a href="#cb795-1395" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(samples, <span class="at">xlab=</span><span class="st">"sample number"</span>, <span class="at">ylab=</span><span class="st">"proportion of water(p)"</span>)</span>
<span id="cb795-1396"><a href="#cb795-1396" aria-hidden="true" tabindex="-1"></a><span class="co"># The workhorse here is sample, which randomly pulls values from a vector. </span></span>
<span id="cb795-1397"><a href="#cb795-1397" aria-hidden="true" tabindex="-1"></a><span class="co"># The vector in this case is p_grid, the grid of parameter values. </span></span>
<span id="cb795-1398"><a href="#cb795-1398" aria-hidden="true" tabindex="-1"></a><span class="co"># The probability of each value is given by posterior, which you computed just above.</span></span>
<span id="cb795-1399"><a href="#cb795-1399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1400"><a href="#cb795-1400" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(samples, <span class="at">xlab=</span> <span class="st">"proportion of water(p)"</span>, <span class="at">ylab=</span> <span class="st">"Density"</span>) </span>
<span id="cb795-1401"><a href="#cb795-1401" aria-hidden="true" tabindex="-1"></a><span class="co"># show density estimate computed from the samples</span></span>
<span id="cb795-1402"><a href="#cb795-1402" aria-hidden="true" tabindex="-1"></a><span class="co"># You can see that the estimated density is very similar to ideal posterior you computed </span></span>
<span id="cb795-1403"><a href="#cb795-1403" aria-hidden="true" tabindex="-1"></a><span class="co"># via grid approximation.</span></span>
<span id="cb795-1404"><a href="#cb795-1404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1405"><a href="#cb795-1405" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw more samples</span></span>
<span id="cb795-1406"><a href="#cb795-1406" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">prob =</span> posterior, <span class="at">size =</span> <span class="fl">1e6</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb795-1407"><a href="#cb795-1407" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(samples, <span class="at">xlab=</span><span class="st">"sample number"</span>, <span class="at">ylab=</span><span class="st">"proportion of water(p)"</span>)</span>
<span id="cb795-1408"><a href="#cb795-1408" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(samples, <span class="at">xlab=</span> <span class="st">"proportion of water(p)"</span>, <span class="at">ylab=</span> <span class="st">"Density"</span>) </span>
<span id="cb795-1409"><a href="#cb795-1409" aria-hidden="true" tabindex="-1"></a><span class="co"># If you draw even more samples, maybe 1e5 or 1e6, the density estimate will get more </span></span>
<span id="cb795-1410"><a href="#cb795-1410" aria-hidden="true" tabindex="-1"></a><span class="co"># and more similar to the ideal.</span></span>
<span id="cb795-1411"><a href="#cb795-1411" aria-hidden="true" tabindex="-1"></a><span class="co"># All you’ve done so far is crudely replicate the posterior density you had already computed.</span></span>
<span id="cb795-1412"><a href="#cb795-1412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1413"><a href="#cb795-1413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1414"><a href="#cb795-1414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1415"><a href="#cb795-1415" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1416"><a href="#cb795-1416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1417"><a href="#cb795-1417" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sampling to summarize</span></span>
<span id="cb795-1418"><a href="#cb795-1418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1419"><a href="#cb795-1419" aria-hidden="true" tabindex="-1"></a>It is necessary to summarize and interpret the posterior distribution. Exactly how it is summarized depends upon your purpose. But common questions include:</span>
<span id="cb795-1420"><a href="#cb795-1420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1421"><a href="#cb795-1421" aria-hidden="true" tabindex="-1"></a>• How much posterior probability lies below some parameter value?</span>
<span id="cb795-1422"><a href="#cb795-1422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1423"><a href="#cb795-1423" aria-hidden="true" tabindex="-1"></a>• How much posterior probability lies between two parameter values?</span>
<span id="cb795-1424"><a href="#cb795-1424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1425"><a href="#cb795-1425" aria-hidden="true" tabindex="-1"></a>• Which parameter value marks the lower 5% of the posterior probability?</span>
<span id="cb795-1426"><a href="#cb795-1426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1427"><a href="#cb795-1427" aria-hidden="true" tabindex="-1"></a>• Which range of parameter values contains 90% of the posterior probability? </span>
<span id="cb795-1428"><a href="#cb795-1428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1429"><a href="#cb795-1429" aria-hidden="true" tabindex="-1"></a>• Which parameter value has highest posterior probability?</span>
<span id="cb795-1430"><a href="#cb795-1430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1431"><a href="#cb795-1431" aria-hidden="true" tabindex="-1"></a>These simple questions can be usefully divided into questions about:</span>
<span id="cb795-1432"><a href="#cb795-1432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1433"><a href="#cb795-1433" aria-hidden="true" tabindex="-1"></a>(1) intervals of defined boundaries, </span>
<span id="cb795-1434"><a href="#cb795-1434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1435"><a href="#cb795-1435" aria-hidden="true" tabindex="-1"></a>(2) intervals of defined probability mass, and </span>
<span id="cb795-1436"><a href="#cb795-1436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1437"><a href="#cb795-1437" aria-hidden="true" tabindex="-1"></a>(3) point estimates.</span>
<span id="cb795-1438"><a href="#cb795-1438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1439"><a href="#cb795-1439" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1440"><a href="#cb795-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1441"><a href="#cb795-1441" aria-hidden="true" tabindex="-1"></a><span class="fu">### Intervals of defined boundaries</span></span>
<span id="cb795-1442"><a href="#cb795-1442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1443"><a href="#cb795-1443" aria-hidden="true" tabindex="-1"></a>Suppose I ask you for the posterior probability that the proportion of water is less than 0.5. Using the grid-approximate posterior, you can just add up all of the probabilities, where the corresponding parameter value is less than 0.5:</span>
<span id="cb795-1444"><a href="#cb795-1444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1445"><a href="#cb795-1445" aria-hidden="true" tabindex="-1"></a><span class="in">```{r intervals}</span></span>
<span id="cb795-1446"><a href="#cb795-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1447"><a href="#cb795-1447" aria-hidden="true" tabindex="-1"></a><span class="co"># add up posterior probability where p &lt; 0.5</span></span>
<span id="cb795-1448"><a href="#cb795-1448" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>( posterior[ p_grid <span class="sc">&lt;</span> <span class="fl">0.5</span> ] )</span>
<span id="cb795-1449"><a href="#cb795-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1450"><a href="#cb795-1450" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1451"><a href="#cb795-1451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1452"><a href="#cb795-1452" aria-hidden="true" tabindex="-1"></a>So let’s see how to perform the same calculation, using samples from the posterior. This approach does generalize to complex models with many parameters, and so you can use it everywhere. All you have to do is similarly add up all of the samples below 0.5, but also divide the resulting count by the total number of samples. In other words, find the frequency of parameter values below 0.5:</span>
<span id="cb795-1453"><a href="#cb795-1453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1454"><a href="#cb795-1454" aria-hidden="true" tabindex="-1"></a><span class="in">```{r samples}</span></span>
<span id="cb795-1455"><a href="#cb795-1455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1456"><a href="#cb795-1456" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(samples <span class="sc">&lt;</span> <span class="fl">0.5</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-1457"><a href="#cb795-1457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1458"><a href="#cb795-1458" aria-hidden="true" tabindex="-1"></a><span class="co"># The answer is the posterior probability below a parameter value of 0.5.</span></span>
<span id="cb795-1459"><a href="#cb795-1459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1460"><a href="#cb795-1460" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1461"><a href="#cb795-1461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1462"><a href="#cb795-1462" aria-hidden="true" tabindex="-1"></a>And that’s nearly the same answer as the grid approximation provided, although your answer will not be exactly the same, because the exact samples you drew from the posterior will be different.</span>
<span id="cb795-1463"><a href="#cb795-1463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1464"><a href="#cb795-1464" aria-hidden="true" tabindex="-1"></a>Using the same approach, you can ask how much posterior probability lies between 0.5 and 0.75:</span>
<span id="cb795-1465"><a href="#cb795-1465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1466"><a href="#cb795-1466" aria-hidden="true" tabindex="-1"></a><span class="in">```{r samples1}</span></span>
<span id="cb795-1467"><a href="#cb795-1467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1468"><a href="#cb795-1468" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(samples <span class="sc">&gt;</span> <span class="fl">0.5</span> <span class="sc">&amp;</span> samples <span class="sc">&lt;</span> <span class="fl">0.75</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-1469"><a href="#cb795-1469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1470"><a href="#cb795-1470" aria-hidden="true" tabindex="-1"></a><span class="co"># So about 61% of the posterior probability lies between 0.5 and 0.75.</span></span>
<span id="cb795-1471"><a href="#cb795-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1472"><a href="#cb795-1472" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1473"><a href="#cb795-1473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1474"><a href="#cb795-1474" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;</span>***Counting with sum***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1475"><a href="#cb795-1475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1476"><a href="#cb795-1476" aria-hidden="true" tabindex="-1"></a>In the R code examples just above, I used the function sum to effectively count up how many samples fulfill a logical criterion. Why does this work? It works because R internally converts a logical expression, like samples &lt; 0.5, to a vector of TRUE and FALSE results, one for each element of samples, saying whether or not each element matches the criterion.Go ahead and enter samples &lt; 0.5 on the R prompt, to see this for yourself. Then when you sum this vector of TRUE and FALSE, R counts each TRUE as 1 and each FALSE as 0. So it ends up counting how many TRUE values are in the vector, which is the same as the number of elements in samples that match the logical criterion.</span>
<span id="cb795-1477"><a href="#cb795-1477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1478"><a href="#cb795-1478" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1479"><a href="#cb795-1479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1480"><a href="#cb795-1480" aria-hidden="true" tabindex="-1"></a><span class="fu">### Intervals of defined mass</span></span>
<span id="cb795-1481"><a href="#cb795-1481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1482"><a href="#cb795-1482" aria-hidden="true" tabindex="-1"></a>It is more common to see scientific journals reporting an interval of defined mass, usually known as a confidence interval. An interval of posterior probability, such as the ones we are working with, may instead be called a credible interval, although the terms may also be used interchangeably.</span>
<span id="cb795-1483"><a href="#cb795-1483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1484"><a href="#cb795-1484" aria-hidden="true" tabindex="-1"></a>These posterior intervals report two parameter values that contain between them a specified amount of posterior probability, a probability mass. For this type of interval, it is easier to find the answer by using samples from the posterior than by using a grid approximation.</span>
<span id="cb795-1485"><a href="#cb795-1485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1486"><a href="#cb795-1486" aria-hidden="true" tabindex="-1"></a><span class="in">```{r example}</span></span>
<span id="cb795-1487"><a href="#cb795-1487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1488"><a href="#cb795-1488" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppose for example you want to know the boundaries of the lower 80% posterior probability. </span></span>
<span id="cb795-1489"><a href="#cb795-1489" aria-hidden="true" tabindex="-1"></a><span class="co"># You know this interval starts at p = 0. To find out where it stops, think of the samples as data </span></span>
<span id="cb795-1490"><a href="#cb795-1490" aria-hidden="true" tabindex="-1"></a><span class="co"># and ask where the 80th percentile lies:</span></span>
<span id="cb795-1491"><a href="#cb795-1491" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(samples, <span class="fl">0.8</span>)</span>
<span id="cb795-1492"><a href="#cb795-1492" aria-hidden="true" tabindex="-1"></a><span class="co"># Lower 80% posterior probability exists below a parameter value of about 0.75. </span></span>
<span id="cb795-1493"><a href="#cb795-1493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1494"><a href="#cb795-1494" aria-hidden="true" tabindex="-1"></a><span class="co"># For the middle 80% interval lies between the 10th percentile and the 90th percentile.</span></span>
<span id="cb795-1495"><a href="#cb795-1495" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(samples, <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>))</span>
<span id="cb795-1496"><a href="#cb795-1496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1497"><a href="#cb795-1497" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervals of this sort are called percentile intervals (PI).</span></span>
<span id="cb795-1498"><a href="#cb795-1498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1499"><a href="#cb795-1499" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1500"><a href="#cb795-1500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1501"><a href="#cb795-1501" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Percentile Intervals (PI)**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1502"><a href="#cb795-1502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1503"><a href="#cb795-1503" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Intervals which assign equal probability mass to each tail</span>
<span id="cb795-1504"><a href="#cb795-1504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1505"><a href="#cb795-1505" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Do a good job of communicating the shape of a distribution, as long as the distribution isn't too asymmetrical</span>
<span id="cb795-1506"><a href="#cb795-1506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1507"><a href="#cb795-1507" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Not perfect for supporting inferences about which parameters are consistent with the data, see the figure and computation below:</span>
<span id="cb795-1508"><a href="#cb795-1508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1509"><a href="#cb795-1509" aria-hidden="true" tabindex="-1"></a><span class="in">```{r creat_sample2}</span></span>
<span id="cb795-1510"><a href="#cb795-1510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1511"><a href="#cb795-1511" aria-hidden="true" tabindex="-1"></a><span class="co"># This posterior is consistent with observing three waters in three tosses and a uniform (flat) prior. </span></span>
<span id="cb795-1512"><a href="#cb795-1512" aria-hidden="true" tabindex="-1"></a><span class="co"># It is highly skewed, having its maximum value at the boundary, p = 1. </span></span>
<span id="cb795-1513"><a href="#cb795-1513" aria-hidden="true" tabindex="-1"></a><span class="co"># You can compute it, via grid approximation, with:</span></span>
<span id="cb795-1514"><a href="#cb795-1514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1515"><a href="#cb795-1515" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample using grid approximation</span></span>
<span id="cb795-1516"><a href="#cb795-1516" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb795-1517"><a href="#cb795-1517" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb795-1518"><a href="#cb795-1518" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">3</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-1519"><a href="#cb795-1519" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> prior <span class="sc">*</span> likelihood</span>
<span id="cb795-1520"><a href="#cb795-1520" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-1521"><a href="#cb795-1521" aria-hidden="true" tabindex="-1"></a>samples2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior) <span class="co"># sample from posterior</span></span>
<span id="cb795-1522"><a href="#cb795-1522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1523"><a href="#cb795-1523" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the 50% percentile confidence interval from the samples with PI (part of rethinking)</span></span>
<span id="cb795-1524"><a href="#cb795-1524" aria-hidden="true" tabindex="-1"></a><span class="fu">PI</span>(samples2, <span class="at">prob =</span> <span class="fl">0.5</span>)</span>
<span id="cb795-1525"><a href="#cb795-1525" aria-hidden="true" tabindex="-1"></a><span class="co"># This interval assigns 25% of the probability mass above and below the interval. </span></span>
<span id="cb795-1526"><a href="#cb795-1526" aria-hidden="true" tabindex="-1"></a><span class="co"># So it provides the central 50% probability. But in this example, it ends up excluding </span></span>
<span id="cb795-1527"><a href="#cb795-1527" aria-hidden="true" tabindex="-1"></a><span class="co"># the most probable parameter values, near p = 1. So in terms of describing </span></span>
<span id="cb795-1528"><a href="#cb795-1528" aria-hidden="true" tabindex="-1"></a><span class="co"># the shape of the posterior distribution—which is really all these intervals are asked to do—</span></span>
<span id="cb795-1529"><a href="#cb795-1529" aria-hidden="true" tabindex="-1"></a><span class="co"># the percentile interval can be misleading.</span></span>
<span id="cb795-1530"><a href="#cb795-1530" aria-hidden="true" tabindex="-1"></a>pi_50 <span class="ot">&lt;-</span> <span class="fu">PI</span>(samples2, <span class="at">prob =</span> <span class="fl">0.5</span>)</span>
<span id="cb795-1531"><a href="#cb795-1531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1532"><a href="#cb795-1532" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data frame for plotting</span></span>
<span id="cb795-1533"><a href="#cb795-1533" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(p_grid, posterior)</span>
<span id="cb795-1534"><a href="#cb795-1534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1535"><a href="#cb795-1535" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 50% PI </span></span>
<span id="cb795-1536"><a href="#cb795-1536" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb795-1537"><a href="#cb795-1537" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> posterior)) <span class="sc">+</span></span>
<span id="cb795-1538"><a href="#cb795-1538" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(p_grid <span class="sc">&gt;</span> pi_50[<span class="dv">1</span>] <span class="sc">&amp;</span> p_grid <span class="sc">&lt;</span> pi_50[<span class="dv">2</span>]),</span>
<span id="cb795-1539"><a href="#cb795-1539" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> posterior),</span>
<span id="cb795-1540"><a href="#cb795-1540" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"purple"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-1541"><a href="#cb795-1541" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"brown"</span>) <span class="sc">+</span></span>
<span id="cb795-1542"><a href="#cb795-1542" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">'50% Percentile interval'</span>,</span>
<span id="cb795-1543"><a href="#cb795-1543" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">'proportion of water (p)'</span>,</span>
<span id="cb795-1544"><a href="#cb795-1544" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">'density'</span>) <span class="sc">+</span></span>
<span id="cb795-1545"><a href="#cb795-1545" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb795-1546"><a href="#cb795-1546" aria-hidden="true" tabindex="-1"></a><span class="co"># The posterior density here corresponds to a flat prior and observing </span></span>
<span id="cb795-1547"><a href="#cb795-1547" aria-hidden="true" tabindex="-1"></a><span class="co"># three water samples in three total tosses of the globe. </span></span>
<span id="cb795-1548"><a href="#cb795-1548" aria-hidden="true" tabindex="-1"></a><span class="co"># This interval assigns equal mass (25%) to both the left and right tail. </span></span>
<span id="cb795-1549"><a href="#cb795-1549" aria-hidden="true" tabindex="-1"></a><span class="co"># As a result, it omits the most probable parameter value, p = 1.</span></span>
<span id="cb795-1550"><a href="#cb795-1550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1551"><a href="#cb795-1551" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1552"><a href="#cb795-1552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1553"><a href="#cb795-1553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1554"><a href="#cb795-1554" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Highest Posterior Density Interval (HPDI)**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1555"><a href="#cb795-1555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1556"><a href="#cb795-1556" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The narrowest interval containing the specified probability mass</span>
<span id="cb795-1557"><a href="#cb795-1557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1558"><a href="#cb795-1558" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>If you think about it, there must be an infinite number of posterior intervals with the same mass. But if you want an interval that best represents the parameter values most consistent with the data, then you want the densest of these intervals- the HPDI.</span>
<span id="cb795-1559"><a href="#cb795-1559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1560"><a href="#cb795-1560" aria-hidden="true" tabindex="-1"></a><span class="in">``` {r HPDI_50}</span></span>
<span id="cb795-1561"><a href="#cb795-1561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1562"><a href="#cb795-1562" aria-hidden="true" tabindex="-1"></a><span class="co"># Create sample using grid approximation</span></span>
<span id="cb795-1563"><a href="#cb795-1563" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb795-1564"><a href="#cb795-1564" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb795-1565"><a href="#cb795-1565" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">3</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-1566"><a href="#cb795-1566" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> prior <span class="sc">*</span> likelihood</span>
<span id="cb795-1567"><a href="#cb795-1567" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-1568"><a href="#cb795-1568" aria-hidden="true" tabindex="-1"></a>samples2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior)</span>
<span id="cb795-1569"><a href="#cb795-1569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1570"><a href="#cb795-1570" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute it from the samples with HPDI (part of rethinking)</span></span>
<span id="cb795-1571"><a href="#cb795-1571" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(samples2, <span class="at">prob =</span> <span class="fl">0.5</span>)</span>
<span id="cb795-1572"><a href="#cb795-1572" aria-hidden="true" tabindex="-1"></a><span class="co"># This interval captures the parameters with highest posterior probability, </span></span>
<span id="cb795-1573"><a href="#cb795-1573" aria-hidden="true" tabindex="-1"></a><span class="co"># as well as being noticeably narrower: </span></span>
<span id="cb795-1574"><a href="#cb795-1574" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.16 in width rather than 0.23 for the percentile interval.</span></span>
<span id="cb795-1575"><a href="#cb795-1575" aria-hidden="true" tabindex="-1"></a>hpdi_50 <span class="ot">&lt;-</span> <span class="fu">HPDI</span>(samples2, <span class="at">prob =</span> <span class="fl">0.5</span>)</span>
<span id="cb795-1576"><a href="#cb795-1576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1577"><a href="#cb795-1577" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data frame for plotting</span></span>
<span id="cb795-1578"><a href="#cb795-1578" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(p_grid, posterior)</span>
<span id="cb795-1579"><a href="#cb795-1579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1580"><a href="#cb795-1580" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 50% PI </span></span>
<span id="cb795-1581"><a href="#cb795-1581" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb795-1582"><a href="#cb795-1582" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> posterior)) <span class="sc">+</span></span>
<span id="cb795-1583"><a href="#cb795-1583" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(p_grid <span class="sc">&gt;</span> hpdi_50[<span class="dv">1</span>] <span class="sc">&amp;</span> p_grid <span class="sc">&lt;</span> hpdi_50[<span class="dv">2</span>]),</span>
<span id="cb795-1584"><a href="#cb795-1584" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> posterior),</span>
<span id="cb795-1585"><a href="#cb795-1585" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"purple"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-1586"><a href="#cb795-1586" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"brown"</span>) <span class="sc">+</span></span>
<span id="cb795-1587"><a href="#cb795-1587" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">'50% Percentile interval'</span>,</span>
<span id="cb795-1588"><a href="#cb795-1588" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">'proportion of water (p)'</span>,</span>
<span id="cb795-1589"><a href="#cb795-1589" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">'density'</span>) <span class="sc">+</span></span>
<span id="cb795-1590"><a href="#cb795-1590" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb795-1591"><a href="#cb795-1591" aria-hidden="true" tabindex="-1"></a><span class="co"># This interval finds the narrowest region with 50% of the posterior probability. </span></span>
<span id="cb795-1592"><a href="#cb795-1592" aria-hidden="true" tabindex="-1"></a><span class="co"># Such a region always includes the most probable parameter value.</span></span>
<span id="cb795-1593"><a href="#cb795-1593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1594"><a href="#cb795-1594" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1595"><a href="#cb795-1595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1596"><a href="#cb795-1596" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1597"><a href="#cb795-1597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1598"><a href="#cb795-1598" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**HPDI vs. PI**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1599"><a href="#cb795-1599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1600"><a href="#cb795-1600" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The two types of intervals are very similar</span>
<span id="cb795-1601"><a href="#cb795-1601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1602"><a href="#cb795-1602" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>HPDI has some advantages over the PI</span>
<span id="cb795-1603"><a href="#cb795-1603" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>only look so different if the posterior distribution is highly skewed, otherwise nearly identical:</span>
<span id="cb795-1604"><a href="#cb795-1604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1605"><a href="#cb795-1605" aria-hidden="true" tabindex="-1"></a><span class="in">```{r HPDI,PI}</span></span>
<span id="cb795-1606"><a href="#cb795-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1607"><a href="#cb795-1607" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare HPDI and PI</span></span>
<span id="cb795-1608"><a href="#cb795-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1609"><a href="#cb795-1609" aria-hidden="true" tabindex="-1"></a><span class="co"># Create samples using observation six waters in nine tosses</span></span>
<span id="cb795-1610"><a href="#cb795-1610" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb795-1611"><a href="#cb795-1611" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb795-1612"><a href="#cb795-1612" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">6</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-1613"><a href="#cb795-1613" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> prior <span class="sc">*</span> likelihood</span>
<span id="cb795-1614"><a href="#cb795-1614" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior<span class="sc">/</span><span class="fu">sum</span>(posterior)</span>
<span id="cb795-1615"><a href="#cb795-1615" aria-hidden="true" tabindex="-1"></a>samples3 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior)</span>
<span id="cb795-1616"><a href="#cb795-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1617"><a href="#cb795-1617" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute 80% HPDI and PI from samples</span></span>
<span id="cb795-1618"><a href="#cb795-1618" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.8</span>)</span>
<span id="cb795-1619"><a href="#cb795-1619" aria-hidden="true" tabindex="-1"></a><span class="fu">PI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.8</span>)</span>
<span id="cb795-1620"><a href="#cb795-1620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1621"><a href="#cb795-1621" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute 95% HPDI and PI from samples</span></span>
<span id="cb795-1622"><a href="#cb795-1622" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-1623"><a href="#cb795-1623" aria-hidden="true" tabindex="-1"></a><span class="fu">PI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-1624"><a href="#cb795-1624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1625"><a href="#cb795-1625" aria-hidden="true" tabindex="-1"></a><span class="co"># Add name for 80% HPDI and PI</span></span>
<span id="cb795-1626"><a href="#cb795-1626" aria-hidden="true" tabindex="-1"></a>hpdi_80 <span class="ot">&lt;-</span> <span class="fu">HPDI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.8</span>)</span>
<span id="cb795-1627"><a href="#cb795-1627" aria-hidden="true" tabindex="-1"></a>pi_80 <span class="ot">&lt;-</span> <span class="fu">PI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.8</span>)</span>
<span id="cb795-1628"><a href="#cb795-1628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1629"><a href="#cb795-1629" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data frame for plotting</span></span>
<span id="cb795-1630"><a href="#cb795-1630" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(p_grid, posterior)</span>
<span id="cb795-1631"><a href="#cb795-1631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1632"><a href="#cb795-1632" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 80% HPDI and PI on the same graph</span></span>
<span id="cb795-1633"><a href="#cb795-1633" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb795-1634"><a href="#cb795-1634" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> posterior)) <span class="sc">+</span></span>
<span id="cb795-1635"><a href="#cb795-1635" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(p_grid <span class="sc">&gt;</span> hpdi_80[<span class="dv">1</span>] <span class="sc">&amp;</span> p_grid <span class="sc">&lt;</span> hpdi_80[<span class="dv">2</span>]),</span>
<span id="cb795-1636"><a href="#cb795-1636" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> posterior),</span>
<span id="cb795-1637"><a href="#cb795-1637" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-1638"><a href="#cb795-1638" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(p_grid <span class="sc">&gt;</span> pi_80[<span class="dv">1</span>] <span class="sc">&amp;</span> p_grid <span class="sc">&lt;</span> pi_80[<span class="dv">2</span>]),</span>
<span id="cb795-1639"><a href="#cb795-1639" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> posterior),</span>
<span id="cb795-1640"><a href="#cb795-1640" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"green"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-1641"><a href="#cb795-1641" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb795-1642"><a href="#cb795-1642" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">'80% HPDI and 80% PI'</span>,</span>
<span id="cb795-1643"><a href="#cb795-1643" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">'proportion of water (p)'</span>,</span>
<span id="cb795-1644"><a href="#cb795-1644" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">'density'</span>) <span class="sc">+</span></span>
<span id="cb795-1645"><a href="#cb795-1645" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb795-1646"><a href="#cb795-1646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1647"><a href="#cb795-1647" aria-hidden="true" tabindex="-1"></a><span class="co"># Add name for 95% HPDI and PI </span></span>
<span id="cb795-1648"><a href="#cb795-1648" aria-hidden="true" tabindex="-1"></a>hpdi_95 <span class="ot">&lt;-</span> <span class="fu">HPDI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-1649"><a href="#cb795-1649" aria-hidden="true" tabindex="-1"></a>pi_95 <span class="ot">&lt;-</span> <span class="fu">PI</span>(samples3, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-1650"><a href="#cb795-1650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1651"><a href="#cb795-1651" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 95% HPDI and PI on the same graph</span></span>
<span id="cb795-1652"><a href="#cb795-1652" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb795-1653"><a href="#cb795-1653" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> posterior)) <span class="sc">+</span></span>
<span id="cb795-1654"><a href="#cb795-1654" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(p_grid <span class="sc">&gt;</span> hpdi_95[<span class="dv">1</span>] <span class="sc">&amp;</span> p_grid <span class="sc">&lt;</span> hpdi_95[<span class="dv">2</span>]),</span>
<span id="cb795-1655"><a href="#cb795-1655" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> posterior),</span>
<span id="cb795-1656"><a href="#cb795-1656" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"brown"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-1657"><a href="#cb795-1657" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(p_grid <span class="sc">&gt;</span> pi_95[<span class="dv">1</span>] <span class="sc">&amp;</span> p_grid <span class="sc">&lt;</span> pi_95[<span class="dv">2</span>]),</span>
<span id="cb795-1658"><a href="#cb795-1658" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> posterior),</span>
<span id="cb795-1659"><a href="#cb795-1659" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"yellow"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-1660"><a href="#cb795-1660" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb795-1661"><a href="#cb795-1661" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">'95% HPDI and 95% PI'</span>,</span>
<span id="cb795-1662"><a href="#cb795-1662" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">'proportion of water (p)'</span>,</span>
<span id="cb795-1663"><a href="#cb795-1663" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">'density'</span>) <span class="sc">+</span></span>
<span id="cb795-1664"><a href="#cb795-1664" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb795-1665"><a href="#cb795-1665" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-1666"><a href="#cb795-1666" aria-hidden="true" tabindex="-1"></a> <span class="co"># When the posterior is bell shaped, it hardly matters which type of interval you use.</span></span>
<span id="cb795-1667"><a href="#cb795-1667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1668"><a href="#cb795-1668" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1669"><a href="#cb795-1669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1670"><a href="#cb795-1670" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>HPDI also has some disadvantages</span>
<span id="cb795-1671"><a href="#cb795-1671" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>HPDI is more computationally intensive than PI</span>
<span id="cb795-1672"><a href="#cb795-1672" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>HPDI suffers from greater simulation variance (it is sensitive to how many samples you draw from the posterior.)</span>
<span id="cb795-1673"><a href="#cb795-1673" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-1674"><a href="#cb795-1674" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1675"><a href="#cb795-1675" aria-hidden="true" tabindex="-1"></a><span class="in">Overall, if the choice of interval type makes a big difference, then you shouldn’t be using intervals </span></span>
<span id="cb795-1676"><a href="#cb795-1676" aria-hidden="true" tabindex="-1"></a><span class="in">to summarize the posterior. Remember, the entire posterior distribution is the Bayesian estimate. It summarizes the relative plausibilities of each possible value of the parameter. Intervals of the </span></span>
<span id="cb795-1677"><a href="#cb795-1677" aria-hidden="true" tabindex="-1"></a><span class="in">distribution are just helpful for summarizing it. If choice of interval leads to different </span></span>
<span id="cb795-1678"><a href="#cb795-1678" aria-hidden="true" tabindex="-1"></a><span class="in">inferences, then you’d be better off just plotting the entire posterior distribution.</span></span>
<span id="cb795-1679"><a href="#cb795-1679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1680"><a href="#cb795-1680" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1681"><a href="#cb795-1681" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1682"><a href="#cb795-1682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1683"><a href="#cb795-1683" aria-hidden="true" tabindex="-1"></a><span class="fu">### Point estimates</span></span>
<span id="cb795-1684"><a href="#cb795-1684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1685"><a href="#cb795-1685" aria-hidden="true" tabindex="-1"></a>The Bayesian parameter estimate is precisely the entire posterior distribution, which is not a single number, but instead a function that maps each unique parameter value onto a plausibility value. So really the most important thing to note is that you don’t have to choose a point estimate. It’s hardly ever necessary.</span>
<span id="cb795-1686"><a href="#cb795-1686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1687"><a href="#cb795-1687" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;</span>***Which point estimate to choose if we must report: Mean, Median or Mode (MAP)?***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1688"><a href="#cb795-1688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1689"><a href="#cb795-1689" aria-hidden="true" tabindex="-1"></a><span class="in">```{r point_estimate}</span></span>
<span id="cb795-1690"><a href="#cb795-1690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1691"><a href="#cb795-1691" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the globe tossing example where 3 water observations out of 3 tosses</span></span>
<span id="cb795-1692"><a href="#cb795-1692" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb795-1693"><a href="#cb795-1693" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb795-1694"><a href="#cb795-1694" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">3</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-1695"><a href="#cb795-1695" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> prior <span class="sc">*</span> likelihood</span>
<span id="cb795-1696"><a href="#cb795-1696" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-1697"><a href="#cb795-1697" aria-hidden="true" tabindex="-1"></a>samples2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior)</span>
<span id="cb795-1698"><a href="#cb795-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1699"><a href="#cb795-1699" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the MAP from posterior</span></span>
<span id="cb795-1700"><a href="#cb795-1700" aria-hidden="true" tabindex="-1"></a><span class="co"># It is very common for scientists to report the parameter value with highest </span></span>
<span id="cb795-1701"><a href="#cb795-1701" aria-hidden="true" tabindex="-1"></a><span class="co"># posterior probability, a maximum a posteriori (MAP) estimate.</span></span>
<span id="cb795-1702"><a href="#cb795-1702" aria-hidden="true" tabindex="-1"></a>p_grid[ <span class="fu">which.max</span>(posterior) ]</span>
<span id="cb795-1703"><a href="#cb795-1703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1704"><a href="#cb795-1704" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute MAP using samples from posterior</span></span>
<span id="cb795-1705"><a href="#cb795-1705" aria-hidden="true" tabindex="-1"></a><span class="fu">chainmode</span>( samples2, <span class="at">adj =</span> <span class="fl">0.01</span>) <span class="co"># rethinking</span></span>
<span id="cb795-1706"><a href="#cb795-1706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1707"><a href="#cb795-1707" aria-hidden="true" tabindex="-1"></a>map_value <span class="ot">&lt;-</span> p_grid[ <span class="fu">which.max</span>(posterior) ]</span>
<span id="cb795-1708"><a href="#cb795-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1709"><a href="#cb795-1709" aria-hidden="true" tabindex="-1"></a><span class="co"># mean of the samples</span></span>
<span id="cb795-1710"><a href="#cb795-1710" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(samples2)</span>
<span id="cb795-1711"><a href="#cb795-1711" aria-hidden="true" tabindex="-1"></a>mean_value <span class="ot">&lt;-</span> <span class="fu">mean</span>(samples2)</span>
<span id="cb795-1712"><a href="#cb795-1712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1713"><a href="#cb795-1713" aria-hidden="true" tabindex="-1"></a><span class="co"># median of the samples</span></span>
<span id="cb795-1714"><a href="#cb795-1714" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(samples2)</span>
<span id="cb795-1715"><a href="#cb795-1715" aria-hidden="true" tabindex="-1"></a>median_value <span class="ot">&lt;-</span> <span class="fu">median</span>(samples2)</span>
<span id="cb795-1716"><a href="#cb795-1716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1717"><a href="#cb795-1717" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data frame for plotting</span></span>
<span id="cb795-1718"><a href="#cb795-1718" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(p_grid, posterior)</span>
<span id="cb795-1719"><a href="#cb795-1719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1720"><a href="#cb795-1720" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot with lines for mean, median, and mode</span></span>
<span id="cb795-1721"><a href="#cb795-1721" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span></span>
<span id="cb795-1722"><a href="#cb795-1722" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> posterior)) <span class="sc">+</span></span>
<span id="cb795-1723"><a href="#cb795-1723" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"brown"</span>) <span class="sc">+</span></span>
<span id="cb795-1724"><a href="#cb795-1724" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> posterior), <span class="at">fill =</span> <span class="st">"yellow"</span>) <span class="sc">+</span></span>
<span id="cb795-1725"><a href="#cb795-1725" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> map_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-1726"><a href="#cb795-1726" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-1727"><a href="#cb795-1727" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> median_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-1728"><a href="#cb795-1728" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> map_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="fu">round</span>(map_value, <span class="dv">2</span>), </span>
<span id="cb795-1729"><a href="#cb795-1729" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-1730"><a href="#cb795-1730" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="fu">round</span>(mean_value, <span class="dv">2</span>), </span>
<span id="cb795-1731"><a href="#cb795-1731" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-1732"><a href="#cb795-1732" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> median_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="fu">round</span>(median_value, <span class="dv">2</span>), </span>
<span id="cb795-1733"><a href="#cb795-1733" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-1734"><a href="#cb795-1734" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> map_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"mode"</span>, </span>
<span id="cb795-1735"><a href="#cb795-1735" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-1736"><a href="#cb795-1736" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"mean"</span>, </span>
<span id="cb795-1737"><a href="#cb795-1737" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-1738"><a href="#cb795-1738" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> median_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"median"</span>,</span>
<span id="cb795-1739"><a href="#cb795-1739" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-1740"><a href="#cb795-1740" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">'Posterior with Mean, Median, and Mode (MAP)'</span>,</span>
<span id="cb795-1741"><a href="#cb795-1741" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">'proportion of water (p)'</span>,</span>
<span id="cb795-1742"><a href="#cb795-1742" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">'density'</span>) <span class="sc">+</span></span>
<span id="cb795-1743"><a href="#cb795-1743" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb795-1744"><a href="#cb795-1744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1745"><a href="#cb795-1745" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1746"><a href="#cb795-1746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1747"><a href="#cb795-1747" aria-hidden="true" tabindex="-1"></a>The value for median, mean, and mode (MAP) are different. In this case, ***use a loss function to estimate the cost associated with using any particular point estimate.*** </span>
<span id="cb795-1748"><a href="#cb795-1748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1749"><a href="#cb795-1749" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Using loss function**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1750"><a href="#cb795-1750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1751"><a href="#cb795-1751" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Different loss functions imply different point estimates</span>
<span id="cb795-1752"><a href="#cb795-1752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1753"><a href="#cb795-1753" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The loss is proportional to the distance of your decision from the true value</span>
<span id="cb795-1754"><a href="#cb795-1754" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Loss $\propto$ d - p, where d is the decision and p is the correct answer or true value </span>
<span id="cb795-1755"><a href="#cb795-1755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1756"><a href="#cb795-1756" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-1757"><a href="#cb795-1757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1758"><a href="#cb795-1758" aria-hidden="true" tabindex="-1"></a><span class="ss">-  </span>The parameter value that maximizes expected winnings (minimizes expected loss) is the median of the posterior distribution</span>
<span id="cb795-1759"><a href="#cb795-1759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1760"><a href="#cb795-1760" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculating expected loss for any given decision means using the posterior to average over our uncertainty in the true value (unknown in most cases)</span>
<span id="cb795-1761"><a href="#cb795-1761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1762"><a href="#cb795-1762" aria-hidden="true" tabindex="-1"></a><span class="in">``` </span></span>
<span id="cb795-1763"><a href="#cb795-1763" aria-hidden="true" tabindex="-1"></a><span class="in">In order to decide upon a point estimate, a single-value summary of the posterior distribution, we need </span></span>
<span id="cb795-1764"><a href="#cb795-1764" aria-hidden="true" tabindex="-1"></a><span class="in">to pick a loss function. Different loss functions nominate different point estimates. The two most </span></span>
<span id="cb795-1765"><a href="#cb795-1765" aria-hidden="true" tabindex="-1"></a><span class="in">common examples are the absolute loss (d - p), which leads to the median as the point estimate, and the quadratic loss (d − p)2, which leads to the posterior mean (mean(samples)) as the point estimate. When </span></span>
<span id="cb795-1766"><a href="#cb795-1766" aria-hidden="true" tabindex="-1"></a><span class="in">the posterior distribution is symmetrical and normal-looking, then the median and mean converge to the same point.</span></span>
<span id="cb795-1767"><a href="#cb795-1767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1768"><a href="#cb795-1768" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1769"><a href="#cb795-1769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1770"><a href="#cb795-1770" aria-hidden="true" tabindex="-1"></a><span class="in">```{r loss}</span></span>
<span id="cb795-1771"><a href="#cb795-1771" aria-hidden="true" tabindex="-1"></a><span class="co"># If our decision is p = 0.5,</span></span>
<span id="cb795-1772"><a href="#cb795-1772" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the weighted average loss, where each loss is weighted by its </span></span>
<span id="cb795-1773"><a href="#cb795-1773" aria-hidden="true" tabindex="-1"></a><span class="co"># corresponding posterior probability</span></span>
<span id="cb795-1774"><a href="#cb795-1774" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(posterior <span class="sc">*</span> <span class="fu">abs</span>(<span class="fl">0.5</span> <span class="sc">-</span> p_grid))</span>
<span id="cb795-1775"><a href="#cb795-1775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1776"><a href="#cb795-1776" aria-hidden="true" tabindex="-1"></a><span class="co"># repeating this calculation for every possible decision, using the function sapply</span></span>
<span id="cb795-1777"><a href="#cb795-1777" aria-hidden="true" tabindex="-1"></a>loss <span class="ot">&lt;-</span> <span class="fu">sapply</span>( p_grid , <span class="cf">function</span>(d) <span class="fu">sum</span>( posterior<span class="sc">*</span><span class="fu">abs</span>( d <span class="sc">-</span> p_grid ) ) )</span>
<span id="cb795-1778"><a href="#cb795-1778" aria-hidden="true" tabindex="-1"></a><span class="co"># Now the symbol loss contains a list of loss values, one for each possible </span></span>
<span id="cb795-1779"><a href="#cb795-1779" aria-hidden="true" tabindex="-1"></a><span class="co"># decision, corresponding the values in p_grid</span></span>
<span id="cb795-1780"><a href="#cb795-1780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1781"><a href="#cb795-1781" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the parameter value that minimizes the loss</span></span>
<span id="cb795-1782"><a href="#cb795-1782" aria-hidden="true" tabindex="-1"></a>p_grid[ <span class="fu">which.min</span>(loss)]</span>
<span id="cb795-1783"><a href="#cb795-1783" aria-hidden="true" tabindex="-1"></a><span class="co"># And this is actually the posterior median, the parameter value that splits </span></span>
<span id="cb795-1784"><a href="#cb795-1784" aria-hidden="true" tabindex="-1"></a><span class="co"># the posterior density such that half of the mass is above it </span></span>
<span id="cb795-1785"><a href="#cb795-1785" aria-hidden="true" tabindex="-1"></a><span class="co"># and half below it</span></span>
<span id="cb795-1786"><a href="#cb795-1786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1787"><a href="#cb795-1787" aria-hidden="true" tabindex="-1"></a><span class="co"># Check with posterior median</span></span>
<span id="cb795-1788"><a href="#cb795-1788" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(samples2)</span>
<span id="cb795-1789"><a href="#cb795-1789" aria-hidden="true" tabindex="-1"></a><span class="co"># The answer match with the value that minimizes the loss</span></span>
<span id="cb795-1790"><a href="#cb795-1790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1791"><a href="#cb795-1791" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the loss function</span></span>
<span id="cb795-1792"><a href="#cb795-1792" aria-hidden="true" tabindex="-1"></a><span class="co"># Find x, y values for minimum loss</span></span>
<span id="cb795-1793"><a href="#cb795-1793" aria-hidden="true" tabindex="-1"></a>min_loss_x <span class="ot">&lt;-</span> p_grid[<span class="fu">which.min</span>(loss)]</span>
<span id="cb795-1794"><a href="#cb795-1794" aria-hidden="true" tabindex="-1"></a>min_loss_y <span class="ot">&lt;-</span> loss[<span class="fu">which.min</span>(loss)]</span>
<span id="cb795-1795"><a href="#cb795-1795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1796"><a href="#cb795-1796" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame and plot </span></span>
<span id="cb795-1797"><a href="#cb795-1797" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(p_grid, loss, posterior)</span>
<span id="cb795-1798"><a href="#cb795-1798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1799"><a href="#cb795-1799" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb795-1800"><a href="#cb795-1800" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid)) <span class="sc">+</span></span>
<span id="cb795-1801"><a href="#cb795-1801" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> loss), <span class="at">fill =</span> <span class="st">'grey75'</span>) <span class="sc">+</span></span>
<span id="cb795-1802"><a href="#cb795-1802" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> min_loss_x, <span class="at">y =</span> min_loss_y), <span class="at">size =</span> <span class="dv">3</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">color =</span> <span class="st">'black'</span>) <span class="sc">+</span></span>
<span id="cb795-1803"><a href="#cb795-1803" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> map_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb795-1804"><a href="#cb795-1804" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb795-1805"><a href="#cb795-1805" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> median_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb795-1806"><a href="#cb795-1806" aria-hidden="true" tabindex="-1"></a>   <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> map_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"mode"</span>, </span>
<span id="cb795-1807"><a href="#cb795-1807" aria-hidden="true" tabindex="-1"></a>            <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-1808"><a href="#cb795-1808" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"mean"</span>, </span>
<span id="cb795-1809"><a href="#cb795-1809" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-1810"><a href="#cb795-1810" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> median_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"median"</span>, </span>
<span id="cb795-1811"><a href="#cb795-1811" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-1812"><a href="#cb795-1812" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> min_loss_x, <span class="at">y =</span> min_loss_y, <span class="at">label =</span> <span class="st">"value that </span><span class="sc">\n</span><span class="st">minimizes loss"</span>, </span>
<span id="cb795-1813"><a href="#cb795-1813" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="fl">1.2</span>, <span class="at">hjust =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-1814"><a href="#cb795-1814" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">'decision'</span>,</span>
<span id="cb795-1815"><a href="#cb795-1815" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">'expected proportional loss'</span>) <span class="sc">+</span></span>
<span id="cb795-1816"><a href="#cb795-1816" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-1817"><a href="#cb795-1817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1818"><a href="#cb795-1818" aria-hidden="true" tabindex="-1"></a><span class="co"># Expected loss under the rule that loss is proportional to absolute distance </span></span>
<span id="cb795-1819"><a href="#cb795-1819" aria-hidden="true" tabindex="-1"></a><span class="co"># of decision (horizontal axis) from the true value. The point marks the value </span></span>
<span id="cb795-1820"><a href="#cb795-1820" aria-hidden="true" tabindex="-1"></a><span class="co"># of p that minimizes the expected loss, the posterior median.</span></span>
<span id="cb795-1821"><a href="#cb795-1821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1822"><a href="#cb795-1822" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1823"><a href="#cb795-1823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1824"><a href="#cb795-1824" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1825"><a href="#cb795-1825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1826"><a href="#cb795-1826" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sampling to simulate prediction</span></span>
<span id="cb795-1827"><a href="#cb795-1827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1828"><a href="#cb795-1828" aria-hidden="true" tabindex="-1"></a>Samples from posterior ease simulation of the model’s implied observations. Generating implied observations from a model is useful for at least four distinct reasons.</span>
<span id="cb795-1829"><a href="#cb795-1829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1830"><a href="#cb795-1830" aria-hidden="true" tabindex="-1"></a>(1) Model checking- to check whether the fit worked correctly and to investigate model behavior</span>
<span id="cb795-1831"><a href="#cb795-1831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1832"><a href="#cb795-1832" aria-hidden="true" tabindex="-1"></a>(2) Software validation- simulate observations under a known model and then attempt to recover the values of the parameters the data were simulated under</span>
<span id="cb795-1833"><a href="#cb795-1833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1834"><a href="#cb795-1834" aria-hidden="true" tabindex="-1"></a>(3) Research design- simulate observations from hypothesis to evaluate whether the research design can be effective</span>
<span id="cb795-1835"><a href="#cb795-1835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1836"><a href="#cb795-1836" aria-hidden="true" tabindex="-1"></a>(4) Forecasting- can be useful as applied prediction, but also for model criticism and revision</span>
<span id="cb795-1837"><a href="#cb795-1837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1838"><a href="#cb795-1838" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1839"><a href="#cb795-1839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1840"><a href="#cb795-1840" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dummy data (simulated data)</span></span>
<span id="cb795-1841"><a href="#cb795-1841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1842"><a href="#cb795-1842" aria-hidden="true" tabindex="-1"></a>Likelihood functions work in both directions. Given a realized observation, the likelihood function says how plausible the observation is. And given only the parameters, the likelihood defines a distribution of possible observations that we can sample from, to simulate observation. In this way, Bayesian models are always generative, capable of simulating predictions. </span>
<span id="cb795-1843"><a href="#cb795-1843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1844"><a href="#cb795-1844" aria-hidden="true" tabindex="-1"></a>With the globe tossing model, the dummy data arises from a binomial likelihood:</span>
<span id="cb795-1845"><a href="#cb795-1845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1846"><a href="#cb795-1846" aria-hidden="true" tabindex="-1"></a>Pr(w|n,p) = $\frac{n!}{w!(n - w)!}$p^w^ (1 - p)^n-w^</span>
<span id="cb795-1847"><a href="#cb795-1847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1848"><a href="#cb795-1848" aria-hidden="true" tabindex="-1"></a>where w is an observed count of “water” and n is the number of tosses. Suppose n = 2, two tosses of the globe. Then there are only three possible observations: 0 water, 1 water, 2 water. You can quickly compute the likelihood of each, for any given value of p. Let’s use p = 0.7, which is just about the true proportion of water on the Earth:</span>
<span id="cb795-1849"><a href="#cb795-1849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1850"><a href="#cb795-1850" aria-hidden="true" tabindex="-1"></a><span class="in">```{r likelihood}</span></span>
<span id="cb795-1851"><a href="#cb795-1851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1852"><a href="#cb795-1852" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">prob =</span> <span class="fl">0.7</span>)</span>
<span id="cb795-1853"><a href="#cb795-1853" aria-hidden="true" tabindex="-1"></a><span class="co"># 9% chance of observing w = 0, a 42% chance of w = 1, and a 49% chance of w = 2</span></span>
<span id="cb795-1854"><a href="#cb795-1854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1855"><a href="#cb795-1855" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1856"><a href="#cb795-1856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1857"><a href="#cb795-1857" aria-hidden="true" tabindex="-1"></a>Now we’re going to simulate observations, using these likelihoods. So a single dummy data observation of w can be sampled with:</span>
<span id="cb795-1858"><a href="#cb795-1858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1859"><a href="#cb795-1859" aria-hidden="true" tabindex="-1"></a><span class="in">```{r rbinom}</span></span>
<span id="cb795-1860"><a href="#cb795-1860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1861"><a href="#cb795-1861" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">prob =</span> <span class="fl">0.7</span>)</span>
<span id="cb795-1862"><a href="#cb795-1862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1863"><a href="#cb795-1863" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1864"><a href="#cb795-1864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1865"><a href="#cb795-1865" aria-hidden="true" tabindex="-1"></a>The “r” in rbinom stands for “random.” It can also generate more than one simulation at a</span>
<span id="cb795-1866"><a href="#cb795-1866" aria-hidden="true" tabindex="-1"></a>time. A set of 10 simulations can be made by:</span>
<span id="cb795-1867"><a href="#cb795-1867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1868"><a href="#cb795-1868" aria-hidden="true" tabindex="-1"></a><span class="in">```{r rbinom1}</span></span>
<span id="cb795-1869"><a href="#cb795-1869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1870"><a href="#cb795-1870" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">prob =</span> <span class="fl">0.7</span>)</span>
<span id="cb795-1871"><a href="#cb795-1871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1872"><a href="#cb795-1872" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1873"><a href="#cb795-1873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1874"><a href="#cb795-1874" aria-hidden="true" tabindex="-1"></a>Let’s generate 100,000 dummy observations, just to verify that each value (0, 1, or 2) appears in proportion to its likelihood:</span>
<span id="cb795-1875"><a href="#cb795-1875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1876"><a href="#cb795-1876" aria-hidden="true" tabindex="-1"></a><span class="in">```{r check}</span></span>
<span id="cb795-1877"><a href="#cb795-1877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1878"><a href="#cb795-1878" aria-hidden="true" tabindex="-1"></a>dummy_w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e5</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">prob =</span> <span class="fl">0.7</span>)</span>
<span id="cb795-1879"><a href="#cb795-1879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1880"><a href="#cb795-1880" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(dummy_w) <span class="sc">/</span><span class="fl">1e5</span></span>
<span id="cb795-1881"><a href="#cb795-1881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1882"><a href="#cb795-1882" aria-hidden="true" tabindex="-1"></a><span class="co"># values are very close to the likelihood values calculated above</span></span>
<span id="cb795-1883"><a href="#cb795-1883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1884"><a href="#cb795-1884" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1885"><a href="#cb795-1885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1886"><a href="#cb795-1886" aria-hidden="true" tabindex="-1"></a>Now let’s simulate the same sample size as before, 9 tosses.</span>
<span id="cb795-1887"><a href="#cb795-1887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1888"><a href="#cb795-1888" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 9tosses}</span></span>
<span id="cb795-1889"><a href="#cb795-1889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1890"><a href="#cb795-1890" aria-hidden="true" tabindex="-1"></a>dummy_w_9 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e5</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> <span class="fl">0.7</span>)</span>
<span id="cb795-1891"><a href="#cb795-1891" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(dummy_w_9)<span class="sc">/</span> <span class="fl">1e5</span></span>
<span id="cb795-1892"><a href="#cb795-1892" aria-hidden="true" tabindex="-1"></a><span class="fu">simplehist</span>(dummy_w_9, <span class="at">xlab =</span> <span class="st">"dummy water count"</span>)</span>
<span id="cb795-1893"><a href="#cb795-1893" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution of simulated sample observations from 9 tosses of the globe. </span></span>
<span id="cb795-1894"><a href="#cb795-1894" aria-hidden="true" tabindex="-1"></a><span class="co"># These samples assume the proportion of water is 0.7.</span></span>
<span id="cb795-1895"><a href="#cb795-1895" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice that most of the time the expected observation does not contain water </span></span>
<span id="cb795-1896"><a href="#cb795-1896" aria-hidden="true" tabindex="-1"></a><span class="co"># in its true proportion, 0.7. That’s the nature of observation: There is a </span></span>
<span id="cb795-1897"><a href="#cb795-1897" aria-hidden="true" tabindex="-1"></a><span class="co"># one-to-many relationship between data and data-generating processes.</span></span>
<span id="cb795-1898"><a href="#cb795-1898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1899"><a href="#cb795-1899" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1900"><a href="#cb795-1900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1901"><a href="#cb795-1901" aria-hidden="true" tabindex="-1"></a>Test with sample size = 40 and probability p = 0.5</span>
<span id="cb795-1902"><a href="#cb795-1902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1903"><a href="#cb795-1903" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 40tosses}</span></span>
<span id="cb795-1904"><a href="#cb795-1904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1905"><a href="#cb795-1905" aria-hidden="true" tabindex="-1"></a>dummy_w_40 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e5</span>, <span class="at">size =</span> <span class="dv">40</span>, <span class="at">prob =</span> <span class="fl">0.5</span>)</span>
<span id="cb795-1906"><a href="#cb795-1906" aria-hidden="true" tabindex="-1"></a><span class="fu">simplehist</span>(dummy_w_40, <span class="at">xlab =</span> <span class="st">"dummy water count"</span>)</span>
<span id="cb795-1907"><a href="#cb795-1907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1908"><a href="#cb795-1908" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1909"><a href="#cb795-1909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1910"><a href="#cb795-1910" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Sampling distribution**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1911"><a href="#cb795-1911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1912"><a href="#cb795-1912" aria-hidden="true" tabindex="-1"></a>In this book, inference about parameters is never done directly through a sampling distribution. The posterior distribution is not sampled, but deduced logically. Then samples can be drawn from the posterior, to aid in inference. In neither case is “sampling” a physical act. In both cases, it’s just a mathematical device and produces only small world numbers.</span>
<span id="cb795-1913"><a href="#cb795-1913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1914"><a href="#cb795-1914" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1915"><a href="#cb795-1915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1916"><a href="#cb795-1916" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model checking</span></span>
<span id="cb795-1917"><a href="#cb795-1917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1918"><a href="#cb795-1918" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ensures the model fitting worked correctly</span>
<span id="cb795-1919"><a href="#cb795-1919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1920"><a href="#cb795-1920" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Evaluate the adequacy of a model for some purpose</span>
<span id="cb795-1921"><a href="#cb795-1921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1922"><a href="#cb795-1922" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1923"><a href="#cb795-1923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1924"><a href="#cb795-1924" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Did the software work?</span></span>
<span id="cb795-1925"><a href="#cb795-1925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1926"><a href="#cb795-1926" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use retrodictions (implied predictions) to check whether the software worked- by checking for correspondence between implied predictions and the data used to fit the model</span>
<span id="cb795-1927"><a href="#cb795-1927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1928"><a href="#cb795-1928" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>An exact match is neither expected nor desired, but when there is no correspondence at all, it probably means the software did something wrong.</span>
<span id="cb795-1929"><a href="#cb795-1929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1930"><a href="#cb795-1930" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>There is no way to really be sure that software works correctly. Even when the retrodictions correspond to the observed data, there may be subtle mistakes.</span>
<span id="cb795-1931"><a href="#cb795-1931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1932"><a href="#cb795-1932" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1933"><a href="#cb795-1933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1934"><a href="#cb795-1934" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Is the model adequate?</span></span>
<span id="cb795-1935"><a href="#cb795-1935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1936"><a href="#cb795-1936" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Look for aspects of the data that are not well described by the model’s expectations</span>
<span id="cb795-1937"><a href="#cb795-1937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1938"><a href="#cb795-1938" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The goal is not to test whether the model’s assumptions are “true,” because all models are false</span>
<span id="cb795-1939"><a href="#cb795-1939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1940"><a href="#cb795-1940" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The goal is to assess exactly how the model fails to describe the data, as a path towards model comprehension, revision, and improvement</span>
<span id="cb795-1941"><a href="#cb795-1941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1942"><a href="#cb795-1942" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;</span>***Basic model checks using simulated observations for the globe tossing model***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1943"><a href="#cb795-1943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1944"><a href="#cb795-1944" aria-hidden="true" tabindex="-1"></a>The implied predictions of the model are uncertain in two ways, and we’d like to propagate the parameter uncertainty as we evaluate the implied predictions, i.e. get a posterior predictive distribution.</span>
<span id="cb795-1945"><a href="#cb795-1945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1946"><a href="#cb795-1946" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Observation uncertainty</span>
<span id="cb795-1947"><a href="#cb795-1947" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>There is uncertainty in the predicted observations, because even if you know p with certainty, you won’t know the next globe toss with certainty (unless p = 0 or p = 1).</span>
<span id="cb795-1948"><a href="#cb795-1948" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-1949"><a href="#cb795-1949" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-1950"><a href="#cb795-1950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1951"><a href="#cb795-1951" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Uncertainty about p </span>
<span id="cb795-1952"><a href="#cb795-1952" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Since there is uncertainty about p, there is uncertainty about everything that depends upon p.</span>
<span id="cb795-1953"><a href="#cb795-1953" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>The uncertainty in p will interact with the sampling variation, when we try to assess what the model tells us about outcomes.</span>
<span id="cb795-1954"><a href="#cb795-1954" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-1955"><a href="#cb795-1955" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1956"><a href="#cb795-1956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1957"><a href="#cb795-1957" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Posterior predictive distribution**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1958"><a href="#cb795-1958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1959"><a href="#cb795-1959" aria-hidden="true" tabindex="-1"></a>For each possible value of the parameter p, there is an implied distribution of outcomes. So if you were to compute the sampling distribution of outcomes at each value of p, then you could average all of these prediction distributions together, using the posterior probabilities of each value of p, to get a posterior predictive distribution.</span>
<span id="cb795-1960"><a href="#cb795-1960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1961"><a href="#cb795-1961" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The sampling distributions for all values of p are combined, using the posterior probabilities to compute the weighted average frequency of each possible observation.</span>
<span id="cb795-1962"><a href="#cb795-1962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1963"><a href="#cb795-1963" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>It incorporates all of the uncertainty embodied in the posterior distribution for the parameter p. As a result, it is honest- the distribution may be narrower (overconfidence) if we discard uncertainty about the parameters. </span>
<span id="cb795-1964"><a href="#cb795-1964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1965"><a href="#cb795-1965" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Calculate posterior predictive distribution***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-1966"><a href="#cb795-1966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1967"><a href="#cb795-1967" aria-hidden="true" tabindex="-1"></a><span class="in">```{r PPD}</span></span>
<span id="cb795-1968"><a href="#cb795-1968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1969"><a href="#cb795-1969" aria-hidden="true" tabindex="-1"></a><span class="co"># To simulate predicted observations for a single value of p, say p = 0.6, </span></span>
<span id="cb795-1970"><a href="#cb795-1970" aria-hidden="true" tabindex="-1"></a><span class="co"># you can use rbinom to generate random binomial samples:</span></span>
<span id="cb795-1971"><a href="#cb795-1971" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> <span class="fl">0.6</span>)</span>
<span id="cb795-1972"><a href="#cb795-1972" aria-hidden="true" tabindex="-1"></a><span class="fu">simplehist</span>(w, <span class="at">xlab =</span> <span class="st">"number of water samples"</span>)</span>
<span id="cb795-1973"><a href="#cb795-1973" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1974"><a href="#cb795-1974" aria-hidden="true" tabindex="-1"></a><span class="co"># All you need to propagate parameter uncertainty into these predictions is </span></span>
<span id="cb795-1975"><a href="#cb795-1975" aria-hidden="true" tabindex="-1"></a><span class="co"># replace the value 0.6 with samples from the posterior:</span></span>
<span id="cb795-1976"><a href="#cb795-1976" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> samples)</span>
<span id="cb795-1977"><a href="#cb795-1977" aria-hidden="true" tabindex="-1"></a><span class="fu">simplehist</span>(w, <span class="at">xlab =</span> <span class="st">"number of water samples"</span>, <span class="at">main =</span> <span class="st">"PPD"</span>)</span>
<span id="cb795-1978"><a href="#cb795-1978" aria-hidden="true" tabindex="-1"></a><span class="co"># For each sampled value, a random binomial observation is generated. </span></span>
<span id="cb795-1979"><a href="#cb795-1979" aria-hidden="true" tabindex="-1"></a><span class="co"># Since the sampled values appear in proportion to their posterior probabilities,</span></span>
<span id="cb795-1980"><a href="#cb795-1980" aria-hidden="true" tabindex="-1"></a><span class="co"># the resulting simulated observations are averaged over the posterior. </span></span>
<span id="cb795-1981"><a href="#cb795-1981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1982"><a href="#cb795-1982" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1983"><a href="#cb795-1983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1984"><a href="#cb795-1984" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1985"><a href="#cb795-1985" aria-hidden="true" tabindex="-1"></a><span class="in">In your own modeling, you’ll have to imagine aspects of the data that are relevant in your context, for your purposes, i.e. inspect the data in new ways, e.g. correlation between samples that may be bias. </span></span>
<span id="cb795-1986"><a href="#cb795-1986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1987"><a href="#cb795-1987" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-1988"><a href="#cb795-1988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1989"><a href="#cb795-1989" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-1990"><a href="#cb795-1990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1991"><a href="#cb795-1991" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice</span></span>
<span id="cb795-1992"><a href="#cb795-1992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1993"><a href="#cb795-1993" aria-hidden="true" tabindex="-1"></a><span class="fu">### Easy</span></span>
<span id="cb795-1994"><a href="#cb795-1994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1995"><a href="#cb795-1995" aria-hidden="true" tabindex="-1"></a><span class="in">```{r practice_sample}</span></span>
<span id="cb795-1996"><a href="#cb795-1996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-1997"><a href="#cb795-1997" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">0</span> , <span class="at">to=</span><span class="dv">1</span> , <span class="at">length.out=</span><span class="dv">10000</span> )</span>
<span id="cb795-1998"><a href="#cb795-1998" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>( <span class="dv">1</span> , <span class="dv">10000</span> )</span>
<span id="cb795-1999"><a href="#cb795-1999" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>( <span class="dv">6</span> , <span class="at">size=</span><span class="dv">9</span> , <span class="at">prob=</span>p_grid )</span>
<span id="cb795-2000"><a href="#cb795-2000" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2001"><a href="#cb795-2001" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior)</span>
<span id="cb795-2002"><a href="#cb795-2002" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb795-2003"><a href="#cb795-2003" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">&lt;-</span> <span class="fu">sample</span>( p_grid , <span class="at">prob=</span>posterior , <span class="at">size=</span><span class="fl">1e4</span> , <span class="at">replace=</span><span class="cn">TRUE</span> )</span>
<span id="cb795-2004"><a href="#cb795-2004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2005"><a href="#cb795-2005" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2006"><a href="#cb795-2006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2007"><a href="#cb795-2007" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3E1. How much posterior probability lies below p = 0.2?</span></span>
<span id="cb795-2008"><a href="#cb795-2008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2009"><a href="#cb795-2009" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3E1}</span></span>
<span id="cb795-2010"><a href="#cb795-2010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2011"><a href="#cb795-2011" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(samples <span class="sc">&lt;</span> <span class="fl">0.2</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-2012"><a href="#cb795-2012" aria-hidden="true" tabindex="-1"></a><span class="co"># 5 x 10^-4^ % of posterior probability lies below p = 0.2.</span></span>
<span id="cb795-2013"><a href="#cb795-2013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2014"><a href="#cb795-2014" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2015"><a href="#cb795-2015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2016"><a href="#cb795-2016" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2017"><a href="#cb795-2017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2018"><a href="#cb795-2018" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3E2. How much posterior probability lies above p = 0.8?</span></span>
<span id="cb795-2019"><a href="#cb795-2019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2020"><a href="#cb795-2020" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3E2}</span></span>
<span id="cb795-2021"><a href="#cb795-2021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2022"><a href="#cb795-2022" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(samples <span class="sc">&gt;</span> <span class="fl">0.8</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-2023"><a href="#cb795-2023" aria-hidden="true" tabindex="-1"></a><span class="co"># 12% of posterior probability lies between p = 0.2 and p = 0.8</span></span>
<span id="cb795-2024"><a href="#cb795-2024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2025"><a href="#cb795-2025" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2026"><a href="#cb795-2026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2027"><a href="#cb795-2027" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2028"><a href="#cb795-2028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2029"><a href="#cb795-2029" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3E3. How much posterior probability lies between p = 0.2 and p = 0.8? </span></span>
<span id="cb795-2030"><a href="#cb795-2030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2031"><a href="#cb795-2031" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3E3}</span></span>
<span id="cb795-2032"><a href="#cb795-2032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2033"><a href="#cb795-2033" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(samples <span class="sc">&gt;</span> <span class="fl">0.2</span> <span class="sc">&amp;</span> samples <span class="sc">&lt;</span> <span class="fl">0.8</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-2034"><a href="#cb795-2034" aria-hidden="true" tabindex="-1"></a><span class="co"># 88% of posterior probability lies between p = 0.2 and p = 0.8</span></span>
<span id="cb795-2035"><a href="#cb795-2035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2036"><a href="#cb795-2036" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2037"><a href="#cb795-2037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2038"><a href="#cb795-2038" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2039"><a href="#cb795-2039" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-2040"><a href="#cb795-2040" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3E4. 20% of the posterior probability lies below which value of p?</span></span>
<span id="cb795-2041"><a href="#cb795-2041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2042"><a href="#cb795-2042" aria-hidden="true" tabindex="-1"></a><span class="in">``` {r 3E4}</span></span>
<span id="cb795-2043"><a href="#cb795-2043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2044"><a href="#cb795-2044" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(samples, <span class="fl">0.2</span>)</span>
<span id="cb795-2045"><a href="#cb795-2045" aria-hidden="true" tabindex="-1"></a><span class="co"># 20% of the posterior probability lies below p = 0.51</span></span>
<span id="cb795-2046"><a href="#cb795-2046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2047"><a href="#cb795-2047" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2048"><a href="#cb795-2048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2049"><a href="#cb795-2049" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3E5. 20% of the posterior probability lies above which value of p?</span></span>
<span id="cb795-2050"><a href="#cb795-2050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2051"><a href="#cb795-2051" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3E5}</span></span>
<span id="cb795-2052"><a href="#cb795-2052" aria-hidden="true" tabindex="-1"></a><span class="co"># 20% is the quantile in the upper end of distribution,</span></span>
<span id="cb795-2053"><a href="#cb795-2053" aria-hidden="true" tabindex="-1"></a><span class="co"># hence we find quantile value below 80%</span></span>
<span id="cb795-2054"><a href="#cb795-2054" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(samples, <span class="fl">0.8</span>)</span>
<span id="cb795-2055"><a href="#cb795-2055" aria-hidden="true" tabindex="-1"></a><span class="co"># 20% of the posterior probability lies above p = 0.76</span></span>
<span id="cb795-2056"><a href="#cb795-2056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2057"><a href="#cb795-2057" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2058"><a href="#cb795-2058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2059"><a href="#cb795-2059" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2060"><a href="#cb795-2060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2061"><a href="#cb795-2061" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3E6. Which values of p contain the narrowest interval equal to 66% of the posterior probability?</span></span>
<span id="cb795-2062"><a href="#cb795-2062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2063"><a href="#cb795-2063" aria-hidden="true" tabindex="-1"></a><span class="in">``` {r 3E6}</span></span>
<span id="cb795-2064"><a href="#cb795-2064" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(samples, <span class="fl">0.66</span>)</span>
<span id="cb795-2065"><a href="#cb795-2065" aria-hidden="true" tabindex="-1"></a><span class="co"># p interval of 0.5-0.8 contain the narrowest interval equal to 66% of </span></span>
<span id="cb795-2066"><a href="#cb795-2066" aria-hidden="true" tabindex="-1"></a><span class="co"># the posterior probability</span></span>
<span id="cb795-2067"><a href="#cb795-2067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2068"><a href="#cb795-2068" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2069"><a href="#cb795-2069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2070"><a href="#cb795-2070" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2071"><a href="#cb795-2071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2072"><a href="#cb795-2072" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3E7. Which values of p contain 66% of the posterior probability, assuming equal posterior probability both below and above the interval?</span></span>
<span id="cb795-2073"><a href="#cb795-2073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2074"><a href="#cb795-2074" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3E7}</span></span>
<span id="cb795-2075"><a href="#cb795-2075" aria-hidden="true" tabindex="-1"></a><span class="fu">PI</span>(samples, <span class="fl">0.66</span>)</span>
<span id="cb795-2076"><a href="#cb795-2076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2077"><a href="#cb795-2077" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2078"><a href="#cb795-2078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2079"><a href="#cb795-2079" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2080"><a href="#cb795-2080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2081"><a href="#cb795-2081" aria-hidden="true" tabindex="-1"></a><span class="fu">### Medium</span></span>
<span id="cb795-2082"><a href="#cb795-2082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2083"><a href="#cb795-2083" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3M1. Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.</span></span>
<span id="cb795-2084"><a href="#cb795-2084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2085"><a href="#cb795-2085" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3M1}</span></span>
<span id="cb795-2086"><a href="#cb795-2086" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10000</span>)</span>
<span id="cb795-2087"><a href="#cb795-2087" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">10000</span>)</span>
<span id="cb795-2088"><a href="#cb795-2088" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">8</span>, <span class="at">size =</span> <span class="dv">15</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2089"><a href="#cb795-2089" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2090"><a href="#cb795-2090" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2091"><a href="#cb795-2091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2092"><a href="#cb795-2092" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(posterior<span class="sc">~</span>p_grid, <span class="at">type =</span><span class="st">"l"</span>)</span>
<span id="cb795-2093"><a href="#cb795-2093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2094"><a href="#cb795-2094" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2095"><a href="#cb795-2095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2096"><a href="#cb795-2096" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2097"><a href="#cb795-2097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2098"><a href="#cb795-2098" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3M2. Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p.</span></span>
<span id="cb795-2099"><a href="#cb795-2099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2100"><a href="#cb795-2100" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3M2}</span></span>
<span id="cb795-2101"><a href="#cb795-2101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2102"><a href="#cb795-2102" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10000</span>)</span>
<span id="cb795-2103"><a href="#cb795-2103" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">10000</span>)</span>
<span id="cb795-2104"><a href="#cb795-2104" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">8</span>, <span class="at">size =</span> <span class="dv">15</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2105"><a href="#cb795-2105" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2106"><a href="#cb795-2106" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2107"><a href="#cb795-2107" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb795-2108"><a href="#cb795-2108" aria-hidden="true" tabindex="-1"></a>sample3m2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior)</span>
<span id="cb795-2109"><a href="#cb795-2109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2110"><a href="#cb795-2110" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 90% HPDI for p </span></span>
<span id="cb795-2111"><a href="#cb795-2111" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample3m2, <span class="fl">0.9</span>)</span>
<span id="cb795-2112"><a href="#cb795-2112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2113"><a href="#cb795-2113" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2114"><a href="#cb795-2114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2115"><a href="#cb795-2115" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2116"><a href="#cb795-2116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2117"><a href="#cb795-2117" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3M3. Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in p. What is the probability of observing 8 water in 15 tosses?</span></span>
<span id="cb795-2118"><a href="#cb795-2118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2119"><a href="#cb795-2119" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3M3}</span></span>
<span id="cb795-2120"><a href="#cb795-2120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2121"><a href="#cb795-2121" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">15</span>, <span class="at">prob =</span> sample3m2)</span>
<span id="cb795-2122"><a href="#cb795-2122" aria-hidden="true" tabindex="-1"></a><span class="fu">simplehist</span>(w, <span class="at">xlab=</span> <span class="st">"number of water observations"</span>)</span>
<span id="cb795-2123"><a href="#cb795-2123" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(w <span class="sc">==</span> <span class="dv">8</span>)<span class="sc">/</span><span class="fl">1e4</span></span>
<span id="cb795-2124"><a href="#cb795-2124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2125"><a href="#cb795-2125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2126"><a href="#cb795-2126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2127"><a href="#cb795-2127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2128"><a href="#cb795-2128" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2129"><a href="#cb795-2129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2130"><a href="#cb795-2130" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3M4. Using the posterior distribution constructed from the new (8/15) data,now calculate the probability of observing 6 water in 9 tosses.</span></span>
<span id="cb795-2131"><a href="#cb795-2131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2132"><a href="#cb795-2132" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3M4}</span></span>
<span id="cb795-2133"><a href="#cb795-2133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2134"><a href="#cb795-2134" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> sample3m2)</span>
<span id="cb795-2135"><a href="#cb795-2135" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(w)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-2136"><a href="#cb795-2136" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability of 6w in 9n is 18%</span></span>
<span id="cb795-2137"><a href="#cb795-2137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2138"><a href="#cb795-2138" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the answer only</span></span>
<span id="cb795-2139"><a href="#cb795-2139" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(w <span class="sc">==</span> <span class="dv">6</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-2140"><a href="#cb795-2140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2141"><a href="#cb795-2141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2142"><a href="#cb795-2142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2143"><a href="#cb795-2143" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2144"><a href="#cb795-2144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2145"><a href="#cb795-2145" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3M5. Start over at 3M1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority of the Earth’s surface is water. Repeat each problem above and compare the inferences. What difference does the better prior make? If it helps, compare inferences (using both priors) to the true value p = 0.7.</span></span>
<span id="cb795-2146"><a href="#cb795-2146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2147"><a href="#cb795-2147" aria-hidden="true" tabindex="-1"></a>*For 3M1 and 3M3*</span>
<span id="cb795-2148"><a href="#cb795-2148" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3M51}</span></span>
<span id="cb795-2149"><a href="#cb795-2149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2150"><a href="#cb795-2150" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up a 1x2 layout for side-by-side plots</span></span>
<span id="cb795-2151"><a href="#cb795-2151" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb795-2152"><a href="#cb795-2152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2153"><a href="#cb795-2153" aria-hidden="true" tabindex="-1"></a><span class="co"># First plot</span></span>
<span id="cb795-2154"><a href="#cb795-2154" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10000</span>)</span>
<span id="cb795-2155"><a href="#cb795-2155" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">10000</span>)</span>
<span id="cb795-2156"><a href="#cb795-2156" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">8</span>, <span class="at">size =</span> <span class="dv">15</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2157"><a href="#cb795-2157" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2158"><a href="#cb795-2158" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2159"><a href="#cb795-2159" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(posterior <span class="sc">~</span> p_grid, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="dv">1</span>, </span>
<span id="cb795-2160"><a href="#cb795-2160" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Probability of water"</span>, <span class="at">ylab =</span> <span class="st">"Posterior distribution"</span>,</span>
<span id="cb795-2161"><a href="#cb795-2161" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Prior = 1"</span>)</span>
<span id="cb795-2162"><a href="#cb795-2162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2163"><a href="#cb795-2163" aria-hidden="true" tabindex="-1"></a><span class="co"># Second plot</span></span>
<span id="cb795-2164"><a href="#cb795-2164" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">15</span>, <span class="at">prob =</span> sample3m2)</span>
<span id="cb795-2165"><a href="#cb795-2165" aria-hidden="true" tabindex="-1"></a><span class="fu">simplehist</span>(w, <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">lty =</span> <span class="dv">1</span>,</span>
<span id="cb795-2166"><a href="#cb795-2166" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Count of water observations"</span>, <span class="at">ylab =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb795-2167"><a href="#cb795-2167" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Prior = 1"</span>)</span>
<span id="cb795-2168"><a href="#cb795-2168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2169"><a href="#cb795-2169" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up a 1x2 layout for side-by-side plots</span></span>
<span id="cb795-2170"><a href="#cb795-2170" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb795-2171"><a href="#cb795-2171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2172"><a href="#cb795-2172" aria-hidden="true" tabindex="-1"></a><span class="co"># Third plot</span></span>
<span id="cb795-2173"><a href="#cb795-2173" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10000</span>)</span>
<span id="cb795-2174"><a href="#cb795-2174" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(p_grid <span class="sc">&lt;</span> <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb795-2175"><a href="#cb795-2175" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">8</span>, <span class="at">size =</span> <span class="dv">15</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2176"><a href="#cb795-2176" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2177"><a href="#cb795-2177" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior <span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2178"><a href="#cb795-2178" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">102</span>)</span>
<span id="cb795-2179"><a href="#cb795-2179" aria-hidden="true" tabindex="-1"></a>sample3m5 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">prob =</span> posterior, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb795-2180"><a href="#cb795-2180" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(posterior <span class="sc">~</span> p_grid, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lty =</span> <span class="dv">1</span>, </span>
<span id="cb795-2181"><a href="#cb795-2181" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Probability of water"</span>, <span class="at">ylab =</span> <span class="st">"Posterior distribution"</span>,</span>
<span id="cb795-2182"><a href="#cb795-2182" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Prior = 0 or 1"</span>)</span>
<span id="cb795-2183"><a href="#cb795-2183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2184"><a href="#cb795-2184" aria-hidden="true" tabindex="-1"></a><span class="co"># Fourth plot</span></span>
<span id="cb795-2185"><a href="#cb795-2185" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">15</span>, <span class="at">prob =</span> sample3m5)</span>
<span id="cb795-2186"><a href="#cb795-2186" aria-hidden="true" tabindex="-1"></a><span class="fu">simplehist</span>(w, <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">lty =</span> <span class="dv">1</span>,</span>
<span id="cb795-2187"><a href="#cb795-2187" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Count of water observations"</span>, <span class="at">ylab =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb795-2188"><a href="#cb795-2188" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Prior = 0 or 1"</span>)</span>
<span id="cb795-2189"><a href="#cb795-2189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2190"><a href="#cb795-2190" aria-hidden="true" tabindex="-1"></a><span class="co"># When the prior becomes more informative, there is a mismatch between prediction and observed data</span></span>
<span id="cb795-2191"><a href="#cb795-2191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2192"><a href="#cb795-2192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2193"><a href="#cb795-2193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2194"><a href="#cb795-2194" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2195"><a href="#cb795-2195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2196"><a href="#cb795-2196" aria-hidden="true" tabindex="-1"></a>*For 3M2*</span>
<span id="cb795-2197"><a href="#cb795-2197" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3M52}</span></span>
<span id="cb795-2198"><a href="#cb795-2198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2199"><a href="#cb795-2199" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 90% HPDI for p when prior = 1</span></span>
<span id="cb795-2200"><a href="#cb795-2200" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample3m2, <span class="fl">0.9</span>)</span>
<span id="cb795-2201"><a href="#cb795-2201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2202"><a href="#cb795-2202" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 90% HPDI for p when prior = 0 or 1</span></span>
<span id="cb795-2203"><a href="#cb795-2203" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample3m5, <span class="fl">0.9</span>)</span>
<span id="cb795-2204"><a href="#cb795-2204" aria-hidden="true" tabindex="-1"></a><span class="co"># narrower interval for 90% HPDI when prior is more informative</span></span>
<span id="cb795-2205"><a href="#cb795-2205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2206"><a href="#cb795-2206" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2207"><a href="#cb795-2207" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2208"><a href="#cb795-2208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2209"><a href="#cb795-2209" aria-hidden="true" tabindex="-1"></a>*For 3M4*</span>
<span id="cb795-2210"><a href="#cb795-2210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2211"><a href="#cb795-2211" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3M54}</span></span>
<span id="cb795-2212"><a href="#cb795-2212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2213"><a href="#cb795-2213" aria-hidden="true" tabindex="-1"></a><span class="co"># % Probability of 6w in 9n when prior = 1</span></span>
<span id="cb795-2214"><a href="#cb795-2214" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> sample3m2)</span>
<span id="cb795-2215"><a href="#cb795-2215" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(w <span class="sc">==</span> <span class="dv">6</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-2216"><a href="#cb795-2216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2217"><a href="#cb795-2217" aria-hidden="true" tabindex="-1"></a><span class="co"># % Probability of 6w in 9n when prior = 0 or 1</span></span>
<span id="cb795-2218"><a href="#cb795-2218" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">9</span>, <span class="at">prob =</span> sample3m5)</span>
<span id="cb795-2219"><a href="#cb795-2219" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(w <span class="sc">==</span><span class="dv">6</span>)<span class="sc">/</span> <span class="fl">1e4</span></span>
<span id="cb795-2220"><a href="#cb795-2220" aria-hidden="true" tabindex="-1"></a><span class="co"># No difference in probability percentage </span></span>
<span id="cb795-2221"><a href="#cb795-2221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2222"><a href="#cb795-2222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2223"><a href="#cb795-2223" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2224"><a href="#cb795-2224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2225"><a href="#cb795-2225" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hard</span></span>
<span id="cb795-2226"><a href="#cb795-2226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2227"><a href="#cb795-2227" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3H1. Using grid approximation, compute the posterior distribution for the probability of a birth being a boy. Assume a uniform prior probability. Which parameter value maximizes the posterior probability?</span></span>
<span id="cb795-2228"><a href="#cb795-2228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2229"><a href="#cb795-2229" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3H1}</span></span>
<span id="cb795-2230"><a href="#cb795-2230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2231"><a href="#cb795-2231" aria-hidden="true" tabindex="-1"></a><span class="co"># Load homework data</span></span>
<span id="cb795-2232"><a href="#cb795-2232" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(homeworkch3)</span>
<span id="cb795-2233"><a href="#cb795-2233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2234"><a href="#cb795-2234" aria-hidden="true" tabindex="-1"></a><span class="co"># Total number of boys born across all this birth</span></span>
<span id="cb795-2235"><a href="#cb795-2235" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(birth1) <span class="sc">+</span> <span class="fu">sum</span>(birth2)</span>
<span id="cb795-2236"><a href="#cb795-2236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2237"><a href="#cb795-2237" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute posterior distribution for a birth being a boy</span></span>
<span id="cb795-2238"><a href="#cb795-2238" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">200</span>)</span>
<span id="cb795-2239"><a href="#cb795-2239" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">200</span>)</span>
<span id="cb795-2240"><a href="#cb795-2240" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">111</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2241"><a href="#cb795-2241" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> prior <span class="sc">*</span> likelihood</span>
<span id="cb795-2242"><a href="#cb795-2242" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2243"><a href="#cb795-2243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2244"><a href="#cb795-2244" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot posterior with abline</span></span>
<span id="cb795-2245"><a href="#cb795-2245" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(posterior<span class="sc">~</span>p_grid, <span class="at">type =</span> <span class="st">"l"</span>)</span>
<span id="cb795-2246"><a href="#cb795-2246" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.5</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-2247"><a href="#cb795-2247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2248"><a href="#cb795-2248" aria-hidden="true" tabindex="-1"></a><span class="co"># Find parameter value that maximizes posterior probability</span></span>
<span id="cb795-2249"><a href="#cb795-2249" aria-hidden="true" tabindex="-1"></a>p_grid[<span class="fu">which.max</span>(posterior)]</span>
<span id="cb795-2250"><a href="#cb795-2250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2251"><a href="#cb795-2251" aria-hidden="true" tabindex="-1"></a><span class="co"># Show parameter with max posterior probability in plot</span></span>
<span id="cb795-2252"><a href="#cb795-2252" aria-hidden="true" tabindex="-1"></a>v <span class="ot">&lt;-</span> p_grid[<span class="fu">which.max</span>(posterior)]</span>
<span id="cb795-2253"><a href="#cb795-2253" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(posterior<span class="sc">~</span>p_grid, <span class="at">type =</span> <span class="st">"l"</span>)</span>
<span id="cb795-2254"><a href="#cb795-2254" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">0.5</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-2255"><a href="#cb795-2255" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> v, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb795-2256"><a href="#cb795-2256" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"p = 0.5"</span>, <span class="st">"p = 0.553"</span>), </span>
<span id="cb795-2257"><a href="#cb795-2257" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"red"</span>, <span class="st">"blue"</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb795-2258"><a href="#cb795-2258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2259"><a href="#cb795-2259" aria-hidden="true" tabindex="-1"></a><span class="co"># OR</span></span>
<span id="cb795-2260"><a href="#cb795-2260" aria-hidden="true" tabindex="-1"></a><span class="co"># Use loss function to calculate parameter value that maximizes posterior probability</span></span>
<span id="cb795-2261"><a href="#cb795-2261" aria-hidden="true" tabindex="-1"></a><span class="co"># Add sample</span></span>
<span id="cb795-2262"><a href="#cb795-2262" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">102</span>)</span>
<span id="cb795-2263"><a href="#cb795-2263" aria-hidden="true" tabindex="-1"></a>sample3h1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">prob =</span> posterior, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb795-2264"><a href="#cb795-2264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2265"><a href="#cb795-2265" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mode (MAP) value</span></span>
<span id="cb795-2266"><a href="#cb795-2266" aria-hidden="true" tabindex="-1"></a>map_value <span class="ot">&lt;-</span> p_grid[<span class="fu">which.max</span>(posterior)]</span>
<span id="cb795-2267"><a href="#cb795-2267" aria-hidden="true" tabindex="-1"></a>map_value</span>
<span id="cb795-2268"><a href="#cb795-2268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2269"><a href="#cb795-2269" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean value</span></span>
<span id="cb795-2270"><a href="#cb795-2270" aria-hidden="true" tabindex="-1"></a>mean_value <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample3h1)</span>
<span id="cb795-2271"><a href="#cb795-2271" aria-hidden="true" tabindex="-1"></a>mean_value</span>
<span id="cb795-2272"><a href="#cb795-2272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2273"><a href="#cb795-2273" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate median value</span></span>
<span id="cb795-2274"><a href="#cb795-2274" aria-hidden="true" tabindex="-1"></a>median_value <span class="ot">&lt;-</span> <span class="fu">median</span>(sample3h1)</span>
<span id="cb795-2275"><a href="#cb795-2275" aria-hidden="true" tabindex="-1"></a>median_value</span>
<span id="cb795-2276"><a href="#cb795-2276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2277"><a href="#cb795-2277" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate loss</span></span>
<span id="cb795-2278"><a href="#cb795-2278" aria-hidden="true" tabindex="-1"></a>loss <span class="ot">&lt;-</span> <span class="fu">sapply</span>(p_grid , <span class="cf">function</span>(d) <span class="fu">sum</span>(posterior <span class="sc">*</span> <span class="fu">abs</span>(d <span class="sc">-</span> p_grid)))</span>
<span id="cb795-2279"><a href="#cb795-2279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2280"><a href="#cb795-2280" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the loss function</span></span>
<span id="cb795-2281"><a href="#cb795-2281" aria-hidden="true" tabindex="-1"></a><span class="co"># Find x, y values for minimum loss</span></span>
<span id="cb795-2282"><a href="#cb795-2282" aria-hidden="true" tabindex="-1"></a>min_loss_x <span class="ot">&lt;-</span> p_grid[<span class="fu">which.min</span>(loss)]</span>
<span id="cb795-2283"><a href="#cb795-2283" aria-hidden="true" tabindex="-1"></a>min_loss_y <span class="ot">&lt;-</span> loss[<span class="fu">which.min</span>(loss)]</span>
<span id="cb795-2284"><a href="#cb795-2284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2285"><a href="#cb795-2285" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame and plot </span></span>
<span id="cb795-2286"><a href="#cb795-2286" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(p_grid, loss, posterior)</span>
<span id="cb795-2287"><a href="#cb795-2287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2288"><a href="#cb795-2288" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb795-2289"><a href="#cb795-2289" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid)) <span class="sc">+</span></span>
<span id="cb795-2290"><a href="#cb795-2290" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> loss), <span class="at">fill =</span> <span class="st">'lightblue'</span>) <span class="sc">+</span></span>
<span id="cb795-2291"><a href="#cb795-2291" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> min_loss_x, <span class="at">y =</span> min_loss_y), <span class="at">size =</span> <span class="dv">3</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">color =</span> <span class="st">'black'</span>) <span class="sc">+</span></span>
<span id="cb795-2292"><a href="#cb795-2292" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> map_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb795-2293"><a href="#cb795-2293" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb795-2294"><a href="#cb795-2294" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> median_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb795-2295"><a href="#cb795-2295" aria-hidden="true" tabindex="-1"></a>   <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> map_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"mode"</span>, </span>
<span id="cb795-2296"><a href="#cb795-2296" aria-hidden="true" tabindex="-1"></a>            <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="dv">3</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-2297"><a href="#cb795-2297" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"mean"</span>, </span>
<span id="cb795-2298"><a href="#cb795-2298" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-2299"><a href="#cb795-2299" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> median_value, <span class="at">y =</span> <span class="fu">max</span>(df<span class="sc">$</span>posterior), <span class="at">label =</span> <span class="st">"median"</span>, </span>
<span id="cb795-2300"><a href="#cb795-2300" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">angle =</span> <span class="dv">90</span>) <span class="sc">+</span></span>
<span id="cb795-2301"><a href="#cb795-2301" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> min_loss_x, <span class="at">y =</span> min_loss_y, <span class="at">label =</span> <span class="st">"value that minimizes loss"</span>, </span>
<span id="cb795-2302"><a href="#cb795-2302" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="fl">1.6</span>, <span class="at">hjust =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb795-2303"><a href="#cb795-2303" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">'parameter value'</span>,</span>
<span id="cb795-2304"><a href="#cb795-2304" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">'expected proportional loss'</span>) <span class="sc">+</span></span>
<span id="cb795-2305"><a href="#cb795-2305" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-2306"><a href="#cb795-2306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2307"><a href="#cb795-2307" aria-hidden="true" tabindex="-1"></a><span class="co"># The parameter value that maximizes probability is 0.553 </span></span>
<span id="cb795-2308"><a href="#cb795-2308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2309"><a href="#cb795-2309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2310"><a href="#cb795-2310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2311"><a href="#cb795-2311" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2312"><a href="#cb795-2312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2313"><a href="#cb795-2313" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3H2. Using the sample function, draw 10,000 random parameter values from the posterior distribution you calculated above. Use these samples to estimate the 50%, 89%, and 97% highest posterior density intervals.</span></span>
<span id="cb795-2314"><a href="#cb795-2314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2315"><a href="#cb795-2315" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3H2}</span></span>
<span id="cb795-2316"><a href="#cb795-2316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2317"><a href="#cb795-2317" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 50% HPDI</span></span>
<span id="cb795-2318"><a href="#cb795-2318" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample3h1, <span class="at">prob =</span> <span class="fl">0.5</span>)</span>
<span id="cb795-2319"><a href="#cb795-2319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2320"><a href="#cb795-2320" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 89% HPDI</span></span>
<span id="cb795-2321"><a href="#cb795-2321" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample3h1, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-2322"><a href="#cb795-2322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2323"><a href="#cb795-2323" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate 97% HPDI</span></span>
<span id="cb795-2324"><a href="#cb795-2324" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample3h1, <span class="at">prob =</span> <span class="fl">0.97</span>)</span>
<span id="cb795-2325"><a href="#cb795-2325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2326"><a href="#cb795-2326" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2327"><a href="#cb795-2327" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2328"><a href="#cb795-2328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2329"><a href="#cb795-2329" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3H3. Use rbinom to simulate 10,000 replicates of 200 births. You should end up with 10,000 numbers, each one a count of boys out of 200 births. Compare the distribution of predicted numbers of boys to the actual count in the data (111 boys out of 200 births). There are many good ways to visualize the simulations, but the dens command (part of the rethinking package) is probably the easiest way in this case. Does it look like the model fits the data well? That is, does the distribution of predictions include the actual observation as a central, likely outcome?</span></span>
<span id="cb795-2330"><a href="#cb795-2330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2331"><a href="#cb795-2331" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3H3}</span></span>
<span id="cb795-2332"><a href="#cb795-2332" aria-hidden="true" tabindex="-1"></a><span class="co"># Use rbinom to simulate 10,000 replicates of 200 births</span></span>
<span id="cb795-2333"><a href="#cb795-2333" aria-hidden="true" tabindex="-1"></a>replicate_w <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">10000</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> sample3h1)</span>
<span id="cb795-2334"><a href="#cb795-2334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2335"><a href="#cb795-2335" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare predictive posterior distribution and actual count using dens function</span></span>
<span id="cb795-2336"><a href="#cb795-2336" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(replicate_w, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"darkgreen"</span>, </span>
<span id="cb795-2337"><a href="#cb795-2337" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"PPD with 200 grids, 1e4 samples, 1e4 observations"</span>)</span>
<span id="cb795-2338"><a href="#cb795-2338" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">111</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-2339"><a href="#cb795-2339" aria-hidden="true" tabindex="-1"></a><span class="co"># PPD is not an exact fit- is that because i used 200 grids only?</span></span>
<span id="cb795-2340"><a href="#cb795-2340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2341"><a href="#cb795-2341" aria-hidden="true" tabindex="-1"></a><span class="co"># Try increasing grid size</span></span>
<span id="cb795-2342"><a href="#cb795-2342" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">10000</span>)</span>
<span id="cb795-2343"><a href="#cb795-2343" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">10000</span>)</span>
<span id="cb795-2344"><a href="#cb795-2344" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">111</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2345"><a href="#cb795-2345" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2346"><a href="#cb795-2346" aria-hidden="true" tabindex="-1"></a>posterior_w <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2347"><a href="#cb795-2347" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">103</span>)</span>
<span id="cb795-2348"><a href="#cb795-2348" aria-hidden="true" tabindex="-1"></a>sample_grid <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="dv">10000</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior_w)</span>
<span id="cb795-2349"><a href="#cb795-2349" aria-hidden="true" tabindex="-1"></a>replicate_w1 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">10000</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> sample_grid)</span>
<span id="cb795-2350"><a href="#cb795-2350" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(replicate_w1, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"darkgreen"</span>, </span>
<span id="cb795-2351"><a href="#cb795-2351" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"PPD with 1e4 grids, 1e4 samples, 1e4 observations"</span>)</span>
<span id="cb795-2352"><a href="#cb795-2352" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">111</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-2353"><a href="#cb795-2353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2354"><a href="#cb795-2354" aria-hidden="true" tabindex="-1"></a><span class="co"># Try with codes from answer key</span></span>
<span id="cb795-2355"><a href="#cb795-2355" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(homeworkch3)</span>
<span id="cb795-2356"><a href="#cb795-2356" aria-hidden="true" tabindex="-1"></a>boys <span class="ot">&lt;-</span> <span class="fu">sum</span>(birth1) <span class="sc">+</span> <span class="fu">sum</span>(birth2)</span>
<span id="cb795-2357"><a href="#cb795-2357" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">0</span> , <span class="at">to=</span><span class="dv">1</span> , <span class="at">length.out=</span><span class="dv">1000</span> )</span>
<span id="cb795-2358"><a href="#cb795-2358" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>,<span class="fu">length</span>(p))</span>
<span id="cb795-2359"><a href="#cb795-2359" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>( boys , <span class="at">size=</span><span class="dv">200</span> , <span class="at">prob=</span>p )</span>
<span id="cb795-2360"><a href="#cb795-2360" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2361"><a href="#cb795-2361" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior <span class="sc">/</span> <span class="fu">sum</span>(posterior)</span>
<span id="cb795-2362"><a href="#cb795-2362" aria-hidden="true" tabindex="-1"></a>p.samples <span class="ot">&lt;-</span> <span class="fu">sample</span>( p , <span class="at">size=</span><span class="dv">10000</span> , <span class="at">replace=</span><span class="cn">TRUE</span> , <span class="at">prob=</span>posterior )</span>
<span id="cb795-2363"><a href="#cb795-2363" aria-hidden="true" tabindex="-1"></a>bsim <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( <span class="dv">10000</span> , <span class="at">size=</span><span class="dv">200</span> , <span class="at">prob=</span>p.samples )</span>
<span id="cb795-2364"><a href="#cb795-2364" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>( bsim , <span class="at">adj=</span><span class="fl">0.1</span>, <span class="at">main =</span> <span class="st">"Given answer: 1000 grids, 1e4 samples, 1e4 observations"</span>)</span>
<span id="cb795-2365"><a href="#cb795-2365" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v=</span><span class="fu">sum</span>(birth1)<span class="sc">+</span><span class="fu">sum</span>(birth2) , <span class="at">col=</span><span class="st">"red"</span> )</span>
<span id="cb795-2366"><a href="#cb795-2366" aria-hidden="true" tabindex="-1"></a><span class="co"># Can't get the exact fit like the graph in answer key even when I just c/p the codes.</span></span>
<span id="cb795-2367"><a href="#cb795-2367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2368"><a href="#cb795-2368" aria-hidden="true" tabindex="-1"></a><span class="co"># Try increasing sample with 1e5 grids</span></span>
<span id="cb795-2369"><a href="#cb795-2369" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="fl">1e5</span>)</span>
<span id="cb795-2370"><a href="#cb795-2370" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fl">1e5</span>)</span>
<span id="cb795-2371"><a href="#cb795-2371" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">111</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2372"><a href="#cb795-2372" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2373"><a href="#cb795-2373" aria-hidden="true" tabindex="-1"></a>posterior_w <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2374"><a href="#cb795-2374" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb795-2375"><a href="#cb795-2375" aria-hidden="true" tabindex="-1"></a>sample_grid <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e5</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior_w)</span>
<span id="cb795-2376"><a href="#cb795-2376" aria-hidden="true" tabindex="-1"></a>replicate_w1 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e5</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> sample_grid)</span>
<span id="cb795-2377"><a href="#cb795-2377" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(replicate_w1, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"darkgreen"</span>, </span>
<span id="cb795-2378"><a href="#cb795-2378" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"PPD with 1e5 grids, 1e5 samples, 1e5 observations"</span>)</span>
<span id="cb795-2379"><a href="#cb795-2379" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">111</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-2380"><a href="#cb795-2380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2381"><a href="#cb795-2381" aria-hidden="true" tabindex="-1"></a><span class="co"># Try with 1e4 observations to see difference</span></span>
<span id="cb795-2382"><a href="#cb795-2382" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="fl">1e5</span>)</span>
<span id="cb795-2383"><a href="#cb795-2383" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fl">1e5</span>)</span>
<span id="cb795-2384"><a href="#cb795-2384" aria-hidden="true" tabindex="-1"></a>likelihood <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">111</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> p_grid)</span>
<span id="cb795-2385"><a href="#cb795-2385" aria-hidden="true" tabindex="-1"></a>unstd.posterior <span class="ot">&lt;-</span> likelihood <span class="sc">*</span> prior</span>
<span id="cb795-2386"><a href="#cb795-2386" aria-hidden="true" tabindex="-1"></a>posterior_w <span class="ot">&lt;-</span> unstd.posterior<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior)</span>
<span id="cb795-2387"><a href="#cb795-2387" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb795-2388"><a href="#cb795-2388" aria-hidden="true" tabindex="-1"></a>sample_grid <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid, <span class="at">size =</span> <span class="fl">1e5</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior_w)</span>
<span id="cb795-2389"><a href="#cb795-2389" aria-hidden="true" tabindex="-1"></a>replicate_w1 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">200</span>, <span class="at">prob =</span> sample_grid)</span>
<span id="cb795-2390"><a href="#cb795-2390" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(replicate_w1, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"darkgreen"</span>, </span>
<span id="cb795-2391"><a href="#cb795-2391" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"PPD with 1e5 grids, 1e5 samples, 1e4 observations"</span>)</span>
<span id="cb795-2392"><a href="#cb795-2392" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">111</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-2393"><a href="#cb795-2393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2394"><a href="#cb795-2394" aria-hidden="true" tabindex="-1"></a><span class="co"># All graphs have slightly different peaks. Is it because of variations in </span></span>
<span id="cb795-2395"><a href="#cb795-2395" aria-hidden="true" tabindex="-1"></a><span class="co"># grid size/ sample size/ observation size or variations in draw?</span></span>
<span id="cb795-2396"><a href="#cb795-2396" aria-hidden="true" tabindex="-1"></a><span class="co"># But PPDs' peaks are within ± 3 of actual counts. This only shows the fit of data-shows model works</span></span>
<span id="cb795-2397"><a href="#cb795-2397" aria-hidden="true" tabindex="-1"></a><span class="co"># Doesn't show if a model is good or not- whether reflect the real world. </span></span>
<span id="cb795-2398"><a href="#cb795-2398" aria-hidden="true" tabindex="-1"></a><span class="co"># So, it doesn't matter if slightly different fit, I think. </span></span>
<span id="cb795-2399"><a href="#cb795-2399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2400"><a href="#cb795-2400" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2401"><a href="#cb795-2401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2402"><a href="#cb795-2402" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2403"><a href="#cb795-2403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2404"><a href="#cb795-2404" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3H4. Now compare 10,000 counts of boys from 100 simulated first borns only to the number of boys in the first births, birth1. How does the model look in this light?</span></span>
<span id="cb795-2405"><a href="#cb795-2405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2406"><a href="#cb795-2406" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3H4}</span></span>
<span id="cb795-2407"><a href="#cb795-2407" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate posterior for first born boys</span></span>
<span id="cb795-2408"><a href="#cb795-2408" aria-hidden="true" tabindex="-1"></a>first_born_boy <span class="ot">&lt;-</span> <span class="fu">sum</span>(birth1)</span>
<span id="cb795-2409"><a href="#cb795-2409" aria-hidden="true" tabindex="-1"></a>p_grid_3h4 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb795-2410"><a href="#cb795-2410" aria-hidden="true" tabindex="-1"></a>prior_3h4 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">1000</span>)</span>
<span id="cb795-2411"><a href="#cb795-2411" aria-hidden="true" tabindex="-1"></a>likelihood_3h4 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(first_born_boy, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> p_grid_3h4)</span>
<span id="cb795-2412"><a href="#cb795-2412" aria-hidden="true" tabindex="-1"></a>unstd.posterior_3h4 <span class="ot">&lt;-</span> prior_3h4 <span class="sc">*</span> likelihood_3h4</span>
<span id="cb795-2413"><a href="#cb795-2413" aria-hidden="true" tabindex="-1"></a>posterior_3h4 <span class="ot">&lt;-</span> unstd.posterior_3h4<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior_3h4)</span>
<span id="cb795-2414"><a href="#cb795-2414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2415"><a href="#cb795-2415" aria-hidden="true" tabindex="-1"></a><span class="co"># Create samples</span></span>
<span id="cb795-2416"><a href="#cb795-2416" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">111</span>)</span>
<span id="cb795-2417"><a href="#cb795-2417" aria-hidden="true" tabindex="-1"></a>sample_3h4 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid_3h4, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior_3h4)</span>
<span id="cb795-2418"><a href="#cb795-2418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2419"><a href="#cb795-2419" aria-hidden="true" tabindex="-1"></a><span class="co"># Create observations</span></span>
<span id="cb795-2420"><a href="#cb795-2420" aria-hidden="true" tabindex="-1"></a>w_3h4 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> sample_3h4)</span>
<span id="cb795-2421"><a href="#cb795-2421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2422"><a href="#cb795-2422" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare PPD with actual count</span></span>
<span id="cb795-2423"><a href="#cb795-2423" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(w_3h4, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb795-2424"><a href="#cb795-2424" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> first_born_boy, <span class="at">col =</span> <span class="st">"green"</span>)</span>
<span id="cb795-2425"><a href="#cb795-2425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2426"><a href="#cb795-2426" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's try increasing the grid to 1e5</span></span>
<span id="cb795-2427"><a href="#cb795-2427" aria-hidden="true" tabindex="-1"></a>p_grid_3h4 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="fl">1e5</span>)</span>
<span id="cb795-2428"><a href="#cb795-2428" aria-hidden="true" tabindex="-1"></a>prior_3h4 <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fl">1e5</span>)</span>
<span id="cb795-2429"><a href="#cb795-2429" aria-hidden="true" tabindex="-1"></a>likelihood_3h4 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(first_born_boy, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> p_grid_3h4)</span>
<span id="cb795-2430"><a href="#cb795-2430" aria-hidden="true" tabindex="-1"></a>unstd.posterior_3h4 <span class="ot">&lt;-</span> prior_3h4 <span class="sc">*</span> likelihood_3h4</span>
<span id="cb795-2431"><a href="#cb795-2431" aria-hidden="true" tabindex="-1"></a>posterior_3h4 <span class="ot">&lt;-</span> unstd.posterior_3h4<span class="sc">/</span> <span class="fu">sum</span>(unstd.posterior_3h4)</span>
<span id="cb795-2432"><a href="#cb795-2432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2433"><a href="#cb795-2433" aria-hidden="true" tabindex="-1"></a><span class="co"># Create samples</span></span>
<span id="cb795-2434"><a href="#cb795-2434" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">111</span>)</span>
<span id="cb795-2435"><a href="#cb795-2435" aria-hidden="true" tabindex="-1"></a>sample_3h4 <span class="ot">&lt;-</span> <span class="fu">sample</span>(p_grid_3h4, <span class="at">size =</span> <span class="fl">1e4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> posterior_3h4)</span>
<span id="cb795-2436"><a href="#cb795-2436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2437"><a href="#cb795-2437" aria-hidden="true" tabindex="-1"></a><span class="co"># Create observations</span></span>
<span id="cb795-2438"><a href="#cb795-2438" aria-hidden="true" tabindex="-1"></a>w_3h4 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> sample_3h4)</span>
<span id="cb795-2439"><a href="#cb795-2439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2440"><a href="#cb795-2440" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare PPD with actual count</span></span>
<span id="cb795-2441"><a href="#cb795-2441" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(w_3h4, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb795-2442"><a href="#cb795-2442" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> first_born_boy, <span class="at">col =</span> <span class="st">"green"</span>)</span>
<span id="cb795-2443"><a href="#cb795-2443" aria-hidden="true" tabindex="-1"></a><span class="co"># Better fit with increased grid size. </span></span>
<span id="cb795-2444"><a href="#cb795-2444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2445"><a href="#cb795-2445" aria-hidden="true" tabindex="-1"></a><span class="co"># If we use the same posterior distribution (given answer)</span></span>
<span id="cb795-2446"><a href="#cb795-2446" aria-hidden="true" tabindex="-1"></a>w_3h4 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="fl">1e4</span>, <span class="at">size =</span> <span class="dv">100</span>, <span class="at">prob =</span> sample3h1)</span>
<span id="cb795-2447"><a href="#cb795-2447" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(w_3h4, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb795-2448"><a href="#cb795-2448" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> first_born_boy, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-2449"><a href="#cb795-2449" aria-hidden="true" tabindex="-1"></a><span class="co"># So, a new posterior with new conditions- changes in number of actual </span></span>
<span id="cb795-2450"><a href="#cb795-2450" aria-hidden="true" tabindex="-1"></a><span class="co"># counts and total counts- will make the model fit the data. I think this is</span></span>
<span id="cb795-2451"><a href="#cb795-2451" aria-hidden="true" tabindex="-1"></a><span class="co"># caused by simulation not exactly halving the observations, i.e., we gave</span></span>
<span id="cb795-2452"><a href="#cb795-2452" aria-hidden="true" tabindex="-1"></a><span class="co"># no command that the observation is 51 for 100.</span></span>
<span id="cb795-2453"><a href="#cb795-2453" aria-hidden="true" tabindex="-1"></a><span class="co"># Given answer: Not bad, but not right on center now. The frequency of boys </span></span>
<span id="cb795-2454"><a href="#cb795-2454" aria-hidden="true" tabindex="-1"></a><span class="co"># among first borns is a little less than the model tends to predict. </span></span>
<span id="cb795-2455"><a href="#cb795-2455" aria-hidden="true" tabindex="-1"></a><span class="co"># The model doesn’t have a problem accounting for this variation though, </span></span>
<span id="cb795-2456"><a href="#cb795-2456" aria-hidden="true" tabindex="-1"></a><span class="co"># as the red line is well within density of simulated data.</span></span>
<span id="cb795-2457"><a href="#cb795-2457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2458"><a href="#cb795-2458" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2459"><a href="#cb795-2459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2460"><a href="#cb795-2460" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2461"><a href="#cb795-2461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2462"><a href="#cb795-2462" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 3H5. The model assumes that sex of first and second births are independent. To check this assumption, focus now on second births that followed female first borns. Compare 10,000 simulated counts of boys to only those second births that followed girls. To do this correctly, you need to count the number of first borns who were girls and simulate that many births, 10,000 times. Compare the counts of boys in your simulations to the actual observed count of boys following girls. How does the model look in this light? Any guesses what is going on in these data?</span></span>
<span id="cb795-2463"><a href="#cb795-2463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2464"><a href="#cb795-2464" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3H5}</span></span>
<span id="cb795-2465"><a href="#cb795-2465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2466"><a href="#cb795-2466" aria-hidden="true" tabindex="-1"></a><span class="co"># Count number of second born boys when first borns are girl</span></span>
<span id="cb795-2467"><a href="#cb795-2467" aria-hidden="true" tabindex="-1"></a>second_boy_first_girl <span class="ot">&lt;-</span> <span class="fu">sum</span>(birth1 <span class="sc">==</span> <span class="dv">0</span> <span class="sc">&amp;</span> birth2 <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb795-2468"><a href="#cb795-2468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2469"><a href="#cb795-2469" aria-hidden="true" tabindex="-1"></a><span class="co"># Count the number of first born girls</span></span>
<span id="cb795-2470"><a href="#cb795-2470" aria-hidden="true" tabindex="-1"></a>first_girl <span class="ot">&lt;-</span> <span class="fu">sum</span>(birth1 <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb795-2471"><a href="#cb795-2471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2472"><a href="#cb795-2472" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate observations for total number of second births when first births are girls</span></span>
<span id="cb795-2473"><a href="#cb795-2473" aria-hidden="true" tabindex="-1"></a>w_3h5 <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( <span class="dv">10000</span> , <span class="at">size =</span> first_girl , <span class="at">prob =</span> sample3h1 )</span>
<span id="cb795-2474"><a href="#cb795-2474" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(w_3h5, <span class="at">adj =</span> <span class="fl">0.1</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb795-2475"><a href="#cb795-2475" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> second_boy_first_girl , <span class="at">col =</span> <span class="st">"green"</span> )</span>
<span id="cb795-2476"><a href="#cb795-2476" aria-hidden="true" tabindex="-1"></a><span class="co"># The sex of first and second birth may not be independent. </span></span>
<span id="cb795-2477"><a href="#cb795-2477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2478"><a href="#cb795-2478" aria-hidden="true" tabindex="-1"></a><span class="co"># Run codes in given answer</span></span>
<span id="cb795-2479"><a href="#cb795-2479" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new vector of birth 2 when birth 1 is 0</span></span>
<span id="cb795-2480"><a href="#cb795-2480" aria-hidden="true" tabindex="-1"></a>b01 <span class="ot">&lt;-</span> birth2[birth1<span class="sc">==</span><span class="dv">0</span>]</span>
<span id="cb795-2481"><a href="#cb795-2481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2482"><a href="#cb795-2482" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate 1e4 observations for new vector size using samples from model posterior</span></span>
<span id="cb795-2483"><a href="#cb795-2483" aria-hidden="true" tabindex="-1"></a>b01sim <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( <span class="dv">10000</span> , <span class="at">size=</span><span class="fu">length</span>(b01) , <span class="at">prob=</span>p.samples )</span>
<span id="cb795-2484"><a href="#cb795-2484" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(b01sim,<span class="at">adj=</span><span class="fl">0.1</span>)</span>
<span id="cb795-2485"><a href="#cb795-2485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2486"><a href="#cb795-2486" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a line for actual count of second born boys when first borns are girls</span></span>
<span id="cb795-2487"><a href="#cb795-2487" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v=</span><span class="fu">sum</span>(b01) , <span class="at">col=</span><span class="st">"red"</span> )</span>
<span id="cb795-2488"><a href="#cb795-2488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2489"><a href="#cb795-2489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2490"><a href="#cb795-2490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2491"><a href="#cb795-2491" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2492"><a href="#cb795-2492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2493"><a href="#cb795-2493" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 4: Linear Models</span></span>
<span id="cb795-2494"><a href="#cb795-2494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2495"><a href="#cb795-2495" aria-hidden="true" tabindex="-1"></a>Under a probability interpretation, which is necessary for Bayesian work, linear regression uses a Gaussian (normal) distribution to describe our golem’s uncertainty about some measurement of interest.</span>
<span id="cb795-2496"><a href="#cb795-2496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2497"><a href="#cb795-2497" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why normal distributions are normal</span></span>
<span id="cb795-2498"><a href="#cb795-2498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2499"><a href="#cb795-2499" aria-hidden="true" tabindex="-1"></a>A thousand friends line up on the halfway line of a soccer field. Each flips a coin 16 times- moves a step to the left if the coin comes up head and to the right if tail. Then, measure the distance of each person from the halfway line. "The distances will be distributed in approximately normal, or Gaussian, fashion. This is true even though the underlying distribution is binomial. It does this because *there are so many more possible ways to realize a sequence of left-right steps that sums to zero. There are slightly fewer ways to realize a sequence that ends up one step left or right of zero, and so on, with the number of possible sequences declining in the characteristic bell curve of the normal distribution*."</span>
<span id="cb795-2500"><a href="#cb795-2500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2501"><a href="#cb795-2501" aria-hidden="true" tabindex="-1"></a><span class="fu">### Normal by addition </span></span>
<span id="cb795-2502"><a href="#cb795-2502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2503"><a href="#cb795-2503" aria-hidden="true" tabindex="-1"></a>Simulate the above experiment in R:</span>
<span id="cb795-2504"><a href="#cb795-2504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2505"><a href="#cb795-2505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c41}</span></span>
<span id="cb795-2506"><a href="#cb795-2506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2507"><a href="#cb795-2507" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">01</span>)</span>
<span id="cb795-2508"><a href="#cb795-2508" aria-hidden="true" tabindex="-1"></a><span class="co"># To simulate this, we generate for each person a list of 16 random numbers between −1 and 1. </span></span>
<span id="cb795-2509"><a href="#cb795-2509" aria-hidden="true" tabindex="-1"></a><span class="co"># These are the individual steps. Then we add these steps together to get the position after 16 steps. </span></span>
<span id="cb795-2510"><a href="#cb795-2510" aria-hidden="true" tabindex="-1"></a><span class="co"># Then we need to replicate this procedure 1000 times.</span></span>
<span id="cb795-2511"><a href="#cb795-2511" aria-hidden="true" tabindex="-1"></a>pos <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">sum</span>(<span class="fu">runif</span>(<span class="dv">16</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>))) </span>
<span id="cb795-2512"><a href="#cb795-2512" aria-hidden="true" tabindex="-1"></a><span class="co"># runif to generate random deviates following the uniform distribution </span></span>
<span id="cb795-2513"><a href="#cb795-2513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2514"><a href="#cb795-2514" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(pos)</span>
<span id="cb795-2515"><a href="#cb795-2515" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(pos))</span>
<span id="cb795-2516"><a href="#cb795-2516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2517"><a href="#cb795-2517" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot the density for 4 steps, 8 steps, and 16 steps</span></span>
<span id="cb795-2518"><a href="#cb795-2518" aria-hidden="true" tabindex="-1"></a>  <span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>))</span>
<span id="cb795-2519"><a href="#cb795-2519" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-2520"><a href="#cb795-2520" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot for 4 steps</span></span>
<span id="cb795-2521"><a href="#cb795-2521" aria-hidden="true" tabindex="-1"></a>  pos4 <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">sum</span>(<span class="fu">runif</span>(<span class="dv">4</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb795-2522"><a href="#cb795-2522" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dens</span>(pos4, <span class="at">main =</span> <span class="st">"4 steps"</span>, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb795-2523"><a href="#cb795-2523" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-2524"><a href="#cb795-2524" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot for 8 steps</span></span>
<span id="cb795-2525"><a href="#cb795-2525" aria-hidden="true" tabindex="-1"></a>  pos8 <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">sum</span>(<span class="fu">runif</span>(<span class="dv">8</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb795-2526"><a href="#cb795-2526" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dens</span>(pos8, <span class="at">main =</span> <span class="st">"8 steps"</span>, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb795-2527"><a href="#cb795-2527" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-2528"><a href="#cb795-2528" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot for 16 steps</span></span>
<span id="cb795-2529"><a href="#cb795-2529" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dens</span>(pos, <span class="at">main =</span> <span class="st">"16 steps"</span>, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb795-2530"><a href="#cb795-2530" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-2531"><a href="#cb795-2531" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Plot for 100 steps</span></span>
<span id="cb795-2532"><a href="#cb795-2532" aria-hidden="true" tabindex="-1"></a>  pos100 <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">sum</span>(<span class="fu">runif</span>(<span class="dv">100</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb795-2533"><a href="#cb795-2533" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dens</span>(pos100, <span class="at">main =</span> <span class="st">"100 steps"</span>, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb795-2534"><a href="#cb795-2534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2535"><a href="#cb795-2535" aria-hidden="true" tabindex="-1"></a><span class="co"># The more steps are taken, the closer the match between the real empirical distribution </span></span>
<span id="cb795-2536"><a href="#cb795-2536" aria-hidden="true" tabindex="-1"></a><span class="co"># of positions and the ideal normal distribution.</span></span>
<span id="cb795-2537"><a href="#cb795-2537" aria-hidden="true" tabindex="-1"></a><span class="co"># After 16 steps, it has already taken on a familiar “bell” curve of the Gaussian distribution </span></span>
<span id="cb795-2538"><a href="#cb795-2538" aria-hidden="true" tabindex="-1"></a><span class="co"># emerging from the randomness, i.e., the distribution of positions is stabilizing on the Gaussian. </span></span>
<span id="cb795-2539"><a href="#cb795-2539" aria-hidden="true" tabindex="-1"></a><span class="co"># But they all look bell shape to me. </span></span>
<span id="cb795-2540"><a href="#cb795-2540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2541"><a href="#cb795-2541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2542"><a href="#cb795-2542" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2543"><a href="#cb795-2543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2544"><a href="#cb795-2544" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2545"><a href="#cb795-2545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2546"><a href="#cb795-2546" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Why addition should result in a bell curve of sums?***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-2547"><a href="#cb795-2547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2548"><a href="#cb795-2548" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Whatever the average value of the source distribution, each sample from it can be thought of as a fluctuation from that average value. </span>
<span id="cb795-2549"><a href="#cb795-2549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2550"><a href="#cb795-2550" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When we begin to add these fluctuations together, they also begin to cancel one another out. A large positive fluctuation will cancel a large negative one. </span>
<span id="cb795-2551"><a href="#cb795-2551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2552"><a href="#cb795-2552" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The more terms in the sum, the more chances for each fluctuation to be canceled by another, or by a series of smaller ones in the opposite direction. So eventually the most likely sum, in the sense that there are the most ways to realize it, will be a sum in which every fluctuation is canceled by another, a sum of zero (relative to the mean).</span>
<span id="cb795-2553"><a href="#cb795-2553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2554"><a href="#cb795-2554" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>It doesn’t matter what shape the underlying distribution possesses- uniform or anything else. Depending upon the underlying distribution, the convergence might be slow (often rapid), but it will be inevitable.</span>
<span id="cb795-2555"><a href="#cb795-2555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2556"><a href="#cb795-2556" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2557"><a href="#cb795-2557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2558"><a href="#cb795-2558" aria-hidden="true" tabindex="-1"></a><span class="fu">### Normal by multiplication</span></span>
<span id="cb795-2559"><a href="#cb795-2559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2560"><a href="#cb795-2560" aria-hidden="true" tabindex="-1"></a>Simulate growth multiplication of an organism:</span>
<span id="cb795-2561"><a href="#cb795-2561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2562"><a href="#cb795-2562" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c42}</span></span>
<span id="cb795-2563"><a href="#cb795-2563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2564"><a href="#cb795-2564" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample 12 random numbers between 1.0 and 1.1, each representing a proportional </span></span>
<span id="cb795-2565"><a href="#cb795-2565" aria-hidden="true" tabindex="-1"></a><span class="co"># increase in growth. Thus 1.0 means no additional growth and 1.1 means a 10% increase. </span></span>
<span id="cb795-2566"><a href="#cb795-2566" aria-hidden="true" tabindex="-1"></a><span class="co"># The product of all 12 is computed and returned as output.</span></span>
<span id="cb795-2567"><a href="#cb795-2567" aria-hidden="true" tabindex="-1"></a><span class="co"># prod returns the product of all the values present in its arguments.</span></span>
<span id="cb795-2568"><a href="#cb795-2568" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)) </span>
<span id="cb795-2569"><a href="#cb795-2569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2570"><a href="#cb795-2570" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate 10,000 random products</span></span>
<span id="cb795-2571"><a href="#cb795-2571" aria-hidden="true" tabindex="-1"></a>growth <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)))</span>
<span id="cb795-2572"><a href="#cb795-2572" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(growth, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"darkred"</span>) <span class="co">#norm.comp overlay normal density comparison if true</span></span>
<span id="cb795-2573"><a href="#cb795-2573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2574"><a href="#cb795-2574" aria-hidden="true" tabindex="-1"></a><span class="co"># Small effects that multiply together are approximately additive, and so </span></span>
<span id="cb795-2575"><a href="#cb795-2575" aria-hidden="true" tabindex="-1"></a><span class="co"># they also tend to stabilize on Gaussian distributions.  For example, if there</span></span>
<span id="cb795-2576"><a href="#cb795-2576" aria-hidden="true" tabindex="-1"></a><span class="co"># are two loci with alleles increasing growth by 10% each, the product is: 1.1 × 1.1 = 1.21</span></span>
<span id="cb795-2577"><a href="#cb795-2577" aria-hidden="true" tabindex="-1"></a><span class="co"># The smaller the effect of each locus, the better this additive approximation will be.</span></span>
<span id="cb795-2578"><a href="#cb795-2578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2579"><a href="#cb795-2579" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify this effect by comparing big vs. small increase in percent value</span></span>
<span id="cb795-2580"><a href="#cb795-2580" aria-hidden="true" tabindex="-1"></a>big <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.5</span>)))</span>
<span id="cb795-2581"><a href="#cb795-2581" aria-hidden="true" tabindex="-1"></a>small <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.01</span>)))</span>
<span id="cb795-2582"><a href="#cb795-2582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2583"><a href="#cb795-2583" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distributions</span></span>
<span id="cb795-2584"><a href="#cb795-2584" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb795-2585"><a href="#cb795-2585" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(big, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">main =</span> <span class="st">"Big effect"</span>)</span>
<span id="cb795-2586"><a href="#cb795-2586" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(small, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">main =</span> <span class="st">"Small effect"</span>)</span>
<span id="cb795-2587"><a href="#cb795-2587" aria-hidden="true" tabindex="-1"></a><span class="co"># The interacting growth deviations, as long as they are sufficiently small, </span></span>
<span id="cb795-2588"><a href="#cb795-2588" aria-hidden="true" tabindex="-1"></a><span class="co"># converge to a Gaussian distribution- extends well beyond purely additive interactions.</span></span>
<span id="cb795-2589"><a href="#cb795-2589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2590"><a href="#cb795-2590" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2591"><a href="#cb795-2591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2592"><a href="#cb795-2592" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2593"><a href="#cb795-2593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2594"><a href="#cb795-2594" aria-hidden="true" tabindex="-1"></a><span class="fu">### Normal by log-multiplication </span></span>
<span id="cb795-2595"><a href="#cb795-2595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2596"><a href="#cb795-2596" aria-hidden="true" tabindex="-1"></a>Large deviates that are multiplied together do not produce Gaussian distributions, but they do tend to produce Gaussian distributions on the log scale. For example:</span>
<span id="cb795-2597"><a href="#cb795-2597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2598"><a href="#cb795-2598" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c43}</span></span>
<span id="cb795-2599"><a href="#cb795-2599" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-2600"><a href="#cb795-2600" aria-hidden="true" tabindex="-1"></a>log.big <span class="ot">&lt;-</span> <span class="fu">replicate</span>( <span class="dv">10000</span> , <span class="fu">log</span>(<span class="fu">prod</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">runif</span>(<span class="dv">12</span>,<span class="dv">0</span>,<span class="fl">0.5</span>))) )</span>
<span id="cb795-2601"><a href="#cb795-2601" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(log.big, <span class="at">norm.comp =</span> <span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">main =</span> <span class="st">"Big effect on log scale"</span>)</span>
<span id="cb795-2602"><a href="#cb795-2602" aria-hidden="true" tabindex="-1"></a><span class="co"># We get the Gaussian distribution back, because adding logs is equivalent to multiplying </span></span>
<span id="cb795-2603"><a href="#cb795-2603" aria-hidden="true" tabindex="-1"></a><span class="co"># the original numbers. So even multiplicative interactions of large deviations can produce </span></span>
<span id="cb795-2604"><a href="#cb795-2604" aria-hidden="true" tabindex="-1"></a><span class="co"># Gaussian distributions, once we measure the outcomes on the log scale. </span></span>
<span id="cb795-2605"><a href="#cb795-2605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2606"><a href="#cb795-2606" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2607"><a href="#cb795-2607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2608"><a href="#cb795-2608" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2609"><a href="#cb795-2609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2610"><a href="#cb795-2610" aria-hidden="true" tabindex="-1"></a><span class="fu">### Using Guassian distributions</span></span>
<span id="cb795-2611"><a href="#cb795-2611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2612"><a href="#cb795-2612" aria-hidden="true" tabindex="-1"></a>The justifications for using the Gaussian distribution- as a skeleton for hypotheses, building up models of measurements as aggregations of normal distributions- fall into two broad categories: </span>
<span id="cb795-2613"><a href="#cb795-2613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2614"><a href="#cb795-2614" aria-hidden="true" tabindex="-1"></a>(1) ontological justification</span>
<span id="cb795-2615"><a href="#cb795-2615" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Repeatedly adding finite fluctuations results in a distribution of sums that have shed all information about the underlying process, aside from mean and spread. One consequence of this is that statistical models based on Gaussian distributions cannot reliably identify micro-process. But it also means that these models can do useful work, even when they cannot identify process.</span>
<span id="cb795-2616"><a href="#cb795-2616" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-2617"><a href="#cb795-2617" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-2618"><a href="#cb795-2618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2619"><a href="#cb795-2619" aria-hidden="true" tabindex="-1"></a>(2) epistemological justification</span>
<span id="cb795-2620"><a href="#cb795-2620" aria-hidden="true" tabindex="-1"></a><span class="ss">      - </span>Gaussian distribution is the most natural expression of our state of ignorance, because if all we are willing to assume is that a measure has finite variance, the Gaussian distribution is the shape that can be realized in the largest number of ways and does not introduce any new assumptions. It is the least surprising and least informative assumption to make. In this way, the Gaussian is the distribution most consistent with our assumptions. Or rather, it is the most consistent with our golem’s assumptions.</span>
<span id="cb795-2621"><a href="#cb795-2621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2622"><a href="#cb795-2622" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2623"><a href="#cb795-2623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2624"><a href="#cb795-2624" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Gaussian distribution**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-2625"><a href="#cb795-2625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2626"><a href="#cb795-2626" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The probability density of some value y, given a Gaussian (normal) distribution with mean $\mu$ and standard deviation $\sigma$, is:</span>
<span id="cb795-2627"><a href="#cb795-2627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2628"><a href="#cb795-2628" aria-hidden="true" tabindex="-1"></a>$$p(y|\mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(- \frac{(y-\mu)^2}{2\sigma^2}\right)$$</span>
<span id="cb795-2629"><a href="#cb795-2629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2630"><a href="#cb795-2630" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>(y − $\mu$)^2^ gives the normal distribution its fundamental shape, a quadratic shape. Once you exponentiate the quadratic shape, you get the classic bell curve. The rest of it just scales and standardizes the distribution so that it sums to one, as all probability distributions must. But an expression as simple as exp(−y^2^) yields the Gaussian prototype.</span>
<span id="cb795-2631"><a href="#cb795-2631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2632"><a href="#cb795-2632" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The value y in the Gaussian distribution can be any continuous value, as Gussian is a continuous distribution. </span>
<span id="cb795-2633"><a href="#cb795-2633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2634"><a href="#cb795-2634" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The binomial, in contrast, requires integers. Probability distributions with only discrete outcomes, like the binomial, are usually called *probability mass functions* and denoted *Pr*. Continuous ones like the Gaussian are called *probability density functions*, denoted with *p* or just plain old *f*. </span>
<span id="cb795-2635"><a href="#cb795-2635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2636"><a href="#cb795-2636" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For mathematical reasons, probability densities, but not masses, can be greater than 1. For example:</span>
<span id="cb795-2637"><a href="#cb795-2637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2638"><a href="#cb795-2638" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c44}</span></span>
<span id="cb795-2639"><a href="#cb795-2639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2640"><a href="#cb795-2640" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate p(0|0, 0.1)</span></span>
<span id="cb795-2641"><a href="#cb795-2641" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)</span>
<span id="cb795-2642"><a href="#cb795-2642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2643"><a href="#cb795-2643" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability density is the rate of change in cumulative probability. </span></span>
<span id="cb795-2644"><a href="#cb795-2644" aria-hidden="true" tabindex="-1"></a><span class="co"># So where cumulative probability is increasing rapidly, density can easily exceed 1. </span></span>
<span id="cb795-2645"><a href="#cb795-2645" aria-hidden="true" tabindex="-1"></a><span class="co"># But if we calculate the area under the density function, it will never exceed 1. </span></span>
<span id="cb795-2646"><a href="#cb795-2646" aria-hidden="true" tabindex="-1"></a><span class="co"># Such areas are also called probability mass.</span></span>
<span id="cb795-2647"><a href="#cb795-2647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2648"><a href="#cb795-2648" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2649"><a href="#cb795-2649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2650"><a href="#cb795-2650" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The Gaussian distribution is routinely seen without $\sigma$ but with another parameter, $\tau$ . The parameter $\tau$ in this context is usually called precision and defined as $\tau$ = 1/$\sigma$^2^. This change of parameters gives us the equivalent formula (just substitute $\sigma$ = 1/ $\sqrt\tau$):</span>
<span id="cb795-2651"><a href="#cb795-2651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2652"><a href="#cb795-2652" aria-hidden="true" tabindex="-1"></a>$$p(y|\mu, \tau) = \sqrt\frac{\tau}{{2\pi}} \exp\left(- \frac{1}{2}\tau(y - \mu)^2 \right)$$</span>
<span id="cb795-2653"><a href="#cb795-2653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2654"><a href="#cb795-2654" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2655"><a href="#cb795-2655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2656"><a href="#cb795-2656" aria-hidden="true" tabindex="-1"></a><span class="fu">## A language for describing models</span></span>
<span id="cb795-2657"><a href="#cb795-2657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2658"><a href="#cb795-2658" aria-hidden="true" tabindex="-1"></a>(1) First, we recognize a set of measurements that we hope to predict or understand, the *outcome* variable or variables.</span>
<span id="cb795-2659"><a href="#cb795-2659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2660"><a href="#cb795-2660" aria-hidden="true" tabindex="-1"></a>(2) For each of these outcome variables, we define a likelihood distribution that defines the plausibility of individual observations. In linear regression, this distribution is always Gaussian.</span>
<span id="cb795-2661"><a href="#cb795-2661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2662"><a href="#cb795-2662" aria-hidden="true" tabindex="-1"></a>(3) Then we recognize a set of other measurements that we hope to use to predict or understand the outcome. Call these *predictor* variables.</span>
<span id="cb795-2663"><a href="#cb795-2663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2664"><a href="#cb795-2664" aria-hidden="true" tabindex="-1"></a>(4) We relate the exact shape of the likelihood distribution—its precise location and variance and other aspects of its shape, if it has them—to the predictor variables. In choosing a way to relate the predictors to the outcomes, we are forced to name and define all of the parameters of the model.</span>
<span id="cb795-2665"><a href="#cb795-2665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2666"><a href="#cb795-2666" aria-hidden="true" tabindex="-1"></a>(5) Finally, we choose priors for all of the parameters in the model. These priors define the initial information state of the model, before seeing the data.</span>
<span id="cb795-2667"><a href="#cb795-2667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2668"><a href="#cb795-2668" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>After all these decisions are made, summarize the model: </span>
<span id="cb795-2669"><a href="#cb795-2669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2670"><a href="#cb795-2670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2671"><a href="#cb795-2671" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-2672"><a href="#cb795-2672" aria-hidden="true" tabindex="-1"></a>\text{outcome}_i \sim \text{Normal}(\mu_i, \sigma) <span class="sc">\\</span></span>
<span id="cb795-2673"><a href="#cb795-2673" aria-hidden="true" tabindex="-1"></a>\mu_i = \beta \times \text{predictor}_i <span class="sc">\\</span></span>
<span id="cb795-2674"><a href="#cb795-2674" aria-hidden="true" tabindex="-1"></a>\beta \sim \text{Normal}(0, 10) <span class="sc">\\</span></span>
<span id="cb795-2675"><a href="#cb795-2675" aria-hidden="true" tabindex="-1"></a>\sigma \sim \text{HalfCauchy}(0, 1)</span>
<span id="cb795-2676"><a href="#cb795-2676" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-2677"><a href="#cb795-2677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2678"><a href="#cb795-2678" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">style</span><span class="ot">=</span><span class="st">"border: 1px solid #999; padding: 10px; background-color: #f9f9f9; margin: 10px 0;"</span><span class="kw">&gt;</span></span>
<span id="cb795-2679"><a href="#cb795-2679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2680"><a href="#cb795-2680" aria-hidden="true" tabindex="-1"></a>outcome~i~                    = outcome variable for the i^th^ observation</span>
<span id="cb795-2681"><a href="#cb795-2681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2682"><a href="#cb795-2682" aria-hidden="true" tabindex="-1"></a>Normal($\mu$~i~, $\sigma$)    = normal distribution with mean $\mu$~i~ and standard deviation $\sigma$</span>
<span id="cb795-2683"><a href="#cb795-2683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2684"><a href="#cb795-2684" aria-hidden="true" tabindex="-1"></a>$\mu$~i~    = mean ($\mu$~i~) of the normal distribution for the i^th^ observation</span>
<span id="cb795-2685"><a href="#cb795-2685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2686"><a href="#cb795-2686" aria-hidden="true" tabindex="-1"></a>$\beta\times\text{predictor}$ = the product of a coefficient ($\beta$) and a predictor variable (predictor~i~)</span>
<span id="cb795-2687"><a href="#cb795-2687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2688"><a href="#cb795-2688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2689"><a href="#cb795-2689" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/div&gt;</span></span>
<span id="cb795-2690"><a href="#cb795-2690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2691"><a href="#cb795-2691" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2692"><a href="#cb795-2692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2693"><a href="#cb795-2693" aria-hidden="true" tabindex="-1"></a><span class="fu">### Re-describing the globe tossing model</span></span>
<span id="cb795-2694"><a href="#cb795-2694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2695"><a href="#cb795-2695" aria-hidden="true" tabindex="-1"></a>The model:</span>
<span id="cb795-2696"><a href="#cb795-2696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2697"><a href="#cb795-2697" aria-hidden="true" tabindex="-1"></a>$$\text{w} \sim \text{Binomial(n, p)}$$</span>
<span id="cb795-2698"><a href="#cb795-2698" aria-hidden="true" tabindex="-1"></a>$$\text{p} \sim \text{Uniform(0, 1)}$$</span>
<span id="cb795-2699"><a href="#cb795-2699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2700"><a href="#cb795-2700" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2701"><a href="#cb795-2701" aria-hidden="true" tabindex="-1"></a><span class="in">w   = observed count of water samples</span></span>
<span id="cb795-2702"><a href="#cb795-2702" aria-hidden="true" tabindex="-1"></a><span class="in">n   = total number of samples</span></span>
<span id="cb795-2703"><a href="#cb795-2703" aria-hidden="true" tabindex="-1"></a><span class="in">p   = proportion of water on actual globe</span></span>
<span id="cb795-2704"><a href="#cb795-2704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2705"><a href="#cb795-2705" aria-hidden="true" tabindex="-1"></a><span class="in">The count w is distributed binomially with sample size n and probability p. </span></span>
<span id="cb795-2706"><a href="#cb795-2706" aria-hidden="true" tabindex="-1"></a><span class="in">The prior for p is assumed to be uniform between zero and one. </span></span>
<span id="cb795-2707"><a href="#cb795-2707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2708"><a href="#cb795-2708" aria-hidden="true" tabindex="-1"></a><span class="in">In these models, the first line defines the likelihood function used in Bayes’ theorem. </span></span>
<span id="cb795-2709"><a href="#cb795-2709" aria-hidden="true" tabindex="-1"></a><span class="in">The other line defines priors. Both of the lines in this model are stochastic, as </span></span>
<span id="cb795-2710"><a href="#cb795-2710" aria-hidden="true" tabindex="-1"></a><span class="in">indicated by the ∼ symbol. A stochastic relationship is just a mapping of a variable </span></span>
<span id="cb795-2711"><a href="#cb795-2711" aria-hidden="true" tabindex="-1"></a><span class="in">or parameter onto a distribution. It is stochastic because no single instance of the </span></span>
<span id="cb795-2712"><a href="#cb795-2712" aria-hidden="true" tabindex="-1"></a><span class="in">variable on the left is known with certainty. Instead, the mapping is probabilistic: </span></span>
<span id="cb795-2713"><a href="#cb795-2713" aria-hidden="true" tabindex="-1"></a><span class="in">Some values are more plausible than others, but very many different values are </span></span>
<span id="cb795-2714"><a href="#cb795-2714" aria-hidden="true" tabindex="-1"></a><span class="in">plausible under any model. </span></span>
<span id="cb795-2715"><a href="#cb795-2715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2716"><a href="#cb795-2716" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2717"><a href="#cb795-2717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2718"><a href="#cb795-2718" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2719"><a href="#cb795-2719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2720"><a href="#cb795-2720" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***From model definition to Bayes' theorem***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-2721"><a href="#cb795-2721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2722"><a href="#cb795-2722" aria-hidden="true" tabindex="-1"></a>To relate the mathematical format above to Bayes’ theorem, you could use the model definition to define the posterior distribution:</span>
<span id="cb795-2723"><a href="#cb795-2723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2724"><a href="#cb795-2724" aria-hidden="true" tabindex="-1"></a>$$\text{Pr(p|w,n)} = \frac{\text{Binomial(w|n,p) Uniform(p|0,1)}}{\int \text{Binomial(w|n,p) Uniform(p|0,1)dp}}$$</span>
<span id="cb795-2725"><a href="#cb795-2725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2726"><a href="#cb795-2726" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2727"><a href="#cb795-2727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2728"><a href="#cb795-2728" aria-hidden="true" tabindex="-1"></a>$$\text{posterior probability of any particular value of p} = \frac{likelihood \times prior}{\text{average likelihood}}$$</span>
<span id="cb795-2729"><a href="#cb795-2729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2730"><a href="#cb795-2730" aria-hidden="true" tabindex="-1"></a>In R code form:</span>
<span id="cb795-2731"><a href="#cb795-2731" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c45}</span></span>
<span id="cb795-2732"><a href="#cb795-2732" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="dv">6</span>; n <span class="ot">&lt;-</span> <span class="dv">9</span>;</span>
<span id="cb795-2733"><a href="#cb795-2733" aria-hidden="true" tabindex="-1"></a>p_grid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb795-2734"><a href="#cb795-2734" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(w, n, p_grid) <span class="sc">*</span> <span class="fu">dunif</span>(p_grid, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb795-2735"><a href="#cb795-2735" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> posterior<span class="sc">/</span> <span class="fu">sum</span>(posterior)</span>
<span id="cb795-2736"><a href="#cb795-2736" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(posterior<span class="sc">~</span>p_grid, <span class="at">type =</span> <span class="st">"l"</span>)</span>
<span id="cb795-2737"><a href="#cb795-2737" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2738"><a href="#cb795-2738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2739"><a href="#cb795-2739" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2740"><a href="#cb795-2740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2741"><a href="#cb795-2741" aria-hidden="true" tabindex="-1"></a><span class="fu">## A Gaussian model of height</span></span>
<span id="cb795-2742"><a href="#cb795-2742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2743"><a href="#cb795-2743" aria-hidden="true" tabindex="-1"></a>There are an infinite number of possible Gaussian distributions. Some have small means. Others have large means. Some are wide, with a large $\sigma$. Others are narrow. We want our Bayesian machine to consider every possible distribution, each defined by a combination of $\mu$ and $\sigma$, and rank them by posterior plausibility. Posterior plausibility provides a measure of the logical compatibility of each possible distribution with the data and model.</span>
<span id="cb795-2744"><a href="#cb795-2744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2745"><a href="#cb795-2745" aria-hidden="true" tabindex="-1"></a>In practice we’ll use approximations to the formal analysis. So we won’t really consider every possible value of $\mu$ and $\sigma$.  The “estimate” here will be the entire posterior distribution, not any point within it. And as a result, the posterior distribution will be a distribution of Gaussian distributions. Yes, a distribution of distributions.</span>
<span id="cb795-2746"><a href="#cb795-2746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2747"><a href="#cb795-2747" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2748"><a href="#cb795-2748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2749"><a href="#cb795-2749" aria-hidden="true" tabindex="-1"></a><span class="fu">### The data</span></span>
<span id="cb795-2750"><a href="#cb795-2750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2751"><a href="#cb795-2751" aria-hidden="true" tabindex="-1"></a>A data frame is a special kind of list in R. So you access the individual variables with the usual list “double bracket” notation, like d[<span class="co">[</span><span class="ot">1</span><span class="co">]</span>] for the first variable or d[<span class="co">[</span><span class="ot">'x'</span><span class="co">]</span>] for the variable named x. Unlike regular lists, however, data frames force all variables to have the same length. That isn’t always a good thing. And that’s why some statistical packages, like the powerful Stan Markov chain sampler (mc-stan.org), accept plain lists of data, rather than proper data frames.</span>
<span id="cb795-2752"><a href="#cb795-2752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2753"><a href="#cb795-2753" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c46}</span></span>
<span id="cb795-2754"><a href="#cb795-2754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2755"><a href="#cb795-2755" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb795-2756"><a href="#cb795-2756" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Howell1"</span>)</span>
<span id="cb795-2757"><a href="#cb795-2757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2758"><a href="#cb795-2758" aria-hidden="true" tabindex="-1"></a><span class="co"># name the data frame as "d"</span></span>
<span id="cb795-2759"><a href="#cb795-2759" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-2760"><a href="#cb795-2760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2761"><a href="#cb795-2761" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the structure of the data frame</span></span>
<span id="cb795-2762"><a href="#cb795-2762" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-2763"><a href="#cb795-2763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2764"><a href="#cb795-2764" aria-hidden="true" tabindex="-1"></a><span class="co"># Select the height column</span></span>
<span id="cb795-2765"><a href="#cb795-2765" aria-hidden="true" tabindex="-1"></a> d0 <span class="ot">&lt;-</span> d<span class="sc">$</span>height</span>
<span id="cb795-2766"><a href="#cb795-2766" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-2767"><a href="#cb795-2767" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter the data frame down to individuals of age 18 or greater </span></span>
<span id="cb795-2768"><a href="#cb795-2768" aria-hidden="true" tabindex="-1"></a> d2 <span class="ot">&lt;-</span> d[d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span>, ]</span>
<span id="cb795-2769"><a href="#cb795-2769" aria-hidden="true" tabindex="-1"></a><span class="co"># You can access any value in the matrix with d[row,col], replacing row and col </span></span>
<span id="cb795-2770"><a href="#cb795-2770" aria-hidden="true" tabindex="-1"></a><span class="co"># with row and column numbers. If row or col are lists of numbers, then you get</span></span>
<span id="cb795-2771"><a href="#cb795-2771" aria-hidden="true" tabindex="-1"></a><span class="co"># more than one row or column. If you leave the spot for row or col blank, then </span></span>
<span id="cb795-2772"><a href="#cb795-2772" aria-hidden="true" tabindex="-1"></a><span class="co"># you get all of whatever you leave blank. For example,d[ 3 , ]gives all columns </span></span>
<span id="cb795-2773"><a href="#cb795-2773" aria-hidden="true" tabindex="-1"></a><span class="co"># at row 3. Typing d[,] just gives you the entire matrix, because it returns all </span></span>
<span id="cb795-2774"><a href="#cb795-2774" aria-hidden="true" tabindex="-1"></a><span class="co"># rows and all columns.</span></span>
<span id="cb795-2775"><a href="#cb795-2775" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-2776"><a href="#cb795-2776" aria-hidden="true" tabindex="-1"></a><span class="co"># d[ d$age &gt;= 18 , ] gives you all of the rows in which d$age is greater-than- </span></span>
<span id="cb795-2777"><a href="#cb795-2777" aria-hidden="true" tabindex="-1"></a><span class="co"># or-equal-to 18. It also gives you all of the columns, because the spot after </span></span>
<span id="cb795-2778"><a href="#cb795-2778" aria-hidden="true" tabindex="-1"></a><span class="co"># the comma is blank.</span></span>
<span id="cb795-2779"><a href="#cb795-2779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2780"><a href="#cb795-2780" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2781"><a href="#cb795-2781" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2782"><a href="#cb795-2782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2783"><a href="#cb795-2783" aria-hidden="true" tabindex="-1"></a><span class="fu">### The model</span></span>
<span id="cb795-2784"><a href="#cb795-2784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2785"><a href="#cb795-2785" aria-hidden="true" tabindex="-1"></a>Our goal is to model these values using a Gaussian distribution.</span>
<span id="cb795-2786"><a href="#cb795-2786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2787"><a href="#cb795-2787" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c47}</span></span>
<span id="cb795-2788"><a href="#cb795-2788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2789"><a href="#cb795-2789" aria-hidden="true" tabindex="-1"></a><span class="co"># First, plot the distribution of heights</span></span>
<span id="cb795-2790"><a href="#cb795-2790" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(d2<span class="sc">$</span>height)</span>
<span id="cb795-2791"><a href="#cb795-2791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2792"><a href="#cb795-2792" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2793"><a href="#cb795-2793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2794"><a href="#cb795-2794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2795"><a href="#cb795-2795" aria-hidden="true" tabindex="-1"></a>Whatever the reason, adult heights are nearly always approximately normal. So it’s reasonable for the moment to adopt the stance that the model’s likelihood should be Gaussian. But be careful about choosing the Gaussian distribution only when the plotted outcome variable looks Gaussian to you. Gawking at the raw data, to try to decide how to model them, is usually not a good idea. The data could be a mixture of different Gaussian distributions, for example, and in that case you won’t be able to detect the underlying normality just by eyeballing the outcome distribution. Furthermore, the empirical distribution needn’t be actually Gaussian in order to justify using a Gaussian likelihood.</span>
<span id="cb795-2796"><a href="#cb795-2796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2797"><a href="#cb795-2797" aria-hidden="true" tabindex="-1"></a>There are an infinite number of Gaussain distributions , with an infinite number of different means and standard deviations. We’re ready to write down the general model and compute the plausibility of each combination of $\mu$ and $\sigma$. To define the heights as normally distributed with a mean $\mu$ and standard deviation $\sigma$, we write:</span>
<span id="cb795-2798"><a href="#cb795-2798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2799"><a href="#cb795-2799" aria-hidden="true" tabindex="-1"></a>$$\text{h}_i \sim \text{Normal}(\mu, \sigma)$$                                  </span>
<span id="cb795-2800"><a href="#cb795-2800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2801"><a href="#cb795-2801" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2802"><a href="#cb795-2802" aria-hidden="true" tabindex="-1"></a><span class="in">h             = the list of heights</span></span>
<span id="cb795-2803"><a href="#cb795-2803" aria-hidden="true" tabindex="-1"></a><span class="in">subscript i   = index- each individual element of this list (row numbers)</span></span>
<span id="cb795-2804"><a href="#cb795-2804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2805"><a href="#cb795-2805" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2806"><a href="#cb795-2806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2807"><a href="#cb795-2807" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2808"><a href="#cb795-2808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2809"><a href="#cb795-2809" aria-hidden="true" tabindex="-1"></a>Then, we add priors assuming Pr($\mu$, $\sigma$) = Pr($\mu$) Pr($\sigma$):</span>
<span id="cb795-2810"><a href="#cb795-2810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2811"><a href="#cb795-2811" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-2812"><a href="#cb795-2812" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-2813"><a href="#cb795-2813" aria-hidden="true" tabindex="-1"></a>\text{h}_i &amp;\sim \text{Normal}(\mu, \sigma) \ &amp;&amp;&amp; <span class="co">[</span><span class="ot">\text{Likelihood}</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-2814"><a href="#cb795-2814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2815"><a href="#cb795-2815" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim \text{Normal}(178, 20) \ &amp;&amp;&amp; <span class="co">[</span><span class="ot">\mu \text{ prior}</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-2816"><a href="#cb795-2816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2817"><a href="#cb795-2817" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; <span class="co">[</span><span class="ot">\sigma \text{ prior}</span><span class="co">]</span></span>
<span id="cb795-2818"><a href="#cb795-2818" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-2819"><a href="#cb795-2819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2820"><a href="#cb795-2820" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-2821"><a href="#cb795-2821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2822"><a href="#cb795-2822" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2823"><a href="#cb795-2823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2824"><a href="#cb795-2824" aria-hidden="true" tabindex="-1"></a>Plot the priors to have a sense of the assumption they build into the model:</span>
<span id="cb795-2825"><a href="#cb795-2825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2826"><a href="#cb795-2826" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c48}</span></span>
<span id="cb795-2827"><a href="#cb795-2827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2828"><a href="#cb795-2828" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dnorm</span>(x, <span class="dv">178</span>, <span class="dv">20</span>), <span class="at">from =</span> <span class="dv">100</span>, <span class="at">to =</span> <span class="dv">250</span>)</span>
<span id="cb795-2829"><a href="#cb795-2829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2830"><a href="#cb795-2830" aria-hidden="true" tabindex="-1"></a><span class="co"># golem is assuming that the average height (not each individual height) is almost certainly </span></span>
<span id="cb795-2831"><a href="#cb795-2831" aria-hidden="true" tabindex="-1"></a><span class="co"># between 140 cm and 220 cm. So this prior carries a little information, but not a lot. </span></span>
<span id="cb795-2832"><a href="#cb795-2832" aria-hidden="true" tabindex="-1"></a><span class="co"># The σ prior is a truly flat prior, a uniform one, that functions just to constrain σ </span></span>
<span id="cb795-2833"><a href="#cb795-2833" aria-hidden="true" tabindex="-1"></a><span class="co"># to have positive probability between zero and 50cm. </span></span>
<span id="cb795-2834"><a href="#cb795-2834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2835"><a href="#cb795-2835" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2836"><a href="#cb795-2836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2837"><a href="#cb795-2837" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2838"><a href="#cb795-2838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2839"><a href="#cb795-2839" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c49}</span></span>
<span id="cb795-2840"><a href="#cb795-2840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2841"><a href="#cb795-2841" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">dunif</span>(x, <span class="dv">0</span>, <span class="dv">50</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">10</span>, <span class="at">to =</span> <span class="dv">60</span>)</span>
<span id="cb795-2842"><a href="#cb795-2842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2843"><a href="#cb795-2843" aria-hidden="true" tabindex="-1"></a><span class="co"># A standard deviation like σ must be positive, so bounding it at zero makes sense. </span></span>
<span id="cb795-2844"><a href="#cb795-2844" aria-hidden="true" tabindex="-1"></a><span class="co"># How should we pick the upper bound? In this case, a standard deviation of 50cm would </span></span>
<span id="cb795-2845"><a href="#cb795-2845" aria-hidden="true" tabindex="-1"></a><span class="co"># imply that 95% of individual heights lie within 100cm of the average height. </span></span>
<span id="cb795-2846"><a href="#cb795-2846" aria-hidden="true" tabindex="-1"></a><span class="co"># That’s a very large range.</span></span>
<span id="cb795-2847"><a href="#cb795-2847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2848"><a href="#cb795-2848" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2849"><a href="#cb795-2849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2850"><a href="#cb795-2850" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2851"><a href="#cb795-2851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2852"><a href="#cb795-2852" aria-hidden="true" tabindex="-1"></a>Simulate heights by sampling from priors (every posterior is also potentially a prior for a subsequent analysis, so you can process priors just like posteriors.):</span>
<span id="cb795-2853"><a href="#cb795-2853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2854"><a href="#cb795-2854" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c50}</span></span>
<span id="cb795-2855"><a href="#cb795-2855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2856"><a href="#cb795-2856" aria-hidden="true" tabindex="-1"></a>sample_mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, <span class="dv">178</span>, <span class="dv">20</span>)</span>
<span id="cb795-2857"><a href="#cb795-2857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2858"><a href="#cb795-2858" aria-hidden="true" tabindex="-1"></a>sample_sigma <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="fl">1e4</span>, <span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-2859"><a href="#cb795-2859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2860"><a href="#cb795-2860" aria-hidden="true" tabindex="-1"></a>prior_h <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, sample_mu, sample_sigma)</span>
<span id="cb795-2861"><a href="#cb795-2861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2862"><a href="#cb795-2862" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(prior_h)</span>
<span id="cb795-2863"><a href="#cb795-2863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2864"><a href="#cb795-2864" aria-hidden="true" tabindex="-1"></a><span class="co"># The density plot you get shows a vaguely bell-shaped density with thick tails. </span></span>
<span id="cb795-2865"><a href="#cb795-2865" aria-hidden="true" tabindex="-1"></a><span class="co"># It is the expected distribution of heights, averaged over the prior. Notice that </span></span>
<span id="cb795-2866"><a href="#cb795-2866" aria-hidden="true" tabindex="-1"></a><span class="co"># the prior probability distribution of height is not itself Gaussian. This is okay. </span></span>
<span id="cb795-2867"><a href="#cb795-2867" aria-hidden="true" tabindex="-1"></a><span class="co"># The distribution you see is not an empirical expectation, but rather the distribution </span></span>
<span id="cb795-2868"><a href="#cb795-2868" aria-hidden="true" tabindex="-1"></a><span class="co"># of relative plausibilities of different heights, before seeing the data.</span></span>
<span id="cb795-2869"><a href="#cb795-2869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2870"><a href="#cb795-2870" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2871"><a href="#cb795-2871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2872"><a href="#cb795-2872" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2873"><a href="#cb795-2873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2874"><a href="#cb795-2874" aria-hidden="true" tabindex="-1"></a><span class="fu">### Grid approximation of the posterior distribution</span></span>
<span id="cb795-2875"><a href="#cb795-2875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2876"><a href="#cb795-2876" aria-hidden="true" tabindex="-1"></a>The guts of the golem:</span>
<span id="cb795-2877"><a href="#cb795-2877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2878"><a href="#cb795-2878" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c51}</span></span>
<span id="cb795-2879"><a href="#cb795-2879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2880"><a href="#cb795-2880" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid of mu and sigma values</span></span>
<span id="cb795-2881"><a href="#cb795-2881" aria-hidden="true" tabindex="-1"></a>mu.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">140</span>, <span class="at">to=</span><span class="dv">160</span> , <span class="at">length.out=</span><span class="dv">200</span> )</span>
<span id="cb795-2882"><a href="#cb795-2882" aria-hidden="true" tabindex="-1"></a>sigma.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">4</span> , <span class="at">to=</span><span class="dv">9</span> , <span class="at">length.out=</span><span class="dv">200</span> )</span>
<span id="cb795-2883"><a href="#cb795-2883" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>( <span class="at">mu=</span>mu.list , <span class="at">sigma=</span>sigma.list )</span>
<span id="cb795-2884"><a href="#cb795-2884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2885"><a href="#cb795-2885" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate log-likelihood</span></span>
<span id="cb795-2886"><a href="#cb795-2886" aria-hidden="true" tabindex="-1"></a>post<span class="sc">$</span>LL <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post) , <span class="cf">function</span>(i) <span class="fu">sum</span>( <span class="fu">dnorm</span>( <span class="co">#calculate PDF of normal distribution</span></span>
<span id="cb795-2887"><a href="#cb795-2887" aria-hidden="true" tabindex="-1"></a>                d2<span class="sc">$</span>height , <span class="co"># sum to add up all log-likelihoods</span></span>
<span id="cb795-2888"><a href="#cb795-2888" aria-hidden="true" tabindex="-1"></a>                <span class="at">mean=</span>post<span class="sc">$</span>mu[i] ,</span>
<span id="cb795-2889"><a href="#cb795-2889" aria-hidden="true" tabindex="-1"></a>                <span class="at">sd=</span>post<span class="sc">$</span>sigma[i] ,</span>
<span id="cb795-2890"><a href="#cb795-2890" aria-hidden="true" tabindex="-1"></a>                <span class="at">log=</span><span class="cn">TRUE</span> ) ) ) <span class="co"># return log-likelihoods</span></span>
<span id="cb795-2891"><a href="#cb795-2891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2892"><a href="#cb795-2892" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probabilities from log-likelihoods</span></span>
<span id="cb795-2893"><a href="#cb795-2893" aria-hidden="true" tabindex="-1"></a>post<span class="sc">$</span>prod <span class="ot">&lt;-</span> post<span class="sc">$</span>LL <span class="sc">+</span> <span class="fu">dnorm</span>( post<span class="sc">$</span>mu , <span class="dv">178</span> , <span class="dv">20</span> , <span class="cn">TRUE</span> ) <span class="sc">+</span></span>
<span id="cb795-2894"><a href="#cb795-2894" aria-hidden="true" tabindex="-1"></a>    <span class="fu">dunif</span>( post<span class="sc">$</span>sigma , <span class="dv">0</span> , <span class="dv">50</span> , <span class="cn">TRUE</span> )</span>
<span id="cb795-2895"><a href="#cb795-2895" aria-hidden="true" tabindex="-1"></a><span class="co"># sum of all log-likelihoods + the log-likelihood of a normal distribution </span></span>
<span id="cb795-2896"><a href="#cb795-2896" aria-hidden="true" tabindex="-1"></a><span class="co"># with a fixed mean of 178 and standard deviation of 20 + he log-likelihood of </span></span>
<span id="cb795-2897"><a href="#cb795-2897" aria-hidden="true" tabindex="-1"></a><span class="co"># a uniform distribution for sigma values between 0 and 50</span></span>
<span id="cb795-2898"><a href="#cb795-2898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2899"><a href="#cb795-2899" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the sum effectively combines the contributions from the likelihood and the priors.</span></span>
<span id="cb795-2900"><a href="#cb795-2900" aria-hidden="true" tabindex="-1"></a><span class="co"># This is constructing the unnormalized log-posterior distribution by summing up the </span></span>
<span id="cb795-2901"><a href="#cb795-2901" aria-hidden="true" tabindex="-1"></a><span class="co"># log-likelihood and the log-prior terms. The final step of the analysis involves </span></span>
<span id="cb795-2902"><a href="#cb795-2902" aria-hidden="true" tabindex="-1"></a><span class="co"># normalizing these probabilities to obtain a proper probability distribution.</span></span>
<span id="cb795-2903"><a href="#cb795-2903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2904"><a href="#cb795-2904" aria-hidden="true" tabindex="-1"></a><span class="co"># Use exp function to exponentiate the log-likelihoods, transforming them back to probabilities</span></span>
<span id="cb795-2905"><a href="#cb795-2905" aria-hidden="true" tabindex="-1"></a>post<span class="sc">$</span>prob <span class="ot">&lt;-</span> <span class="fu">exp</span>( post<span class="sc">$</span>prod <span class="sc">-</span> <span class="fu">max</span>(post<span class="sc">$</span>prod) )</span>
<span id="cb795-2906"><a href="#cb795-2906" aria-hidden="true" tabindex="-1"></a><span class="co"># subtracting helps with numerical stability by preventing very large or small values</span></span>
<span id="cb795-2907"><a href="#cb795-2907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2908"><a href="#cb795-2908" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple contour plot</span></span>
<span id="cb795-2909"><a href="#cb795-2909" aria-hidden="true" tabindex="-1"></a><span class="fu">contour_xyz</span>( post<span class="sc">$</span>mu , post<span class="sc">$</span>sigma , post<span class="sc">$</span>prob )</span>
<span id="cb795-2910"><a href="#cb795-2910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2911"><a href="#cb795-2911" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple heat map</span></span>
<span id="cb795-2912"><a href="#cb795-2912" aria-hidden="true" tabindex="-1"></a><span class="fu">image_xyz</span>( post<span class="sc">$</span>mu , post<span class="sc">$</span>sigma , post<span class="sc">$</span>prob )</span>
<span id="cb795-2913"><a href="#cb795-2913" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2914"><a href="#cb795-2914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2915"><a href="#cb795-2915" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2916"><a href="#cb795-2916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2917"><a href="#cb795-2917" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sampling from the posterior</span></span>
<span id="cb795-2918"><a href="#cb795-2918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2919"><a href="#cb795-2919" aria-hidden="true" tabindex="-1"></a>Since there are two parameters, and we want to sample combinations of them, we first randomly sample row numbers in post in proportion to the values in post$prob. Then we pull out the parameter values on those randomly sampled rows. </span>
<span id="cb795-2920"><a href="#cb795-2920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2921"><a href="#cb795-2921" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.17}</span></span>
<span id="cb795-2922"><a href="#cb795-2922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2923"><a href="#cb795-2923" aria-hidden="true" tabindex="-1"></a><span class="co"># First randomly sample row numbers in post in proportion to the values in post$prob</span></span>
<span id="cb795-2924"><a href="#cb795-2924" aria-hidden="true" tabindex="-1"></a>sample.rows <span class="ot">&lt;-</span> <span class="fu">sample</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post) , <span class="at">size=</span><span class="fl">1e4</span> , <span class="at">replace=</span><span class="cn">TRUE</span> ,</span>
<span id="cb795-2925"><a href="#cb795-2925" aria-hidden="true" tabindex="-1"></a>    <span class="at">prob=</span>post<span class="sc">$</span>prob )</span>
<span id="cb795-2926"><a href="#cb795-2926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2927"><a href="#cb795-2927" aria-hidden="true" tabindex="-1"></a><span class="co"># Pull out the parameter values on those randomly sampled rows</span></span>
<span id="cb795-2928"><a href="#cb795-2928" aria-hidden="true" tabindex="-1"></a>sample.mu <span class="ot">&lt;-</span> post<span class="sc">$</span>mu[ sample.rows ]</span>
<span id="cb795-2929"><a href="#cb795-2929" aria-hidden="true" tabindex="-1"></a>sample.sigma <span class="ot">&lt;-</span> post<span class="sc">$</span>sigma[ sample.rows ]</span>
<span id="cb795-2930"><a href="#cb795-2930" aria-hidden="true" tabindex="-1"></a><span class="co"># You end up with 10,000 samples, with replacement, from the posterior for the height data.</span></span>
<span id="cb795-2931"><a href="#cb795-2931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2932"><a href="#cb795-2932" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the samples</span></span>
<span id="cb795-2933"><a href="#cb795-2933" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( sample.mu , sample.sigma , <span class="at">cex=</span><span class="fl">0.5</span> , <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) )</span>
<span id="cb795-2934"><a href="#cb795-2934" aria-hidden="true" tabindex="-1"></a><span class="co"># Samples from the posterior distribution for the heights data. The density of </span></span>
<span id="cb795-2935"><a href="#cb795-2935" aria-hidden="true" tabindex="-1"></a><span class="co"># points is highest in the center, reflecting the most plausible combinations of μ and σ.</span></span>
<span id="cb795-2936"><a href="#cb795-2936" aria-hidden="true" tabindex="-1"></a><span class="co"># There are many more ways for these parameter values to produce the data, conditional on the model.</span></span>
<span id="cb795-2937"><a href="#cb795-2937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2938"><a href="#cb795-2938" aria-hidden="true" tabindex="-1"></a><span class="co"># Describe the distribution of confidence in each combination of μ and σ by summarizing the samples</span></span>
<span id="cb795-2939"><a href="#cb795-2939" aria-hidden="true" tabindex="-1"></a><span class="co"># Characterize the shapes of the marginal posterior densities of μ and σ</span></span>
<span id="cb795-2940"><a href="#cb795-2940" aria-hidden="true" tabindex="-1"></a><span class="co"># The jargon “marginal” here means “averaging over the other parameters.” </span></span>
<span id="cb795-2941"><a href="#cb795-2941" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(sample.mu, <span class="at">main =</span> <span class="st">"sample.mu"</span>)</span>
<span id="cb795-2942"><a href="#cb795-2942" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(sample.sigma, <span class="at">main =</span> <span class="st">"sample.sigma"</span>)</span>
<span id="cb795-2943"><a href="#cb795-2943" aria-hidden="true" tabindex="-1"></a><span class="co"># As sample size increases, posterior densities approach the normal distribution. </span></span>
<span id="cb795-2944"><a href="#cb795-2944" aria-hidden="true" tabindex="-1"></a><span class="co"># If you look closely, though, you’ll notice that the density for σ has a longer right-hand tail.</span></span>
<span id="cb795-2945"><a href="#cb795-2945" aria-hidden="true" tabindex="-1"></a><span class="co"># This condition is very common for standard deviation parameters.</span></span>
<span id="cb795-2946"><a href="#cb795-2946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2947"><a href="#cb795-2947" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the widths of these densities with highest posterior density intervals</span></span>
<span id="cb795-2948"><a href="#cb795-2948" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample.mu)</span>
<span id="cb795-2949"><a href="#cb795-2949" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(sample.sigma)</span>
<span id="cb795-2950"><a href="#cb795-2950" aria-hidden="true" tabindex="-1"></a><span class="co"># Since these samples are just vectors of numbers, you can compute any statistic </span></span>
<span id="cb795-2951"><a href="#cb795-2951" aria-hidden="true" tabindex="-1"></a><span class="co"># from them that you could from ordinary data. If you want the mean or median, </span></span>
<span id="cb795-2952"><a href="#cb795-2952" aria-hidden="true" tabindex="-1"></a><span class="co"># just use the corresponding R functions.</span></span>
<span id="cb795-2953"><a href="#cb795-2953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2954"><a href="#cb795-2954" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-2955"><a href="#cb795-2955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2956"><a href="#cb795-2956" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-2957"><a href="#cb795-2957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2958"><a href="#cb795-2958" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Sample size and the normality of $\sigma$'s posterior**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-2959"><a href="#cb795-2959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2960"><a href="#cb795-2960" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Repeat the above analysis using only a fraction of the original data to demonstrate the posterior is not always so Gaussian in shape</span>
<span id="cb795-2961"><a href="#cb795-2961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2962"><a href="#cb795-2962" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For a Gaussian likelihood and a Gaussian prior on μ, the posterior distribution is always Gaussian as well, regardless of sample size.</span>
<span id="cb795-2963"><a href="#cb795-2963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2964"><a href="#cb795-2964" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>There’s no trouble with the mean, μ. It is the standard deviation σ that causes problems- need to be careful of abusing the quadratic approximation.</span>
<span id="cb795-2965"><a href="#cb795-2965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2966"><a href="#cb795-2966" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The deep reasons for the posterior of σ tending to have a long right-hand tail are complex. But a useful way to conceive of the problem is that variances must be positive. As a result, there must be more uncertainty about how big the variance (or standard deviation) is than about how small it is. For example, if the variance is estimated to be near zero, then you know for sure that it can’t be much smaller. But it could be a lot bigger.</span>
<span id="cb795-2967"><a href="#cb795-2967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2968"><a href="#cb795-2968" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.21}</span></span>
<span id="cb795-2969"><a href="#cb795-2969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2970"><a href="#cb795-2970" aria-hidden="true" tabindex="-1"></a><span class="co"># Take only 20 samples from height data</span></span>
<span id="cb795-2971"><a href="#cb795-2971" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">&lt;-</span> <span class="fu">sample</span>(d2<span class="sc">$</span>height, <span class="at">size =</span> <span class="dv">20</span>)</span>
<span id="cb795-2972"><a href="#cb795-2972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2973"><a href="#cb795-2973" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid from mean and SD values</span></span>
<span id="cb795-2974"><a href="#cb795-2974" aria-hidden="true" tabindex="-1"></a>mu.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">150</span>, <span class="at">to=</span><span class="dv">170</span> , <span class="at">length.out=</span><span class="dv">200</span> )</span>
<span id="cb795-2975"><a href="#cb795-2975" aria-hidden="true" tabindex="-1"></a>sigma.list <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">4</span> , <span class="at">to=</span><span class="dv">20</span> , <span class="at">length.out=</span><span class="dv">200</span> )</span>
<span id="cb795-2976"><a href="#cb795-2976" aria-hidden="true" tabindex="-1"></a>post2 <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>( <span class="at">mu=</span>mu.list , <span class="at">sigma=</span>sigma.list )</span>
<span id="cb795-2977"><a href="#cb795-2977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2978"><a href="#cb795-2978" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate log-likelihoods</span></span>
<span id="cb795-2979"><a href="#cb795-2979" aria-hidden="true" tabindex="-1"></a>post2<span class="sc">$</span>LL <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post2) , <span class="cf">function</span>(i)</span>
<span id="cb795-2980"><a href="#cb795-2980" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>( <span class="fu">dnorm</span>( d3 , <span class="at">mean=</span>post2<span class="sc">$</span>mu[i] , <span class="at">sd=</span>post2<span class="sc">$</span>sigma[i] ,</span>
<span id="cb795-2981"><a href="#cb795-2981" aria-hidden="true" tabindex="-1"></a>    <span class="at">log=</span><span class="cn">TRUE</span> ) ) )</span>
<span id="cb795-2982"><a href="#cb795-2982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2983"><a href="#cb795-2983" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probabilities from log-likelihood values</span></span>
<span id="cb795-2984"><a href="#cb795-2984" aria-hidden="true" tabindex="-1"></a>post2<span class="sc">$</span>prod <span class="ot">&lt;-</span> post2<span class="sc">$</span>LL <span class="sc">+</span> <span class="fu">dnorm</span>( post2<span class="sc">$</span>mu , <span class="dv">178</span> , <span class="dv">20</span> , <span class="cn">TRUE</span> ) <span class="sc">+</span></span>
<span id="cb795-2985"><a href="#cb795-2985" aria-hidden="true" tabindex="-1"></a>    <span class="fu">dunif</span>( post2<span class="sc">$</span>sigma , <span class="dv">0</span> , <span class="dv">50</span> , <span class="cn">TRUE</span> )</span>
<span id="cb795-2986"><a href="#cb795-2986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2987"><a href="#cb795-2987" aria-hidden="true" tabindex="-1"></a><span class="co"># Exponentiate the log-likelihoods back to probability</span></span>
<span id="cb795-2988"><a href="#cb795-2988" aria-hidden="true" tabindex="-1"></a>post2<span class="sc">$</span>prob <span class="ot">&lt;-</span> <span class="fu">exp</span>( post2<span class="sc">$</span>prod <span class="sc">-</span> <span class="fu">max</span>(post2<span class="sc">$</span>prod) )</span>
<span id="cb795-2989"><a href="#cb795-2989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2990"><a href="#cb795-2990" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomly sample row numbers in post2 in proportion to probability</span></span>
<span id="cb795-2991"><a href="#cb795-2991" aria-hidden="true" tabindex="-1"></a>sample2.rows <span class="ot">&lt;-</span> <span class="fu">sample</span>( <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(post2) , <span class="at">size=</span><span class="fl">1e4</span> , <span class="at">replace=</span><span class="cn">TRUE</span> ,</span>
<span id="cb795-2992"><a href="#cb795-2992" aria-hidden="true" tabindex="-1"></a>    <span class="at">prob=</span>post2<span class="sc">$</span>prob )</span>
<span id="cb795-2993"><a href="#cb795-2993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2994"><a href="#cb795-2994" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the parameter values from randomly sampled row numbers</span></span>
<span id="cb795-2995"><a href="#cb795-2995" aria-hidden="true" tabindex="-1"></a>sample2.mu <span class="ot">&lt;-</span> post2<span class="sc">$</span>mu[ sample2.rows ]</span>
<span id="cb795-2996"><a href="#cb795-2996" aria-hidden="true" tabindex="-1"></a>sample2.sigma <span class="ot">&lt;-</span> post2<span class="sc">$</span>sigma[ sample2.rows ]</span>
<span id="cb795-2997"><a href="#cb795-2997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-2998"><a href="#cb795-2998" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the samples</span></span>
<span id="cb795-2999"><a href="#cb795-2999" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( sample2.mu , sample2.sigma , <span class="at">cex=</span><span class="fl">0.5</span> ,</span>
<span id="cb795-3000"><a href="#cb795-3000" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) ,</span>
<span id="cb795-3001"><a href="#cb795-3001" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">"mu"</span> , <span class="at">ylab=</span><span class="st">"sigma"</span> , <span class="at">pch=</span><span class="dv">16</span> )</span>
<span id="cb795-3002"><a href="#cb795-3002" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice a distinctly longer tail at the top of the cloud of points</span></span>
<span id="cb795-3003"><a href="#cb795-3003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3004"><a href="#cb795-3004" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the marginal posterior density for σ, averaging over μ</span></span>
<span id="cb795-3005"><a href="#cb795-3005" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>( sample2.sigma , <span class="at">norm.comp=</span><span class="cn">TRUE</span>, <span class="at">col =</span> <span class="st">"purple"</span> )</span>
<span id="cb795-3006"><a href="#cb795-3006" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can see that the posterior for σ is not Gaussian, but rather has a long tail of</span></span>
<span id="cb795-3007"><a href="#cb795-3007" aria-hidden="true" tabindex="-1"></a><span class="co"># uncertainty towards higher values.</span></span>
<span id="cb795-3008"><a href="#cb795-3008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3009"><a href="#cb795-3009" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3010"><a href="#cb795-3010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3011"><a href="#cb795-3011" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3012"><a href="#cb795-3012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3013"><a href="#cb795-3013" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fitting the model with `map`</span></span>
<span id="cb795-3014"><a href="#cb795-3014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3015"><a href="#cb795-3015" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Quadratic approximation is as a handy way to quickly make inferences about the shape of the posterior.</span>
<span id="cb795-3016"><a href="#cb795-3016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3017"><a href="#cb795-3017" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The posterior’s peak will lie at the maximum a posteriori estimate (MAP), and we can get a useful image of the posterior’s shape by using the quadratic approximation of the posterior distribution at this peak.</span>
<span id="cb795-3018"><a href="#cb795-3018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3019"><a href="#cb795-3019" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3020"><a href="#cb795-3020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3021"><a href="#cb795-3021" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown; text-decoration:underline"</span><span class="kw">&gt;</span>**Use `map` to find the values of $\mu$ and $\sigma$ that maximize the posterior probability:**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3022"><a href="#cb795-3022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3023"><a href="#cb795-3023" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.24}</span></span>
<span id="cb795-3024"><a href="#cb795-3024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3025"><a href="#cb795-3025" aria-hidden="true" tabindex="-1"></a><span class="co"># Load Howell1 data and select out the adults</span></span>
<span id="cb795-3026"><a href="#cb795-3026" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb795-3027"><a href="#cb795-3027" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-3028"><a href="#cb795-3028" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> d[ d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span> , ]</span>
<span id="cb795-3029"><a href="#cb795-3029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3030"><a href="#cb795-3030" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3031"><a href="#cb795-3031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3032"><a href="#cb795-3032" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Define the model, using R's formula syntax:</span>
<span id="cb795-3033"><a href="#cb795-3033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3034"><a href="#cb795-3034" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-3035"><a href="#cb795-3035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3036"><a href="#cb795-3036" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-3037"><a href="#cb795-3037" aria-hidden="true" tabindex="-1"></a>\text{h}_i &amp; \sim \text{Normal}(\mu, \sigma) \ &amp;&amp;&amp; \text{<span class="co">[</span><span class="ot">height} &amp; \sim \text{dnorm(mu, sigma)}\text{</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb795-3038"><a href="#cb795-3038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3039"><a href="#cb795-3039" aria-hidden="true" tabindex="-1"></a>\mu &amp;\sim \text{Normal}(178, 20) \ &amp;&amp;&amp; <span class="co">[</span><span class="ot">\text{mu} &amp;\sim \text{dnorm}(178, 20)</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-3040"><a href="#cb795-3040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3041"><a href="#cb795-3041" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; <span class="co">[</span><span class="ot">\text{sigma} &amp;\sim \text{dunif}(0, 50)</span><span class="co">]</span></span>
<span id="cb795-3042"><a href="#cb795-3042" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-3043"><a href="#cb795-3043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3044"><a href="#cb795-3044" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-3045"><a href="#cb795-3045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3046"><a href="#cb795-3046" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3047"><a href="#cb795-3047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3048"><a href="#cb795-3048" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Now, place the R code equivalents into <span class="in">`alist`</span>. </span>
<span id="cb795-3049"><a href="#cb795-3049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3050"><a href="#cb795-3050" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.25}</span></span>
<span id="cb795-3051"><a href="#cb795-3051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3052"><a href="#cb795-3052" aria-hidden="true" tabindex="-1"></a>flist <span class="ot">&lt;-</span> <span class="fu">alist</span>(</span>
<span id="cb795-3053"><a href="#cb795-3053" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-3054"><a href="#cb795-3054" aria-hidden="true" tabindex="-1"></a>    mu <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">20</span> ) ,</span>
<span id="cb795-3055"><a href="#cb795-3055" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-3056"><a href="#cb795-3056" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3057"><a href="#cb795-3057" aria-hidden="true" tabindex="-1"></a><span class="co"># Note the commas at the end of each line, except the last. </span></span>
<span id="cb795-3058"><a href="#cb795-3058" aria-hidden="true" tabindex="-1"></a><span class="co"># These commas separate each line of the model definition.</span></span>
<span id="cb795-3059"><a href="#cb795-3059" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3060"><a href="#cb795-3060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3061"><a href="#cb795-3061" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3062"><a href="#cb795-3062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3063"><a href="#cb795-3063" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fit the model to the data in the data frame d2 with: </span>
<span id="cb795-3064"><a href="#cb795-3064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3065"><a href="#cb795-3065" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.26}</span></span>
<span id="cb795-3066"><a href="#cb795-3066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3067"><a href="#cb795-3067" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.1</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>( flist , <span class="at">data=</span>d2 )</span>
<span id="cb795-3068"><a href="#cb795-3068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3069"><a href="#cb795-3069" aria-hidden="true" tabindex="-1"></a><span class="co"># After executing this code, you’ll have a fit model stored in the symbol m4.1.</span></span>
<span id="cb795-3070"><a href="#cb795-3070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3071"><a href="#cb795-3071" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3072"><a href="#cb795-3072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3073"><a href="#cb795-3073" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3074"><a href="#cb795-3074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3075"><a href="#cb795-3075" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Now take a look at the fit maximum a posteriori model:</span>
<span id="cb795-3076"><a href="#cb795-3076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3077"><a href="#cb795-3077" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.27}</span></span>
<span id="cb795-3078"><a href="#cb795-3078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3079"><a href="#cb795-3079" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.1</span>)</span>
<span id="cb795-3080"><a href="#cb795-3080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3081"><a href="#cb795-3081" aria-hidden="true" tabindex="-1"></a><span class="co"># These numbers provide Gaussian approximations for each parameter’s marginal distribution. </span></span>
<span id="cb795-3082"><a href="#cb795-3082" aria-hidden="true" tabindex="-1"></a><span class="co"># This means the plausibility of each value of μ, after averaging over the plausibilities </span></span>
<span id="cb795-3083"><a href="#cb795-3083" aria-hidden="true" tabindex="-1"></a><span class="co"># of each value of σ, is given by a Gaussian distribution with mean 154.6 and standard deviation 0.4.</span></span>
<span id="cb795-3084"><a href="#cb795-3084" aria-hidden="true" tabindex="-1"></a><span class="co"># The 5.5% and 94.5% quantiles are percentile interval boundaries, corresponding to an 89% interval.</span></span>
<span id="cb795-3085"><a href="#cb795-3085" aria-hidden="true" tabindex="-1"></a><span class="co"># They are almost identical with the HPDIs from the grid approximation earlier.</span></span>
<span id="cb795-3086"><a href="#cb795-3086" aria-hidden="true" tabindex="-1"></a><span class="co"># When the posterior is approximately Gaussian, then this is what you should expect.</span></span>
<span id="cb795-3087"><a href="#cb795-3087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3088"><a href="#cb795-3088" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3089"><a href="#cb795-3089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3090"><a href="#cb795-3090" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3091"><a href="#cb795-3091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3092"><a href="#cb795-3092" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown; text-decoration:underline"</span><span class="kw">&gt;</span>**Start values for `map`**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3093"><a href="#cb795-3093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3094"><a href="#cb795-3094" aria-hidden="true" tabindex="-1"></a><span class="in">`map`</span> estimates the posterior by climbing it like a hill. To do this, it has to start climbing someplace, at some combination of parameter values. Unless you tell it otherwise, map starts at random values sampled from the prior. But it’s also possible to specify a starting value for any parameter in the model.</span>
<span id="cb795-3095"><a href="#cb795-3095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3096"><a href="#cb795-3096" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.28}</span></span>
<span id="cb795-3097"><a href="#cb795-3097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3098"><a href="#cb795-3098" aria-hidden="true" tabindex="-1"></a><span class="co"># Use parameters μ and σ as starting values- good guesses of the rough location of the MAP values</span></span>
<span id="cb795-3099"><a href="#cb795-3099" aria-hidden="true" tabindex="-1"></a>start <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb795-3100"><a href="#cb795-3100" aria-hidden="true" tabindex="-1"></a>    <span class="at">mu=</span><span class="fu">mean</span>(d2<span class="sc">$</span>height),</span>
<span id="cb795-3101"><a href="#cb795-3101" aria-hidden="true" tabindex="-1"></a>    <span class="at">sigma=</span><span class="fu">sd</span>(d2<span class="sc">$</span>height)</span>
<span id="cb795-3102"><a href="#cb795-3102" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3103"><a href="#cb795-3103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3104"><a href="#cb795-3104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3105"><a href="#cb795-3105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3106"><a href="#cb795-3106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3107"><a href="#cb795-3107" aria-hidden="true" tabindex="-1"></a><span class="in">Note that the list of start values is a regular list, not an alist like the formula list is. </span></span>
<span id="cb795-3108"><a href="#cb795-3108" aria-hidden="true" tabindex="-1"></a><span class="in">The two functions alist and list do the same basic thing: allow you to make a collection of arbitrary R objects. They differ in one important respect: list evaluates the code you embed inside it, while</span></span>
<span id="cb795-3109"><a href="#cb795-3109" aria-hidden="true" tabindex="-1"></a><span class="in">alist does not. So when you define a list of formulas, you should use alist, so the code isn’t </span></span>
<span id="cb795-3110"><a href="#cb795-3110" aria-hidden="true" tabindex="-1"></a><span class="in">executed. But when you define a list of start values for parameters, you should use list, so </span></span>
<span id="cb795-3111"><a href="#cb795-3111" aria-hidden="true" tabindex="-1"></a><span class="in">that code like mean(d2$height) will be evaluated to a numeric value.</span></span>
<span id="cb795-3112"><a href="#cb795-3112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3113"><a href="#cb795-3113" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3114"><a href="#cb795-3114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3115"><a href="#cb795-3115" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3116"><a href="#cb795-3116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3117"><a href="#cb795-3117" aria-hidden="true" tabindex="-1"></a>See the effect of a more information prior for $\mu$:</span>
<span id="cb795-3118"><a href="#cb795-3118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3119"><a href="#cb795-3119" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.29}</span></span>
<span id="cb795-3120"><a href="#cb795-3120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3121"><a href="#cb795-3121" aria-hidden="true" tabindex="-1"></a><span class="co"># Change the standard deviation of the prior to 0.1, so it’s a very narrow prior</span></span>
<span id="cb795-3122"><a href="#cb795-3122" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.2</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3123"><a href="#cb795-3123" aria-hidden="true" tabindex="-1"></a>        <span class="fu">alist</span>(</span>
<span id="cb795-3124"><a href="#cb795-3124" aria-hidden="true" tabindex="-1"></a>            height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-3125"><a href="#cb795-3125" aria-hidden="true" tabindex="-1"></a>            mu <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="fl">0.1</span> ) ,</span>
<span id="cb795-3126"><a href="#cb795-3126" aria-hidden="true" tabindex="-1"></a>            sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-3127"><a href="#cb795-3127" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-3128"><a href="#cb795-3128" aria-hidden="true" tabindex="-1"></a>        <span class="at">data=</span>d2 )</span>
<span id="cb795-3129"><a href="#cb795-3129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3130"><a href="#cb795-3130" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m4<span class="fl">.2</span> )</span>
<span id="cb795-3131"><a href="#cb795-3131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3132"><a href="#cb795-3132" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice that the estimate for μ has hardly moved off the prior. </span></span>
<span id="cb795-3133"><a href="#cb795-3133" aria-hidden="true" tabindex="-1"></a><span class="co"># The prior was very concentrated around 178. Also notice that the estimate for </span></span>
<span id="cb795-3134"><a href="#cb795-3134" aria-hidden="true" tabindex="-1"></a><span class="co"># σ has changed quite a lot, even though we didn’t change its prior at all.</span></span>
<span id="cb795-3135"><a href="#cb795-3135" aria-hidden="true" tabindex="-1"></a><span class="co"># Once the golem is certain that the mean is near 178—as the prior insists—then </span></span>
<span id="cb795-3136"><a href="#cb795-3136" aria-hidden="true" tabindex="-1"></a><span class="co"># the golem has to estimate σ conditional on that fact. This results in a different</span></span>
<span id="cb795-3137"><a href="#cb795-3137" aria-hidden="true" tabindex="-1"></a><span class="co"># posterior for σ, even though all we changed is prior information about the other parameter.</span></span>
<span id="cb795-3138"><a href="#cb795-3138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3139"><a href="#cb795-3139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3140"><a href="#cb795-3140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3141"><a href="#cb795-3141" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3142"><a href="#cb795-3142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3143"><a href="#cb795-3143" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sampling from a `map` fit</span></span>
<span id="cb795-3144"><a href="#cb795-3144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3145"><a href="#cb795-3145" aria-hidden="true" tabindex="-1"></a>Getting samples from the quadratic approximate posterior distribution requires recognizing that a quadratic approximation to a posterior distribution with more than one parameter dimension— μ and σ each contribute one dimension— is just a multi-dimensional Gaussian distribution.</span>
<span id="cb795-3146"><a href="#cb795-3146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3147"><a href="#cb795-3147" aria-hidden="true" tabindex="-1"></a>As a consequence, when R constructs a quadratic approximation, it calculates not only standard deviations for all parameters, but also the covariances among all pairs of parameters.</span>
<span id="cb795-3148"><a href="#cb795-3148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3149"><a href="#cb795-3149" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.30}</span></span>
<span id="cb795-3150"><a href="#cb795-3150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3151"><a href="#cb795-3151" aria-hidden="true" tabindex="-1"></a><span class="co">#  A multi-dimensional Gaussian distribution requires a list of means and </span></span>
<span id="cb795-3152"><a href="#cb795-3152" aria-hidden="true" tabindex="-1"></a><span class="co"># a matrix of variances and covariances</span></span>
<span id="cb795-3153"><a href="#cb795-3153" aria-hidden="true" tabindex="-1"></a><span class="fu">vcov</span>( m4<span class="fl">.1</span> )</span>
<span id="cb795-3154"><a href="#cb795-3154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3155"><a href="#cb795-3155" aria-hidden="true" tabindex="-1"></a><span class="co"># The above is a variance-covariance matrix- it tells us how each parameter relates </span></span>
<span id="cb795-3156"><a href="#cb795-3156" aria-hidden="true" tabindex="-1"></a><span class="co"># to every other param- eter in the posterior distribution.</span></span>
<span id="cb795-3157"><a href="#cb795-3157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3158"><a href="#cb795-3158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3159"><a href="#cb795-3159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3160"><a href="#cb795-3160" aria-hidden="true" tabindex="-1"></a>A variance-covariance matrix can be factored into two elements: </span>
<span id="cb795-3161"><a href="#cb795-3161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3162"><a href="#cb795-3162" aria-hidden="true" tabindex="-1"></a>(1) a vector of variances for the parameters </span>
<span id="cb795-3163"><a href="#cb795-3163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3164"><a href="#cb795-3164" aria-hidden="true" tabindex="-1"></a>(2) a correlation matrix that tells us how changes in any parameter lead to correlated changes in the others.</span>
<span id="cb795-3165"><a href="#cb795-3165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3166"><a href="#cb795-3166" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.31}</span></span>
<span id="cb795-3167"><a href="#cb795-3167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3168"><a href="#cb795-3168" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>( <span class="fu">vcov</span>( m4<span class="fl">.1</span> ) )</span>
<span id="cb795-3169"><a href="#cb795-3169" aria-hidden="true" tabindex="-1"></a><span class="co"># The two-element vector in the output is the list of variances. </span></span>
<span id="cb795-3170"><a href="#cb795-3170" aria-hidden="true" tabindex="-1"></a><span class="co"># If you take the square root of this vector, you get the standard deviations that </span></span>
<span id="cb795-3171"><a href="#cb795-3171" aria-hidden="true" tabindex="-1"></a><span class="co"># are shown in precis output.</span></span>
<span id="cb795-3172"><a href="#cb795-3172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3173"><a href="#cb795-3173" aria-hidden="true" tabindex="-1"></a><span class="fu">cov2cor</span>( <span class="fu">vcov</span>( m4<span class="fl">.1</span> ) )</span>
<span id="cb795-3174"><a href="#cb795-3174" aria-hidden="true" tabindex="-1"></a><span class="co"># The two-by-two matrix in the output is the correlation matrix. Each entry shows </span></span>
<span id="cb795-3175"><a href="#cb795-3175" aria-hidden="true" tabindex="-1"></a><span class="co"># the correlation, bounded between −1 and +1, for each pair of parameters. The 1’s </span></span>
<span id="cb795-3176"><a href="#cb795-3176" aria-hidden="true" tabindex="-1"></a><span class="co"># indicate a parameter’s correlation with itself. If these values were anything </span></span>
<span id="cb795-3177"><a href="#cb795-3177" aria-hidden="true" tabindex="-1"></a><span class="co"># except 1, we would be worried. The other entries are typically closer to zero, </span></span>
<span id="cb795-3178"><a href="#cb795-3178" aria-hidden="true" tabindex="-1"></a><span class="co"># and they are very close to zero in this example. This indicates that learning </span></span>
<span id="cb795-3179"><a href="#cb795-3179" aria-hidden="true" tabindex="-1"></a><span class="co"># μ tells us nothing about σ and likewise that learning σ tells us nothing about μ.</span></span>
<span id="cb795-3180"><a href="#cb795-3180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3181"><a href="#cb795-3181" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3182"><a href="#cb795-3182" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3183"><a href="#cb795-3183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3184"><a href="#cb795-3184" aria-hidden="true" tabindex="-1"></a>To get samples from this multi-dimensional posterior, we sample vectors of values from a multi-dimensional Gaussian distribution- instead of sampling single values from a simple Gaussian distribution.</span>
<span id="cb795-3185"><a href="#cb795-3185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3186"><a href="#cb795-3186" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.32}</span></span>
<span id="cb795-3187"><a href="#cb795-3187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3188"><a href="#cb795-3188" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m4<span class="fl">.1</span> , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-3189"><a href="#cb795-3189" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(post)</span>
<span id="cb795-3190"><a href="#cb795-3190" aria-hidden="true" tabindex="-1"></a><span class="co"># You end up with a data frame, post, with 10,000 (1e4) rows and two columns, </span></span>
<span id="cb795-3191"><a href="#cb795-3191" aria-hidden="true" tabindex="-1"></a><span class="co"># one column for μ and one for σ. Each value is a sample from the posterior, </span></span>
<span id="cb795-3192"><a href="#cb795-3192" aria-hidden="true" tabindex="-1"></a><span class="co"># so the mean and standard deviation of each column will be very close to the</span></span>
<span id="cb795-3193"><a href="#cb795-3193" aria-hidden="true" tabindex="-1"></a><span class="co"># MAP values from before.</span></span>
<span id="cb795-3194"><a href="#cb795-3194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3195"><a href="#cb795-3195" aria-hidden="true" tabindex="-1"></a><span class="co"># Confirm this by summarizing the samples</span></span>
<span id="cb795-3196"><a href="#cb795-3196" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(post)</span>
<span id="cb795-3197"><a href="#cb795-3197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3198"><a href="#cb795-3198" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with values from quadratic approximate posterior distribution</span></span>
<span id="cb795-3199"><a href="#cb795-3199" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.1</span>)</span>
<span id="cb795-3200"><a href="#cb795-3200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3201"><a href="#cb795-3201" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with the samples from the grid approximation</span></span>
<span id="cb795-3202"><a href="#cb795-3202" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb795-3203"><a href="#cb795-3203" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(post, <span class="at">cex=</span><span class="fl">0.5</span> , <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>))</span>
<span id="cb795-3204"><a href="#cb795-3204" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( sample.mu , sample.sigma , <span class="at">cex=</span><span class="fl">0.5</span> , <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) )</span>
<span id="cb795-3205"><a href="#cb795-3205" aria-hidden="true" tabindex="-1"></a><span class="co"># There is resembalance with the grid approximation</span></span>
<span id="cb795-3206"><a href="#cb795-3206" aria-hidden="true" tabindex="-1"></a><span class="co"># These samples also preserve the covariance between μ and σ. This hardly matters right now, </span></span>
<span id="cb795-3207"><a href="#cb795-3207" aria-hidden="true" tabindex="-1"></a><span class="co"># because μ and σ don’t covary at all in this model. But once you add a predictor variable </span></span>
<span id="cb795-3208"><a href="#cb795-3208" aria-hidden="true" tabindex="-1"></a><span class="co"># to your model, covariance will matter a lot.</span></span>
<span id="cb795-3209"><a href="#cb795-3209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3210"><a href="#cb795-3210" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3211"><a href="#cb795-3211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3212"><a href="#cb795-3212" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3213"><a href="#cb795-3213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3214"><a href="#cb795-3214" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Under the hood with multivariate sampling***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3215"><a href="#cb795-3215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3216"><a href="#cb795-3216" aria-hidden="true" tabindex="-1"></a>The function extract.samples is for convenience. The work is done by a multi-dimensional version of rnorm, mvrnorm. The function rnorm simulates random Gaussian values, while mvrnorm simulates random vectors of multivariate Gaussian values. Here’s how to use it directly to do what extract.samples does:</span>
<span id="cb795-3217"><a href="#cb795-3217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3218"><a href="#cb795-3218" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.34}</span></span>
<span id="cb795-3219"><a href="#cb795-3219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3220"><a href="#cb795-3220" aria-hidden="true" tabindex="-1"></a><span class="co"># library(MASS)</span></span>
<span id="cb795-3221"><a href="#cb795-3221" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>( <span class="at">n=</span><span class="fl">1e4</span> , <span class="at">mu=</span><span class="fu">coef</span>(m4<span class="fl">.1</span>) , <span class="at">Sigma=</span><span class="fu">vcov</span>(m4<span class="fl">.1</span>) )</span>
<span id="cb795-3222"><a href="#cb795-3222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3223"><a href="#cb795-3223" aria-hidden="true" tabindex="-1"></a><span class="co"># You don’t usually need to use mvrnorm directly like this, but sometimes you want to</span></span>
<span id="cb795-3224"><a href="#cb795-3224" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate multi-variate Gaussian outcomes. In that case, you’ll need to access mvrnorm directly.</span></span>
<span id="cb795-3225"><a href="#cb795-3225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3226"><a href="#cb795-3226" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3227"><a href="#cb795-3227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3228"><a href="#cb795-3228" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3229"><a href="#cb795-3229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3230"><a href="#cb795-3230" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Getting $\sigma$ right***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3231"><a href="#cb795-3231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3232"><a href="#cb795-3232" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The quadratic assumption for σ can be problematic- more uncertainty at higher values. </span>
<span id="cb795-3233"><a href="#cb795-3233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3234"><a href="#cb795-3234" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>A conventional way to improve the situation is the estimate log(σ) instead- while the posterior distribution of σ will often not be Gaussian, the distribution of its logarithm can be much closer to Gaussian.</span>
<span id="cb795-3235"><a href="#cb795-3235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3236"><a href="#cb795-3236" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>So if we impose the quadratic approximation on the logarithm, rather than the standard deviation itself, we can often get a better approximation of the uncertainty.</span>
<span id="cb795-3237"><a href="#cb795-3237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3238"><a href="#cb795-3238" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.35}</span></span>
<span id="cb795-3239"><a href="#cb795-3239" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">435</span>)</span>
<span id="cb795-3240"><a href="#cb795-3240" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate log(σ) using map</span></span>
<span id="cb795-3241"><a href="#cb795-3241" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.1</span>_logsigma <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3242"><a href="#cb795-3242" aria-hidden="true" tabindex="-1"></a>        <span class="fu">alist</span>(</span>
<span id="cb795-3243"><a href="#cb795-3243" aria-hidden="true" tabindex="-1"></a>          <span class="co"># the exp inside the likelihood converts a continuous parameter, log_sigma, </span></span>
<span id="cb795-3244"><a href="#cb795-3244" aria-hidden="true" tabindex="-1"></a>          <span class="co"># to be strictly positive, because exp(x) &gt; 0 for any real value x.</span></span>
<span id="cb795-3245"><a href="#cb795-3245" aria-hidden="true" tabindex="-1"></a>            height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , <span class="fu">exp</span>(log_sigma) ) ,</span>
<span id="cb795-3246"><a href="#cb795-3246" aria-hidden="true" tabindex="-1"></a>            mu <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">20</span> ) ,</span>
<span id="cb795-3247"><a href="#cb795-3247" aria-hidden="true" tabindex="-1"></a>            log_sigma <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> )   </span>
<span id="cb795-3248"><a href="#cb795-3248" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Since log_sigma is continuous now, it can have a Gaussian prior.</span></span>
<span id="cb795-3249"><a href="#cb795-3249" aria-hidden="true" tabindex="-1"></a>) , <span class="at">data=</span>d2 )</span>
<span id="cb795-3250"><a href="#cb795-3250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3251"><a href="#cb795-3251" aria-hidden="true" tabindex="-1"></a><span class="co"># When you extract samples, it is log_sigma that has a Gaussian distribution. </span></span>
<span id="cb795-3252"><a href="#cb795-3252" aria-hidden="true" tabindex="-1"></a><span class="co"># To get the distribution of sigma, you just need to use the same exp as in the </span></span>
<span id="cb795-3253"><a href="#cb795-3253" aria-hidden="true" tabindex="-1"></a><span class="co"># model definition, to get back on the natural scale:</span></span>
<span id="cb795-3254"><a href="#cb795-3254" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m4<span class="fl">.1</span>_logsigma )</span>
<span id="cb795-3255"><a href="#cb795-3255" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">exp</span>( post<span class="sc">$</span>log_sigma )</span>
<span id="cb795-3256"><a href="#cb795-3256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3257"><a href="#cb795-3257" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the three samples of sigma</span></span>
<span id="cb795-3258"><a href="#cb795-3258" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb795-3259"><a href="#cb795-3259" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(sigma, <span class="at">main =</span><span class="st">"log.sigma"</span>)</span>
<span id="cb795-3260"><a href="#cb795-3260" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(sample.sigma, <span class="at">main =</span><span class="st">"sample.sigma"</span>)</span>
<span id="cb795-3261"><a href="#cb795-3261" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>( sample2.sigma , <span class="at">main =</span> <span class="st">"smaller.sample.sigma"</span>)</span>
<span id="cb795-3262"><a href="#cb795-3262" aria-hidden="true" tabindex="-1"></a><span class="co"># log.sima and sample.sigma have same sample sizes, while smaller.sample.sigma has</span></span>
<span id="cb795-3263"><a href="#cb795-3263" aria-hidden="true" tabindex="-1"></a><span class="co"># significantly smaller sample size of 20. </span></span>
<span id="cb795-3264"><a href="#cb795-3264" aria-hidden="true" tabindex="-1"></a><span class="co"># When you have a lot of data, this won’t make any noticeable difference. </span></span>
<span id="cb795-3265"><a href="#cb795-3265" aria-hidden="true" tabindex="-1"></a><span class="co"># But the use of exp to effectively constrain a parameter to be positive is a </span></span>
<span id="cb795-3266"><a href="#cb795-3266" aria-hidden="true" tabindex="-1"></a><span class="co"># robust and useful one. And it relates to link functions.</span></span>
<span id="cb795-3267"><a href="#cb795-3267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3268"><a href="#cb795-3268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3269"><a href="#cb795-3269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3270"><a href="#cb795-3270" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3271"><a href="#cb795-3271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3272"><a href="#cb795-3272" aria-hidden="true" tabindex="-1"></a><span class="fu">## Adding a predictor</span></span>
<span id="cb795-3273"><a href="#cb795-3273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3274"><a href="#cb795-3274" aria-hidden="true" tabindex="-1"></a>Typically, we are interested in modeling how an outcome is related to some predictor variable. And by including a predictor variable in a particular way, we’ll have linear regression.</span>
<span id="cb795-3275"><a href="#cb795-3275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3276"><a href="#cb795-3276" aria-hidden="true" tabindex="-1"></a><span class="in">```{r c4.37}</span></span>
<span id="cb795-3277"><a href="#cb795-3277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3278"><a href="#cb795-3278" aria-hidden="true" tabindex="-1"></a><span class="co"># See how height covaries with weight</span></span>
<span id="cb795-3279"><a href="#cb795-3279" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d2<span class="sc">$</span>height <span class="sc">~</span> d2<span class="sc">$</span>weight)</span>
<span id="cb795-3280"><a href="#cb795-3280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3281"><a href="#cb795-3281" aria-hidden="true" tabindex="-1"></a><span class="co"># there’s obviously a relationship: Knowing a person’s weight helps you predict height.</span></span>
<span id="cb795-3282"><a href="#cb795-3282" aria-hidden="true" tabindex="-1"></a><span class="co"># Incorporate predictor variables to Gaussian model to make this vague observation into</span></span>
<span id="cb795-3283"><a href="#cb795-3283" aria-hidden="true" tabindex="-1"></a><span class="co"># a more precise quantitative model that relates values of weight to plausible values of height</span></span>
<span id="cb795-3284"><a href="#cb795-3284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3285"><a href="#cb795-3285" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3286"><a href="#cb795-3286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3287"><a href="#cb795-3287" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3288"><a href="#cb795-3288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3289"><a href="#cb795-3289" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fitting the model</span></span>
<span id="cb795-3290"><a href="#cb795-3290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3291"><a href="#cb795-3291" aria-hidden="true" tabindex="-1"></a>All we have to do is incorporate our new model for the mean into the model specification inside map and be sure to add our new parameters to the start list.</span>
<span id="cb795-3292"><a href="#cb795-3292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3293"><a href="#cb795-3293" aria-hidden="true" tabindex="-1"></a>Repeat model definition, with corresponding R code:</span>
<span id="cb795-3294"><a href="#cb795-3294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3295"><a href="#cb795-3295" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-3296"><a href="#cb795-3296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3297"><a href="#cb795-3297" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-3298"><a href="#cb795-3298" aria-hidden="true" tabindex="-1"></a>\text{h}_i &amp; \sim \text{Normal}(\mu_i, \sigma) \ &amp;&amp;&amp; \text{height} &amp; \sim \text{dnorm(mu, sigma)} <span class="sc">\\</span></span>
<span id="cb795-3299"><a href="#cb795-3299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3300"><a href="#cb795-3300" aria-hidden="true" tabindex="-1"></a>\mu_i &amp; = \alpha + \beta x_i \ &amp;&amp;&amp; \text{mu} &amp; \leftarrow \text{a + b*weight} <span class="sc">\\</span></span>
<span id="cb795-3301"><a href="#cb795-3301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3302"><a href="#cb795-3302" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(178, 100) \ &amp;&amp;&amp; a &amp;\sim \text{dnorm}(178, 100)<span class="sc">\\</span></span>
<span id="cb795-3303"><a href="#cb795-3303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3304"><a href="#cb795-3304" aria-hidden="true" tabindex="-1"></a>\beta &amp;\sim \text{Normal}(0, 10) \ &amp;&amp;&amp; b &amp;\sim \text{dnorm}(0, 10)<span class="sc">\\</span></span>
<span id="cb795-3305"><a href="#cb795-3305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3306"><a href="#cb795-3306" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; \text{sigma} &amp;\sim \text{dunif}(0, 50)</span>
<span id="cb795-3307"><a href="#cb795-3307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3308"><a href="#cb795-3308" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-3309"><a href="#cb795-3309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3310"><a href="#cb795-3310" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-3311"><a href="#cb795-3311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3312"><a href="#cb795-3312" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3313"><a href="#cb795-3313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3314"><a href="#cb795-3314" aria-hidden="true" tabindex="-1"></a>Build the MAP model fit using the above formulas:</span>
<span id="cb795-3315"><a href="#cb795-3315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3316"><a href="#cb795-3316" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.38}</span></span>
<span id="cb795-3317"><a href="#cb795-3317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3318"><a href="#cb795-3318" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data Howell1</span></span>
<span id="cb795-3319"><a href="#cb795-3319" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb795-3320"><a href="#cb795-3320" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-3321"><a href="#cb795-3321" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> d[d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span>, ]</span>
<span id="cb795-3322"><a href="#cb795-3322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3323"><a href="#cb795-3323" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb795-3324"><a href="#cb795-3324" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.3</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3325"><a href="#cb795-3325" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-3326"><a href="#cb795-3326" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-3327"><a href="#cb795-3327" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight,</span>
<span id="cb795-3328"><a href="#cb795-3328" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">100</span>),</span>
<span id="cb795-3329"><a href="#cb795-3329" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-3330"><a href="#cb795-3330" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-3331"><a href="#cb795-3331" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-3332"><a href="#cb795-3332" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d2</span>
<span id="cb795-3333"><a href="#cb795-3333" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3334"><a href="#cb795-3334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3335"><a href="#cb795-3335" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that starting b at zero is not the same as having β’s prior with mean zero. </span></span>
<span id="cb795-3336"><a href="#cb795-3336" aria-hidden="true" tabindex="-1"></a><span class="co"># The values in the start list don’t alter the posterior probabilities, while priors definitely do.</span></span>
<span id="cb795-3337"><a href="#cb795-3337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3338"><a href="#cb795-3338" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.3</span>)</span>
<span id="cb795-3339"><a href="#cb795-3339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3340"><a href="#cb795-3340" aria-hidden="true" tabindex="-1"></a><span class="co"># Another way to fit the same model without a separate line for linear model</span></span>
<span id="cb795-3341"><a href="#cb795-3341" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the linear model into likelihood function</span></span>
<span id="cb795-3342"><a href="#cb795-3342" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.3</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3343"><a href="#cb795-3343" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-3344"><a href="#cb795-3344" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(a <span class="sc">+</span> b<span class="sc">*</span>weight, sigma),</span>
<span id="cb795-3345"><a href="#cb795-3345" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">100</span>),</span>
<span id="cb795-3346"><a href="#cb795-3346" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-3347"><a href="#cb795-3347" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-3348"><a href="#cb795-3348" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-3349"><a href="#cb795-3349" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d2</span>
<span id="cb795-3350"><a href="#cb795-3350" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3351"><a href="#cb795-3351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3352"><a href="#cb795-3352" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.3</span>)</span>
<span id="cb795-3353"><a href="#cb795-3353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3354"><a href="#cb795-3354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3355"><a href="#cb795-3355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3356"><a href="#cb795-3356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3357"><a href="#cb795-3357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3358"><a href="#cb795-3358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3359"><a href="#cb795-3359" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3360"><a href="#cb795-3360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3361"><a href="#cb795-3361" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpreting the model fit</span></span>
<span id="cb795-3362"><a href="#cb795-3362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3363"><a href="#cb795-3363" aria-hidden="true" tabindex="-1"></a>Two broad categories of processing:</span>
<span id="cb795-3364"><a href="#cb795-3364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3365"><a href="#cb795-3365" aria-hidden="true" tabindex="-1"></a>(1) reading tables</span>
<span id="cb795-3366"><a href="#cb795-3366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3367"><a href="#cb795-3367" aria-hidden="true" tabindex="-1"></a>(2) plotting</span>
<span id="cb795-3368"><a href="#cb795-3368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3369"><a href="#cb795-3369" aria-hidden="true" tabindex="-1"></a>Plotting the implications of your estimates will allow you to inquire about several things that are sometimes hard to read from tables:</span>
<span id="cb795-3370"><a href="#cb795-3370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3371"><a href="#cb795-3371" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Whether or not the model fitting procedure worked correctly</span>
<span id="cb795-3372"><a href="#cb795-3372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3373"><a href="#cb795-3373" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The absolute magnitude, rather than merely relative magnitude, of a relationship between outcome and predictor</span>
<span id="cb795-3374"><a href="#cb795-3374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3375"><a href="#cb795-3375" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The uncertainty surrounding an average relationship</span>
<span id="cb795-3376"><a href="#cb795-3376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3377"><a href="#cb795-3377" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The uncertainty surrounding the implied predictions of the model, as these are distinct from mere parameter uncertainty</span>
<span id="cb795-3378"><a href="#cb795-3378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3379"><a href="#cb795-3379" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3380"><a href="#cb795-3380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3381"><a href="#cb795-3381" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***What do parameters mean?***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3382"><a href="#cb795-3382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3383"><a href="#cb795-3383" aria-hidden="true" tabindex="-1"></a>Posterior probabilities of parameter values describe the relative compatibility of different states of the world with the data, ac- cording to the model.</span>
<span id="cb795-3384"><a href="#cb795-3384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3385"><a href="#cb795-3385" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3386"><a href="#cb795-3386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3387"><a href="#cb795-3387" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Tables of estimates</span></span>
<span id="cb795-3388"><a href="#cb795-3388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3389"><a href="#cb795-3389" aria-hidden="true" tabindex="-1"></a>With the new linear regression fit to the Kalahari data, we inspect the estimates:</span>
<span id="cb795-3390"><a href="#cb795-3390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3391"><a href="#cb795-3391" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.40}</span></span>
<span id="cb795-3392"><a href="#cb795-3392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3393"><a href="#cb795-3393" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.3</span>)</span>
<span id="cb795-3394"><a href="#cb795-3394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3395"><a href="#cb795-3395" aria-hidden="true" tabindex="-1"></a><span class="co"># The first row gives the quadratic approximation for α, the second the approximation </span></span>
<span id="cb795-3396"><a href="#cb795-3396" aria-hidden="true" tabindex="-1"></a><span class="co"># for β, and the third approximation for σ.</span></span>
<span id="cb795-3397"><a href="#cb795-3397" aria-hidden="true" tabindex="-1"></a><span class="co"># Since β is a slope, the value 0.90 can be read as a person 1 kg heavier is expected </span></span>
<span id="cb795-3398"><a href="#cb795-3398" aria-hidden="true" tabindex="-1"></a><span class="co"># to be 0.90 cm taller. 89% of the posterior probability lies between 0.84 and 0.97. </span></span>
<span id="cb795-3399"><a href="#cb795-3399" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate of α, a in the precis table, indicates that a person of weight 0 should be 114cm tall.</span></span>
<span id="cb795-3400"><a href="#cb795-3400" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate for σ, sigma, informs us of the width of the distribution of heights around the mean.</span></span>
<span id="cb795-3401"><a href="#cb795-3401" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate tells us that 95% of plausible heights lie within 10cm (2σ) of the mean height. </span></span>
<span id="cb795-3402"><a href="#cb795-3402" aria-hidden="true" tabindex="-1"></a><span class="co"># But there is also uncertainty about this, as indicated by the 89% percentile interval</span></span>
<span id="cb795-3403"><a href="#cb795-3403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3404"><a href="#cb795-3404" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3405"><a href="#cb795-3405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3406"><a href="#cb795-3406" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3407"><a href="#cb795-3407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3408"><a href="#cb795-3408" aria-hidden="true" tabindex="-1"></a>The numbers in the default precis output aren’t sufficient to describe the quadratic posterior completely. For that, we also require the variance-covariance matrix. We’re interested in correlations among parameters—we already have their variance in the table above—so let’s go straight to the correlation matrix:</span>
<span id="cb795-3409"><a href="#cb795-3409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3410"><a href="#cb795-3410" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.41}</span></span>
<span id="cb795-3411"><a href="#cb795-3411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3412"><a href="#cb795-3412" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation matrix</span></span>
<span id="cb795-3413"><a href="#cb795-3413" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m4<span class="fl">.3</span> , <span class="at">corr=</span><span class="cn">TRUE</span> )<span class="co"># This code not working</span></span>
<span id="cb795-3414"><a href="#cb795-3414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3415"><a href="#cb795-3415" aria-hidden="true" tabindex="-1"></a><span class="fu">cov2cor</span>(<span class="fu">vcov</span>(m4<span class="fl">.3</span>))</span>
<span id="cb795-3416"><a href="#cb795-3416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3417"><a href="#cb795-3417" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice that α and β are almost perfectly negatively correlated. Right now, </span></span>
<span id="cb795-3418"><a href="#cb795-3418" aria-hidden="true" tabindex="-1"></a><span class="co"># this is harmless. It just means that these two parameters carry the same information—</span></span>
<span id="cb795-3419"><a href="#cb795-3419" aria-hidden="true" tabindex="-1"></a><span class="co"># as you change the slope of the line, the best intercept changes to match it. </span></span>
<span id="cb795-3420"><a href="#cb795-3420" aria-hidden="true" tabindex="-1"></a><span class="co"># But in more complex models, strong correlations like this can make it difficult </span></span>
<span id="cb795-3421"><a href="#cb795-3421" aria-hidden="true" tabindex="-1"></a><span class="co"># to fit the model to the data. One of the tricks to avoid it is centering.</span></span>
<span id="cb795-3422"><a href="#cb795-3422" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3423"><a href="#cb795-3423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3424"><a href="#cb795-3424" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3425"><a href="#cb795-3425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3426"><a href="#cb795-3426" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Centering**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3427"><a href="#cb795-3427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3428"><a href="#cb795-3428" aria-hidden="true" tabindex="-1"></a>Centering is the procedure of subtracting the mean of a variable from each value. </span>
<span id="cb795-3429"><a href="#cb795-3429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3430"><a href="#cb795-3430" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.42}</span></span>
<span id="cb795-3431"><a href="#cb795-3431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3432"><a href="#cb795-3432" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a centered version of the weight variable</span></span>
<span id="cb795-3433"><a href="#cb795-3433" aria-hidden="true" tabindex="-1"></a>d2<span class="sc">$</span>weight.c <span class="ot">&lt;-</span> d2<span class="sc">$</span>weight <span class="sc">-</span> <span class="fu">mean</span>(d2<span class="sc">$</span>weight)</span>
<span id="cb795-3434"><a href="#cb795-3434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3435"><a href="#cb795-3435" aria-hidden="true" tabindex="-1"></a><span class="co"># Confirm that the average value of weight.c is zero</span></span>
<span id="cb795-3436"><a href="#cb795-3436" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(d2<span class="sc">$</span>weight.c)</span>
<span id="cb795-3437"><a href="#cb795-3437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3438"><a href="#cb795-3438" aria-hidden="true" tabindex="-1"></a><span class="co"># Refit the model and see the changes</span></span>
<span id="cb795-3439"><a href="#cb795-3439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3440"><a href="#cb795-3440" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.4</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3441"><a href="#cb795-3441" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-3442"><a href="#cb795-3442" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-3443"><a href="#cb795-3443" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight.c ,</span>
<span id="cb795-3444"><a href="#cb795-3444" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-3445"><a href="#cb795-3445" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-3446"><a href="#cb795-3446" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> ) ),</span>
<span id="cb795-3447"><a href="#cb795-3447" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d2,</span>
<span id="cb795-3448"><a href="#cb795-3448" aria-hidden="true" tabindex="-1"></a><span class="at">start =</span> <span class="fu">list</span>(<span class="at">a =</span> <span class="dv">178</span>, <span class="at">b =</span> <span class="dv">0</span>, <span class="at">sigma =</span> <span class="dv">1</span>))</span>
<span id="cb795-3449"><a href="#cb795-3449" aria-hidden="true" tabindex="-1"></a><span class="co"># I got error "Start values for parameters may be too far from MAP." if specify start value.</span></span>
<span id="cb795-3450"><a href="#cb795-3450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3451"><a href="#cb795-3451" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.4</span>, <span class="at">corr =</span> <span class="cn">TRUE</span>) </span>
<span id="cb795-3452"><a href="#cb795-3452" aria-hidden="true" tabindex="-1"></a><span class="fu">cov2cor</span>(<span class="fu">vcov</span>(m4<span class="fl">.4</span>))</span>
<span id="cb795-3453"><a href="#cb795-3453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3454"><a href="#cb795-3454" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimates for β and σ are unchanged (within rounding error), but the estimate for</span></span>
<span id="cb795-3455"><a href="#cb795-3455" aria-hidden="true" tabindex="-1"></a><span class="co"># α (a) is now the same as the average height value in the raw data. </span></span>
<span id="cb795-3456"><a href="#cb795-3456" aria-hidden="true" tabindex="-1"></a><span class="co"># And the correlations among parameters are now all zero</span></span>
<span id="cb795-3457"><a href="#cb795-3457" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(d2<span class="sc">$</span>height)</span>
<span id="cb795-3458"><a href="#cb795-3458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3459"><a href="#cb795-3459" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate for the intercept, α, still means the same thing it did before: </span></span>
<span id="cb795-3460"><a href="#cb795-3460" aria-hidden="true" tabindex="-1"></a><span class="co"># the expected value of the outcome variable, when the predictor variable is equal to zero. </span></span>
<span id="cb795-3461"><a href="#cb795-3461" aria-hidden="true" tabindex="-1"></a><span class="co"># But now the mean value of the predictor is also zero. So the intercept also means: </span></span>
<span id="cb795-3462"><a href="#cb795-3462" aria-hidden="true" tabindex="-1"></a><span class="co"># the expected value of the outcome, when the predictor is at its average value. </span></span>
<span id="cb795-3463"><a href="#cb795-3463" aria-hidden="true" tabindex="-1"></a><span class="co"># This makes interpreting the intercept a lot easier.</span></span>
<span id="cb795-3464"><a href="#cb795-3464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3465"><a href="#cb795-3465" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3466"><a href="#cb795-3466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3467"><a href="#cb795-3467" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3468"><a href="#cb795-3468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3469"><a href="#cb795-3469" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Plotting posterior inference aganist the data</span></span>
<span id="cb795-3470"><a href="#cb795-3470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3471"><a href="#cb795-3471" aria-hidden="true" tabindex="-1"></a>Not only does plotting help in interpreting the posterior, but it also provides an informal check on model assumptions. When the model’s predictions don’t come close to key observations or patterns in the plotted data, then you might suspect the model either did not fit correctly or is rather badly specified.</span>
<span id="cb795-3472"><a href="#cb795-3472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3473"><a href="#cb795-3473" aria-hidden="true" tabindex="-1"></a>We’re going to start with a simple version of that task, superimposing just the MAP values over the height and weight data.</span>
<span id="cb795-3474"><a href="#cb795-3474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3475"><a href="#cb795-3475" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.45}</span></span>
<span id="cb795-3476"><a href="#cb795-3476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3477"><a href="#cb795-3477" aria-hidden="true" tabindex="-1"></a><span class="co"># superimpose the MAP values for mean height over the actual data</span></span>
<span id="cb795-3478"><a href="#cb795-3478" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight, <span class="at">data =</span> d2, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb795-3479"><a href="#cb795-3479" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fu">coef</span>(m4<span class="fl">.3</span>)[<span class="st">"a"</span>], <span class="at">b =</span> <span class="fu">coef</span>(m4<span class="fl">.3</span>)[<span class="st">"b"</span>])</span>
<span id="cb795-3480"><a href="#cb795-3480" aria-hidden="true" tabindex="-1"></a><span class="co"># Height in centimeters (vertical) plotted against weight in kilograms (horizontal), </span></span>
<span id="cb795-3481"><a href="#cb795-3481" aria-hidden="true" tabindex="-1"></a><span class="co"># with the maximum a posteriori (MAP) line for the mean height at each weight plotted in black.</span></span>
<span id="cb795-3482"><a href="#cb795-3482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3483"><a href="#cb795-3483" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3484"><a href="#cb795-3484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3485"><a href="#cb795-3485" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3486"><a href="#cb795-3486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3487"><a href="#cb795-3487" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Adding uncertainty around the mean</span></span>
<span id="cb795-3488"><a href="#cb795-3488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3489"><a href="#cb795-3489" aria-hidden="true" tabindex="-1"></a>The posterior distribution considers every possible regression line connecting height to weight. It assigns a relative plausibility to each. This means that each combination of $\alpha$ and $\beta$ has a posterior probability. It could be that there are many lines with nearly the same posterior probability as the MAP line. Or it could be instead that the posterior distribution is rather narrow near the MAP line.</span>
<span id="cb795-3490"><a href="#cb795-3490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3491"><a href="#cb795-3491" aria-hidden="true" tabindex="-1"></a>So how can we get that uncertainty onto the plot? Together, a combination of $\alpha$ and $\beta$ define a line. And so we could sample a bunch of lines from the posterior distribution. Then we could display those lines on the plot, to visualize the uncertainty in the regression relationship.</span>
<span id="cb795-3492"><a href="#cb795-3492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3493"><a href="#cb795-3493" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.46}</span></span>
<span id="cb795-3494"><a href="#cb795-3494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3495"><a href="#cb795-3495" aria-hidden="true" tabindex="-1"></a><span class="co"># To better appreciate how the posterior distribution contains lines, extract some samples from the model</span></span>
<span id="cb795-3496"><a href="#cb795-3496" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m4<span class="fl">.3</span>)</span>
<span id="cb795-3497"><a href="#cb795-3497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3498"><a href="#cb795-3498" aria-hidden="true" tabindex="-1"></a><span class="co"># Inspect the first 5 rows of the samples</span></span>
<span id="cb795-3499"><a href="#cb795-3499" aria-hidden="true" tabindex="-1"></a>post[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span>
<span id="cb795-3500"><a href="#cb795-3500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3501"><a href="#cb795-3501" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3502"><a href="#cb795-3502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3503"><a href="#cb795-3503" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3504"><a href="#cb795-3504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3505"><a href="#cb795-3505" aria-hidden="true" tabindex="-1"></a>Each row is a correlated random sample from the joint posterior of all three parameters, using the covariances provided by vcov(m4.3). The paired values of a and b on each row define a line. The average of very many of these lines is the MAP line. But the scatter around that average is meaningful, because it alters our confidence in the relationship between the predictor and the outcome.</span>
<span id="cb795-3506"><a href="#cb795-3506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3507"><a href="#cb795-3507" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.48}</span></span>
<span id="cb795-3508"><a href="#cb795-3508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3509"><a href="#cb795-3509" aria-hidden="true" tabindex="-1"></a><span class="co"># extracts the first 10 cases and re-estimates the model</span></span>
<span id="cb795-3510"><a href="#cb795-3510" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb795-3511"><a href="#cb795-3511" aria-hidden="true" tabindex="-1"></a>dN <span class="ot">&lt;-</span> d2[<span class="dv">1</span><span class="sc">:</span>N, ]</span>
<span id="cb795-3512"><a href="#cb795-3512" aria-hidden="true" tabindex="-1"></a>mN <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3513"><a href="#cb795-3513" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-3514"><a href="#cb795-3514" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-3515"><a href="#cb795-3515" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight,</span>
<span id="cb795-3516"><a href="#cb795-3516" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">100</span>),</span>
<span id="cb795-3517"><a href="#cb795-3517" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-3518"><a href="#cb795-3518" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-3519"><a href="#cb795-3519" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">data =</span> dN</span>
<span id="cb795-3520"><a href="#cb795-3520" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3521"><a href="#cb795-3521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3522"><a href="#cb795-3522" aria-hidden="true" tabindex="-1"></a><span class="co"># plot 20 of these lines, to see what the uncertainty looks like</span></span>
<span id="cb795-3523"><a href="#cb795-3523" aria-hidden="true" tabindex="-1"></a><span class="co"># extract 20 samples from the posterior</span></span>
<span id="cb795-3524"><a href="#cb795-3524" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mN, <span class="at">n =</span> <span class="dv">20</span>)</span>
<span id="cb795-3525"><a href="#cb795-3525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3526"><a href="#cb795-3526" aria-hidden="true" tabindex="-1"></a><span class="co"># display raw data and sample size</span></span>
<span id="cb795-3527"><a href="#cb795-3527" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dN<span class="sc">$</span>weight, dN<span class="sc">$</span>height,</span>
<span id="cb795-3528"><a href="#cb795-3528" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">range</span>(d2<span class="sc">$</span>weight), <span class="at">ylim =</span> <span class="fu">range</span>(d2<span class="sc">$</span>height),</span>
<span id="cb795-3529"><a href="#cb795-3529" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> rangi2, <span class="at">xlab =</span> <span class="st">"weight"</span>, <span class="at">ylab =</span> <span class="st">"height"</span>)</span>
<span id="cb795-3530"><a href="#cb795-3530" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">concat</span>(<span class="st">"N = "</span>, N)) <span class="co"># add text to the plot indicating sample size</span></span>
<span id="cb795-3531"><a href="#cb795-3531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3532"><a href="#cb795-3532" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the lines with transparency</span></span>
<span id="cb795-3533"><a href="#cb795-3533" aria-hidden="true" tabindex="-1"></a><span class="co"># i-th sample is a set of random parameter values sampled from posterior distribution</span></span>
<span id="cb795-3534"><a href="#cb795-3534" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>) <span class="co"># loops over all 20 lines, using abline to display each</span></span>
<span id="cb795-3535"><a href="#cb795-3535" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">a =</span> post<span class="sc">$</span>a[i], <span class="at">b =</span> post<span class="sc">$</span>b[i], <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"black"</span>, <span class="fl">0.3</span>))</span>
<span id="cb795-3536"><a href="#cb795-3536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3537"><a href="#cb795-3537" aria-hidden="true" tabindex="-1"></a><span class="co"># The cloud of regression lines displays greater uncertainty at extreme values for weight. </span></span>
<span id="cb795-3538"><a href="#cb795-3538" aria-hidden="true" tabindex="-1"></a><span class="co"># This is very common.</span></span>
<span id="cb795-3539"><a href="#cb795-3539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3540"><a href="#cb795-3540" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3541"><a href="#cb795-3541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3542"><a href="#cb795-3542" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3543"><a href="#cb795-3543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3544"><a href="#cb795-3544" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.48.1}</span></span>
<span id="cb795-3545"><a href="#cb795-3545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3546"><a href="#cb795-3546" aria-hidden="true" tabindex="-1"></a><span class="co"># compare higher N values (bigger sample size)</span></span>
<span id="cb795-3547"><a href="#cb795-3547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3548"><a href="#cb795-3548" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>))</span>
<span id="cb795-3549"><a href="#cb795-3549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3550"><a href="#cb795-3550" aria-hidden="true" tabindex="-1"></a><span class="co"># 20 samples</span></span>
<span id="cb795-3551"><a href="#cb795-3551" aria-hidden="true" tabindex="-1"></a><span class="do">## show error in knitting if I use 10 sample here, although it works above with warning</span></span>
<span id="cb795-3552"><a href="#cb795-3552" aria-hidden="true" tabindex="-1"></a><span class="do">## 10 samples is too low to reach stable estimates</span></span>
<span id="cb795-3553"><a href="#cb795-3553" aria-hidden="true" tabindex="-1"></a>N0 <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb795-3554"><a href="#cb795-3554" aria-hidden="true" tabindex="-1"></a>dN0 <span class="ot">&lt;-</span> d2[<span class="dv">1</span><span class="sc">:</span>N0, ]</span>
<span id="cb795-3555"><a href="#cb795-3555" aria-hidden="true" tabindex="-1"></a>mN0 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3556"><a href="#cb795-3556" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-3557"><a href="#cb795-3557" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-3558"><a href="#cb795-3558" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight,</span>
<span id="cb795-3559"><a href="#cb795-3559" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">100</span>),</span>
<span id="cb795-3560"><a href="#cb795-3560" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-3561"><a href="#cb795-3561" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-3562"><a href="#cb795-3562" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">data =</span> dN0</span>
<span id="cb795-3563"><a href="#cb795-3563" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3564"><a href="#cb795-3564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3565"><a href="#cb795-3565" aria-hidden="true" tabindex="-1"></a>post0 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mN0, <span class="at">n =</span> <span class="dv">20</span>)</span>
<span id="cb795-3566"><a href="#cb795-3566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3567"><a href="#cb795-3567" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dN0<span class="sc">$</span>weight, dN0<span class="sc">$</span>height,</span>
<span id="cb795-3568"><a href="#cb795-3568" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">range</span>(d2<span class="sc">$</span>weight), <span class="at">ylim =</span> <span class="fu">range</span>(d2<span class="sc">$</span>height),</span>
<span id="cb795-3569"><a href="#cb795-3569" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> rangi2, <span class="at">xlab =</span> <span class="st">"weight"</span>, <span class="at">ylab =</span> <span class="st">"height"</span>)</span>
<span id="cb795-3570"><a href="#cb795-3570" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">concat</span>(<span class="st">"N = "</span>, N0)) </span>
<span id="cb795-3571"><a href="#cb795-3571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3572"><a href="#cb795-3572" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>) </span>
<span id="cb795-3573"><a href="#cb795-3573" aria-hidden="true" tabindex="-1"></a>  <span class="fu">abline</span>(<span class="at">a =</span> post0<span class="sc">$</span>a[i], <span class="at">b =</span> post0<span class="sc">$</span>b[i], <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"black"</span>, <span class="fl">0.3</span>))</span>
<span id="cb795-3574"><a href="#cb795-3574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3575"><a href="#cb795-3575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3576"><a href="#cb795-3576" aria-hidden="true" tabindex="-1"></a><span class="co"># 50 samples</span></span>
<span id="cb795-3577"><a href="#cb795-3577" aria-hidden="true" tabindex="-1"></a>N1 <span class="ot">=</span> <span class="dv">50</span></span>
<span id="cb795-3578"><a href="#cb795-3578" aria-hidden="true" tabindex="-1"></a>dN1 <span class="ot">&lt;-</span> d2[<span class="dv">1</span><span class="sc">:</span>N1, ]</span>
<span id="cb795-3579"><a href="#cb795-3579" aria-hidden="true" tabindex="-1"></a>mN1 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3580"><a href="#cb795-3580" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-3581"><a href="#cb795-3581" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-3582"><a href="#cb795-3582" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight ,</span>
<span id="cb795-3583"><a href="#cb795-3583" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-3584"><a href="#cb795-3584" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-3585"><a href="#cb795-3585" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-3586"><a href="#cb795-3586" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">data =</span> dN1</span>
<span id="cb795-3587"><a href="#cb795-3587" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3588"><a href="#cb795-3588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3589"><a href="#cb795-3589" aria-hidden="true" tabindex="-1"></a>post1 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( mN1, <span class="at">n=</span><span class="dv">20</span>)</span>
<span id="cb795-3590"><a href="#cb795-3590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3591"><a href="#cb795-3591" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( dN1<span class="sc">$</span>weight , dN1<span class="sc">$</span>height ,</span>
<span id="cb795-3592"><a href="#cb795-3592" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">range</span>(d2<span class="sc">$</span>weight) , <span class="at">ylim=</span><span class="fu">range</span>(d2<span class="sc">$</span>height) ,</span>
<span id="cb795-3593"><a href="#cb795-3593" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>rangi2 , <span class="at">xlab=</span><span class="st">"weight"</span> , <span class="at">ylab=</span><span class="st">"height"</span> )</span>
<span id="cb795-3594"><a href="#cb795-3594" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">concat</span>(<span class="st">"N = "</span>,N1))</span>
<span id="cb795-3595"><a href="#cb795-3595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3596"><a href="#cb795-3596" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span> )</span>
<span id="cb795-3597"><a href="#cb795-3597" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>( <span class="at">a=</span>post1<span class="sc">$</span>a[i] , <span class="at">b=</span>post1<span class="sc">$</span>b[i] , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"black"</span>,<span class="fl">0.3</span>) )</span>
<span id="cb795-3598"><a href="#cb795-3598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3599"><a href="#cb795-3599" aria-hidden="true" tabindex="-1"></a><span class="co"># 150 samples</span></span>
<span id="cb795-3600"><a href="#cb795-3600" aria-hidden="true" tabindex="-1"></a>N2 <span class="ot">=</span> <span class="dv">150</span></span>
<span id="cb795-3601"><a href="#cb795-3601" aria-hidden="true" tabindex="-1"></a>dN2 <span class="ot">&lt;-</span> d2[<span class="dv">1</span><span class="sc">:</span>N2, ]</span>
<span id="cb795-3602"><a href="#cb795-3602" aria-hidden="true" tabindex="-1"></a>mN2 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3603"><a href="#cb795-3603" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-3604"><a href="#cb795-3604" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-3605"><a href="#cb795-3605" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight ,</span>
<span id="cb795-3606"><a href="#cb795-3606" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-3607"><a href="#cb795-3607" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-3608"><a href="#cb795-3608" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-3609"><a href="#cb795-3609" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">data =</span> dN2</span>
<span id="cb795-3610"><a href="#cb795-3610" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3611"><a href="#cb795-3611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3612"><a href="#cb795-3612" aria-hidden="true" tabindex="-1"></a>post2 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( mN2, <span class="at">n=</span><span class="dv">20</span> )</span>
<span id="cb795-3613"><a href="#cb795-3613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3614"><a href="#cb795-3614" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( dN2<span class="sc">$</span>weight , dN2<span class="sc">$</span>height ,</span>
<span id="cb795-3615"><a href="#cb795-3615" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">range</span>(d2<span class="sc">$</span>weight) , <span class="at">ylim=</span><span class="fu">range</span>(d2<span class="sc">$</span>height) ,</span>
<span id="cb795-3616"><a href="#cb795-3616" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>rangi2 , <span class="at">xlab=</span><span class="st">"weight"</span> , <span class="at">ylab=</span><span class="st">"height"</span> )</span>
<span id="cb795-3617"><a href="#cb795-3617" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">concat</span>(<span class="st">"N = "</span>,N2))</span>
<span id="cb795-3618"><a href="#cb795-3618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3619"><a href="#cb795-3619" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span> )</span>
<span id="cb795-3620"><a href="#cb795-3620" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>( <span class="at">a=</span>post2<span class="sc">$</span>a[i] , <span class="at">b=</span>post2<span class="sc">$</span>b[i] , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"black"</span>,<span class="fl">0.3</span>) )</span>
<span id="cb795-3621"><a href="#cb795-3621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3622"><a href="#cb795-3622" aria-hidden="true" tabindex="-1"></a><span class="co"># 352 samples</span></span>
<span id="cb795-3623"><a href="#cb795-3623" aria-hidden="true" tabindex="-1"></a>N3 <span class="ot">=</span> <span class="dv">352</span></span>
<span id="cb795-3624"><a href="#cb795-3624" aria-hidden="true" tabindex="-1"></a>dN3 <span class="ot">&lt;-</span> d2[<span class="dv">1</span><span class="sc">:</span>N3, ]</span>
<span id="cb795-3625"><a href="#cb795-3625" aria-hidden="true" tabindex="-1"></a>mN3 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-3626"><a href="#cb795-3626" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-3627"><a href="#cb795-3627" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-3628"><a href="#cb795-3628" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight ,</span>
<span id="cb795-3629"><a href="#cb795-3629" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-3630"><a href="#cb795-3630" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-3631"><a href="#cb795-3631" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-3632"><a href="#cb795-3632" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">data =</span> dN3</span>
<span id="cb795-3633"><a href="#cb795-3633" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-3634"><a href="#cb795-3634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3635"><a href="#cb795-3635" aria-hidden="true" tabindex="-1"></a>post3 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( mN3, <span class="at">n=</span><span class="dv">20</span> )</span>
<span id="cb795-3636"><a href="#cb795-3636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3637"><a href="#cb795-3637" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( dN3<span class="sc">$</span>weight , dN3<span class="sc">$</span>height ,</span>
<span id="cb795-3638"><a href="#cb795-3638" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">range</span>(d2<span class="sc">$</span>weight) , <span class="at">ylim=</span><span class="fu">range</span>(d2<span class="sc">$</span>height) ,</span>
<span id="cb795-3639"><a href="#cb795-3639" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>rangi2 , <span class="at">xlab=</span><span class="st">"weight"</span> , <span class="at">ylab=</span><span class="st">"height"</span> )</span>
<span id="cb795-3640"><a href="#cb795-3640" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="fu">concat</span>(<span class="st">"N = "</span>,N3))</span>
<span id="cb795-3641"><a href="#cb795-3641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3642"><a href="#cb795-3642" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span> )</span>
<span id="cb795-3643"><a href="#cb795-3643" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>( <span class="at">a=</span>post3<span class="sc">$</span>a[i] , <span class="at">b=</span>post3<span class="sc">$</span>b[i] , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"black"</span>,<span class="fl">0.3</span>) )</span>
<span id="cb795-3644"><a href="#cb795-3644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3645"><a href="#cb795-3645" aria-hidden="true" tabindex="-1"></a><span class="co"># The cloud of regression lines grows more compact as the sample size increases. </span></span>
<span id="cb795-3646"><a href="#cb795-3646" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a result of the model growing more confident about the location of the mean.</span></span>
<span id="cb795-3647"><a href="#cb795-3647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3648"><a href="#cb795-3648" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3649"><a href="#cb795-3649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3650"><a href="#cb795-3650" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3651"><a href="#cb795-3651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3652"><a href="#cb795-3652" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Plotting regression intervals and contours</span></span>
<span id="cb795-3653"><a href="#cb795-3653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3654"><a href="#cb795-3654" aria-hidden="true" tabindex="-1"></a>It’s much more common to see the uncertainty displayed by plotting an interval or contour around the MAP regression line, than a cloud of regression lines. </span>
<span id="cb795-3655"><a href="#cb795-3655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3656"><a href="#cb795-3656" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.50}</span></span>
<span id="cb795-3657"><a href="#cb795-3657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3658"><a href="#cb795-3658" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb795-3659"><a href="#cb795-3659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3660"><a href="#cb795-3660" aria-hidden="true" tabindex="-1"></a><span class="co"># See the vector</span></span>
<span id="cb795-3661"><a href="#cb795-3661" aria-hidden="true" tabindex="-1"></a>post_test <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mN, <span class="at">n =</span> <span class="dv">20</span>)</span>
<span id="cb795-3662"><a href="#cb795-3662" aria-hidden="true" tabindex="-1"></a>mu_at_40 <span class="ot">&lt;-</span> post_test<span class="sc">$</span>a <span class="sc">+</span> post_test<span class="sc">$</span>b <span class="sc">*</span> <span class="dv">40</span></span>
<span id="cb795-3663"><a href="#cb795-3663" aria-hidden="true" tabindex="-1"></a>mu_at_40</span>
<span id="cb795-3664"><a href="#cb795-3664" aria-hidden="true" tabindex="-1"></a><span class="co"># It’s a vector of predicted means, one for each random sample from the posterior. </span></span>
<span id="cb795-3665"><a href="#cb795-3665" aria-hidden="true" tabindex="-1"></a><span class="co"># Since joint a and b went into computing each, the variation across those means </span></span>
<span id="cb795-3666"><a href="#cb795-3666" aria-hidden="true" tabindex="-1"></a><span class="co"># incorporates the uncertainty in and correlation between both parameters.</span></span>
<span id="cb795-3667"><a href="#cb795-3667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3668"><a href="#cb795-3668" aria-hidden="true" tabindex="-1"></a><span class="co"># make a list of 10,000 values of μ for an individual who weighs 50 kilograms, </span></span>
<span id="cb795-3669"><a href="#cb795-3669" aria-hidden="true" tabindex="-1"></a><span class="co"># by using samples from the posterior (μ_i = α + βx_i)</span></span>
<span id="cb795-3670"><a href="#cb795-3670" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mN, <span class="at">n =</span> <span class="fl">1e4</span>)</span>
<span id="cb795-3671"><a href="#cb795-3671" aria-hidden="true" tabindex="-1"></a>mu_at_50 <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b <span class="sc">*</span> <span class="dv">50</span> <span class="co"># value of x_i is 50 in this case</span></span>
<span id="cb795-3672"><a href="#cb795-3672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3673"><a href="#cb795-3673" aria-hidden="true" tabindex="-1"></a>post3 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mN3, <span class="at">n =</span> <span class="fl">1e4</span>)</span>
<span id="cb795-3674"><a href="#cb795-3674" aria-hidden="true" tabindex="-1"></a>mu_at_50_3 <span class="ot">&lt;-</span> post3<span class="sc">$</span>a <span class="sc">+</span> post3<span class="sc">$</span>b <span class="sc">*</span> <span class="dv">50</span></span>
<span id="cb795-3675"><a href="#cb795-3675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3676"><a href="#cb795-3676" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the density for the vector of means</span></span>
<span id="cb795-3677"><a href="#cb795-3677" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-3678"><a href="#cb795-3678" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(mu_at_50, <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">xlab =</span> <span class="st">"mu|weight = 50 (10 samples)"</span>)</span>
<span id="cb795-3679"><a href="#cb795-3679" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(mu_at_50_3, <span class="at">col =</span> rangi2, <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">xlab =</span> <span class="st">"mu|weight = 50 (352 samples)"</span>)</span>
<span id="cb795-3680"><a href="#cb795-3680" aria-hidden="true" tabindex="-1"></a><span class="co"># The quadratic approximate posterior distribution of the mean height, μ, when </span></span>
<span id="cb795-3681"><a href="#cb795-3681" aria-hidden="true" tabindex="-1"></a><span class="co"># weight is 50 kg. This distribution represents the relative plausibility of </span></span>
<span id="cb795-3682"><a href="#cb795-3682" aria-hidden="true" tabindex="-1"></a><span class="co"># different values of the mean.</span></span>
<span id="cb795-3683"><a href="#cb795-3683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3684"><a href="#cb795-3684" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3685"><a href="#cb795-3685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3686"><a href="#cb795-3686" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3687"><a href="#cb795-3687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3688"><a href="#cb795-3688" aria-hidden="true" tabindex="-1"></a>Since the posterior for $\mu$ is a distribution, you can find intervals for it, just like for any posterior distribution. To find the 89% highest posterior density interval of $\mu$ at 50 kg, just use the HPDI command as usual:</span>
<span id="cb795-3689"><a href="#cb795-3689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3690"><a href="#cb795-3690" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.52}</span></span>
<span id="cb795-3691"><a href="#cb795-3691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3692"><a href="#cb795-3692" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(mu_at_50, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-3693"><a href="#cb795-3693" aria-hidden="true" tabindex="-1"></a><span class="co"># Wider interval of distribution (more uncertainty) with low number of observed data.</span></span>
<span id="cb795-3694"><a href="#cb795-3694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3695"><a href="#cb795-3695" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(mu_at_50_3, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-3696"><a href="#cb795-3696" aria-hidden="true" tabindex="-1"></a><span class="co"># The central 89% of the ways for the model to produce the data place the average </span></span>
<span id="cb795-3697"><a href="#cb795-3697" aria-hidden="true" tabindex="-1"></a><span class="co"># height between about 159 cm and 160 cm (conditional on the model and data), </span></span>
<span id="cb795-3698"><a href="#cb795-3698" aria-hidden="true" tabindex="-1"></a><span class="co"># assuming the weight is 50 kg.</span></span>
<span id="cb795-3699"><a href="#cb795-3699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3700"><a href="#cb795-3700" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3701"><a href="#cb795-3701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3702"><a href="#cb795-3702" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3703"><a href="#cb795-3703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3704"><a href="#cb795-3704" aria-hidden="true" tabindex="-1"></a>We need to repeat the above calculation for every weight value on the horizontal axis, not just when it is 50 kg. We want to draw 89% HPDIs around the MAP slope. This can be done by using <span class="in">`link`</span> function. What <span class="in">`link`</span> will do is take your <span class="in">`map`</span> model fit, sample from the posterior distribution, and then compute $\mu$ for each case in the data and sample from the posterior distribution.</span>
<span id="cb795-3705"><a href="#cb795-3705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3706"><a href="#cb795-3706" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.53}</span></span>
<span id="cb795-3707"><a href="#cb795-3707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3708"><a href="#cb795-3708" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m4<span class="fl">.3</span>)</span>
<span id="cb795-3709"><a href="#cb795-3709" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mu) <span class="co"># to compactly show data frame</span></span>
<span id="cb795-3710"><a href="#cb795-3710" aria-hidden="true" tabindex="-1"></a><span class="co"># You end up with a big matrix of values of μ. Each row is a sample from the posterior distribution. </span></span>
<span id="cb795-3711"><a href="#cb795-3711" aria-hidden="true" tabindex="-1"></a><span class="co"># The default is 1000 samples, but you can use as many or as few as you like. </span></span>
<span id="cb795-3712"><a href="#cb795-3712" aria-hidden="true" tabindex="-1"></a><span class="co"># Each column is a case (row) in the data. There are 352 rows in d2, corresponding </span></span>
<span id="cb795-3713"><a href="#cb795-3713" aria-hidden="true" tabindex="-1"></a><span class="co"># to 352 individuals. So there are 352 columns in the matrix mu above.</span></span>
<span id="cb795-3714"><a href="#cb795-3714" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3715"><a href="#cb795-3715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3716"><a href="#cb795-3716" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3717"><a href="#cb795-3717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3718"><a href="#cb795-3718" aria-hidden="true" tabindex="-1"></a>Now we have a distribution of $\mu$ for each individual in the original data. We actually want something slightly different: a distribution of $\mu$ for each unique weight value on the horizontal axis.</span>
<span id="cb795-3719"><a href="#cb795-3719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3720"><a href="#cb795-3720" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.54}</span></span>
<span id="cb795-3721"><a href="#cb795-3721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3722"><a href="#cb795-3722" aria-hidden="true" tabindex="-1"></a><span class="co"># define sequence of weights to compute predictions for</span></span>
<span id="cb795-3723"><a href="#cb795-3723" aria-hidden="true" tabindex="-1"></a><span class="co"># these values will be on the horizontal axis</span></span>
<span id="cb795-3724"><a href="#cb795-3724" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">25</span> , <span class="at">to=</span><span class="dv">70</span> , <span class="at">by=</span><span class="dv">1</span> )</span>
<span id="cb795-3725"><a href="#cb795-3725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3726"><a href="#cb795-3726" aria-hidden="true" tabindex="-1"></a><span class="co"># use link to compute mu</span></span>
<span id="cb795-3727"><a href="#cb795-3727" aria-hidden="true" tabindex="-1"></a><span class="co"># for each sample from posterior</span></span>
<span id="cb795-3728"><a href="#cb795-3728" aria-hidden="true" tabindex="-1"></a><span class="co"># and for each weight in weight.seq</span></span>
<span id="cb795-3729"><a href="#cb795-3729" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m4<span class="fl">.3</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">weight=</span>weight.seq) )</span>
<span id="cb795-3730"><a href="#cb795-3730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3731"><a href="#cb795-3731" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mu)</span>
<span id="cb795-3732"><a href="#cb795-3732" aria-hidden="true" tabindex="-1"></a><span class="co"># Now there are only 46 columns in mu, because we fed it 46 different values for weight.</span></span>
<span id="cb795-3733"><a href="#cb795-3733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3734"><a href="#cb795-3734" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distribution of μ values at each height</span></span>
<span id="cb795-3735"><a href="#cb795-3735" aria-hidden="true" tabindex="-1"></a><span class="co"># use type="n" to hide raw data</span></span>
<span id="cb795-3736"><a href="#cb795-3736" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , d2 , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-3737"><a href="#cb795-3737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3738"><a href="#cb795-3738" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over samples and plot each mu value</span></span>
<span id="cb795-3739"><a href="#cb795-3739" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span> )</span>
<span id="cb795-3740"><a href="#cb795-3740" aria-hidden="true" tabindex="-1"></a>    <span class="fu">points</span>( weight.seq , mu[i,] , <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) )</span>
<span id="cb795-3741"><a href="#cb795-3741" aria-hidden="true" tabindex="-1"></a><span class="co"># The first 100 values in the distribution of μ at each weight value.</span></span>
<span id="cb795-3742"><a href="#cb795-3742" aria-hidden="true" tabindex="-1"></a><span class="co"># At each weight value in weight.seq, a pile of computed μ values are shown. </span></span>
<span id="cb795-3743"><a href="#cb795-3743" aria-hidden="true" tabindex="-1"></a><span class="co"># Each of these piles is a Gaussian distribution. You can see now that the amount </span></span>
<span id="cb795-3744"><a href="#cb795-3744" aria-hidden="true" tabindex="-1"></a><span class="co"># of uncertainty in μ depends upon the value of weight.</span></span>
<span id="cb795-3745"><a href="#cb795-3745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3746"><a href="#cb795-3746" aria-hidden="true" tabindex="-1"></a><span class="do">## The final step is to summarize the distribution for each weight value.</span></span>
<span id="cb795-3747"><a href="#cb795-3747" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize the distribution of mu</span></span>
<span id="cb795-3748"><a href="#cb795-3748" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean ) <span class="co"># 2 is columns, 1 is rows</span></span>
<span id="cb795-3749"><a href="#cb795-3749" aria-hidden="true" tabindex="-1"></a>mu.mean</span>
<span id="cb795-3750"><a href="#cb795-3750" aria-hidden="true" tabindex="-1"></a><span class="co"># Read apply(mu,2,mean) as compute the mean of each column (dimension “2”) of the matrix mu. </span></span>
<span id="cb795-3751"><a href="#cb795-3751" aria-hidden="true" tabindex="-1"></a><span class="co"># mu.mean contains the average μ at each weight value.</span></span>
<span id="cb795-3752"><a href="#cb795-3752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3753"><a href="#cb795-3753" aria-hidden="true" tabindex="-1"></a>mu.HPDI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , HPDI , <span class="at">prob=</span><span class="fl">0.89</span> )</span>
<span id="cb795-3754"><a href="#cb795-3754" aria-hidden="true" tabindex="-1"></a>mu.HPDI</span>
<span id="cb795-3755"><a href="#cb795-3755" aria-hidden="true" tabindex="-1"></a><span class="co"># mu.HPDI contains 89% lower and upper bounds for each weight value.</span></span>
<span id="cb795-3756"><a href="#cb795-3756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3757"><a href="#cb795-3757" aria-hidden="true" tabindex="-1"></a><span class="do">## You can plot these summaries on top of the data with a few lines of R code:</span></span>
<span id="cb795-3758"><a href="#cb795-3758" aria-hidden="true" tabindex="-1"></a><span class="co"># plot raw data</span></span>
<span id="cb795-3759"><a href="#cb795-3759" aria-hidden="true" tabindex="-1"></a><span class="co"># fading out points to make line and interval more visible</span></span>
<span id="cb795-3760"><a href="#cb795-3760" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , <span class="at">data=</span>d2 , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.5</span>) )</span>
<span id="cb795-3761"><a href="#cb795-3761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3762"><a href="#cb795-3762" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the MAP line, aka the mean mu for each weight</span></span>
<span id="cb795-3763"><a href="#cb795-3763" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( weight.seq , mu.mean )</span>
<span id="cb795-3764"><a href="#cb795-3764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3765"><a href="#cb795-3765" aria-hidden="true" tabindex="-1"></a><span class="co"># plot a shaded region for 89% HPDI</span></span>
<span id="cb795-3766"><a href="#cb795-3766" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.HPDI , weight.seq )</span>
<span id="cb795-3767"><a href="#cb795-3767" aria-hidden="true" tabindex="-1"></a><span class="co"># The !Kung height data again, now with 89% HPDI of the mean indicated by the shaded region.</span></span>
<span id="cb795-3768"><a href="#cb795-3768" aria-hidden="true" tabindex="-1"></a><span class="co"># The confidence interval for the regression line clings tightly to the MAP line. Thus there is </span></span>
<span id="cb795-3769"><a href="#cb795-3769" aria-hidden="true" tabindex="-1"></a><span class="co"># very little uncertainty about the average height as a function of average weight. But you have</span></span>
<span id="cb795-3770"><a href="#cb795-3770" aria-hidden="true" tabindex="-1"></a><span class="co"># to keep in mind that these inferences are always conditional on the model. Even a very bad model </span></span>
<span id="cb795-3771"><a href="#cb795-3771" aria-hidden="true" tabindex="-1"></a><span class="co"># can have very tight confidence intervals. It may help if you think of the regression line as: </span></span>
<span id="cb795-3772"><a href="#cb795-3772" aria-hidden="true" tabindex="-1"></a><span class="co"># Conditional on the assumption that height and weight are related by a straight line, then this is </span></span>
<span id="cb795-3773"><a href="#cb795-3773" aria-hidden="true" tabindex="-1"></a><span class="co"># the most plausible line, and these are its plausible bounds.</span></span>
<span id="cb795-3774"><a href="#cb795-3774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3775"><a href="#cb795-3775" aria-hidden="true" tabindex="-1"></a><span class="do">## Compare this region to the distributions of blue points on the left.</span></span>
<span id="cb795-3776"><a href="#cb795-3776" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-3777"><a href="#cb795-3777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3778"><a href="#cb795-3778" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , d2 , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-3779"><a href="#cb795-3779" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span> )</span>
<span id="cb795-3780"><a href="#cb795-3780" aria-hidden="true" tabindex="-1"></a>    <span class="fu">points</span>( weight.seq , mu[i,] , <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) )</span>
<span id="cb795-3781"><a href="#cb795-3781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3782"><a href="#cb795-3782" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , <span class="at">data=</span>d2 , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.5</span>) )</span>
<span id="cb795-3783"><a href="#cb795-3783" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( weight.seq , mu.mean )</span>
<span id="cb795-3784"><a href="#cb795-3784" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.HPDI , weight.seq )</span>
<span id="cb795-3785"><a href="#cb795-3785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3786"><a href="#cb795-3786" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3787"><a href="#cb795-3787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3788"><a href="#cb795-3788" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3789"><a href="#cb795-3789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3790"><a href="#cb795-3790" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Recipe for generating predictions and intervals from the posterior of a fit model**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-3791"><a href="#cb795-3791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3792"><a href="#cb795-3792" aria-hidden="true" tabindex="-1"></a>(1) Use <span class="in">`link`</span> to generate distributions of posterior values for $\mu$. The default behavior of <span class="in">`link`</span> is to use the original data, so you have to pass it a list of new horizontal axis values you want to plot posterior predictions across.</span>
<span id="cb795-3793"><a href="#cb795-3793" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3794"><a href="#cb795-3794" aria-hidden="true" tabindex="-1"></a>(2) Use summary functions like <span class="in">`mean`</span> or <span class="in">`HPDI`</span> or <span class="in">`PI`</span> to find averages and lower and upper bounds of $\mu$ for each value of the predictor variable.</span>
<span id="cb795-3795"><a href="#cb795-3795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3796"><a href="#cb795-3796" aria-hidden="true" tabindex="-1"></a>(3) Finally, use plotting functions like <span class="in">`lines`</span> and <span class="in">`shade`</span> to draw the lines and intervals. Or you might plot the distributions of the predictions, or do further numerical calculations with them. It’s really up to you.</span>
<span id="cb795-3797"><a href="#cb795-3797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3798"><a href="#cb795-3798" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3799"><a href="#cb795-3799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3800"><a href="#cb795-3800" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Manual method for using `link`:***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3801"><a href="#cb795-3801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3802"><a href="#cb795-3802" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.58}</span></span>
<span id="cb795-3803"><a href="#cb795-3803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3804"><a href="#cb795-3804" aria-hidden="true" tabindex="-1"></a><span class="co"># extract samples from the fitted model</span></span>
<span id="cb795-3805"><a href="#cb795-3805" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m4<span class="fl">.3</span>)</span>
<span id="cb795-3806"><a href="#cb795-3806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3807"><a href="#cb795-3807" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict mu based on weight using linear function</span></span>
<span id="cb795-3808"><a href="#cb795-3808" aria-hidden="true" tabindex="-1"></a>mu.link <span class="ot">&lt;-</span> <span class="cf">function</span>(weight) post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b<span class="sc">*</span>weight</span>
<span id="cb795-3809"><a href="#cb795-3809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3810"><a href="#cb795-3810" aria-hidden="true" tabindex="-1"></a><span class="co"># Define sequence of weights, with increment of 1, to compute predictions</span></span>
<span id="cb795-3811"><a href="#cb795-3811" aria-hidden="true" tabindex="-1"></a><span class="co"># This clears the repetition in weights?</span></span>
<span id="cb795-3812"><a href="#cb795-3812" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="dv">25</span> , <span class="at">to=</span><span class="dv">70</span> , <span class="at">by=</span><span class="dv">1</span> )</span>
<span id="cb795-3813"><a href="#cb795-3813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3814"><a href="#cb795-3814" aria-hidden="true" tabindex="-1"></a><span class="co"># For each value in weight.seq, calculate corresponding mu values based on the linear</span></span>
<span id="cb795-3815"><a href="#cb795-3815" aria-hidden="true" tabindex="-1"></a><span class="co"># prediction function mu.link</span></span>
<span id="cb795-3816"><a href="#cb795-3816" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">sapply</span>( weight.seq , mu.link )</span>
<span id="cb795-3817"><a href="#cb795-3817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3818"><a href="#cb795-3818" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate a vector of mean mu and HPDI for each column (each sample) of mu</span></span>
<span id="cb795-3819"><a href="#cb795-3819" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-3820"><a href="#cb795-3820" aria-hidden="true" tabindex="-1"></a>mu.HPDI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , HPDI , <span class="at">prob=</span><span class="fl">0.89</span> )</span>
<span id="cb795-3821"><a href="#cb795-3821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3822"><a href="#cb795-3822" aria-hidden="true" tabindex="-1"></a><span class="co"># The values in mu.mean and mu.HPDI should be very similar (allowing for </span></span>
<span id="cb795-3823"><a href="#cb795-3823" aria-hidden="true" tabindex="-1"></a><span class="co"># simulation variance) to what you got the automated way, using link.</span></span>
<span id="cb795-3824"><a href="#cb795-3824" aria-hidden="true" tabindex="-1"></a>mu.mean</span>
<span id="cb795-3825"><a href="#cb795-3825" aria-hidden="true" tabindex="-1"></a>mu.HPDI</span>
<span id="cb795-3826"><a href="#cb795-3826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3827"><a href="#cb795-3827" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3828"><a href="#cb795-3828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3829"><a href="#cb795-3829" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3830"><a href="#cb795-3830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3831"><a href="#cb795-3831" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Prediction intervals</span></span>
<span id="cb795-3832"><a href="#cb795-3832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3833"><a href="#cb795-3833" aria-hidden="true" tabindex="-1"></a>Now let's generate an 89% prediction interval for actual heights, not just the average height, $\mu$ by incorporating the standard deviation $\sigma$ and its uncertainty as well. </span>
<span id="cb795-3834"><a href="#cb795-3834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3835"><a href="#cb795-3835" aria-hidden="true" tabindex="-1"></a>Imagine simulating heights. For any unique weight value, you sample from a Gaussian distribution with the correct mean $\mu$ for that weight, using the correct value of $\sigma$ sampled from the same posterior distribution. If you do this for every sample from the posterior, for every weight value of interest, you end up with a collection of simulated heights that embody the uncertainty in the posterior as well as the uncertainty in the Gaussian likelihood.</span>
<span id="cb795-3836"><a href="#cb795-3836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3837"><a href="#cb795-3837" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.59}</span></span>
<span id="cb795-3838"><a href="#cb795-3838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3839"><a href="#cb795-3839" aria-hidden="true" tabindex="-1"></a>sim.height <span class="ot">&lt;-</span> <span class="fu">sim</span>(m4<span class="fl">.3</span>, <span class="at">data =</span> <span class="fu">list</span>(<span class="at">weight =</span> weight.seq))</span>
<span id="cb795-3840"><a href="#cb795-3840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3841"><a href="#cb795-3841" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(sim.height)</span>
<span id="cb795-3842"><a href="#cb795-3842" aria-hidden="true" tabindex="-1"></a><span class="co"># This matrix is much like the earlier one, mu, but it contains simulated heights, </span></span>
<span id="cb795-3843"><a href="#cb795-3843" aria-hidden="true" tabindex="-1"></a><span class="co"># not distributions of plausible average height, μ.</span></span>
<span id="cb795-3844"><a href="#cb795-3844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3845"><a href="#cb795-3845" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize these simulated heights in the same way we summarized the distributions of μ, </span></span>
<span id="cb795-3846"><a href="#cb795-3846" aria-hidden="true" tabindex="-1"></a><span class="co"># by using apply</span></span>
<span id="cb795-3847"><a href="#cb795-3847" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-3848"><a href="#cb795-3848" aria-hidden="true" tabindex="-1"></a>height.PI</span>
<span id="cb795-3849"><a href="#cb795-3849" aria-hidden="true" tabindex="-1"></a><span class="co"># Now height.PI contains the 89% posterior prediction interval of observable </span></span>
<span id="cb795-3850"><a href="#cb795-3850" aria-hidden="true" tabindex="-1"></a><span class="co"># (according to the model) heights, across the values of weight in weight.seq.</span></span>
<span id="cb795-3851"><a href="#cb795-3851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3852"><a href="#cb795-3852" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot everything we’ve built up: (1) the MAP line, (2) the shaded region of 89% plausible μ, </span></span>
<span id="cb795-3853"><a href="#cb795-3853" aria-hidden="true" tabindex="-1"></a><span class="do">## and (3) the boundaries of the simulated heights the model expects</span></span>
<span id="cb795-3854"><a href="#cb795-3854" aria-hidden="true" tabindex="-1"></a><span class="co"># plot raw data</span></span>
<span id="cb795-3855"><a href="#cb795-3855" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , d2 , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.5</span>) )</span>
<span id="cb795-3856"><a href="#cb795-3856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3857"><a href="#cb795-3857" aria-hidden="true" tabindex="-1"></a><span class="co"># draw MAP line</span></span>
<span id="cb795-3858"><a href="#cb795-3858" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( weight.seq , mu.mean )</span>
<span id="cb795-3859"><a href="#cb795-3859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3860"><a href="#cb795-3860" aria-hidden="true" tabindex="-1"></a><span class="co"># draw HPDI region for line</span></span>
<span id="cb795-3861"><a href="#cb795-3861" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.HPDI , weight.seq )</span>
<span id="cb795-3862"><a href="#cb795-3862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3863"><a href="#cb795-3863" aria-hidden="true" tabindex="-1"></a><span class="co"># draw PI region for simulated heights</span></span>
<span id="cb795-3864"><a href="#cb795-3864" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( height.PI , weight.seq )</span>
<span id="cb795-3865"><a href="#cb795-3865" aria-hidden="true" tabindex="-1"></a><span class="co"># 89% prediction interval for height, as a function of weight. The solid line is </span></span>
<span id="cb795-3866"><a href="#cb795-3866" aria-hidden="true" tabindex="-1"></a><span class="co"># the MAP estimate of the mean height at each weight. The two shaded regions show </span></span>
<span id="cb795-3867"><a href="#cb795-3867" aria-hidden="true" tabindex="-1"></a><span class="co"># different 89% plausible regions. The narrow shaded interval around the line is </span></span>
<span id="cb795-3868"><a href="#cb795-3868" aria-hidden="true" tabindex="-1"></a><span class="co"># the distribution of μ. The wider shaded region represents the region within which </span></span>
<span id="cb795-3869"><a href="#cb795-3869" aria-hidden="true" tabindex="-1"></a><span class="co"># the model expects to find 89% of actual heights in the population, at each weight.</span></span>
<span id="cb795-3870"><a href="#cb795-3870" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3871"><a href="#cb795-3871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3872"><a href="#cb795-3872" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3873"><a href="#cb795-3873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3874"><a href="#cb795-3874" aria-hidden="true" tabindex="-1"></a>Notice that the outline for the wide shaded interval is a little jagged. This is the simulation variance in the tails of the sampled Gaussian values. If it really bothers you, increase the number of samples you take from the posterior distribution. The optional n parameter for sim.height controls how many samples are used.</span>
<span id="cb795-3875"><a href="#cb795-3875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3876"><a href="#cb795-3876" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.62}</span></span>
<span id="cb795-3877"><a href="#cb795-3877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3878"><a href="#cb795-3878" aria-hidden="true" tabindex="-1"></a><span class="co"># Increase samples for simulation</span></span>
<span id="cb795-3879"><a href="#cb795-3879" aria-hidden="true" tabindex="-1"></a>sim.height <span class="ot">&lt;-</span> <span class="fu">sim</span>(m4<span class="fl">.3</span>, <span class="at">data =</span> <span class="fu">list</span>(<span class="at">weight =</span> weight.seq), <span class="at">n =</span> <span class="fl">1e4</span>)</span>
<span id="cb795-3880"><a href="#cb795-3880" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-3881"><a href="#cb795-3881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3882"><a href="#cb795-3882" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the PI again</span></span>
<span id="cb795-3883"><a href="#cb795-3883" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , d2 , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.5</span>) )</span>
<span id="cb795-3884"><a href="#cb795-3884" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( weight.seq , mu.mean )</span>
<span id="cb795-3885"><a href="#cb795-3885" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.HPDI , weight.seq )</span>
<span id="cb795-3886"><a href="#cb795-3886" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( height.PI , weight.seq )</span>
<span id="cb795-3887"><a href="#cb795-3887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3888"><a href="#cb795-3888" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3889"><a href="#cb795-3889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3890"><a href="#cb795-3890" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3891"><a href="#cb795-3891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3892"><a href="#cb795-3892" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Compare 67% and 97% intervals***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3893"><a href="#cb795-3893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3894"><a href="#cb795-3894" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 67.97}</span></span>
<span id="cb795-3895"><a href="#cb795-3895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3896"><a href="#cb795-3896" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-3897"><a href="#cb795-3897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3898"><a href="#cb795-3898" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate height</span></span>
<span id="cb795-3899"><a href="#cb795-3899" aria-hidden="true" tabindex="-1"></a>sim.height <span class="ot">&lt;-</span> <span class="fu">sim</span>(m4<span class="fl">.3</span>, <span class="at">data =</span> <span class="fu">list</span>(<span class="at">weight =</span> weight.seq))</span>
<span id="cb795-3900"><a href="#cb795-3900" aria-hidden="true" tabindex="-1"></a>                  </span>
<span id="cb795-3901"><a href="#cb795-3901" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot for 67%</span></span>
<span id="cb795-3902"><a href="#cb795-3902" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.67</span>)</span>
<span id="cb795-3903"><a href="#cb795-3903" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight, d2, <span class="at">col =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.5</span>), <span class="at">main =</span> <span class="st">"67% interval"</span>)</span>
<span id="cb795-3904"><a href="#cb795-3904" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean)</span>
<span id="cb795-3905"><a href="#cb795-3905" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.HPDI, weight.seq)</span>
<span id="cb795-3906"><a href="#cb795-3906" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI, weight.seq)</span>
<span id="cb795-3907"><a href="#cb795-3907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3908"><a href="#cb795-3908" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot for 97%</span></span>
<span id="cb795-3909"><a href="#cb795-3909" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.97</span>)</span>
<span id="cb795-3910"><a href="#cb795-3910" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight, d2, <span class="at">col =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.5</span>), <span class="at">main =</span> <span class="st">"97% interval"</span>)</span>
<span id="cb795-3911"><a href="#cb795-3911" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean)</span>
<span id="cb795-3912"><a href="#cb795-3912" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.HPDI, weight.seq)</span>
<span id="cb795-3913"><a href="#cb795-3913" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI, weight.seq)</span>
<span id="cb795-3914"><a href="#cb795-3914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3915"><a href="#cb795-3915" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3916"><a href="#cb795-3916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3917"><a href="#cb795-3917" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3918"><a href="#cb795-3918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3919"><a href="#cb795-3919" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Manual method for using `sim`:***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-3920"><a href="#cb795-3920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3921"><a href="#cb795-3921" aria-hidden="true" tabindex="-1"></a>For every distribution like <span class="in">`dnorm`</span>, there is a companion simulation function. For the Gaussian distribution, the companion is <span class="in">`rnorm`</span>, and it simulates sampling from a Gaussian distribution. What we want R to do is simulate a height for each set of samples, and to do this for each value of weight.</span>
<span id="cb795-3922"><a href="#cb795-3922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3923"><a href="#cb795-3923" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.63}</span></span>
<span id="cb795-3924"><a href="#cb795-3924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3925"><a href="#cb795-3925" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract posterior or prior samples from map model</span></span>
<span id="cb795-3926"><a href="#cb795-3926" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m4<span class="fl">.3</span>) <span class="co"># default n = 1e4</span></span>
<span id="cb795-3927"><a href="#cb795-3927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3928"><a href="#cb795-3928" aria-hidden="true" tabindex="-1"></a><span class="co"># Define weight sequence</span></span>
<span id="cb795-3929"><a href="#cb795-3929" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="dv">25</span><span class="sc">:</span><span class="dv">70</span></span>
<span id="cb795-3930"><a href="#cb795-3930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3931"><a href="#cb795-3931" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate height </span></span>
<span id="cb795-3932"><a href="#cb795-3932" aria-hidden="true" tabindex="-1"></a>sim.height <span class="ot">&lt;-</span> <span class="fu">sapply</span>( weight.seq , <span class="cf">function</span>(weight)</span>
<span id="cb795-3933"><a href="#cb795-3933" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rnorm</span>( <span class="co"># use rnorm to generate random normal values based on the parameters</span></span>
<span id="cb795-3934"><a href="#cb795-3934" aria-hidden="true" tabindex="-1"></a>        <span class="at">n=</span><span class="fu">nrow</span>(post) ,</span>
<span id="cb795-3935"><a href="#cb795-3935" aria-hidden="true" tabindex="-1"></a>        <span class="at">mean=</span>post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b<span class="sc">*</span>weight ,</span>
<span id="cb795-3936"><a href="#cb795-3936" aria-hidden="true" tabindex="-1"></a>        <span class="at">sd=</span>post<span class="sc">$</span>sigma ) )</span>
<span id="cb795-3937"><a href="#cb795-3937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3938"><a href="#cb795-3938" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate predicted interval of height</span></span>
<span id="cb795-3939"><a href="#cb795-3939" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( sim.height , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.89</span> )</span>
<span id="cb795-3940"><a href="#cb795-3940" aria-hidden="true" tabindex="-1"></a>height.PI</span>
<span id="cb795-3941"><a href="#cb795-3941" aria-hidden="true" tabindex="-1"></a><span class="co"># The values in height.PI will be practically identical to the ones computed above for 89%.</span></span>
<span id="cb795-3942"><a href="#cb795-3942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3943"><a href="#cb795-3943" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3944"><a href="#cb795-3944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3945"><a href="#cb795-3945" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3946"><a href="#cb795-3946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3947"><a href="#cb795-3947" aria-hidden="true" tabindex="-1"></a><span class="fu">## Polynomial regression</span></span>
<span id="cb795-3948"><a href="#cb795-3948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3949"><a href="#cb795-3949" aria-hidden="true" tabindex="-1"></a>It helps to see how to model the outcome as a curved function of a single predictor. The models so far all assume that a straight line describes the relationship. But there’s nothing special about straight lines, aside from their simplicity.</span>
<span id="cb795-3950"><a href="#cb795-3950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3951"><a href="#cb795-3951" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.64}</span></span>
<span id="cb795-3952"><a href="#cb795-3952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3953"><a href="#cb795-3953" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb795-3954"><a href="#cb795-3954" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Howell1"</span>)</span>
<span id="cb795-3955"><a href="#cb795-3955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3956"><a href="#cb795-3956" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data set d including all data </span></span>
<span id="cb795-3957"><a href="#cb795-3957" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-3958"><a href="#cb795-3958" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-3959"><a href="#cb795-3959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3960"><a href="#cb795-3960" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot d</span></span>
<span id="cb795-3961"><a href="#cb795-3961" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight, d, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"black"</span>, <span class="fl">0.5</span>))</span>
<span id="cb795-3962"><a href="#cb795-3962" aria-hidden="true" tabindex="-1"></a><span class="co"># The relationship is visibly curved, now that we’ve included the non-adult individuals.</span></span>
<span id="cb795-3963"><a href="#cb795-3963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3964"><a href="#cb795-3964" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3965"><a href="#cb795-3965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3966"><a href="#cb795-3966" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3967"><a href="#cb795-3967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3968"><a href="#cb795-3968" aria-hidden="true" tabindex="-1"></a>Polynomial regression is one of the ways to model a curved relationship between two variables. In this context, “polynomial” means equations for $\mu_i$ that add additional terms with squares, cubes, and even higher powers of the predictor variable. There’s still only one predictor variable in the model, so this is still a bivariate regression. But the definition of $\mu_i$ has more parameters now.</span>
<span id="cb795-3969"><a href="#cb795-3969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3970"><a href="#cb795-3970" aria-hidden="true" tabindex="-1"></a>The most common polynomial regression, a parabolic model of the mean:</span>
<span id="cb795-3971"><a href="#cb795-3971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3972"><a href="#cb795-3972" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i^2$$</span>
<span id="cb795-3973"><a href="#cb795-3973" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3974"><a href="#cb795-3974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3975"><a href="#cb795-3975" aria-hidden="true" tabindex="-1"></a>The above is a parabolic (second order) polynomial. The $\alpha + \beta_1 \text{x}_i$ part is the same linear function of x in a linear regression, just with a little “1” subscript added to the parameter name, so we can tell it apart from the new parameter. The additional term uses the square of $x_i$ to construct a parabola, rather than a perfectly straight line. The new parameter $\beta_2$ measures the curvature of the relationship.</span>
<span id="cb795-3976"><a href="#cb795-3976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3977"><a href="#cb795-3977" aria-hidden="true" tabindex="-1"></a>The parabolic model of $\mu_i$ above is still called a “linear model” of the mean. What “linear” usually means in this context is that $\mu_i$ is a linear function of any single parameter. </span>
<span id="cb795-3978"><a href="#cb795-3978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3979"><a href="#cb795-3979" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3980"><a href="#cb795-3980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3981"><a href="#cb795-3981" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fitting the model to data</span></span>
<span id="cb795-3982"><a href="#cb795-3982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3983"><a href="#cb795-3983" aria-hidden="true" tabindex="-1"></a>The first thing to do is to standardize the predictor variable. This means to first center the variable and then divide it by its standard deviation.</span>
<span id="cb795-3984"><a href="#cb795-3984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3985"><a href="#cb795-3985" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.65}</span></span>
<span id="cb795-3986"><a href="#cb795-3986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3987"><a href="#cb795-3987" aria-hidden="true" tabindex="-1"></a><span class="co"># Subtract the mean and then divide by the standard deviation to standardize weight</span></span>
<span id="cb795-3988"><a href="#cb795-3988" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>weight.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>weight <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>weight))<span class="sc">/</span> <span class="fu">sd</span>(d<span class="sc">$</span>weight)</span>
<span id="cb795-3989"><a href="#cb795-3989" aria-hidden="true" tabindex="-1"></a><span class="co"># This new variable weight.s has mean zero and standard deviation 1.</span></span>
<span id="cb795-3990"><a href="#cb795-3990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3991"><a href="#cb795-3991" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the standardized data to verify no information has been lost</span></span>
<span id="cb795-3992"><a href="#cb795-3992" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight.s, d, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"black"</span>, <span class="fl">0.5</span>))</span>
<span id="cb795-3993"><a href="#cb795-3993" aria-hidden="true" tabindex="-1"></a><span class="co"># The same curved relationship as before, but now with a different range on the horizontal axis.</span></span>
<span id="cb795-3994"><a href="#cb795-3994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3995"><a href="#cb795-3995" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-3996"><a href="#cb795-3996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3997"><a href="#cb795-3997" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-3998"><a href="#cb795-3998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-3999"><a href="#cb795-3999" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Parabolic regression**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-4000"><a href="#cb795-4000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4001"><a href="#cb795-4001" aria-hidden="true" tabindex="-1"></a>To fit the parabolic model, just modify the definition of $\mu_i$. Here’s the model (with very weak priors):</span>
<span id="cb795-4002"><a href="#cb795-4002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4003"><a href="#cb795-4003" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-4004"><a href="#cb795-4004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4005"><a href="#cb795-4005" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-4006"><a href="#cb795-4006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4007"><a href="#cb795-4007" aria-hidden="true" tabindex="-1"></a>\text{h}_i &amp; \sim \text{Normal}(\mu_i, \sigma) \ &amp;&amp;&amp; \text{height} &amp; \sim \text{dnorm(mu, sigma)} <span class="sc">\\</span></span>
<span id="cb795-4008"><a href="#cb795-4008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4009"><a href="#cb795-4009" aria-hidden="true" tabindex="-1"></a>\mu_i &amp; = \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i^2 \ &amp;&amp;&amp; \text{mu} &amp; \leftarrow \text{a + b1*weight.s + b2*weight.s^2} <span class="sc">\\</span></span>
<span id="cb795-4010"><a href="#cb795-4010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4011"><a href="#cb795-4011" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(178, 100) \ &amp;&amp;&amp; a &amp;\sim \text{dnorm}(178, 100)<span class="sc">\\</span></span>
<span id="cb795-4012"><a href="#cb795-4012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4013"><a href="#cb795-4013" aria-hidden="true" tabindex="-1"></a>\beta_1 &amp;\sim \text{Normal}(0, 10) \ &amp;&amp;&amp; b1 &amp;\sim \text{dnorm}(0, 10)<span class="sc">\\</span></span>
<span id="cb795-4014"><a href="#cb795-4014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4015"><a href="#cb795-4015" aria-hidden="true" tabindex="-1"></a>\beta_2 &amp;\sim \text{Normal}(0, 10) \ &amp;&amp;&amp; b2 &amp;\sim \text{dnorm}(0,10)<span class="sc">\\</span>         </span>
<span id="cb795-4016"><a href="#cb795-4016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4017"><a href="#cb795-4017" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 50) \ &amp;&amp;&amp; \text{sigma} &amp;\sim \text{dunif}(0, 50)</span>
<span id="cb795-4018"><a href="#cb795-4018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4019"><a href="#cb795-4019" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-4020"><a href="#cb795-4020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4021"><a href="#cb795-4021" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-4022"><a href="#cb795-4022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4023"><a href="#cb795-4023" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4024"><a href="#cb795-4024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4025"><a href="#cb795-4025" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.66}</span></span>
<span id="cb795-4026"><a href="#cb795-4026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4027"><a href="#cb795-4027" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the square weight.s as separate variable</span></span>
<span id="cb795-4028"><a href="#cb795-4028" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>weight.s2 <span class="ot">&lt;-</span> d<span class="sc">$</span>weight.s<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb795-4029"><a href="#cb795-4029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4030"><a href="#cb795-4030" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model by modifying the definition of mu so that it contains </span></span>
<span id="cb795-4031"><a href="#cb795-4031" aria-hidden="true" tabindex="-1"></a><span class="co"># both the ordinary and quadratic terms</span></span>
<span id="cb795-4032"><a href="#cb795-4032" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.5</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4033"><a href="#cb795-4033" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-4034"><a href="#cb795-4034" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-4035"><a href="#cb795-4035" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b1<span class="sc">*</span>weight.s <span class="sc">+</span> b2<span class="sc">*</span>weight.s2,</span>
<span id="cb795-4036"><a href="#cb795-4036" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">100</span>),</span>
<span id="cb795-4037"><a href="#cb795-4037" aria-hidden="true" tabindex="-1"></a>    b1 <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-4038"><a href="#cb795-4038" aria-hidden="true" tabindex="-1"></a>    b2 <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-4039"><a href="#cb795-4039" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-4040"><a href="#cb795-4040" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-4041"><a href="#cb795-4041" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-4042"><a href="#cb795-4042" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-4043"><a href="#cb795-4043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4044"><a href="#cb795-4044" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the map model</span></span>
<span id="cb795-4045"><a href="#cb795-4045" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.5</span>)</span>
<span id="cb795-4046"><a href="#cb795-4046" aria-hidden="true" tabindex="-1"></a><span class="co"># The parameter α (a) is still the intercept, so it tells us the expected value of height </span></span>
<span id="cb795-4047"><a href="#cb795-4047" aria-hidden="true" tabindex="-1"></a><span class="co"># when weight.s is zero. But it is no longer equal to the mean height in the sample, </span></span>
<span id="cb795-4048"><a href="#cb795-4048" aria-hidden="true" tabindex="-1"></a><span class="co"># since there is no guarantee it should in a polynomial regression.</span></span>
<span id="cb795-4049"><a href="#cb795-4049" aria-hidden="true" tabindex="-1"></a><span class="co"># β1 and β2 parameters are the linear and square components of the curve, respectively.</span></span>
<span id="cb795-4050"><a href="#cb795-4050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4051"><a href="#cb795-4051" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the model fits</span></span>
<span id="cb795-4052"><a href="#cb795-4052" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the mean relationship and the 89% intervals of the mean and the predictions</span></span>
<span id="cb795-4053"><a href="#cb795-4053" aria-hidden="true" tabindex="-1"></a><span class="co"># Define predictor values for weight</span></span>
<span id="cb795-4054"><a href="#cb795-4054" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="sc">-</span><span class="fl">2.2</span> , <span class="at">to=</span><span class="dv">2</span> , <span class="at">length.out=</span><span class="dv">30</span> )</span>
<span id="cb795-4055"><a href="#cb795-4055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4056"><a href="#cb795-4056" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list with weight.s and weight.s2 values (pre-calculation)</span></span>
<span id="cb795-4057"><a href="#cb795-4057" aria-hidden="true" tabindex="-1"></a>pred_dat <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">weight.s=</span>weight.seq , <span class="at">weight.s2=</span>weight.seq<span class="sc">^</span><span class="dv">2</span> )</span>
<span id="cb795-4058"><a href="#cb795-4058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4059"><a href="#cb795-4059" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate predicted mu values based on model m4.5 using predictor values in pred_dat</span></span>
<span id="cb795-4060"><a href="#cb795-4060" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m4<span class="fl">.5</span> , <span class="at">data=</span>pred_dat )</span>
<span id="cb795-4061"><a href="#cb795-4061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4062"><a href="#cb795-4062" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean of predicted mu values across columns</span></span>
<span id="cb795-4063"><a href="#cb795-4063" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-4064"><a href="#cb795-4064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4065"><a href="#cb795-4065" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate prediction interval with prob 89% of the predicted mu values</span></span>
<span id="cb795-4066"><a href="#cb795-4066" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.89</span> )</span>
<span id="cb795-4067"><a href="#cb795-4067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4068"><a href="#cb795-4068" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate height values based on model m4.5 using predictor values in pred_dat</span></span>
<span id="cb795-4069"><a href="#cb795-4069" aria-hidden="true" tabindex="-1"></a>sim.height <span class="ot">&lt;-</span> <span class="fu">sim</span>( m4<span class="fl">.5</span> , <span class="at">data=</span>pred_dat )</span>
<span id="cb795-4070"><a href="#cb795-4070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4071"><a href="#cb795-4071" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate prediction interval for simulated heights with prob 89%</span></span>
<span id="cb795-4072"><a href="#cb795-4072" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( sim.height , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.89</span> )</span>
<span id="cb795-4073"><a href="#cb795-4073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4074"><a href="#cb795-4074" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot MAP, PI of predicted means and PI of simulated heights</span></span>
<span id="cb795-4075"><a href="#cb795-4075" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot raw data</span></span>
<span id="cb795-4076"><a href="#cb795-4076" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight.s , d , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.5</span>) )</span>
<span id="cb795-4077"><a href="#cb795-4077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4078"><a href="#cb795-4078" aria-hidden="true" tabindex="-1"></a><span class="co"># Add map line</span></span>
<span id="cb795-4079"><a href="#cb795-4079" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( weight.seq , mu.mean )</span>
<span id="cb795-4080"><a href="#cb795-4080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4081"><a href="#cb795-4081" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade prediction interval for mu values</span></span>
<span id="cb795-4082"><a href="#cb795-4082" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , weight.seq )</span>
<span id="cb795-4083"><a href="#cb795-4083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4084"><a href="#cb795-4084" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade prediction interval for simulated heights</span></span>
<span id="cb795-4085"><a href="#cb795-4085" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( height.PI , weight.seq )</span>
<span id="cb795-4086"><a href="#cb795-4086" aria-hidden="true" tabindex="-1"></a><span class="co"># The curve does a much better job of finding a central path through the data, than </span></span>
<span id="cb795-4087"><a href="#cb795-4087" aria-hidden="true" tabindex="-1"></a><span class="co"># the linear model. </span></span>
<span id="cb795-4088"><a href="#cb795-4088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4089"><a href="#cb795-4089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4090"><a href="#cb795-4090" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4091"><a href="#cb795-4091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4092"><a href="#cb795-4092" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4093"><a href="#cb795-4093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4094"><a href="#cb795-4094" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Cubic regression**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-4095"><a href="#cb795-4095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4096"><a href="#cb795-4096" aria-hidden="true" tabindex="-1"></a>The model is (hiding the priors, but they are the same as before):</span>
<span id="cb795-4097"><a href="#cb795-4097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4098"><a href="#cb795-4098" aria-hidden="true" tabindex="-1"></a>$$\text{h}_i \sim \text{Normal}(\mu_i, \sigma)$$</span>
<span id="cb795-4099"><a href="#cb795-4099" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i^2 + \beta_3 \text{x}_i^3$$</span>
<span id="cb795-4100"><a href="#cb795-4100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4101"><a href="#cb795-4101" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4102"><a href="#cb795-4102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4103"><a href="#cb795-4103" aria-hidden="true" tabindex="-1"></a>Fit the model with a slight modification of the parabolic model’s code:</span>
<span id="cb795-4104"><a href="#cb795-4104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4105"><a href="#cb795-4105" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.70}</span></span>
<span id="cb795-4106"><a href="#cb795-4106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4107"><a href="#cb795-4107" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a separate variable for cubic weight</span></span>
<span id="cb795-4108"><a href="#cb795-4108" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>weight.s3 <span class="ot">&lt;-</span> d<span class="sc">$</span>weight.s<span class="sc">^</span><span class="dv">3</span></span>
<span id="cb795-4109"><a href="#cb795-4109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4110"><a href="#cb795-4110" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the map model</span></span>
<span id="cb795-4111"><a href="#cb795-4111" aria-hidden="true" tabindex="-1"></a>m4<span class="fl">.6</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4112"><a href="#cb795-4112" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-4113"><a href="#cb795-4113" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-4114"><a href="#cb795-4114" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b1<span class="sc">*</span>weight.s <span class="sc">+</span> b2<span class="sc">*</span>weight.s2 <span class="sc">+</span> b3<span class="sc">*</span>weight.s3 ,</span>
<span id="cb795-4115"><a href="#cb795-4115" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-4116"><a href="#cb795-4116" aria-hidden="true" tabindex="-1"></a>        b1 <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-4117"><a href="#cb795-4117" aria-hidden="true" tabindex="-1"></a>        b2 <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-4118"><a href="#cb795-4118" aria-hidden="true" tabindex="-1"></a>        b3 <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-4119"><a href="#cb795-4119" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-4120"><a href="#cb795-4120" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>d )</span>
<span id="cb795-4121"><a href="#cb795-4121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4122"><a href="#cb795-4122" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the map model</span></span>
<span id="cb795-4123"><a href="#cb795-4123" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4<span class="fl">.6</span>)</span>
<span id="cb795-4124"><a href="#cb795-4124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4125"><a href="#cb795-4125" aria-hidden="true" tabindex="-1"></a><span class="co"># Define predictor values for weight</span></span>
<span id="cb795-4126"><a href="#cb795-4126" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="fl">2.2</span>, <span class="at">to =</span> <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">30</span>)</span>
<span id="cb795-4127"><a href="#cb795-4127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4128"><a href="#cb795-4128" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list with weight.s, weight.s2 and weight.s3 values</span></span>
<span id="cb795-4129"><a href="#cb795-4129" aria-hidden="true" tabindex="-1"></a>pred_dat_c <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">weight.s =</span> weight.seq, <span class="at">weight.s2 =</span> weight.seq<span class="sc">^</span><span class="dv">2</span>, <span class="at">weight.s3 =</span> weight.seq<span class="sc">^</span><span class="dv">3</span>)</span>
<span id="cb795-4130"><a href="#cb795-4130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4131"><a href="#cb795-4131" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate predicted mu values for based on model and predictor values</span></span>
<span id="cb795-4132"><a href="#cb795-4132" aria-hidden="true" tabindex="-1"></a>mu_c <span class="ot">&lt;-</span> <span class="fu">link</span>(m4<span class="fl">.6</span>, <span class="at">data =</span> pred_dat_c)</span>
<span id="cb795-4133"><a href="#cb795-4133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4134"><a href="#cb795-4134" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean of predicted mu values across column</span></span>
<span id="cb795-4135"><a href="#cb795-4135" aria-hidden="true" tabindex="-1"></a>mu.mean_c <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu_c, <span class="dv">2</span>, mean)</span>
<span id="cb795-4136"><a href="#cb795-4136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4137"><a href="#cb795-4137" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PI of predicted mu values (89% interval)</span></span>
<span id="cb795-4138"><a href="#cb795-4138" aria-hidden="true" tabindex="-1"></a>mu.PI_c <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu_c, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4139"><a href="#cb795-4139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4140"><a href="#cb795-4140" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate height values based on model and predictor values</span></span>
<span id="cb795-4141"><a href="#cb795-4141" aria-hidden="true" tabindex="-1"></a>sim.height_c <span class="ot">&lt;-</span> <span class="fu">sim</span>(m4<span class="fl">.6</span>, <span class="at">data =</span> pred_dat_c)</span>
<span id="cb795-4142"><a href="#cb795-4142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4143"><a href="#cb795-4143" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PI of simulated heights</span></span>
<span id="cb795-4144"><a href="#cb795-4144" aria-hidden="true" tabindex="-1"></a>height.PI_c <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height_c, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4145"><a href="#cb795-4145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4146"><a href="#cb795-4146" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot raw data</span></span>
<span id="cb795-4147"><a href="#cb795-4147" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight.s, d, <span class="at">col =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.5</span>))</span>
<span id="cb795-4148"><a href="#cb795-4148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4149"><a href="#cb795-4149" aria-hidden="true" tabindex="-1"></a><span class="co"># Add map line</span></span>
<span id="cb795-4150"><a href="#cb795-4150" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean_c)</span>
<span id="cb795-4151"><a href="#cb795-4151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4152"><a href="#cb795-4152" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI for mu values</span></span>
<span id="cb795-4153"><a href="#cb795-4153" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI_c, weight.seq)</span>
<span id="cb795-4154"><a href="#cb795-4154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4155"><a href="#cb795-4155" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI of simulated heights</span></span>
<span id="cb795-4156"><a href="#cb795-4156" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI_c, weight.seq)</span>
<span id="cb795-4157"><a href="#cb795-4157" aria-hidden="true" tabindex="-1"></a><span class="co"># This cubic curve is even more flexible than the parabola, so it fits the data even better.</span></span>
<span id="cb795-4158"><a href="#cb795-4158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4159"><a href="#cb795-4159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4160"><a href="#cb795-4160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4161"><a href="#cb795-4161" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4162"><a href="#cb795-4162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4163"><a href="#cb795-4163" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Compare linear, parabolic and cubic regressions***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-4164"><a href="#cb795-4164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4165"><a href="#cb795-4165" aria-hidden="true" tabindex="-1"></a><span class="in">```{r regression}</span></span>
<span id="cb795-4166"><a href="#cb795-4166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4167"><a href="#cb795-4167" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb795-4168"><a href="#cb795-4168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4169"><a href="#cb795-4169" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the linear regression</span></span>
<span id="cb795-4170"><a href="#cb795-4170" aria-hidden="true" tabindex="-1"></a>m4_l <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4171"><a href="#cb795-4171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-4172"><a href="#cb795-4172" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-4173"><a href="#cb795-4173" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight.s,</span>
<span id="cb795-4174"><a href="#cb795-4174" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">100</span>),</span>
<span id="cb795-4175"><a href="#cb795-4175" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-4176"><a href="#cb795-4176" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-4177"><a href="#cb795-4177" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-4178"><a href="#cb795-4178" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-4179"><a href="#cb795-4179" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-4180"><a href="#cb795-4180" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4_l)</span>
<span id="cb795-4181"><a href="#cb795-4181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4182"><a href="#cb795-4182" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="fl">2.2</span>, <span class="at">to =</span> <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">30</span>)</span>
<span id="cb795-4183"><a href="#cb795-4183" aria-hidden="true" tabindex="-1"></a>pred_dat_l <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">weight.s =</span> weight.seq)</span>
<span id="cb795-4184"><a href="#cb795-4184" aria-hidden="true" tabindex="-1"></a>mu_l <span class="ot">&lt;-</span> <span class="fu">link</span>(m4_l, <span class="at">data =</span> pred_dat_l)</span>
<span id="cb795-4185"><a href="#cb795-4185" aria-hidden="true" tabindex="-1"></a>mu.mean_l <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu_l, <span class="dv">2</span>, mean)</span>
<span id="cb795-4186"><a href="#cb795-4186" aria-hidden="true" tabindex="-1"></a>mu.PI_l <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu_l, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4187"><a href="#cb795-4187" aria-hidden="true" tabindex="-1"></a>sim.height_l <span class="ot">&lt;-</span> <span class="fu">sim</span>(m4_l, <span class="at">data =</span> pred_dat_l)</span>
<span id="cb795-4188"><a href="#cb795-4188" aria-hidden="true" tabindex="-1"></a>height.PI_l <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height_l, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4189"><a href="#cb795-4189" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight.s, d, <span class="at">col =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.5</span>), <span class="at">main =</span> <span class="st">"(a)"</span>)</span>
<span id="cb795-4190"><a href="#cb795-4190" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean_l)</span>
<span id="cb795-4191"><a href="#cb795-4191" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI_l, weight.seq)</span>
<span id="cb795-4192"><a href="#cb795-4192" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI_l, weight.seq)</span>
<span id="cb795-4193"><a href="#cb795-4193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4194"><a href="#cb795-4194" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the parabolic regression</span></span>
<span id="cb795-4195"><a href="#cb795-4195" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight.s , d , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.5</span>), <span class="at">main =</span> <span class="st">"(b)"</span>)</span>
<span id="cb795-4196"><a href="#cb795-4196" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( weight.seq , mu.mean )</span>
<span id="cb795-4197"><a href="#cb795-4197" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , weight.seq )</span>
<span id="cb795-4198"><a href="#cb795-4198" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( height.PI , weight.seq )</span>
<span id="cb795-4199"><a href="#cb795-4199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4200"><a href="#cb795-4200" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the cubic regression</span></span>
<span id="cb795-4201"><a href="#cb795-4201" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight.s, d, <span class="at">col =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.5</span>), <span class="at">main =</span> <span class="st">"(c)"</span>)</span>
<span id="cb795-4202"><a href="#cb795-4202" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean_c)</span>
<span id="cb795-4203"><a href="#cb795-4203" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI_c, weight.seq)</span>
<span id="cb795-4204"><a href="#cb795-4204" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI_c, weight.seq)</span>
<span id="cb795-4205"><a href="#cb795-4205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4206"><a href="#cb795-4206" aria-hidden="true" tabindex="-1"></a><span class="co"># Polynomial regressions of height on weight (standardized),for the full !Kung data. </span></span>
<span id="cb795-4207"><a href="#cb795-4207" aria-hidden="true" tabindex="-1"></a><span class="co"># In each plot, the raw data are shown by the circles. The solid curves show the path </span></span>
<span id="cb795-4208"><a href="#cb795-4208" aria-hidden="true" tabindex="-1"></a><span class="co"># of μ in each model, and the shaded regions show the 89% interval of the mean (close to </span></span>
<span id="cb795-4209"><a href="#cb795-4209" aria-hidden="true" tabindex="-1"></a><span class="co"># the solid curve) and the 89% interval of predictions (wider). </span></span>
<span id="cb795-4210"><a href="#cb795-4210" aria-hidden="true" tabindex="-1"></a><span class="co"># (a) Linear regression. (b) A second order polynomial, a parabolic regression. </span></span>
<span id="cb795-4211"><a href="#cb795-4211" aria-hidden="true" tabindex="-1"></a><span class="co"># (c) A third order polynomial, a cubic regression.</span></span>
<span id="cb795-4212"><a href="#cb795-4212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4213"><a href="#cb795-4213" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4214"><a href="#cb795-4214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4215"><a href="#cb795-4215" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4216"><a href="#cb795-4216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4217"><a href="#cb795-4217" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Converting back to natural scale**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-4218"><a href="#cb795-4218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4219"><a href="#cb795-4219" aria-hidden="true" tabindex="-1"></a>The three plots above have standard units on the horizontal axis. These units are sometimes called z-scores. But suppose you fit the model using standardized variables, but want to plot the estimates on the original scale. All that’s really needed is first to turn off the horizontal axis when you plot the raw data:</span>
<span id="cb795-4220"><a href="#cb795-4220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4221"><a href="#cb795-4221" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4.71}</span></span>
<span id="cb795-4222"><a href="#cb795-4222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4223"><a href="#cb795-4223" aria-hidden="true" tabindex="-1"></a><span class="do">## Turn off the horizontal axis using xaxt (x-axis shouldn't be plotted- to plot manually)</span></span>
<span id="cb795-4224"><a href="#cb795-4224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight.s, d, <span class="at">col =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.5</span>), <span class="at">xaxt =</span> <span class="st">"n"</span>) <span class="co"># n = none</span></span>
<span id="cb795-4225"><a href="#cb795-4225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4226"><a href="#cb795-4226" aria-hidden="true" tabindex="-1"></a><span class="do">## Construct the axis, using axis function</span></span>
<span id="cb795-4227"><a href="#cb795-4227" aria-hidden="true" tabindex="-1"></a><span class="co"># Defines location of the labels, in standardized units</span></span>
<span id="cb795-4228"><a href="#cb795-4228" aria-hidden="true" tabindex="-1"></a>at <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb795-4229"><a href="#cb795-4229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4230"><a href="#cb795-4230" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert those units back to the original scale</span></span>
<span id="cb795-4231"><a href="#cb795-4231" aria-hidden="true" tabindex="-1"></a>labels <span class="ot">&lt;-</span> at<span class="sc">*</span><span class="fu">sd</span>(d<span class="sc">$</span>weight) <span class="sc">+</span> <span class="fu">mean</span>(d<span class="sc">$</span>weight)</span>
<span id="cb795-4232"><a href="#cb795-4232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4233"><a href="#cb795-4233" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the axis                     # round the labels to 1 decimal place</span></span>
<span id="cb795-4234"><a href="#cb795-4234" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="at">side =</span> <span class="dv">1</span> , <span class="at">at =</span> at , <span class="at">labels =</span> <span class="fu">round</span>(labels,<span class="dv">1</span>)) <span class="co"># 1=below, 2=left, 3=above, 4=right</span></span>
<span id="cb795-4235"><a href="#cb795-4235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4236"><a href="#cb795-4236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4237"><a href="#cb795-4237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4238"><a href="#cb795-4238" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4239"><a href="#cb795-4239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4240"><a href="#cb795-4240" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice</span></span>
<span id="cb795-4241"><a href="#cb795-4241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4242"><a href="#cb795-4242" aria-hidden="true" tabindex="-1"></a><span class="fu">### Easy</span></span>
<span id="cb795-4243"><a href="#cb795-4243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4244"><a href="#cb795-4244" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4245"><a href="#cb795-4245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4246"><a href="#cb795-4246" aria-hidden="true" tabindex="-1"></a>4E1. $\text{y}_i \sim \text{Normal}(\mu, \sigma)$</span>
<span id="cb795-4247"><a href="#cb795-4247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4248"><a href="#cb795-4248" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4249"><a href="#cb795-4249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4250"><a href="#cb795-4250" aria-hidden="true" tabindex="-1"></a>4E2. two parameters: mu and sigma</span>
<span id="cb795-4251"><a href="#cb795-4251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4252"><a href="#cb795-4252" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4253"><a href="#cb795-4253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4254"><a href="#cb795-4254" aria-hidden="true" tabindex="-1"></a>4E3. $Pr(\mu, \sigma|y) = \frac{Normal(y|\mu,\sigma) Normal(\mu|0,10) Uniform(\sigma|0,10) }{\int \int Normal(y|\mu,\sigma) Normal(\mu|0,10) Uniform(\sigma|0,10)d\mu d\sigma}$</span>
<span id="cb795-4255"><a href="#cb795-4255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4256"><a href="#cb795-4256" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4257"><a href="#cb795-4257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4258"><a href="#cb795-4258" aria-hidden="true" tabindex="-1"></a>4E4. $\mu_i = \alpha + \beta \text{x}_i$</span>
<span id="cb795-4259"><a href="#cb795-4259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4260"><a href="#cb795-4260" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4261"><a href="#cb795-4261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4262"><a href="#cb795-4262" aria-hidden="true" tabindex="-1"></a>4E5. three parameters: alpha, beta and sigma</span>
<span id="cb795-4263"><a href="#cb795-4263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4264"><a href="#cb795-4264" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4265"><a href="#cb795-4265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4266"><a href="#cb795-4266" aria-hidden="true" tabindex="-1"></a><span class="fu">### Medium</span></span>
<span id="cb795-4267"><a href="#cb795-4267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4268"><a href="#cb795-4268" aria-hidden="true" tabindex="-1"></a>4M1. </span>
<span id="cb795-4269"><a href="#cb795-4269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4270"><a href="#cb795-4270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4M1}</span></span>
<span id="cb795-4271"><a href="#cb795-4271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4272"><a href="#cb795-4272" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate samples for mu</span></span>
<span id="cb795-4273"><a href="#cb795-4273" aria-hidden="true" tabindex="-1"></a>sample_mu <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-4274"><a href="#cb795-4274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4275"><a href="#cb795-4275" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate samples for sigma</span></span>
<span id="cb795-4276"><a href="#cb795-4276" aria-hidden="true" tabindex="-1"></a>sample_sigma <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="fl">1e4</span>, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-4277"><a href="#cb795-4277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4278"><a href="#cb795-4278" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate heights from prior</span></span>
<span id="cb795-4279"><a href="#cb795-4279" aria-hidden="true" tabindex="-1"></a>prior_height <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>, sample_mu, sample_sigma)</span>
<span id="cb795-4280"><a href="#cb795-4280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4281"><a href="#cb795-4281" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot heights</span></span>
<span id="cb795-4282"><a href="#cb795-4282" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(prior_height)</span>
<span id="cb795-4283"><a href="#cb795-4283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4284"><a href="#cb795-4284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4285"><a href="#cb795-4285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4286"><a href="#cb795-4286" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4287"><a href="#cb795-4287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4288"><a href="#cb795-4288" aria-hidden="true" tabindex="-1"></a>4M2.</span>
<span id="cb795-4289"><a href="#cb795-4289" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4M2}</span></span>
<span id="cb795-4290"><a href="#cb795-4290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4291"><a href="#cb795-4291" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Howell1"</span>)</span>
<span id="cb795-4292"><a href="#cb795-4292" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-4293"><a href="#cb795-4293" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> d[d<span class="sc">$</span>age <span class="sc">&gt;=</span> <span class="dv">18</span>, ]</span>
<span id="cb795-4294"><a href="#cb795-4294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4295"><a href="#cb795-4295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4296"><a href="#cb795-4296" aria-hidden="true" tabindex="-1"></a>m<span class="fl">.4</span>m2 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4297"><a href="#cb795-4297" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-4298"><a href="#cb795-4298" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-4299"><a href="#cb795-4299" aria-hidden="true" tabindex="-1"></a>    mu <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-4300"><a href="#cb795-4300" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-4301"><a href="#cb795-4301" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb795-4302"><a href="#cb795-4302" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d2</span>
<span id="cb795-4303"><a href="#cb795-4303" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb795-4304"><a href="#cb795-4304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4305"><a href="#cb795-4305" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m<span class="fl">.4</span>m2)</span>
<span id="cb795-4306"><a href="#cb795-4306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4307"><a href="#cb795-4307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4308"><a href="#cb795-4308" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4309"><a href="#cb795-4309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4310"><a href="#cb795-4310" aria-hidden="true" tabindex="-1"></a>4M3. </span>
<span id="cb795-4311"><a href="#cb795-4311" aria-hidden="true" tabindex="-1"></a>$$\text{y}_i \sim \text{Normal}(\mu, \sigma)$$</span>
<span id="cb795-4312"><a href="#cb795-4312" aria-hidden="true" tabindex="-1"></a>$$\mu = \alpha + \beta \text{x}_i $$</span>
<span id="cb795-4313"><a href="#cb795-4313" aria-hidden="true" tabindex="-1"></a>$$\alpha \sim \text{Normal(0, 50)}$$</span>
<span id="cb795-4314"><a href="#cb795-4314" aria-hidden="true" tabindex="-1"></a>$$\beta \sim \text{Normal(0, 10)}$$</span>
<span id="cb795-4315"><a href="#cb795-4315" aria-hidden="true" tabindex="-1"></a>$$\sigma \sim \text{Uniform(0, 50)}$$</span>
<span id="cb795-4316"><a href="#cb795-4316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4317"><a href="#cb795-4317" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4318"><a href="#cb795-4318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4319"><a href="#cb795-4319" aria-hidden="true" tabindex="-1"></a>4M4. We don't know the age and gender of students. So, we will use uninformative priors, inclusive school age children to adult. 200 is chosen considering the adult height (may not be necessary?) and mean $\beta$ is zero considering height will not increase if the students are adult, but $\sigma$ is 40 to leave room for potential increase in height. </span>
<span id="cb795-4320"><a href="#cb795-4320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4321"><a href="#cb795-4321" aria-hidden="true" tabindex="-1"></a>$$\text{h}_i \sim \text{Normal}(\mu, \sigma)$$</span>
<span id="cb795-4322"><a href="#cb795-4322" aria-hidden="true" tabindex="-1"></a>$$\mu = \alpha + \beta \text{y}_i$$</span>
<span id="cb795-4323"><a href="#cb795-4323" aria-hidden="true" tabindex="-1"></a>$$\alpha \sim \text{Normal}(0, 200)$$</span>
<span id="cb795-4324"><a href="#cb795-4324" aria-hidden="true" tabindex="-1"></a>$$\beta \sim \text{Normal}(0, 40)$$</span>
<span id="cb795-4325"><a href="#cb795-4325" aria-hidden="true" tabindex="-1"></a>$$\sigma \sim \text{Uniform}(0, 50)$$</span>
<span id="cb795-4326"><a href="#cb795-4326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4327"><a href="#cb795-4327" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4328"><a href="#cb795-4328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4329"><a href="#cb795-4329" aria-hidden="true" tabindex="-1"></a>4M5. Since average age is 120 cm, we will assume the students are around 7 years old, and estimate annual growth at 6-7 cm per year based on literature. </span>
<span id="cb795-4330"><a href="#cb795-4330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4331"><a href="#cb795-4331" aria-hidden="true" tabindex="-1"></a>$$\text{h}_i \sim \text{Normal}(\mu, \sigma)$$</span>
<span id="cb795-4332"><a href="#cb795-4332" aria-hidden="true" tabindex="-1"></a>$$\mu = \alpha + \beta \text{y}_i$$</span>
<span id="cb795-4333"><a href="#cb795-4333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4334"><a href="#cb795-4334" aria-hidden="true" tabindex="-1"></a>$$\alpha \sim \text{Normal}(120, 20)$$</span>
<span id="cb795-4335"><a href="#cb795-4335" aria-hidden="true" tabindex="-1"></a>$$\beta \sim \text{Normal}(6, 10)$$</span>
<span id="cb795-4336"><a href="#cb795-4336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4337"><a href="#cb795-4337" aria-hidden="true" tabindex="-1"></a>$$\sigma \sim \text{Uniform}(0, 30)$$</span>
<span id="cb795-4338"><a href="#cb795-4338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4339"><a href="#cb795-4339" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4340"><a href="#cb795-4340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4341"><a href="#cb795-4341" aria-hidden="true" tabindex="-1"></a>4M6. If the variance  among heights for students of the same age is never more than 64cm:</span>
<span id="cb795-4342"><a href="#cb795-4342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4343"><a href="#cb795-4343" aria-hidden="true" tabindex="-1"></a>$$\text{h}_i \sim \text{Normal}(\mu, \sigma)$$</span>
<span id="cb795-4344"><a href="#cb795-4344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4345"><a href="#cb795-4345" aria-hidden="true" tabindex="-1"></a>$$\mu = \alpha + \beta \text{y}_i$$</span>
<span id="cb795-4346"><a href="#cb795-4346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4347"><a href="#cb795-4347" aria-hidden="true" tabindex="-1"></a>$$\alpha \sim \text{Normal}(120, 20)$$</span>
<span id="cb795-4348"><a href="#cb795-4348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4349"><a href="#cb795-4349" aria-hidden="true" tabindex="-1"></a>$$\beta \sim \text{Normal}(6, 10)$$</span>
<span id="cb795-4350"><a href="#cb795-4350" aria-hidden="true" tabindex="-1"></a>$$\sigma \sim \text{Uniform}(0, 64)$$</span>
<span id="cb795-4351"><a href="#cb795-4351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4352"><a href="#cb795-4352" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4353"><a href="#cb795-4353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4354"><a href="#cb795-4354" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hard</span></span>
<span id="cb795-4355"><a href="#cb795-4355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4356"><a href="#cb795-4356" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4H1. The weights listed below were recorded in the !Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals (either HPDI or PI) for each of these individuals.</span></span>
<span id="cb795-4357"><a href="#cb795-4357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4358"><a href="#cb795-4358" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4H1}</span></span>
<span id="cb795-4359"><a href="#cb795-4359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4360"><a href="#cb795-4360" aria-hidden="true" tabindex="-1"></a><span class="co"># Create map model</span></span>
<span id="cb795-4361"><a href="#cb795-4361" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Howell1"</span>)</span>
<span id="cb795-4362"><a href="#cb795-4362" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-4363"><a href="#cb795-4363" aria-hidden="true" tabindex="-1"></a>mN <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4364"><a href="#cb795-4364" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>( </span>
<span id="cb795-4365"><a href="#cb795-4365" aria-hidden="true" tabindex="-1"></a>     height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-4366"><a href="#cb795-4366" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight,</span>
<span id="cb795-4367"><a href="#cb795-4367" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">120</span>, <span class="dv">20</span>),</span>
<span id="cb795-4368"><a href="#cb795-4368" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">6</span>, <span class="dv">10</span>),</span>
<span id="cb795-4369"><a href="#cb795-4369" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">64</span>)</span>
<span id="cb795-4370"><a href="#cb795-4370" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-4371"><a href="#cb795-4371" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-4372"><a href="#cb795-4372" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-4373"><a href="#cb795-4373" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-4374"><a href="#cb795-4374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4375"><a href="#cb795-4375" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(mN)</span>
<span id="cb795-4376"><a href="#cb795-4376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4377"><a href="#cb795-4377" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract samples from map model</span></span>
<span id="cb795-4378"><a href="#cb795-4378" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mN, <span class="at">n =</span> <span class="fl">1e5</span>)</span>
<span id="cb795-4379"><a href="#cb795-4379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4380"><a href="#cb795-4380" aria-hidden="true" tabindex="-1"></a><span class="co"># For individual1 with weight 46.95</span></span>
<span id="cb795-4381"><a href="#cb795-4381" aria-hidden="true" tabindex="-1"></a>mu_at_46<span class="fl">.95</span> <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b <span class="sc">*</span> <span class="fl">46.95</span></span>
<span id="cb795-4382"><a href="#cb795-4382" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(mu_at_46<span class="fl">.95</span>, <span class="at">xlab =</span> <span class="st">"mu|weight = 46.95"</span>)</span>
<span id="cb795-4383"><a href="#cb795-4383" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(mu_at_46<span class="fl">.95</span>)</span>
<span id="cb795-4384"><a href="#cb795-4384" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(mu_at_46<span class="fl">.95</span>, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4385"><a href="#cb795-4385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4386"><a href="#cb795-4386" aria-hidden="true" tabindex="-1"></a><span class="co"># For individual2 with weight 43.72</span></span>
<span id="cb795-4387"><a href="#cb795-4387" aria-hidden="true" tabindex="-1"></a>mu_at_43<span class="fl">.72</span> <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b <span class="sc">*</span> <span class="fl">43.72</span></span>
<span id="cb795-4388"><a href="#cb795-4388" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(mu_at_43<span class="fl">.72</span>, <span class="at">xlab =</span> <span class="st">"mu|weight = 43.72"</span>)</span>
<span id="cb795-4389"><a href="#cb795-4389" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(mu_at_43<span class="fl">.72</span>)</span>
<span id="cb795-4390"><a href="#cb795-4390" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(mu_at_43<span class="fl">.72</span>, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4391"><a href="#cb795-4391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4392"><a href="#cb795-4392" aria-hidden="true" tabindex="-1"></a><span class="co"># For individual3 with weight 64.78</span></span>
<span id="cb795-4393"><a href="#cb795-4393" aria-hidden="true" tabindex="-1"></a>mu_at_64<span class="fl">.78</span> <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b <span class="sc">*</span> <span class="fl">64.78</span></span>
<span id="cb795-4394"><a href="#cb795-4394" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(mu_at_64<span class="fl">.78</span>, <span class="at">xlab =</span> <span class="st">"mu|weight = 64.78"</span>)</span>
<span id="cb795-4395"><a href="#cb795-4395" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(mu_at_64<span class="fl">.78</span>)</span>
<span id="cb795-4396"><a href="#cb795-4396" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(mu_at_64<span class="fl">.78</span>, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4397"><a href="#cb795-4397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4398"><a href="#cb795-4398" aria-hidden="true" tabindex="-1"></a><span class="co"># For individual4 with weight 32.59</span></span>
<span id="cb795-4399"><a href="#cb795-4399" aria-hidden="true" tabindex="-1"></a>mu_at_32<span class="fl">.59</span> <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b <span class="sc">*</span> <span class="fl">32.59</span></span>
<span id="cb795-4400"><a href="#cb795-4400" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(mu_at_32<span class="fl">.59</span>, <span class="at">xlab =</span> <span class="st">"mu|weight = 32.59"</span>)</span>
<span id="cb795-4401"><a href="#cb795-4401" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(mu_at_32<span class="fl">.59</span>)</span>
<span id="cb795-4402"><a href="#cb795-4402" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(mu_at_32<span class="fl">.59</span>, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4403"><a href="#cb795-4403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4404"><a href="#cb795-4404" aria-hidden="true" tabindex="-1"></a><span class="co"># For individual5 with weight 54.63</span></span>
<span id="cb795-4405"><a href="#cb795-4405" aria-hidden="true" tabindex="-1"></a>mu_at_54<span class="fl">.63</span> <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b <span class="sc">*</span> <span class="fl">54.63</span></span>
<span id="cb795-4406"><a href="#cb795-4406" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>(mu_at_54<span class="fl">.63</span>, <span class="at">xlab =</span> <span class="st">"mu|weight = 54.63"</span>)</span>
<span id="cb795-4407"><a href="#cb795-4407" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(mu_at_54<span class="fl">.63</span>)</span>
<span id="cb795-4408"><a href="#cb795-4408" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(mu_at_54<span class="fl">.63</span>, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4409"><a href="#cb795-4409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4410"><a href="#cb795-4410" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4411"><a href="#cb795-4411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4412"><a href="#cb795-4412" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4413"><a href="#cb795-4413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4414"><a href="#cb795-4414" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span> <span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Given Answer:***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-4415"><a href="#cb795-4415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4416"><a href="#cb795-4416" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3.4}</span></span>
<span id="cb795-4417"><a href="#cb795-4417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4418"><a href="#cb795-4418" aria-hidden="true" tabindex="-1"></a><span class="co"># First, fit the model with map, to provide a quadratic approximation of the posterior. </span></span>
<span id="cb795-4419"><a href="#cb795-4419" aria-hidden="true" tabindex="-1"></a><span class="co"># I’ll use quite flat priors here, but if you used stronger priors, that’s fine. </span></span>
<span id="cb795-4420"><a href="#cb795-4420" aria-hidden="true" tabindex="-1"></a><span class="co"># What matters is the procedure be coherent.</span></span>
<span id="cb795-4421"><a href="#cb795-4421" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb795-4422"><a href="#cb795-4422" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-4423"><a href="#cb795-4423" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> d[d<span class="sc">$</span>age<span class="sc">&gt;=</span><span class="dv">18</span>,]</span>
<span id="cb795-4424"><a href="#cb795-4424" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4425"><a href="#cb795-4425" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-4426"><a href="#cb795-4426" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-4427"><a href="#cb795-4427" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight ,</span>
<span id="cb795-4428"><a href="#cb795-4428" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">100</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-4429"><a href="#cb795-4429" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-4430"><a href="#cb795-4430" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> ) ),</span>
<span id="cb795-4431"><a href="#cb795-4431" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d2 )</span>
<span id="cb795-4432"><a href="#cb795-4432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4433"><a href="#cb795-4433" aria-hidden="true" tabindex="-1"></a><span class="co"># Then produce samples from the quadratic approximate posterior. You could use mvrnorm directly, </span></span>
<span id="cb795-4434"><a href="#cb795-4434" aria-hidden="true" tabindex="-1"></a><span class="co"># or the convenient extract.samples function:</span></span>
<span id="cb795-4435"><a href="#cb795-4435" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m )</span>
<span id="cb795-4436"><a href="#cb795-4436" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(post)</span>
<span id="cb795-4437"><a href="#cb795-4437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4438"><a href="#cb795-4438" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we want to plug the weights in the table into this model, and then average over </span></span>
<span id="cb795-4439"><a href="#cb795-4439" aria-hidden="true" tabindex="-1"></a><span class="co"># the posterior to compute predictions for each individual’s height. The question is ambiguous </span></span>
<span id="cb795-4440"><a href="#cb795-4440" aria-hidden="true" tabindex="-1"></a><span class="co"># as to whether it wants μ only or rather the distribution of individual height measurements </span></span>
<span id="cb795-4441"><a href="#cb795-4441" aria-hidden="true" tabindex="-1"></a><span class="co"># (using σ). I’ll show the harder approach, that uses σ and simulates individual heights. </span></span>
<span id="cb795-4442"><a href="#cb795-4442" aria-hidden="true" tabindex="-1"></a><span class="co"># Also, I won’t use link or sim, but it’s fine if you did.</span></span>
<span id="cb795-4443"><a href="#cb795-4443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4444"><a href="#cb795-4444" aria-hidden="true" tabindex="-1"></a><span class="co"># For the first individual, the code might look like this:</span></span>
<span id="cb795-4445"><a href="#cb795-4445" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>( <span class="fl">1e5</span> , post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b<span class="sc">*</span><span class="fl">46.95</span> , post<span class="sc">$</span>sigma )</span>
<span id="cb795-4446"><a href="#cb795-4446" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span>
<span id="cb795-4447"><a href="#cb795-4447" aria-hidden="true" tabindex="-1"></a><span class="fu">HPDI</span>(y,<span class="at">prob=</span><span class="fl">0.90</span>)</span>
<span id="cb795-4448"><a href="#cb795-4448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4449"><a href="#cb795-4449" aria-hidden="true" tabindex="-1"></a><span class="co"># How does the code work? The first line, which includes rnorm, simulates 100-thousand heights, </span></span>
<span id="cb795-4450"><a href="#cb795-4450" aria-hidden="true" tabindex="-1"></a><span class="co"># using the samples from the posterior and an assumed weight of 46.95 kg. The second line then </span></span>
<span id="cb795-4451"><a href="#cb795-4451" aria-hidden="true" tabindex="-1"></a><span class="co"># computes the average of these simulated heights. That gives the expected (mean) height. </span></span>
<span id="cb795-4452"><a href="#cb795-4452" aria-hidden="true" tabindex="-1"></a><span class="co"># The third line then computes the 90% HPDI of height.</span></span>
<span id="cb795-4453"><a href="#cb795-4453" aria-hidden="true" tabindex="-1"></a><span class="co"># You could have also computed the expected heights straight from the MAP. </span></span>
<span id="cb795-4454"><a href="#cb795-4454" aria-hidden="true" tabindex="-1"></a><span class="co"># That approach is fine, and will give nearly the same answer.</span></span>
<span id="cb795-4455"><a href="#cb795-4455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4456"><a href="#cb795-4456" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4457"><a href="#cb795-4457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4458"><a href="#cb795-4458" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4459"><a href="#cb795-4459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4460"><a href="#cb795-4460" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4H2. Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right, you should end up with a new data frame with 192 rows in it.</span></span>
<span id="cb795-4461"><a href="#cb795-4461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4462"><a href="#cb795-4462" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4H2}</span></span>
<span id="cb795-4463"><a href="#cb795-4463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4464"><a href="#cb795-4464" aria-hidden="true" tabindex="-1"></a><span class="co"># Select out all the rows in the Howell1 data with ages below 18 years of age</span></span>
<span id="cb795-4465"><a href="#cb795-4465" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Howell1"</span>)</span>
<span id="cb795-4466"><a href="#cb795-4466" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-4467"><a href="#cb795-4467" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> d[d<span class="sc">$</span>age <span class="sc">&lt;</span> <span class="dv">18</span>, ]</span>
<span id="cb795-4468"><a href="#cb795-4468" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d2)</span>
<span id="cb795-4469"><a href="#cb795-4469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4470"><a href="#cb795-4470" aria-hidden="true" tabindex="-1"></a><span class="do">## (a) Fit a linear regression to these data, using map. Present and interpret the estimates. </span></span>
<span id="cb795-4471"><a href="#cb795-4471" aria-hidden="true" tabindex="-1"></a><span class="do">## For every 10 units of increase in weight, how much taller does the model predict a child gets?</span></span>
<span id="cb795-4472"><a href="#cb795-4472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4473"><a href="#cb795-4473" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a linear regression using map</span></span>
<span id="cb795-4474"><a href="#cb795-4474" aria-hidden="true" tabindex="-1"></a>mN <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4475"><a href="#cb795-4475" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>( </span>
<span id="cb795-4476"><a href="#cb795-4476" aria-hidden="true" tabindex="-1"></a>     height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-4477"><a href="#cb795-4477" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight,</span>
<span id="cb795-4478"><a href="#cb795-4478" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">120</span>, <span class="dv">20</span>),</span>
<span id="cb795-4479"><a href="#cb795-4479" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">6</span>, <span class="dv">10</span>),</span>
<span id="cb795-4480"><a href="#cb795-4480" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">64</span>)</span>
<span id="cb795-4481"><a href="#cb795-4481" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-4482"><a href="#cb795-4482" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-4483"><a href="#cb795-4483" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d2</span>
<span id="cb795-4484"><a href="#cb795-4484" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-4485"><a href="#cb795-4485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4486"><a href="#cb795-4486" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(mN)</span>
<span id="cb795-4487"><a href="#cb795-4487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4488"><a href="#cb795-4488" aria-hidden="true" tabindex="-1"></a><span class="co"># The model predicts the child's height at 58.53 cm when the predictor value is zero.</span></span>
<span id="cb795-4489"><a href="#cb795-4489" aria-hidden="true" tabindex="-1"></a><span class="co"># Every 1 unit increase in weight, the model predicts 2.71 cm increase in height.</span></span>
<span id="cb795-4490"><a href="#cb795-4490" aria-hidden="true" tabindex="-1"></a><span class="co"># So, height will be increased by 27.1 cm (sd = 0.07) for every 10 units increase in weight. </span></span>
<span id="cb795-4491"><a href="#cb795-4491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4492"><a href="#cb795-4492" aria-hidden="true" tabindex="-1"></a><span class="do">## (b) Plot the raw data, with height on the vertical axis and weight on the horizontal axis. </span></span>
<span id="cb795-4493"><a href="#cb795-4493" aria-hidden="true" tabindex="-1"></a><span class="do">## Superimpose the MAP regression line and 89% HPDI for the mean. Also superimpose the </span></span>
<span id="cb795-4494"><a href="#cb795-4494" aria-hidden="true" tabindex="-1"></a><span class="do">## 89% HPDI for predicted heights.</span></span>
<span id="cb795-4495"><a href="#cb795-4495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4496"><a href="#cb795-4496" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute mu for each chase in data and sample for posterior distribution</span></span>
<span id="cb795-4497"><a href="#cb795-4497" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mN)</span>
<span id="cb795-4498"><a href="#cb795-4498" aria-hidden="true" tabindex="-1"></a>mu.link <span class="ot">&lt;-</span> <span class="cf">function</span>(weight) post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b<span class="sc">*</span>weight</span>
<span id="cb795-4499"><a href="#cb795-4499" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">50</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb795-4500"><a href="#cb795-4500" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">sapply</span>(weight.seq, mu.link)</span>
<span id="cb795-4501"><a href="#cb795-4501" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mu)</span>
<span id="cb795-4502"><a href="#cb795-4502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4503"><a href="#cb795-4503" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute mean and HPDI of mu </span></span>
<span id="cb795-4504"><a href="#cb795-4504" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, mean)</span>
<span id="cb795-4505"><a href="#cb795-4505" aria-hidden="true" tabindex="-1"></a>mu.HPDI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, HPDI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4506"><a href="#cb795-4506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4507"><a href="#cb795-4507" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the raw data</span></span>
<span id="cb795-4508"><a href="#cb795-4508" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight, d2, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"red"</span>, <span class="fl">0.4</span>))</span>
<span id="cb795-4509"><a href="#cb795-4509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4510"><a href="#cb795-4510" aria-hidden="true" tabindex="-1"></a><span class="co"># Add map line</span></span>
<span id="cb795-4511"><a href="#cb795-4511" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean)</span>
<span id="cb795-4512"><a href="#cb795-4512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4513"><a href="#cb795-4513" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade 89% HDPI</span></span>
<span id="cb795-4514"><a href="#cb795-4514" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.HPDI, weight.seq)</span>
<span id="cb795-4515"><a href="#cb795-4515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4516"><a href="#cb795-4516" aria-hidden="true" tabindex="-1"></a><span class="do">## (c) What aspects of the model fit concern you? Describe the kinds of assumptions</span></span>
<span id="cb795-4517"><a href="#cb795-4517" aria-hidden="true" tabindex="-1"></a><span class="do">## you would change, if any, to improve the model. You don’t have to write any new code. </span></span>
<span id="cb795-4518"><a href="#cb795-4518" aria-hidden="true" tabindex="-1"></a><span class="do">## Just explain what the model appears to be doing a bad job of, and what you hypothesize </span></span>
<span id="cb795-4519"><a href="#cb795-4519" aria-hidden="true" tabindex="-1"></a><span class="do">## would be a better model.</span></span>
<span id="cb795-4520"><a href="#cb795-4520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4521"><a href="#cb795-4521" aria-hidden="true" tabindex="-1"></a><span class="co"># The MAP line of the linear regression does not follow the central path of the data.</span></span>
<span id="cb795-4522"><a href="#cb795-4522" aria-hidden="true" tabindex="-1"></a><span class="co"># Hence, the model does not fit the data well. A cubic regression might be a better </span></span>
<span id="cb795-4523"><a href="#cb795-4523" aria-hidden="true" tabindex="-1"></a><span class="co"># model, considering the curvature of the distribution. </span></span>
<span id="cb795-4524"><a href="#cb795-4524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4525"><a href="#cb795-4525" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4526"><a href="#cb795-4526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4527"><a href="#cb795-4527" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4528"><a href="#cb795-4528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4529"><a href="#cb795-4529" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Check model fit with cubic regression***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-4530"><a href="#cb795-4530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4531"><a href="#cb795-4531" aria-hidden="true" tabindex="-1"></a><span class="in">```{r test.cubic}</span></span>
<span id="cb795-4532"><a href="#cb795-4532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4533"><a href="#cb795-4533" aria-hidden="true" tabindex="-1"></a><span class="do">## Test cubic regression</span></span>
<span id="cb795-4534"><a href="#cb795-4534" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize the weights</span></span>
<span id="cb795-4535"><a href="#cb795-4535" aria-hidden="true" tabindex="-1"></a>weight.s <span class="ot">&lt;-</span> (d2<span class="sc">$</span>weight <span class="sc">-</span> <span class="fu">mean</span>(d2<span class="sc">$</span>weight))<span class="sc">/</span> <span class="fu">sd</span>(d2<span class="sc">$</span>weight)</span>
<span id="cb795-4536"><a href="#cb795-4536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4537"><a href="#cb795-4537" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-calculate weight.s2 and weight.s3</span></span>
<span id="cb795-4538"><a href="#cb795-4538" aria-hidden="true" tabindex="-1"></a>weight.s2 <span class="ot">&lt;-</span> weight.s<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb795-4539"><a href="#cb795-4539" aria-hidden="true" tabindex="-1"></a>weight.s3 <span class="ot">&lt;-</span> weight.s<span class="sc">^</span><span class="dv">3</span></span>
<span id="cb795-4540"><a href="#cb795-4540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4541"><a href="#cb795-4541" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the map model</span></span>
<span id="cb795-4542"><a href="#cb795-4542" aria-hidden="true" tabindex="-1"></a>mN <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4543"><a href="#cb795-4543" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>( </span>
<span id="cb795-4544"><a href="#cb795-4544" aria-hidden="true" tabindex="-1"></a>     height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-4545"><a href="#cb795-4545" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b1<span class="sc">*</span>weight.s <span class="sc">+</span> b2<span class="sc">*</span>weight.s2 <span class="sc">+</span> b3<span class="sc">*</span>weight.s3,</span>
<span id="cb795-4546"><a href="#cb795-4546" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">120</span>, <span class="dv">20</span>),</span>
<span id="cb795-4547"><a href="#cb795-4547" aria-hidden="true" tabindex="-1"></a>        b1 <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">6</span>, <span class="dv">10</span>),</span>
<span id="cb795-4548"><a href="#cb795-4548" aria-hidden="true" tabindex="-1"></a>        b2 <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-4549"><a href="#cb795-4549" aria-hidden="true" tabindex="-1"></a>        b3 <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-4550"><a href="#cb795-4550" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">64</span>)</span>
<span id="cb795-4551"><a href="#cb795-4551" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-4552"><a href="#cb795-4552" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-4553"><a href="#cb795-4553" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d2</span>
<span id="cb795-4554"><a href="#cb795-4554" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-4555"><a href="#cb795-4555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4556"><a href="#cb795-4556" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(mN)</span>
<span id="cb795-4557"><a href="#cb795-4557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4558"><a href="#cb795-4558" aria-hidden="true" tabindex="-1"></a><span class="co"># Define weight sequence</span></span>
<span id="cb795-4559"><a href="#cb795-4559" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">to =</span> <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">61</span>)</span>
<span id="cb795-4560"><a href="#cb795-4560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4561"><a href="#cb795-4561" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of predictor data</span></span>
<span id="cb795-4562"><a href="#cb795-4562" aria-hidden="true" tabindex="-1"></a>pred_dat <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">weight.s =</span> weight.seq, <span class="at">weight.s2 =</span> weight.seq<span class="sc">^</span><span class="dv">2</span>, <span class="at">weight.s3 =</span> weight.seq<span class="sc">^</span><span class="dv">3</span>)</span>
<span id="cb795-4563"><a href="#cb795-4563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4564"><a href="#cb795-4564" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate predicted mu values for based on model and predictor values</span></span>
<span id="cb795-4565"><a href="#cb795-4565" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(mN, <span class="at">data =</span> pred_dat)</span>
<span id="cb795-4566"><a href="#cb795-4566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4567"><a href="#cb795-4567" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mean of predicted mu values across column</span></span>
<span id="cb795-4568"><a href="#cb795-4568" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, mean)</span>
<span id="cb795-4569"><a href="#cb795-4569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4570"><a href="#cb795-4570" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PI of predicted mu values (89% interval)</span></span>
<span id="cb795-4571"><a href="#cb795-4571" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4572"><a href="#cb795-4572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4573"><a href="#cb795-4573" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate height values based on model and predictor values</span></span>
<span id="cb795-4574"><a href="#cb795-4574" aria-hidden="true" tabindex="-1"></a>sim.height <span class="ot">&lt;-</span> <span class="fu">sim</span>(mN, <span class="at">data =</span> pred_dat)</span>
<span id="cb795-4575"><a href="#cb795-4575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4576"><a href="#cb795-4576" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PI of simulated heights</span></span>
<span id="cb795-4577"><a href="#cb795-4577" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.89</span>)</span>
<span id="cb795-4578"><a href="#cb795-4578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4579"><a href="#cb795-4579" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot raw data</span></span>
<span id="cb795-4580"><a href="#cb795-4580" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight.s, d2, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"red"</span>, <span class="fl">0.5</span>), <span class="at">xlab =</span> <span class="st">"weight"</span>)</span>
<span id="cb795-4581"><a href="#cb795-4581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4582"><a href="#cb795-4582" aria-hidden="true" tabindex="-1"></a><span class="co"># Add map line</span></span>
<span id="cb795-4583"><a href="#cb795-4583" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean)</span>
<span id="cb795-4584"><a href="#cb795-4584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4585"><a href="#cb795-4585" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI for mu values</span></span>
<span id="cb795-4586"><a href="#cb795-4586" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, weight.seq)</span>
<span id="cb795-4587"><a href="#cb795-4587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4588"><a href="#cb795-4588" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI of simulated heights</span></span>
<span id="cb795-4589"><a href="#cb795-4589" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI, weight.seq)</span>
<span id="cb795-4590"><a href="#cb795-4590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4591"><a href="#cb795-4591" aria-hidden="true" tabindex="-1"></a><span class="do">## Convert back to natural scale</span></span>
<span id="cb795-4592"><a href="#cb795-4592" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove x-axis </span></span>
<span id="cb795-4593"><a href="#cb795-4593" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(height <span class="sc">~</span> weight.s, d2, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"red"</span>, <span class="fl">0.5</span>), <span class="at">xaxt =</span> <span class="st">"n"</span>, <span class="at">xlab =</span> <span class="st">"weight"</span>)</span>
<span id="cb795-4594"><a href="#cb795-4594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4595"><a href="#cb795-4595" aria-hidden="true" tabindex="-1"></a><span class="co"># Defines location of the labels, in standardized units</span></span>
<span id="cb795-4596"><a href="#cb795-4596" aria-hidden="true" tabindex="-1"></a>at <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb795-4597"><a href="#cb795-4597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4598"><a href="#cb795-4598" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert those units back to the original scale</span></span>
<span id="cb795-4599"><a href="#cb795-4599" aria-hidden="true" tabindex="-1"></a>labels <span class="ot">&lt;-</span> at<span class="sc">*</span><span class="fu">sd</span>(d2<span class="sc">$</span>weight) <span class="sc">+</span> <span class="fu">mean</span>(d2<span class="sc">$</span>weight)</span>
<span id="cb795-4600"><a href="#cb795-4600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4601"><a href="#cb795-4601" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the axis                    </span></span>
<span id="cb795-4602"><a href="#cb795-4602" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="at">side =</span> <span class="dv">1</span> , <span class="at">at =</span> at , <span class="at">labels =</span> <span class="fu">round</span>(labels,<span class="dv">0</span>))</span>
<span id="cb795-4603"><a href="#cb795-4603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4604"><a href="#cb795-4604" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw map line</span></span>
<span id="cb795-4605"><a href="#cb795-4605" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(weight.seq, mu.mean)</span>
<span id="cb795-4606"><a href="#cb795-4606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4607"><a href="#cb795-4607" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI for mu values</span></span>
<span id="cb795-4608"><a href="#cb795-4608" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, weight.seq)</span>
<span id="cb795-4609"><a href="#cb795-4609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4610"><a href="#cb795-4610" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI of simulated heights</span></span>
<span id="cb795-4611"><a href="#cb795-4611" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI, weight.seq)</span>
<span id="cb795-4612"><a href="#cb795-4612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4613"><a href="#cb795-4613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4614"><a href="#cb795-4614" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4615"><a href="#cb795-4615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4616"><a href="#cb795-4616" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4617"><a href="#cb795-4617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4618"><a href="#cb795-4618" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Given answer:***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-4619"><a href="#cb795-4619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4620"><a href="#cb795-4620" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3.7}</span></span>
<span id="cb795-4621"><a href="#cb795-4621" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">37</span>)</span>
<span id="cb795-4622"><a href="#cb795-4622" aria-hidden="true" tabindex="-1"></a><span class="do">## (a)First make a new data frame with just the non-adults in it:</span></span>
<span id="cb795-4623"><a href="#cb795-4623" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb795-4624"><a href="#cb795-4624" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-4625"><a href="#cb795-4625" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">&lt;-</span> d[ d<span class="sc">$</span>age <span class="sc">&lt;</span> <span class="dv">18</span> , ]</span>
<span id="cb795-4626"><a href="#cb795-4626" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d3)</span>
<span id="cb795-4627"><a href="#cb795-4627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4628"><a href="#cb795-4628" aria-hidden="true" tabindex="-1"></a><span class="co"># Now find the quadratic approximate posterior. The code is the same as before. </span></span>
<span id="cb795-4629"><a href="#cb795-4629" aria-hidden="true" tabindex="-1"></a><span class="co"># The data frame just changes.</span></span>
<span id="cb795-4630"><a href="#cb795-4630" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4631"><a href="#cb795-4631" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-4632"><a href="#cb795-4632" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-4633"><a href="#cb795-4633" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>weight ,</span>
<span id="cb795-4634"><a href="#cb795-4634" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">100</span> , <span class="dv">100</span> ),</span>
<span id="cb795-4635"><a href="#cb795-4635" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-4636"><a href="#cb795-4636" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> ) ),</span>
<span id="cb795-4637"><a href="#cb795-4637" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d3 )</span>
<span id="cb795-4638"><a href="#cb795-4638" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m)</span>
<span id="cb795-4639"><a href="#cb795-4639" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimates suggest that the MAP coefficient for weight is 2.7. This implies that </span></span>
<span id="cb795-4640"><a href="#cb795-4640" aria-hidden="true" tabindex="-1"></a><span class="co"># for a unit change of 1kg of weight, we predict an average of 2.7cm of increase in height.</span></span>
<span id="cb795-4641"><a href="#cb795-4641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4642"><a href="#cb795-4642" aria-hidden="true" tabindex="-1"></a><span class="do">## (b) Now to plot the raw data and superimpose the model estimates, modify the code in </span></span>
<span id="cb795-4643"><a href="#cb795-4643" aria-hidden="true" tabindex="-1"></a><span class="do">## Chapter 4. We will sample from the naive posterior, then compute 90% intervals for the </span></span>
<span id="cb795-4644"><a href="#cb795-4644" aria-hidden="true" tabindex="-1"></a><span class="do">## mean and predicted heights. This is what the complete code looks like, if you opt not </span></span>
<span id="cb795-4645"><a href="#cb795-4645" aria-hidden="true" tabindex="-1"></a><span class="do">## to use the convenience functions link and sim:</span></span>
<span id="cb795-4646"><a href="#cb795-4646" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m )</span>
<span id="cb795-4647"><a href="#cb795-4647" aria-hidden="true" tabindex="-1"></a>w.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="dv">1</span>,<span class="at">to=</span><span class="dv">45</span>,<span class="at">length.out=</span><span class="dv">50</span>)</span>
<span id="cb795-4648"><a href="#cb795-4648" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">sapply</span>( w.seq , <span class="cf">function</span>(z) <span class="fu">mean</span>( post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b<span class="sc">*</span>z ) )</span>
<span id="cb795-4649"><a href="#cb795-4649" aria-hidden="true" tabindex="-1"></a>mu.ci <span class="ot">&lt;-</span> <span class="fu">sapply</span>( w.seq , <span class="cf">function</span>(z)</span>
<span id="cb795-4650"><a href="#cb795-4650" aria-hidden="true" tabindex="-1"></a>    <span class="fu">HPDI</span>( post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b<span class="sc">*</span>z , <span class="at">prob=</span><span class="fl">0.9</span> ) )</span>
<span id="cb795-4651"><a href="#cb795-4651" aria-hidden="true" tabindex="-1"></a>pred.ci <span class="ot">&lt;-</span> <span class="fu">sapply</span>( w.seq , <span class="cf">function</span>(z)</span>
<span id="cb795-4652"><a href="#cb795-4652" aria-hidden="true" tabindex="-1"></a>    <span class="fu">HPDI</span>( <span class="fu">rnorm</span>(<span class="dv">10000</span>,post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b<span class="sc">*</span>z,post<span class="sc">$</span>sigma) , <span class="fl">0.9</span> ) )</span>
<span id="cb795-4653"><a href="#cb795-4653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4654"><a href="#cb795-4654" aria-hidden="true" tabindex="-1"></a><span class="co"># And then to plot everything:</span></span>
<span id="cb795-4655"><a href="#cb795-4655" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , <span class="at">data=</span>d3 ,</span>
<span id="cb795-4656"><a href="#cb795-4656" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"slateblue"</span>,<span class="fl">0.5</span>) , <span class="at">cex=</span><span class="fl">0.5</span> )</span>
<span id="cb795-4657"><a href="#cb795-4657" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( w.seq , mu )</span>
<span id="cb795-4658"><a href="#cb795-4658" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( w.seq , mu.ci[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4659"><a href="#cb795-4659" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( w.seq , mu.ci[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4660"><a href="#cb795-4660" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( w.seq , pred.ci[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4661"><a href="#cb795-4661" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( w.seq , pred.ci[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4662"><a href="#cb795-4662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4663"><a href="#cb795-4663" aria-hidden="true" tabindex="-1"></a><span class="do">## (c) The major problem with this model appears to be that the relationship between </span></span>
<span id="cb795-4664"><a href="#cb795-4664" aria-hidden="true" tabindex="-1"></a><span class="do">## weight and height, for non-adults, isn’t very linear. Instead it is curved. As a result, </span></span>
<span id="cb795-4665"><a href="#cb795-4665" aria-hidden="true" tabindex="-1"></a><span class="do">## at low weight values, the predicted mean is above most of the actual heights. At middle </span></span>
<span id="cb795-4666"><a href="#cb795-4666" aria-hidden="true" tabindex="-1"></a><span class="do">## weight values, the predicted mean is below most of the heights. Then again at high </span></span>
<span id="cb795-4667"><a href="#cb795-4667" aria-hidden="true" tabindex="-1"></a><span class="do">## weight values, the mean is above the heights.</span></span>
<span id="cb795-4668"><a href="#cb795-4668" aria-hidden="true" tabindex="-1"></a><span class="co"># A parabolic model would likely fit these data much better. But that’s not the only option. </span></span>
<span id="cb795-4669"><a href="#cb795-4669" aria-hidden="true" tabindex="-1"></a><span class="co"># What we’re after essentially is some way to model a reduction of the slope between height </span></span>
<span id="cb795-4670"><a href="#cb795-4670" aria-hidden="true" tabindex="-1"></a><span class="co"># and weight, as weight increases. And onwards to the next solution, which does that, for the </span></span>
<span id="cb795-4671"><a href="#cb795-4671" aria-hidden="true" tabindex="-1"></a><span class="co"># entire data.</span></span>
<span id="cb795-4672"><a href="#cb795-4672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4673"><a href="#cb795-4673" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4674"><a href="#cb795-4674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4675"><a href="#cb795-4675" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4676"><a href="#cb795-4676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4677"><a href="#cb795-4677" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 4H3. Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body weight that scales with height!” Let’s take your colleague’s advice and see what happens.</span></span>
<span id="cb795-4678"><a href="#cb795-4678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4679"><a href="#cb795-4679" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; (a) Model the relationship between height (cm) and the natural logarithm of weight (log-kg). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Fit this model, using quadratic approximation:</span></span>
<span id="cb795-4680"><a href="#cb795-4680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4681"><a href="#cb795-4681" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4H3a}</span></span>
<span id="cb795-4682"><a href="#cb795-4682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4683"><a href="#cb795-4683" aria-hidden="true" tabindex="-1"></a><span class="co"># Use entire Howell1 data frame</span></span>
<span id="cb795-4684"><a href="#cb795-4684" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Howell1"</span>)</span>
<span id="cb795-4685"><a href="#cb795-4685" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-4686"><a href="#cb795-4686" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-4687"><a href="#cb795-4687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4688"><a href="#cb795-4688" aria-hidden="true" tabindex="-1"></a>qfit <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4689"><a href="#cb795-4689" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-4690"><a href="#cb795-4690" aria-hidden="true" tabindex="-1"></a>    height <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-4691"><a href="#cb795-4691" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b <span class="sc">*</span> <span class="fu">log</span>(weight),</span>
<span id="cb795-4692"><a href="#cb795-4692" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">178</span>, <span class="dv">100</span>),</span>
<span id="cb795-4693"><a href="#cb795-4693" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb795-4694"><a href="#cb795-4694" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">50</span>)</span>
<span id="cb795-4695"><a href="#cb795-4695" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-4696"><a href="#cb795-4696" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-4697"><a href="#cb795-4697" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-4698"><a href="#cb795-4698" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-4699"><a href="#cb795-4699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4700"><a href="#cb795-4700" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(qfit)</span>
<span id="cb795-4701"><a href="#cb795-4701" aria-hidden="true" tabindex="-1"></a><span class="co"># When predictor value is zero, the height is -23.78, meaning there is no height at zero weight.</span></span>
<span id="cb795-4702"><a href="#cb795-4702" aria-hidden="true" tabindex="-1"></a><span class="co"># When log value of weight increases by 1 unit, height will increase by 47 cm. </span></span>
<span id="cb795-4703"><a href="#cb795-4703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4704"><a href="#cb795-4704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4705"><a href="#cb795-4705" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4706"><a href="#cb795-4706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4707"><a href="#cb795-4707" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4708"><a href="#cb795-4708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4709"><a href="#cb795-4709" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; (b) Use samples from the quadratic approximate posterior of the model in (a) to superimpose on the plot: (1) the predicted mean height as a function of weight, (2) the 97% HPDI for the mean, and (3) the 97% HPDI for predicted heights.</span></span>
<span id="cb795-4710"><a href="#cb795-4710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4711"><a href="#cb795-4711" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 4H3b}</span></span>
<span id="cb795-4712"><a href="#cb795-4712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4713"><a href="#cb795-4713" aria-hidden="true" tabindex="-1"></a><span class="co"># Define weight sequence</span></span>
<span id="cb795-4714"><a href="#cb795-4714" aria-hidden="true" tabindex="-1"></a>weight.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">3</span>, <span class="at">to =</span> <span class="dv">80</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb795-4715"><a href="#cb795-4715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4716"><a href="#cb795-4716" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate mu values for each data and sample from posterior distribution using link</span></span>
<span id="cb795-4717"><a href="#cb795-4717" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(qfit, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">weight =</span> weight.seq))</span>
<span id="cb795-4718"><a href="#cb795-4718" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(mu)</span>
<span id="cb795-4719"><a href="#cb795-4719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4720"><a href="#cb795-4720" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute mean and HPDI of mu </span></span>
<span id="cb795-4721"><a href="#cb795-4721" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, mean)</span>
<span id="cb795-4722"><a href="#cb795-4722" aria-hidden="true" tabindex="-1"></a>mu.HPDI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, HPDI, <span class="at">prob =</span> <span class="fl">0.97</span>)</span>
<span id="cb795-4723"><a href="#cb795-4723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4724"><a href="#cb795-4724" aria-hidden="true" tabindex="-1"></a><span class="co"># Start with the given plot</span></span>
<span id="cb795-4725"><a href="#cb795-4725" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , <span class="at">data=</span>Howell1 ,</span>
<span id="cb795-4726"><a href="#cb795-4726" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.4</span>) )</span>
<span id="cb795-4727"><a href="#cb795-4727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4728"><a href="#cb795-4728" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the MAP line, aka the mean mu for each weight</span></span>
<span id="cb795-4729"><a href="#cb795-4729" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( weight.seq , mu.mean )</span>
<span id="cb795-4730"><a href="#cb795-4730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4731"><a href="#cb795-4731" aria-hidden="true" tabindex="-1"></a><span class="co"># plot a shaded region for 97% HPDI</span></span>
<span id="cb795-4732"><a href="#cb795-4732" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.HPDI , weight.seq )</span>
<span id="cb795-4733"><a href="#cb795-4733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4734"><a href="#cb795-4734" aria-hidden="true" tabindex="-1"></a><span class="co"># Pre-define data</span></span>
<span id="cb795-4735"><a href="#cb795-4735" aria-hidden="true" tabindex="-1"></a>pre_data <span class="ot">&lt;-</span> <span class="fu">list</span> (<span class="at">weight =</span> weight.seq)</span>
<span id="cb795-4736"><a href="#cb795-4736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4737"><a href="#cb795-4737" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate height values based on model and predictor values</span></span>
<span id="cb795-4738"><a href="#cb795-4738" aria-hidden="true" tabindex="-1"></a>sim.height <span class="ot">&lt;-</span> <span class="fu">sim</span>(qfit, <span class="at">data =</span> pre_data )</span>
<span id="cb795-4739"><a href="#cb795-4739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4740"><a href="#cb795-4740" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PI of simulated heights</span></span>
<span id="cb795-4741"><a href="#cb795-4741" aria-hidden="true" tabindex="-1"></a>height.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim.height, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.97</span>)</span>
<span id="cb795-4742"><a href="#cb795-4742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4743"><a href="#cb795-4743" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade predicted height HPDI</span></span>
<span id="cb795-4744"><a href="#cb795-4744" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(height.PI, weight.seq)</span>
<span id="cb795-4745"><a href="#cb795-4745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4746"><a href="#cb795-4746" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4747"><a href="#cb795-4747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4748"><a href="#cb795-4748" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4749"><a href="#cb795-4749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4750"><a href="#cb795-4750" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Given answer:***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-4751"><a href="#cb795-4751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4752"><a href="#cb795-4752" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 3.11}</span></span>
<span id="cb795-4753"><a href="#cb795-4753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4754"><a href="#cb795-4754" aria-hidden="true" tabindex="-1"></a><span class="do">## (a) You can just use log inside the call to map:</span></span>
<span id="cb795-4755"><a href="#cb795-4755" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb795-4756"><a href="#cb795-4756" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-4757"><a href="#cb795-4757" aria-hidden="true" tabindex="-1"></a>mlw <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4758"><a href="#cb795-4758" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-4759"><a href="#cb795-4759" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="at">mean=</span>mu , <span class="at">sd=</span>sigma ) ,</span>
<span id="cb795-4760"><a href="#cb795-4760" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span><span class="fu">log</span>(weight) ,</span>
<span id="cb795-4761"><a href="#cb795-4761" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">138</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-4762"><a href="#cb795-4762" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-4763"><a href="#cb795-4763" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-4764"><a href="#cb795-4764" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-4765"><a href="#cb795-4765" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-4766"><a href="#cb795-4766" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(mlw)</span>
<span id="cb795-4767"><a href="#cb795-4767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4768"><a href="#cb795-4768" aria-hidden="true" tabindex="-1"></a><span class="co"># Pretty hard to know what to make of these estimates, aside from the fact that the </span></span>
<span id="cb795-4769"><a href="#cb795-4769" aria-hidden="true" tabindex="-1"></a><span class="co"># confidence intervals are quite narrow, owing to there being 544 rows. The estimate </span></span>
<span id="cb795-4770"><a href="#cb795-4770" aria-hidden="true" tabindex="-1"></a><span class="co"># for b (β) is hard to understand, because it refers to log-kg, not raw kg. It means </span></span>
<span id="cb795-4771"><a href="#cb795-4771" aria-hidden="true" tabindex="-1"></a><span class="co"># that for every increase of 1 log-kg of weight, you expect a increase of 47 cm of height. </span></span>
<span id="cb795-4772"><a href="#cb795-4772" aria-hidden="true" tabindex="-1"></a><span class="co"># But what’s a log-kg? You want to know what the model predicts on the natural scale </span></span>
<span id="cb795-4773"><a href="#cb795-4773" aria-hidden="true" tabindex="-1"></a><span class="co"># of measurement. So now to plotting...</span></span>
<span id="cb795-4774"><a href="#cb795-4774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4775"><a href="#cb795-4775" aria-hidden="true" tabindex="-1"></a><span class="do">## (b) Begin by sampling from the naive posterior and computing the confidence intervals </span></span>
<span id="cb795-4776"><a href="#cb795-4776" aria-hidden="true" tabindex="-1"></a><span class="do">## as per the examples in the book. Again, I’ll not use the convenience functions, </span></span>
<span id="cb795-4777"><a href="#cb795-4777" aria-hidden="true" tabindex="-1"></a><span class="do">## but it’s fine if you did.</span></span>
<span id="cb795-4778"><a href="#cb795-4778" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(mlw)</span>
<span id="cb795-4779"><a href="#cb795-4779" aria-hidden="true" tabindex="-1"></a>lw.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="fl">1.4</span>,<span class="at">to=</span><span class="fl">4.2</span>,<span class="at">length.out=</span><span class="dv">50</span>)</span>
<span id="cb795-4780"><a href="#cb795-4780" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">sapply</span>( lw.seq , <span class="cf">function</span>(z) <span class="fu">mean</span>( post<span class="sc">$</span>a<span class="sc">+</span>post<span class="sc">$</span>b<span class="sc">*</span>z ) )</span>
<span id="cb795-4781"><a href="#cb795-4781" aria-hidden="true" tabindex="-1"></a>mu.ci <span class="ot">&lt;-</span> <span class="fu">sapply</span>( lw.seq , <span class="cf">function</span>(z) <span class="fu">HPDI</span>( post<span class="sc">$</span>a<span class="sc">+</span>post<span class="sc">$</span>b<span class="sc">*</span>z ) )</span>
<span id="cb795-4782"><a href="#cb795-4782" aria-hidden="true" tabindex="-1"></a>h.ci <span class="ot">&lt;-</span> <span class="fu">sapply</span>( lw.seq , <span class="cf">function</span>(z)</span>
<span id="cb795-4783"><a href="#cb795-4783" aria-hidden="true" tabindex="-1"></a>    <span class="fu">HPDI</span>( <span class="fu">rnorm</span>(<span class="dv">10000</span>,post<span class="sc">$</span>a<span class="sc">+</span>post<span class="sc">$</span>b<span class="sc">*</span>z,post<span class="sc">$</span>sigma) ) )</span>
<span id="cb795-4784"><a href="#cb795-4784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4785"><a href="#cb795-4785" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you have lists of numbers that can be plotted to produce the confidence curves. </span></span>
<span id="cb795-4786"><a href="#cb795-4786" aria-hidden="true" tabindex="-1"></a><span class="co"># But how to translate back to the non-log scale of measurement on the horizontal axis? </span></span>
<span id="cb795-4787"><a href="#cb795-4787" aria-hidden="true" tabindex="-1"></a><span class="co"># Just exponentiate the x-axis coordinates in lw.seq, and the job is done:</span></span>
<span id="cb795-4788"><a href="#cb795-4788" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( height <span class="sc">~</span> weight , <span class="at">data=</span>d , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"slateblue"</span>,<span class="fl">0.4</span>) )</span>
<span id="cb795-4789"><a href="#cb795-4789" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="fu">exp</span>(lw.seq) , mu )</span>
<span id="cb795-4790"><a href="#cb795-4790" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="fu">exp</span>(lw.seq) , mu.ci[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4791"><a href="#cb795-4791" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="fu">exp</span>(lw.seq) , mu.ci[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4792"><a href="#cb795-4792" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="fu">exp</span>(lw.seq) , h.ci[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4793"><a href="#cb795-4793" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="fu">exp</span>(lw.seq) , h.ci[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-4794"><a href="#cb795-4794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4795"><a href="#cb795-4795" aria-hidden="true" tabindex="-1"></a><span class="co"># The model may have been linear, but plotted on the raw scale of measurement, it is </span></span>
<span id="cb795-4796"><a href="#cb795-4796" aria-hidden="true" tabindex="-1"></a><span class="co"># clearly non-linear. Not only is the trend for the mean curved, but the variance around </span></span>
<span id="cb795-4797"><a href="#cb795-4797" aria-hidden="true" tabindex="-1"></a><span class="co"># the mean is not constant, on this scale. Instead, the variance around the mean increases </span></span>
<span id="cb795-4798"><a href="#cb795-4798" aria-hidden="true" tabindex="-1"></a><span class="co"># with weight. On the scale you fit the model on, the variance was assumed to be constant. </span></span>
<span id="cb795-4799"><a href="#cb795-4799" aria-hidden="true" tabindex="-1"></a><span class="co"># But once you transform the measurement scale, it usually won’t be.</span></span>
<span id="cb795-4800"><a href="#cb795-4800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4801"><a href="#cb795-4801" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice also that the estimate for the mean is so precise that you can hardly even see </span></span>
<span id="cb795-4802"><a href="#cb795-4802" aria-hidden="true" tabindex="-1"></a><span class="co"># the confidence interval for it. Don’t get too confident about such results, though. </span></span>
<span id="cb795-4803"><a href="#cb795-4803" aria-hidden="true" tabindex="-1"></a><span class="co"># Remember, all inferences of the model are conditional on the model. Even estimated </span></span>
<span id="cb795-4804"><a href="#cb795-4804" aria-hidden="true" tabindex="-1"></a><span class="co"># trends that do a terrible job of prediction can have tight confidence intervals, </span></span>
<span id="cb795-4805"><a href="#cb795-4805" aria-hidden="true" tabindex="-1"></a><span class="co"># when the data set is large.</span></span>
<span id="cb795-4806"><a href="#cb795-4806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4807"><a href="#cb795-4807" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4808"><a href="#cb795-4808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4809"><a href="#cb795-4809" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4810"><a href="#cb795-4810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4811"><a href="#cb795-4811" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 5: Multivariate Linear Models</span></span>
<span id="cb795-4812"><a href="#cb795-4812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4813"><a href="#cb795-4813" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4814"><a href="#cb795-4814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4815"><a href="#cb795-4815" aria-hidden="true" tabindex="-1"></a>Multivariate regression uses more than one predictor variable to model an outcome. Reasons often given for multivariate models include:</span>
<span id="cb795-4816"><a href="#cb795-4816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4817"><a href="#cb795-4817" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Statistical “control” for confounds</span>
<span id="cb795-4818"><a href="#cb795-4818" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>A confound is a variable that may be correlated with another variable of interest. In a particularly important type of confound, known as Simpson’s paradox, the entire direction of an apparent association between a predictor and outcome can be reversed by considering a confound</span>
<span id="cb795-4819"><a href="#cb795-4819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4820"><a href="#cb795-4820" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multiple causation</span>
<span id="cb795-4821"><a href="#cb795-4821" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Even when confounds are absent, due for example to tight experimental control, a phenomenon may really arise from multiple causes. Furthermore, when causation is multiple, one cause can hide another. Multivariate models can help in such settings.</span>
<span id="cb795-4822"><a href="#cb795-4822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4823"><a href="#cb795-4823" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Interaction</span>
<span id="cb795-4824"><a href="#cb795-4824" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Even when variables are completely uncorrelated, the importance of each may still depend upon the other. Such interactions occur in a very large number of systems. So effective inference about one variable will usually depend upon consideration of other variables.</span>
<span id="cb795-4825"><a href="#cb795-4825" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-4826"><a href="#cb795-4826" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4827"><a href="#cb795-4827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4828"><a href="#cb795-4828" aria-hidden="true" tabindex="-1"></a><span class="fu">## Spurious association</span></span>
<span id="cb795-4829"><a href="#cb795-4829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4830"><a href="#cb795-4830" aria-hidden="true" tabindex="-1"></a>Linear regression model for correlation between age at marriage and divorce rate:</span>
<span id="cb795-4831"><a href="#cb795-4831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4832"><a href="#cb795-4832" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-4833"><a href="#cb795-4833" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-4834"><a href="#cb795-4834" aria-hidden="true" tabindex="-1"></a>\text{D}_i &amp;\sim \text{Normal}(\mu_i, \sigma) <span class="sc">\\</span></span>
<span id="cb795-4835"><a href="#cb795-4835" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_A \text{A}_i <span class="sc">\\</span></span>
<span id="cb795-4836"><a href="#cb795-4836" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(10, 10) <span class="sc">\\</span></span>
<span id="cb795-4837"><a href="#cb795-4837" aria-hidden="true" tabindex="-1"></a>\beta_A &amp;\sim \text{Normal}(0, 1) <span class="sc">\\</span></span>
<span id="cb795-4838"><a href="#cb795-4838" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 10)</span>
<span id="cb795-4839"><a href="#cb795-4839" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-4840"><a href="#cb795-4840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4841"><a href="#cb795-4841" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-4842"><a href="#cb795-4842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4843"><a href="#cb795-4843" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4844"><a href="#cb795-4844" aria-hidden="true" tabindex="-1"></a><span class="in">Di = the divorce rate for State i</span></span>
<span id="cb795-4845"><a href="#cb795-4845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4846"><a href="#cb795-4846" aria-hidden="true" tabindex="-1"></a><span class="in">Ai = State i’s median age at marriage</span></span>
<span id="cb795-4847"><a href="#cb795-4847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4848"><a href="#cb795-4848" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4849"><a href="#cb795-4849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4850"><a href="#cb795-4850" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.1}</span></span>
<span id="cb795-4851"><a href="#cb795-4851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4852"><a href="#cb795-4852" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb795-4853"><a href="#cb795-4853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4854"><a href="#cb795-4854" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb795-4855"><a href="#cb795-4855" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(WaffleDivorce)</span>
<span id="cb795-4856"><a href="#cb795-4856" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> WaffleDivorce</span>
<span id="cb795-4857"><a href="#cb795-4857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4858"><a href="#cb795-4858" aria-hidden="true" tabindex="-1"></a><span class="do">## Median age at marriage vs. divorce rate</span></span>
<span id="cb795-4859"><a href="#cb795-4859" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize predictor</span></span>
<span id="cb795-4860"><a href="#cb795-4860" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>MedianAgeMarriage.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>MedianAgeMarriage<span class="sc">-</span><span class="fu">mean</span>(d<span class="sc">$</span>MedianAgeMarriage))<span class="sc">/</span></span>
<span id="cb795-4861"><a href="#cb795-4861" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sd</span>(d<span class="sc">$</span>MedianAgeMarriage)</span>
<span id="cb795-4862"><a href="#cb795-4862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4863"><a href="#cb795-4863" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb795-4864"><a href="#cb795-4864" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.1</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4865"><a href="#cb795-4865" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-4866"><a href="#cb795-4866" aria-hidden="true" tabindex="-1"></a>        Divorce <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-4867"><a href="#cb795-4867" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bA <span class="sc">*</span> MedianAgeMarriage.s ,</span>
<span id="cb795-4868"><a href="#cb795-4868" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-4869"><a href="#cb795-4869" aria-hidden="true" tabindex="-1"></a>        bA <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-4870"><a href="#cb795-4870" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-4871"><a href="#cb795-4871" aria-hidden="true" tabindex="-1"></a>) , <span class="at">data =</span> d )</span>
<span id="cb795-4872"><a href="#cb795-4872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4873"><a href="#cb795-4873" aria-hidden="true" tabindex="-1"></a><span class="co"># Check precis output</span></span>
<span id="cb795-4874"><a href="#cb795-4874" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.1</span>)</span>
<span id="cb795-4875"><a href="#cb795-4875" aria-hidden="true" tabindex="-1"></a><span class="co"># each additional standard deviation of delay in marriage (1.24 years- the difference between</span></span>
<span id="cb795-4876"><a href="#cb795-4876" aria-hidden="true" tabindex="-1"></a><span class="co"># two data points after converting back to natural scale) predicts a decrease of </span></span>
<span id="cb795-4877"><a href="#cb795-4877" aria-hidden="true" tabindex="-1"></a><span class="co"># about one divorce per thousand adults, with a 89% interval from about −1.4 to −0.7.</span></span>
<span id="cb795-4878"><a href="#cb795-4878" aria-hidden="true" tabindex="-1"></a><span class="co"># So it’s reliably negative, even though the magnitude of the difference may vary quite a lot—</span></span>
<span id="cb795-4879"><a href="#cb795-4879" aria-hidden="true" tabindex="-1"></a><span class="co"># the upper bound is half the lower bound. Of course there’s nothing special about the interval</span></span>
<span id="cb795-4880"><a href="#cb795-4880" aria-hidden="true" tabindex="-1"></a><span class="co"># boundaries, but the magnitude of the difference means that even though the association here </span></span>
<span id="cb795-4881"><a href="#cb795-4881" aria-hidden="true" tabindex="-1"></a><span class="co"># (conditional on model and data) is implausibly positive, it could be both much stronger </span></span>
<span id="cb795-4882"><a href="#cb795-4882" aria-hidden="true" tabindex="-1"></a><span class="co"># or weaker than the mean.</span></span>
<span id="cb795-4883"><a href="#cb795-4883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4884"><a href="#cb795-4884" aria-hidden="true" tabindex="-1"></a><span class="co"># compute percentile interval of mean</span></span>
<span id="cb795-4885"><a href="#cb795-4885" aria-hidden="true" tabindex="-1"></a>MAM.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="sc">-</span><span class="dv">3</span> , <span class="at">to=</span><span class="fl">3.5</span> , <span class="at">length.out=</span><span class="dv">30</span> )</span>
<span id="cb795-4886"><a href="#cb795-4886" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.1</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">MedianAgeMarriage.s=</span>MAM.seq) )</span>
<span id="cb795-4887"><a href="#cb795-4887" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-4888"><a href="#cb795-4888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4889"><a href="#cb795-4889" aria-hidden="true" tabindex="-1"></a><span class="co"># plot it all</span></span>
<span id="cb795-4890"><a href="#cb795-4890" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> MedianAgeMarriage.s , <span class="at">data=</span>d , <span class="at">col=</span>rangi2 , <span class="at">main =</span> <span class="st">"Standardized scale"</span>)</span>
<span id="cb795-4891"><a href="#cb795-4891" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( m5<span class="fl">.1</span> )</span>
<span id="cb795-4892"><a href="#cb795-4892" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , MAM.seq )</span>
<span id="cb795-4893"><a href="#cb795-4893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4894"><a href="#cb795-4894" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to natural scale</span></span>
<span id="cb795-4895"><a href="#cb795-4895" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> MedianAgeMarriage.s , <span class="at">data=</span>d , <span class="at">col=</span>rangi2, <span class="at">xaxt =</span> <span class="st">"n"</span>,</span>
<span id="cb795-4896"><a href="#cb795-4896" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span><span class="st">"MedianAgeMarriage"</span>, <span class="at">main =</span> <span class="st">"Natural scale"</span>)</span>
<span id="cb795-4897"><a href="#cb795-4897" aria-hidden="true" tabindex="-1"></a>at <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb795-4898"><a href="#cb795-4898" aria-hidden="true" tabindex="-1"></a>labels <span class="ot">&lt;-</span> at<span class="sc">*</span><span class="fu">sd</span>(d<span class="sc">$</span>MedianAgeMarriage) <span class="sc">+</span> <span class="fu">mean</span>(d<span class="sc">$</span>MedianAgeMarriage)</span>
<span id="cb795-4899"><a href="#cb795-4899" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="at">side =</span> <span class="dv">1</span> , <span class="at">at =</span> at , <span class="at">labels =</span> <span class="fu">round</span>(labels,<span class="dv">2</span>))</span>
<span id="cb795-4900"><a href="#cb795-4900" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( m5<span class="fl">.1</span> )</span>
<span id="cb795-4901"><a href="#cb795-4901" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , MAM.seq )</span>
<span id="cb795-4902"><a href="#cb795-4902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4903"><a href="#cb795-4903" aria-hidden="true" tabindex="-1"></a><span class="do">## Marriage rate vs. divorce rate</span></span>
<span id="cb795-4904"><a href="#cb795-4904" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize predictor (marriage rate)</span></span>
<span id="cb795-4905"><a href="#cb795-4905" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>Marriage.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>Marriage <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>Marriage))<span class="sc">/</span><span class="fu">sd</span>(d<span class="sc">$</span>Marriage)</span>
<span id="cb795-4906"><a href="#cb795-4906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4907"><a href="#cb795-4907" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb795-4908"><a href="#cb795-4908" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.2</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-4909"><a href="#cb795-4909" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-4910"><a href="#cb795-4910" aria-hidden="true" tabindex="-1"></a>        Divorce <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-4911"><a href="#cb795-4911" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR <span class="sc">*</span> Marriage.s ,</span>
<span id="cb795-4912"><a href="#cb795-4912" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-4913"><a href="#cb795-4913" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-4914"><a href="#cb795-4914" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-4915"><a href="#cb795-4915" aria-hidden="true" tabindex="-1"></a>) , <span class="at">data =</span> d )</span>
<span id="cb795-4916"><a href="#cb795-4916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4917"><a href="#cb795-4917" aria-hidden="true" tabindex="-1"></a><span class="co"># check precis output</span></span>
<span id="cb795-4918"><a href="#cb795-4918" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.2</span>)</span>
<span id="cb795-4919"><a href="#cb795-4919" aria-hidden="true" tabindex="-1"></a><span class="co"># This shows an increase of 0.6 divorces for every additional standard deviation </span></span>
<span id="cb795-4920"><a href="#cb795-4920" aria-hidden="true" tabindex="-1"></a><span class="co"># of marriage rate (3.8). this relationship isn’t as strong as the previous one.</span></span>
<span id="cb795-4921"><a href="#cb795-4921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4922"><a href="#cb795-4922" aria-hidden="true" tabindex="-1"></a><span class="co"># compute percentile interval of mean</span></span>
<span id="cb795-4923"><a href="#cb795-4923" aria-hidden="true" tabindex="-1"></a>MAM.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="sc">-</span><span class="dv">3</span> , <span class="at">to=</span><span class="dv">3</span> , <span class="at">length.out=</span><span class="dv">30</span> )</span>
<span id="cb795-4924"><a href="#cb795-4924" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.2</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">Marriage.s=</span>MAM.seq) )</span>
<span id="cb795-4925"><a href="#cb795-4925" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-4926"><a href="#cb795-4926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4927"><a href="#cb795-4927" aria-hidden="true" tabindex="-1"></a><span class="co"># plot it all</span></span>
<span id="cb795-4928"><a href="#cb795-4928" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> Marriage.s , <span class="at">data=</span>d , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-4929"><a href="#cb795-4929" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( m5<span class="fl">.2</span> )</span>
<span id="cb795-4930"><a href="#cb795-4930" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , MAM.seq )</span>
<span id="cb795-4931"><a href="#cb795-4931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4932"><a href="#cb795-4932" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to natural scale</span></span>
<span id="cb795-4933"><a href="#cb795-4933" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> Marriage.s , <span class="at">data=</span>d , <span class="at">col=</span>rangi2, <span class="at">xaxt =</span> <span class="st">"n"</span>,</span>
<span id="cb795-4934"><a href="#cb795-4934" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab =</span><span class="st">"Marriage"</span>)</span>
<span id="cb795-4935"><a href="#cb795-4935" aria-hidden="true" tabindex="-1"></a>at <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb795-4936"><a href="#cb795-4936" aria-hidden="true" tabindex="-1"></a>labels <span class="ot">&lt;-</span> at<span class="sc">*</span><span class="fu">sd</span>(d<span class="sc">$</span>Marriage) <span class="sc">+</span> <span class="fu">mean</span>(d<span class="sc">$</span>Marriage)</span>
<span id="cb795-4937"><a href="#cb795-4937" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="at">side =</span> <span class="dv">1</span> , <span class="at">at =</span> at , <span class="at">labels =</span> <span class="fu">round</span>(labels,<span class="dv">2</span>))</span>
<span id="cb795-4938"><a href="#cb795-4938" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( m5<span class="fl">.2</span> )</span>
<span id="cb795-4939"><a href="#cb795-4939" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , MAM.seq )</span>
<span id="cb795-4940"><a href="#cb795-4940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4941"><a href="#cb795-4941" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4942"><a href="#cb795-4942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4943"><a href="#cb795-4943" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4944"><a href="#cb795-4944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4945"><a href="#cb795-4945" aria-hidden="true" tabindex="-1"></a>Merely comparing parameter means between different bivariate regressions is no way to decide which predictor is better. Both of these predictors could provide independent value, or they could be redundant, or one could eliminate the value of the other. So we’ll build a multivariate model with the goal of measuring the partial value of each predictor. The question we want answered is:</span>
<span id="cb795-4946"><a href="#cb795-4946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4947"><a href="#cb795-4947" aria-hidden="true" tabindex="-1"></a>  ***What is the predictive value of a variable, once I already know all of the other predictor variables?***</span>
<span id="cb795-4948"><a href="#cb795-4948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4949"><a href="#cb795-4949" aria-hidden="true" tabindex="-1"></a>So for example once you fit a multivariate regression to predict divorce using both marriage rate and age at marriage, the model answers the questions:</span>
<span id="cb795-4950"><a href="#cb795-4950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4951"><a href="#cb795-4951" aria-hidden="true" tabindex="-1"></a>  (1) After I already know marriage rate, what additional value is there in also knowing age at marriage?</span>
<span id="cb795-4952"><a href="#cb795-4952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4953"><a href="#cb795-4953" aria-hidden="true" tabindex="-1"></a>  (2) After I already know age at marriage, what additional value is there in also knowing marriage rate?</span>
<span id="cb795-4954"><a href="#cb795-4954" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-4955"><a href="#cb795-4955" aria-hidden="true" tabindex="-1"></a>The parameter estimates corresponding to each predictor are the (often opaque) answers to these questions.</span>
<span id="cb795-4956"><a href="#cb795-4956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4957"><a href="#cb795-4957" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4958"><a href="#cb795-4958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4959"><a href="#cb795-4959" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multivariate notation</span></span>
<span id="cb795-4960"><a href="#cb795-4960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4961"><a href="#cb795-4961" aria-hidden="true" tabindex="-1"></a>Multivariate regression formulas look a lot like the polynomial models- they add more parameters and variables to the definition of $\mu_i$. The strategy is straightforward:</span>
<span id="cb795-4962"><a href="#cb795-4962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4963"><a href="#cb795-4963" aria-hidden="true" tabindex="-1"></a>(1) Nominate the predictor variables you want in the linear model of the mean.</span>
<span id="cb795-4964"><a href="#cb795-4964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4965"><a href="#cb795-4965" aria-hidden="true" tabindex="-1"></a>(2) For each predictor, make a parameter that will measure its association with the outcome.</span>
<span id="cb795-4966"><a href="#cb795-4966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4967"><a href="#cb795-4967" aria-hidden="true" tabindex="-1"></a>(3) Multiply the parameter by the variable and add that term to the linear model.</span>
<span id="cb795-4968"><a href="#cb795-4968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4969"><a href="#cb795-4969" aria-hidden="true" tabindex="-1"></a>Example model that predicts divorce rate, using both marriage rate and age at marriage:</span>
<span id="cb795-4970"><a href="#cb795-4970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4971"><a href="#cb795-4971" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-4972"><a href="#cb795-4972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4973"><a href="#cb795-4973" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-4974"><a href="#cb795-4974" aria-hidden="true" tabindex="-1"></a>\text{D}_i &amp;\sim \text{Normal}(\mu, \sigma)\ &amp;&amp;&amp;  \text{<span class="co">[</span><span class="ot">likelihood</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb795-4975"><a href="#cb795-4975" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_R R_i + \beta_A A_i\ &amp;&amp;&amp;  \text{<span class="co">[</span><span class="ot">linear model</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb795-4976"><a href="#cb795-4976" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(10, 10)\ &amp;&amp;&amp;           \text{<span class="co">[</span><span class="ot">prior for }\alpha</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-4977"><a href="#cb795-4977" aria-hidden="true" tabindex="-1"></a>\beta_R &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{<span class="co">[</span><span class="ot">prior for }\beta_R</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-4978"><a href="#cb795-4978" aria-hidden="true" tabindex="-1"></a>\beta_A &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{<span class="co">[</span><span class="ot">prior for }\beta_A</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-4979"><a href="#cb795-4979" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 10)\ &amp;&amp;&amp;           \text{<span class="co">[</span><span class="ot">prior for }\sigma</span><span class="co">]</span></span>
<span id="cb795-4980"><a href="#cb795-4980" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-4981"><a href="#cb795-4981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4982"><a href="#cb795-4982" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-4983"><a href="#cb795-4983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4984"><a href="#cb795-4984" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4985"><a href="#cb795-4985" aria-hidden="true" tabindex="-1"></a><span class="in">R = marriage rate </span></span>
<span id="cb795-4986"><a href="#cb795-4986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4987"><a href="#cb795-4987" aria-hidden="true" tabindex="-1"></a><span class="in">A = age at marriage</span></span>
<span id="cb795-4988"><a href="#cb795-4988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4989"><a href="#cb795-4989" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-4990"><a href="#cb795-4990" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-4991"><a href="#cb795-4991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4992"><a href="#cb795-4992" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Compact notation and the design matrix**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-4993"><a href="#cb795-4993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4994"><a href="#cb795-4994" aria-hidden="true" tabindex="-1"></a>Linear model with n number of predictor variables:</span>
<span id="cb795-4995"><a href="#cb795-4995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4996"><a href="#cb795-4996" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha + \beta_1 \text{x}_{1i} + \beta_2 \text{x}_{2i} + ... + \beta_n \text{x}_{ni}$$</span>
<span id="cb795-4997"><a href="#cb795-4997" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-4998"><a href="#cb795-4998" aria-hidden="true" tabindex="-1"></a>In compact form:</span>
<span id="cb795-4999"><a href="#cb795-4999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5000"><a href="#cb795-5000" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha + \sum_{j = 1}^{n} \beta_j \text{x}_{ji}$$</span>
<span id="cb795-5001"><a href="#cb795-5001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5002"><a href="#cb795-5002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5003"><a href="#cb795-5003" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5004"><a href="#cb795-5004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5005"><a href="#cb795-5005" aria-hidden="true" tabindex="-1"></a><span class="in">j = an index over predictor variables </span></span>
<span id="cb795-5006"><a href="#cb795-5006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5007"><a href="#cb795-5007" aria-hidden="true" tabindex="-1"></a><span class="in">n = the number of predictor variables</span></span>
<span id="cb795-5008"><a href="#cb795-5008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5009"><a href="#cb795-5009" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5010"><a href="#cb795-5010" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5011"><a href="#cb795-5011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5012"><a href="#cb795-5012" aria-hidden="true" tabindex="-1"></a>Both of these forms may be read as *the mean is a modeled as the sum of an intercept and an additive combination of the products of parameters and predictors.* Even more compactly, using matrix notation:</span>
<span id="cb795-5013"><a href="#cb795-5013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5014"><a href="#cb795-5014" aria-hidden="true" tabindex="-1"></a>$$m = Xb$$</span>
<span id="cb795-5015"><a href="#cb795-5015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5016"><a href="#cb795-5016" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5017"><a href="#cb795-5017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5018"><a href="#cb795-5018" aria-hidden="true" tabindex="-1"></a><span class="in">m = a vector of predicted means, one for each row in the data</span></span>
<span id="cb795-5019"><a href="#cb795-5019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5020"><a href="#cb795-5020" aria-hidden="true" tabindex="-1"></a><span class="in">b = a (column) vector of parameters, one for each predictor variable</span></span>
<span id="cb795-5021"><a href="#cb795-5021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5022"><a href="#cb795-5022" aria-hidden="true" tabindex="-1"></a><span class="in">X = a matrix</span></span>
<span id="cb795-5023"><a href="#cb795-5023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5024"><a href="#cb795-5024" aria-hidden="true" tabindex="-1"></a><span class="in">This matrix is called a design matrix. It has as many rows as the data, and as many columns as</span></span>
<span id="cb795-5025"><a href="#cb795-5025" aria-hidden="true" tabindex="-1"></a><span class="in">there are predictors plus one. So X is basically a data frame, but with an extra first column. </span></span>
<span id="cb795-5026"><a href="#cb795-5026" aria-hidden="true" tabindex="-1"></a><span class="in">The extra column is filled with 1s. These 1s are multiplied by the first parameter, which is </span></span>
<span id="cb795-5027"><a href="#cb795-5027" aria-hidden="true" tabindex="-1"></a><span class="in">the intercept, and so return the unmodified intercept. When X is matrix-multiplied by b, you get </span></span>
<span id="cb795-5028"><a href="#cb795-5028" aria-hidden="true" tabindex="-1"></a><span class="in">the predicted means. In R notation, this operation is X %*% b.</span></span>
<span id="cb795-5029"><a href="#cb795-5029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5030"><a href="#cb795-5030" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5031"><a href="#cb795-5031" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5032"><a href="#cb795-5032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5033"><a href="#cb795-5033" aria-hidden="true" tabindex="-1"></a><span class="fu">### Fitting the model</span></span>
<span id="cb795-5034"><a href="#cb795-5034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5035"><a href="#cb795-5035" aria-hidden="true" tabindex="-1"></a>To fit this model to the divorce data, we just expand the linear model.</span>
<span id="cb795-5036"><a href="#cb795-5036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5037"><a href="#cb795-5037" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-5038"><a href="#cb795-5038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5039"><a href="#cb795-5039" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-5040"><a href="#cb795-5040" aria-hidden="true" tabindex="-1"></a>\text{D}_i &amp;\sim \text{Normal}(\mu, \sigma)\ &amp;&amp;&amp;  \text{Divorce} \sim \text{dnorm(mu, sigma)}<span class="sc">\\</span></span>
<span id="cb795-5041"><a href="#cb795-5041" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_R R_i + \beta_A A_i\ &amp;&amp;&amp;  \text{mu} \leftarrow \text{a + bR}^* \text{Marriage.s + bA}^* \text{MedianAgeMarriage.s}<span class="sc">\\</span></span>
<span id="cb795-5042"><a href="#cb795-5042" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(10, 10)\ &amp;&amp;&amp;           \text{a} \sim \text{dnorm}(10, 10)<span class="sc">\\</span></span>
<span id="cb795-5043"><a href="#cb795-5043" aria-hidden="true" tabindex="-1"></a>\beta_R &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{bR} \sim \text{dnorm}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-5044"><a href="#cb795-5044" aria-hidden="true" tabindex="-1"></a>\beta_A &amp;\sim \text{Normal}(0, 1)\ &amp;&amp;&amp;            \text{bA} \sim \text{dnorm}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-5045"><a href="#cb795-5045" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 10)\ &amp;&amp;&amp;           \text{sigma} \sim \text{dunif}(0, 10)</span>
<span id="cb795-5046"><a href="#cb795-5046" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-5047"><a href="#cb795-5047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5048"><a href="#cb795-5048" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-5049"><a href="#cb795-5049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5050"><a href="#cb795-5050" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.4}</span></span>
<span id="cb795-5051"><a href="#cb795-5051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5052"><a href="#cb795-5052" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.3</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5053"><a href="#cb795-5053" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5054"><a href="#cb795-5054" aria-hidden="true" tabindex="-1"></a>        Divorce <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5055"><a href="#cb795-5055" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>Marriage.s <span class="sc">+</span> bA<span class="sc">*</span>MedianAgeMarriage.s ,</span>
<span id="cb795-5056"><a href="#cb795-5056" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-5057"><a href="#cb795-5057" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5058"><a href="#cb795-5058" aria-hidden="true" tabindex="-1"></a>        bA <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5059"><a href="#cb795-5059" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-5060"><a href="#cb795-5060" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-5061"><a href="#cb795-5061" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> d )</span>
<span id="cb795-5062"><a href="#cb795-5062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5063"><a href="#cb795-5063" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m5<span class="fl">.3</span> )</span>
<span id="cb795-5064"><a href="#cb795-5064" aria-hidden="true" tabindex="-1"></a><span class="co"># The posterior mean for marriage rate, bR, is now close to zero, with plenty of probability </span></span>
<span id="cb795-5065"><a href="#cb795-5065" aria-hidden="true" tabindex="-1"></a><span class="co"># of both sides of zero. The posterior mean for age at marriage, bA, has actually gotten slightly </span></span>
<span id="cb795-5066"><a href="#cb795-5066" aria-hidden="true" tabindex="-1"></a><span class="co"># farther from zero, but is essentially unchanged.</span></span>
<span id="cb795-5067"><a href="#cb795-5067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5068"><a href="#cb795-5068" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the posterior distribution estimates</span></span>
<span id="cb795-5069"><a href="#cb795-5069" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m5<span class="fl">.3</span>)) <span class="co"># same as plot(m5.3)</span></span>
<span id="cb795-5070"><a href="#cb795-5070" aria-hidden="true" tabindex="-1"></a><span class="co"># The result, with MAP values shown by the points and the percentile intervals </span></span>
<span id="cb795-5071"><a href="#cb795-5071" aria-hidden="true" tabindex="-1"></a><span class="co"># by the solid horizontal lines. </span></span>
<span id="cb795-5072"><a href="#cb795-5072" aria-hidden="true" tabindex="-1"></a><span class="co"># You can interpret these estimates as saying: Once we know median age at marriage for a State, </span></span>
<span id="cb795-5073"><a href="#cb795-5073" aria-hidden="true" tabindex="-1"></a><span class="co"># there is little or no additional predictive power in also knowing the rate of marriage in that State.</span></span>
<span id="cb795-5074"><a href="#cb795-5074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5075"><a href="#cb795-5075" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5076"><a href="#cb795-5076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5077"><a href="#cb795-5077" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5078"><a href="#cb795-5078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5079"><a href="#cb795-5079" aria-hidden="true" tabindex="-1"></a><span class="fu">### Plotting multivariate posteriors</span></span>
<span id="cb795-5080"><a href="#cb795-5080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5081"><a href="#cb795-5081" aria-hidden="true" tabindex="-1"></a>Three types of interpretive plots:</span>
<span id="cb795-5082"><a href="#cb795-5082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5083"><a href="#cb795-5083" aria-hidden="true" tabindex="-1"></a>(1) ***Predictor residual plots.*** These plots show the outcome against residual predictor values.</span>
<span id="cb795-5084"><a href="#cb795-5084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5085"><a href="#cb795-5085" aria-hidden="true" tabindex="-1"></a>(2) ***Counterfactual plots.*** These show the implied predictions for imaginary experiments in which the different predictor variables can be changed independently of one another.</span>
<span id="cb795-5086"><a href="#cb795-5086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5087"><a href="#cb795-5087" aria-hidden="true" tabindex="-1"></a>(3) ***Posterior prediction plots.*** These show model-based predictions against raw data, or otherwise display the error in prediction.</span>
<span id="cb795-5088"><a href="#cb795-5088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5089"><a href="#cb795-5089" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5090"><a href="#cb795-5090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5091"><a href="#cb795-5091" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Predictor residual plots</span></span>
<span id="cb795-5092"><a href="#cb795-5092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5093"><a href="#cb795-5093" aria-hidden="true" tabindex="-1"></a>A predictor variable residual is the average prediction error when we use all of the other predictor variables to model a predictor of interest. The benefit of computing these things is that, once plotted against the outcome, we have a bivariate regression of sorts that has already “controlled” for all of the other predictor variables. It just leaves in the variation that is not expected by the model of the mean, $\mu$, as a function of the other predictors.</span>
<span id="cb795-5094"><a href="#cb795-5094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5095"><a href="#cb795-5095" aria-hidden="true" tabindex="-1"></a>In our multivariate model of divorce rate, we have two predictors: </span>
<span id="cb795-5096"><a href="#cb795-5096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5097"><a href="#cb795-5097" aria-hidden="true" tabindex="-1"></a>(1) marriage rate (Marriage.s) </span>
<span id="cb795-5098"><a href="#cb795-5098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5099"><a href="#cb795-5099" aria-hidden="true" tabindex="-1"></a>(2) median age at marriage (MedianAgeMarriage.s) </span>
<span id="cb795-5100"><a href="#cb795-5100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5101"><a href="#cb795-5101" aria-hidden="true" tabindex="-1"></a>To compute predictor residuals for either, we just use the other predictor to model it. The model for marraige rate:</span>
<span id="cb795-5102"><a href="#cb795-5102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5103"><a href="#cb795-5103" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-5104"><a href="#cb795-5104" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-5105"><a href="#cb795-5105" aria-hidden="true" tabindex="-1"></a>\text{R}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-5106"><a href="#cb795-5106" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta \text{A}_i<span class="sc">\\</span></span>
<span id="cb795-5107"><a href="#cb795-5107" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(0, 10)<span class="sc">\\</span></span>
<span id="cb795-5108"><a href="#cb795-5108" aria-hidden="true" tabindex="-1"></a>\beta &amp;\sim \text{Normal}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-5109"><a href="#cb795-5109" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 10)</span>
<span id="cb795-5110"><a href="#cb795-5110" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-5111"><a href="#cb795-5111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5112"><a href="#cb795-5112" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-5113"><a href="#cb795-5113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5114"><a href="#cb795-5114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5115"><a href="#cb795-5115" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.4a}</span></span>
<span id="cb795-5116"><a href="#cb795-5116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5117"><a href="#cb795-5117" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using standardized variables</span></span>
<span id="cb795-5118"><a href="#cb795-5118" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.4</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5119"><a href="#cb795-5119" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5120"><a href="#cb795-5120" aria-hidden="true" tabindex="-1"></a>        Marriage.s <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5121"><a href="#cb795-5121" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>MedianAgeMarriage.s ,</span>
<span id="cb795-5122"><a href="#cb795-5122" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-5123"><a href="#cb795-5123" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5124"><a href="#cb795-5124" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-5125"><a href="#cb795-5125" aria-hidden="true" tabindex="-1"></a><span class="at">data =</span> d )</span>
<span id="cb795-5126"><a href="#cb795-5126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5127"><a href="#cb795-5127" aria-hidden="true" tabindex="-1"></a><span class="do">## Compute the residuals by subtracting the observed marriage rate in each State from </span></span>
<span id="cb795-5128"><a href="#cb795-5128" aria-hidden="true" tabindex="-1"></a><span class="do">## the predicted rate, based upon median age at marriage</span></span>
<span id="cb795-5129"><a href="#cb795-5129" aria-hidden="true" tabindex="-1"></a><span class="co"># compute expected value at MAP, for each State</span></span>
<span id="cb795-5130"><a href="#cb795-5130" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">coef</span>(m5<span class="fl">.4</span>)[<span class="st">'a'</span>] <span class="sc">+</span> <span class="fu">coef</span>(m5<span class="fl">.4</span>)[<span class="st">'b'</span>]<span class="sc">*</span>d<span class="sc">$</span>MedianAgeMarriage.s</span>
<span id="cb795-5131"><a href="#cb795-5131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5132"><a href="#cb795-5132" aria-hidden="true" tabindex="-1"></a><span class="co"># compute residual for each State</span></span>
<span id="cb795-5133"><a href="#cb795-5133" aria-hidden="true" tabindex="-1"></a>m.resid <span class="ot">&lt;-</span> d<span class="sc">$</span>Marriage.s <span class="sc">-</span> mu</span>
<span id="cb795-5134"><a href="#cb795-5134" aria-hidden="true" tabindex="-1"></a>m.resid</span>
<span id="cb795-5135"><a href="#cb795-5135" aria-hidden="true" tabindex="-1"></a><span class="co"># States with positive residuals marry fast for their age of marriage, </span></span>
<span id="cb795-5136"><a href="#cb795-5136" aria-hidden="true" tabindex="-1"></a><span class="co"># while States with negative residuals marry slow for their age of marriage. </span></span>
<span id="cb795-5137"><a href="#cb795-5137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5138"><a href="#cb795-5138" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the relationship between these two variables, and show the residuals</span></span>
<span id="cb795-5139"><a href="#cb795-5139" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Marriage.s <span class="sc">~</span> MedianAgeMarriage.s , d , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-5140"><a href="#cb795-5140" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( m5<span class="fl">.4</span> )</span>
<span id="cb795-5141"><a href="#cb795-5141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5142"><a href="#cb795-5142" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over States</span></span>
<span id="cb795-5143"><a href="#cb795-5143" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(m.resid) ) {</span>
<span id="cb795-5144"><a href="#cb795-5144" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> d<span class="sc">$</span>MedianAgeMarriage.s[i] <span class="co"># x location of line segment</span></span>
<span id="cb795-5145"><a href="#cb795-5145" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> d<span class="sc">$</span>Marriage.s[i] <span class="co"># observed endpoint of line segment</span></span>
<span id="cb795-5146"><a href="#cb795-5146" aria-hidden="true" tabindex="-1"></a>    <span class="co"># draw the line segment</span></span>
<span id="cb795-5147"><a href="#cb795-5147" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">c</span>(x,x) , <span class="fu">c</span>(mu[i],y) , <span class="at">lwd=</span><span class="fl">0.5</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"black"</span>,<span class="fl">0.7</span>) )</span>
<span id="cb795-5148"><a href="#cb795-5148" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-5149"><a href="#cb795-5149" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual marriage rate in each State, after accounting for the linear association </span></span>
<span id="cb795-5150"><a href="#cb795-5150" aria-hidden="true" tabindex="-1"></a><span class="co"># with median age at marriage. Each gray line segment is a residual, the distance of </span></span>
<span id="cb795-5151"><a href="#cb795-5151" aria-hidden="true" tabindex="-1"></a><span class="co"># each observed marriage rate from the expected value, attempting to predict marriage </span></span>
<span id="cb795-5152"><a href="#cb795-5152" aria-hidden="true" tabindex="-1"></a><span class="co"># rate with median age at marriage alone. So States that lie above the black regression </span></span>
<span id="cb795-5153"><a href="#cb795-5153" aria-hidden="true" tabindex="-1"></a><span class="co"># line have higher rates of marriage than expected, according to age at marriage. </span></span>
<span id="cb795-5154"><a href="#cb795-5154" aria-hidden="true" tabindex="-1"></a><span class="co"># Those below the line have lower rates than expected.</span></span>
<span id="cb795-5155"><a href="#cb795-5155" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice that the residuals are variation in marriage rate that is left over, </span></span>
<span id="cb795-5156"><a href="#cb795-5156" aria-hidden="true" tabindex="-1"></a><span class="co"># after taking out the purely linear relationship between the two variables.</span></span>
<span id="cb795-5157"><a href="#cb795-5157" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5158"><a href="#cb795-5158" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5159"><a href="#cb795-5159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5160"><a href="#cb795-5160" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Residual plots for the divorce rate***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-5161"><a href="#cb795-5161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5162"><a href="#cb795-5162" aria-hidden="true" tabindex="-1"></a><span class="in">```{r divorce}</span></span>
<span id="cb795-5163"><a href="#cb795-5163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5164"><a href="#cb795-5164" aria-hidden="true" tabindex="-1"></a><span class="do">## Compute the predicted divorce rate value at MAP based on marriage rate</span></span>
<span id="cb795-5165"><a href="#cb795-5165" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using standardized variables</span></span>
<span id="cb795-5166"><a href="#cb795-5166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5167"><a href="#cb795-5167" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.41</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5168"><a href="#cb795-5168" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5169"><a href="#cb795-5169" aria-hidden="true" tabindex="-1"></a>        Divorce <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5170"><a href="#cb795-5170" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>Marriage.s ,</span>
<span id="cb795-5171"><a href="#cb795-5171" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-5172"><a href="#cb795-5172" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5173"><a href="#cb795-5173" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-5174"><a href="#cb795-5174" aria-hidden="true" tabindex="-1"></a><span class="at">data =</span> d )</span>
<span id="cb795-5175"><a href="#cb795-5175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5176"><a href="#cb795-5176" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.41</span></span>
<span id="cb795-5177"><a href="#cb795-5177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5178"><a href="#cb795-5178" aria-hidden="true" tabindex="-1"></a><span class="co"># compute expected value at MAP, for each State</span></span>
<span id="cb795-5179"><a href="#cb795-5179" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">coef</span>(m5<span class="fl">.41</span>)[<span class="st">'a'</span>] <span class="sc">+</span> <span class="fu">coef</span>(m5<span class="fl">.41</span>)[<span class="st">'b'</span>]<span class="sc">*</span>d<span class="sc">$</span>Marriage.s</span>
<span id="cb795-5180"><a href="#cb795-5180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5181"><a href="#cb795-5181" aria-hidden="true" tabindex="-1"></a><span class="co"># compute residual for each State</span></span>
<span id="cb795-5182"><a href="#cb795-5182" aria-hidden="true" tabindex="-1"></a>d.resid <span class="ot">&lt;-</span> d<span class="sc">$</span>Divorce <span class="sc">-</span> mu</span>
<span id="cb795-5183"><a href="#cb795-5183" aria-hidden="true" tabindex="-1"></a>d.resid</span>
<span id="cb795-5184"><a href="#cb795-5184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5185"><a href="#cb795-5185" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the relationship between these two variables, and show the residuals</span></span>
<span id="cb795-5186"><a href="#cb795-5186" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> Marriage.s , d , <span class="at">col=</span><span class="st">"brown"</span> , <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb795-5187"><a href="#cb795-5187" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( m5<span class="fl">.41</span>, <span class="at">col =</span> <span class="st">"brown"</span>)</span>
<span id="cb795-5188"><a href="#cb795-5188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5189"><a href="#cb795-5189" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over States</span></span>
<span id="cb795-5190"><a href="#cb795-5190" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(d.resid) ) {</span>
<span id="cb795-5191"><a href="#cb795-5191" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> d<span class="sc">$</span>Marriage.s[i] <span class="co"># x location of line segment</span></span>
<span id="cb795-5192"><a href="#cb795-5192" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> d<span class="sc">$</span>Divorce[i] <span class="co"># observed endpoint of line segment</span></span>
<span id="cb795-5193"><a href="#cb795-5193" aria-hidden="true" tabindex="-1"></a>    <span class="co"># draw the line segment</span></span>
<span id="cb795-5194"><a href="#cb795-5194" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">c</span>(x,x) , <span class="fu">c</span>(mu[i],y) , <span class="at">lwd=</span><span class="fl">0.5</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"brown"</span>,<span class="fl">0.7</span>) )</span>
<span id="cb795-5195"><a href="#cb795-5195" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-5196"><a href="#cb795-5196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5197"><a href="#cb795-5197" aria-hidden="true" tabindex="-1"></a><span class="co"># To add PI shade</span></span>
<span id="cb795-5198"><a href="#cb795-5198" aria-hidden="true" tabindex="-1"></a><span class="co"># compute percentile interval of mean</span></span>
<span id="cb795-5199"><a href="#cb795-5199" aria-hidden="true" tabindex="-1"></a>MAM.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="sc">-</span><span class="dv">2</span> , <span class="at">to=</span><span class="dv">3</span> , <span class="at">length.out=</span><span class="dv">30</span> )</span>
<span id="cb795-5200"><a href="#cb795-5200" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.41</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">Marriage.s=</span>MAM.seq) )</span>
<span id="cb795-5201"><a href="#cb795-5201" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5202"><a href="#cb795-5202" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, MAM.seq, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"brown"</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>))</span>
<span id="cb795-5203"><a href="#cb795-5203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5204"><a href="#cb795-5204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5205"><a href="#cb795-5205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5206"><a href="#cb795-5206" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5207"><a href="#cb795-5207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5208"><a href="#cb795-5208" aria-hidden="true" tabindex="-1"></a><span class="in">```{r divorce1}</span></span>
<span id="cb795-5209"><a href="#cb795-5209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5210"><a href="#cb795-5210" aria-hidden="true" tabindex="-1"></a><span class="do">## Compute the predicted divorce rate value at MAP based on median age of marriage</span></span>
<span id="cb795-5211"><a href="#cb795-5211" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using standardized variables</span></span>
<span id="cb795-5212"><a href="#cb795-5212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5213"><a href="#cb795-5213" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.42</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5214"><a href="#cb795-5214" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5215"><a href="#cb795-5215" aria-hidden="true" tabindex="-1"></a>        Divorce <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5216"><a href="#cb795-5216" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>MedianAgeMarriage.s ,</span>
<span id="cb795-5217"><a href="#cb795-5217" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-5218"><a href="#cb795-5218" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5219"><a href="#cb795-5219" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-5220"><a href="#cb795-5220" aria-hidden="true" tabindex="-1"></a><span class="at">data =</span> d )</span>
<span id="cb795-5221"><a href="#cb795-5221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5222"><a href="#cb795-5222" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.42</span></span>
<span id="cb795-5223"><a href="#cb795-5223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5224"><a href="#cb795-5224" aria-hidden="true" tabindex="-1"></a><span class="co"># compute expected value at MAP, for each State</span></span>
<span id="cb795-5225"><a href="#cb795-5225" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">coef</span>(m5<span class="fl">.42</span>)[<span class="st">'a'</span>] <span class="sc">+</span> <span class="fu">coef</span>(m5<span class="fl">.42</span>)[<span class="st">'b'</span>]<span class="sc">*</span>d<span class="sc">$</span>MedianAgeMarriage.s</span>
<span id="cb795-5226"><a href="#cb795-5226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5227"><a href="#cb795-5227" aria-hidden="true" tabindex="-1"></a><span class="co"># compute residual for each State</span></span>
<span id="cb795-5228"><a href="#cb795-5228" aria-hidden="true" tabindex="-1"></a>d.resid <span class="ot">&lt;-</span> d<span class="sc">$</span>Divorce <span class="sc">-</span> mu</span>
<span id="cb795-5229"><a href="#cb795-5229" aria-hidden="true" tabindex="-1"></a>d.resid</span>
<span id="cb795-5230"><a href="#cb795-5230" aria-hidden="true" tabindex="-1"></a><span class="co"># States with positive residuals marry fast for their age of marriage, </span></span>
<span id="cb795-5231"><a href="#cb795-5231" aria-hidden="true" tabindex="-1"></a><span class="co"># while States with negative residuals marry slow for their age of marriage. </span></span>
<span id="cb795-5232"><a href="#cb795-5232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5233"><a href="#cb795-5233" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the relationship between these two variables, and show the residuals</span></span>
<span id="cb795-5234"><a href="#cb795-5234" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> MedianAgeMarriage.s , d , <span class="at">col=</span><span class="st">"brown"</span> , <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb795-5235"><a href="#cb795-5235" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( m5<span class="fl">.42</span>, <span class="at">col =</span> <span class="st">"brown"</span>)</span>
<span id="cb795-5236"><a href="#cb795-5236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5237"><a href="#cb795-5237" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over States</span></span>
<span id="cb795-5238"><a href="#cb795-5238" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(d.resid) ) {</span>
<span id="cb795-5239"><a href="#cb795-5239" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> d<span class="sc">$</span>MedianAgeMarriage.s[i] <span class="co"># x location of line segment</span></span>
<span id="cb795-5240"><a href="#cb795-5240" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> d<span class="sc">$</span>Divorce[i] <span class="co"># observed endpoint of line segment</span></span>
<span id="cb795-5241"><a href="#cb795-5241" aria-hidden="true" tabindex="-1"></a>    <span class="co"># draw the line segment</span></span>
<span id="cb795-5242"><a href="#cb795-5242" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">c</span>(x,x) , <span class="fu">c</span>(mu[i],y) , <span class="at">lwd=</span><span class="fl">0.5</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"brown"</span>,<span class="fl">0.7</span>) )</span>
<span id="cb795-5243"><a href="#cb795-5243" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-5244"><a href="#cb795-5244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5245"><a href="#cb795-5245" aria-hidden="true" tabindex="-1"></a><span class="co"># To add PI shade</span></span>
<span id="cb795-5246"><a href="#cb795-5246" aria-hidden="true" tabindex="-1"></a><span class="co"># compute percentile interval of mean</span></span>
<span id="cb795-5247"><a href="#cb795-5247" aria-hidden="true" tabindex="-1"></a>MAM.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="sc">-</span><span class="dv">3</span> , <span class="at">to=</span><span class="dv">4</span> , <span class="at">length.out=</span><span class="dv">30</span> )</span>
<span id="cb795-5248"><a href="#cb795-5248" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.42</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">MedianAgeMarriage.s=</span>MAM.seq) )</span>
<span id="cb795-5249"><a href="#cb795-5249" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5250"><a href="#cb795-5250" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, MAM.seq, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"brown"</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>))</span>
<span id="cb795-5251"><a href="#cb795-5251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5252"><a href="#cb795-5252" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5253"><a href="#cb795-5253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5254"><a href="#cb795-5254" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5255"><a href="#cb795-5255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5256"><a href="#cb795-5256" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Predictor residual plots for the divorce data***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-5257"><a href="#cb795-5257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5258"><a href="#cb795-5258" aria-hidden="true" tabindex="-1"></a><span class="in">```{r divorce2}</span></span>
<span id="cb795-5259"><a href="#cb795-5259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5260"><a href="#cb795-5260" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-5261"><a href="#cb795-5261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5262"><a href="#cb795-5262" aria-hidden="true" tabindex="-1"></a><span class="do">## Divorce rate vs. marriage rate residuals</span></span>
<span id="cb795-5263"><a href="#cb795-5263" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a map model for divorce rate based on marriage rate residuals</span></span>
<span id="cb795-5264"><a href="#cb795-5264" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.43</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5265"><a href="#cb795-5265" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-5266"><a href="#cb795-5266" aria-hidden="true" tabindex="-1"></a>    Divorce <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-5267"><a href="#cb795-5267" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>m.resid,</span>
<span id="cb795-5268"><a href="#cb795-5268" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-5269"><a href="#cb795-5269" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-5270"><a href="#cb795-5270" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-5271"><a href="#cb795-5271" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-5272"><a href="#cb795-5272" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-5273"><a href="#cb795-5273" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5274"><a href="#cb795-5274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5275"><a href="#cb795-5275" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.43</span></span>
<span id="cb795-5276"><a href="#cb795-5276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5277"><a href="#cb795-5277" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb795-5278"><a href="#cb795-5278" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Divorce <span class="sc">~</span> m.resid, d, <span class="at">col =</span> rangi2, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">16</span>),</span>
<span id="cb795-5279"><a href="#cb795-5279" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Marriage rate residuals"</span>, <span class="at">ylab =</span> <span class="st">"Divorce rate"</span>)</span>
<span id="cb795-5280"><a href="#cb795-5280" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m5<span class="fl">.43</span>)</span>
<span id="cb795-5281"><a href="#cb795-5281" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb795-5282"><a href="#cb795-5282" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.05</span>, <span class="dv">15</span>, <span class="st">"faster"</span>, <span class="at">pos =</span> <span class="dv">4</span>)  </span>
<span id="cb795-5283"><a href="#cb795-5283" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="sc">-</span><span class="fl">0.05</span>, <span class="dv">15</span>, <span class="st">"slower"</span>, <span class="at">pos =</span> <span class="dv">2</span>)</span>
<span id="cb795-5284"><a href="#cb795-5284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5285"><a href="#cb795-5285" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI </span></span>
<span id="cb795-5286"><a href="#cb795-5286" aria-hidden="true" tabindex="-1"></a>mar.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">to =</span> <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">30</span>)</span>
<span id="cb795-5287"><a href="#cb795-5287" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m5<span class="fl">.43</span>, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">m.resid =</span> mar.seq))</span>
<span id="cb795-5288"><a href="#cb795-5288" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI)</span>
<span id="cb795-5289"><a href="#cb795-5289" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, mar.seq)</span>
<span id="cb795-5290"><a href="#cb795-5290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5291"><a href="#cb795-5291" aria-hidden="true" tabindex="-1"></a><span class="do">## Divorce rate Vs. Age of marriage residuals</span></span>
<span id="cb795-5292"><a href="#cb795-5292" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using standardized variables</span></span>
<span id="cb795-5293"><a href="#cb795-5293" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.44</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5294"><a href="#cb795-5294" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5295"><a href="#cb795-5295" aria-hidden="true" tabindex="-1"></a>        MedianAgeMarriage.s <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5296"><a href="#cb795-5296" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>Marriage.s ,</span>
<span id="cb795-5297"><a href="#cb795-5297" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-5298"><a href="#cb795-5298" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5299"><a href="#cb795-5299" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-5300"><a href="#cb795-5300" aria-hidden="true" tabindex="-1"></a><span class="at">data =</span> d )</span>
<span id="cb795-5301"><a href="#cb795-5301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5302"><a href="#cb795-5302" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.44</span></span>
<span id="cb795-5303"><a href="#cb795-5303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5304"><a href="#cb795-5304" aria-hidden="true" tabindex="-1"></a><span class="co"># compute expected value at MAP, for each State</span></span>
<span id="cb795-5305"><a href="#cb795-5305" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">coef</span>(m5<span class="fl">.44</span>)[<span class="st">'a'</span>] <span class="sc">+</span> <span class="fu">coef</span>(m5<span class="fl">.44</span>)[<span class="st">'b'</span>]<span class="sc">*</span>d<span class="sc">$</span>Marriage.s</span>
<span id="cb795-5306"><a href="#cb795-5306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5307"><a href="#cb795-5307" aria-hidden="true" tabindex="-1"></a><span class="co"># compute residual for each State</span></span>
<span id="cb795-5308"><a href="#cb795-5308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5309"><a href="#cb795-5309" aria-hidden="true" tabindex="-1"></a>ma.resid <span class="ot">&lt;-</span> d<span class="sc">$</span>MedianAgeMarriage.s <span class="sc">-</span> mu</span>
<span id="cb795-5310"><a href="#cb795-5310" aria-hidden="true" tabindex="-1"></a>ma.resid</span>
<span id="cb795-5311"><a href="#cb795-5311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5312"><a href="#cb795-5312" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate residual for median age of marriage</span></span>
<span id="cb795-5313"><a href="#cb795-5313" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a map model of divorce rate based on median age of marriage</span></span>
<span id="cb795-5314"><a href="#cb795-5314" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.45</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5315"><a href="#cb795-5315" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-5316"><a href="#cb795-5316" aria-hidden="true" tabindex="-1"></a>    Divorce <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-5317"><a href="#cb795-5317" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>ma.resid,</span>
<span id="cb795-5318"><a href="#cb795-5318" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-5319"><a href="#cb795-5319" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-5320"><a href="#cb795-5320" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-5321"><a href="#cb795-5321" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-5322"><a href="#cb795-5322" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-5323"><a href="#cb795-5323" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5324"><a href="#cb795-5324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5325"><a href="#cb795-5325" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.45</span></span>
<span id="cb795-5326"><a href="#cb795-5326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5327"><a href="#cb795-5327" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb795-5328"><a href="#cb795-5328" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Divorce <span class="sc">~</span> ma.resid, d, <span class="at">col =</span> rangi2, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">16</span>),</span>
<span id="cb795-5329"><a href="#cb795-5329" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Age of marriage residuals"</span>, <span class="at">ylab =</span> <span class="st">"Divorce rate"</span>)</span>
<span id="cb795-5330"><a href="#cb795-5330" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m5<span class="fl">.45</span>)</span>
<span id="cb795-5331"><a href="#cb795-5331" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="dv">0</span>, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb795-5332"><a href="#cb795-5332" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.05</span>, <span class="dv">15</span>, <span class="st">"older"</span>, <span class="at">pos =</span> <span class="dv">4</span>)  </span>
<span id="cb795-5333"><a href="#cb795-5333" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="sc">-</span><span class="fl">0.05</span>, <span class="dv">15</span>, <span class="st">"younger"</span>, <span class="at">pos =</span> <span class="dv">2</span>)</span>
<span id="cb795-5334"><a href="#cb795-5334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5335"><a href="#cb795-5335" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade PI </span></span>
<span id="cb795-5336"><a href="#cb795-5336" aria-hidden="true" tabindex="-1"></a>mar.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">3</span>, <span class="at">to =</span> <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">30</span>)</span>
<span id="cb795-5337"><a href="#cb795-5337" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m5<span class="fl">.45</span>, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">ma.resid =</span> mar.seq))</span>
<span id="cb795-5338"><a href="#cb795-5338" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI)</span>
<span id="cb795-5339"><a href="#cb795-5339" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, mar.seq)</span>
<span id="cb795-5340"><a href="#cb795-5340" aria-hidden="true" tabindex="-1"></a><span class="co"># Left: States with fast marriage rates for their median age of marriage have about </span></span>
<span id="cb795-5341"><a href="#cb795-5341" aria-hidden="true" tabindex="-1"></a><span class="co"># the same divorce rates as do States with slow marriage rates. This plot displays the </span></span>
<span id="cb795-5342"><a href="#cb795-5342" aria-hidden="true" tabindex="-1"></a><span class="co"># linear relationship between divorce and marriage rates, having statistically </span></span>
<span id="cb795-5343"><a href="#cb795-5343" aria-hidden="true" tabindex="-1"></a><span class="co"># “controlled” for median age of marriage. The vertical dashed line indicates marriage </span></span>
<span id="cb795-5344"><a href="#cb795-5344" aria-hidden="true" tabindex="-1"></a><span class="co"># rate that exactly matches the expectation from median age at marriage. The slope of </span></span>
<span id="cb795-5345"><a href="#cb795-5345" aria-hidden="true" tabindex="-1"></a><span class="co"># the regression line is −0.13, exactly what we found in the multivariate model, m5.3.</span></span>
<span id="cb795-5346"><a href="#cb795-5346" aria-hidden="true" tabindex="-1"></a><span class="do">## I got -0.17 for residual plot here.</span></span>
<span id="cb795-5347"><a href="#cb795-5347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5348"><a href="#cb795-5348" aria-hidden="true" tabindex="-1"></a><span class="co"># Right: States with old median age of marriage for their marriage rate have lower </span></span>
<span id="cb795-5349"><a href="#cb795-5349" aria-hidden="true" tabindex="-1"></a><span class="co"># divorce rates, while States with young median age of marriage have higher divorce rates.</span></span>
<span id="cb795-5350"><a href="#cb795-5350" aria-hidden="true" tabindex="-1"></a><span class="co"># This plot displays linear relationship between divorce and median age at marriage, </span></span>
<span id="cb795-5351"><a href="#cb795-5351" aria-hidden="true" tabindex="-1"></a><span class="co"># “controlling” for marriage rate. The slope of the regression line </span></span>
<span id="cb795-5352"><a href="#cb795-5352" aria-hidden="true" tabindex="-1"></a><span class="co"># here is −1.13, again the same as in the multivariate model, m5.3.</span></span>
<span id="cb795-5353"><a href="#cb795-5353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5354"><a href="#cb795-5354" aria-hidden="true" tabindex="-1"></a><span class="co"># There’s direct value in seeing the model-based predictions displayed against the outcome, </span></span>
<span id="cb795-5355"><a href="#cb795-5355" aria-hidden="true" tabindex="-1"></a><span class="co"># after subtracting out the influence of other predictors.</span></span>
<span id="cb795-5356"><a href="#cb795-5356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5357"><a href="#cb795-5357" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5358"><a href="#cb795-5358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5359"><a href="#cb795-5359" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5360"><a href="#cb795-5360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5361"><a href="#cb795-5361" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Counterfactual plots</span></span>
<span id="cb795-5362"><a href="#cb795-5362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5363"><a href="#cb795-5363" aria-hidden="true" tabindex="-1"></a>A second sort of inferential plot displays the implied predictions of the model. The counterfactual plots can be produced for any values of the predictor variables you like, even unobserved or impossible combinations. </span>
<span id="cb795-5364"><a href="#cb795-5364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5365"><a href="#cb795-5365" aria-hidden="true" tabindex="-1"></a>The simplest use of a counterfactual plot is to see how the predictions change as you change only one predictor at a time. This means holding the values of all predictors constant, except for a single predictor of interest. Such predictions will not necessarily look like your raw data— they are counterfactual after all— but they will help you understand the implications of the model.</span>
<span id="cb795-5366"><a href="#cb795-5366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5367"><a href="#cb795-5367" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5368"><a href="#cb795-5368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5369"><a href="#cb795-5369" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/span</span> <span class="er">style="color:purple"</span><span class="kw">&gt;</span>***Counterfactual plots for the multivariate divorce model, m5.3***<span class="kw">&lt;span&gt;</span></span>
<span id="cb795-5370"><a href="#cb795-5370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5371"><a href="#cb795-5371" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.9}</span></span>
<span id="cb795-5372"><a href="#cb795-5372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5373"><a href="#cb795-5373" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-5374"><a href="#cb795-5374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5375"><a href="#cb795-5375" aria-hidden="true" tabindex="-1"></a><span class="do">## Begin with a plot showing the impact of changes in Marriage.s on predictions</span></span>
<span id="cb795-5376"><a href="#cb795-5376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5377"><a href="#cb795-5377" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare new counterfactual data</span></span>
<span id="cb795-5378"><a href="#cb795-5378" aria-hidden="true" tabindex="-1"></a>A.avg <span class="ot">&lt;-</span> <span class="fu">mean</span>( d<span class="sc">$</span>MedianAgeMarriage.s ) </span>
<span id="cb795-5379"><a href="#cb795-5379" aria-hidden="true" tabindex="-1"></a>R.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="sc">-</span><span class="dv">3</span> , <span class="at">to=</span><span class="dv">3</span> , <span class="at">length.out=</span><span class="dv">30</span> )</span>
<span id="cb795-5380"><a href="#cb795-5380" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-5381"><a href="#cb795-5381" aria-hidden="true" tabindex="-1"></a>    <span class="at">Marriage.s=</span>R.seq,</span>
<span id="cb795-5382"><a href="#cb795-5382" aria-hidden="true" tabindex="-1"></a>    <span class="at">MedianAgeMarriage.s=</span>A.avg</span>
<span id="cb795-5383"><a href="#cb795-5383" aria-hidden="true" tabindex="-1"></a>) <span class="co"># Marriage.s changes across the values in MR.seq, while the other predictor is held </span></span>
<span id="cb795-5384"><a href="#cb795-5384" aria-hidden="true" tabindex="-1"></a>  <span class="co"># constant at its mean, MAM.avg</span></span>
<span id="cb795-5385"><a href="#cb795-5385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5386"><a href="#cb795-5386" aria-hidden="true" tabindex="-1"></a><span class="co"># compute counterfactual mean divorce (mu)</span></span>
<span id="cb795-5387"><a href="#cb795-5387" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.3</span> , <span class="at">data=</span>pred.data ) <span class="co">#m5.3: divorce based on marriage.s &amp; MedianAgemarriage.s</span></span>
<span id="cb795-5388"><a href="#cb795-5388" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5389"><a href="#cb795-5389" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5390"><a href="#cb795-5390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5391"><a href="#cb795-5391" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate counterfactual divorce outcomes</span></span>
<span id="cb795-5392"><a href="#cb795-5392" aria-hidden="true" tabindex="-1"></a>R.sim <span class="ot">&lt;-</span> <span class="fu">sim</span>( m5<span class="fl">.3</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5393"><a href="#cb795-5393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5394"><a href="#cb795-5394" aria-hidden="true" tabindex="-1"></a>R.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( R.sim , <span class="dv">2</span> , PI )</span>
<span id="cb795-5395"><a href="#cb795-5395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5396"><a href="#cb795-5396" aria-hidden="true" tabindex="-1"></a><span class="co"># display predictions, hiding raw data with type="n"</span></span>
<span id="cb795-5397"><a href="#cb795-5397" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> Marriage.s , <span class="at">data=</span>d , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-5398"><a href="#cb795-5398" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">"MedianAgeMarriage.s = 0"</span> )</span>
<span id="cb795-5399"><a href="#cb795-5399" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( R.seq , mu.mean )</span>
<span id="cb795-5400"><a href="#cb795-5400" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , R.seq )</span>
<span id="cb795-5401"><a href="#cb795-5401" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( R.PI , R.seq )</span>
<span id="cb795-5402"><a href="#cb795-5402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5403"><a href="#cb795-5403" aria-hidden="true" tabindex="-1"></a><span class="do">## Now with Marriage.s set to its average and MedianAgeMarriage.s allowed to vary</span></span>
<span id="cb795-5404"><a href="#cb795-5404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5405"><a href="#cb795-5405" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare new counterfactual data</span></span>
<span id="cb795-5406"><a href="#cb795-5406" aria-hidden="true" tabindex="-1"></a>R.avg <span class="ot">&lt;-</span> <span class="fu">mean</span>( d<span class="sc">$</span>Marriage.s )</span>
<span id="cb795-5407"><a href="#cb795-5407" aria-hidden="true" tabindex="-1"></a>A.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>( <span class="at">from=</span><span class="sc">-</span><span class="dv">3</span> , <span class="at">to=</span><span class="fl">3.5</span> , <span class="at">length.out=</span><span class="dv">30</span> )</span>
<span id="cb795-5408"><a href="#cb795-5408" aria-hidden="true" tabindex="-1"></a>pred.data2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-5409"><a href="#cb795-5409" aria-hidden="true" tabindex="-1"></a>    <span class="at">Marriage.s=</span>R.avg,</span>
<span id="cb795-5410"><a href="#cb795-5410" aria-hidden="true" tabindex="-1"></a>    <span class="at">MedianAgeMarriage.s=</span>A.seq</span>
<span id="cb795-5411"><a href="#cb795-5411" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5412"><a href="#cb795-5412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5413"><a href="#cb795-5413" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate counterfactual mean divorce (mu)</span></span>
<span id="cb795-5414"><a href="#cb795-5414" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.3</span> , <span class="at">data=</span>pred.data2 )</span>
<span id="cb795-5415"><a href="#cb795-5415" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5416"><a href="#cb795-5416" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5417"><a href="#cb795-5417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5418"><a href="#cb795-5418" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate counterfactual divorce outcomes</span></span>
<span id="cb795-5419"><a href="#cb795-5419" aria-hidden="true" tabindex="-1"></a>A.sim <span class="ot">&lt;-</span> <span class="fu">sim</span>( m5<span class="fl">.3</span> , <span class="at">data=</span>pred.data2 , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5420"><a href="#cb795-5420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5421"><a href="#cb795-5421" aria-hidden="true" tabindex="-1"></a>A.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( A.sim , <span class="dv">2</span> , PI )</span>
<span id="cb795-5422"><a href="#cb795-5422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5423"><a href="#cb795-5423" aria-hidden="true" tabindex="-1"></a><span class="co"># display predictions, hiding raw data with type="n"</span></span>
<span id="cb795-5424"><a href="#cb795-5424" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( Divorce <span class="sc">~</span> MedianAgeMarriage.s , <span class="at">data=</span>d , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-5425"><a href="#cb795-5425" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">"Marriage.s = 0"</span> )</span>
<span id="cb795-5426"><a href="#cb795-5426" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( A.seq , mu.mean )</span>
<span id="cb795-5427"><a href="#cb795-5427" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.PI , A.seq )</span>
<span id="cb795-5428"><a href="#cb795-5428" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( A.PI , A.seq )</span>
<span id="cb795-5429"><a href="#cb795-5429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5430"><a href="#cb795-5430" aria-hidden="true" tabindex="-1"></a><span class="co"># Each plot shows the change in predicted mean across values of a single predictor, </span></span>
<span id="cb795-5431"><a href="#cb795-5431" aria-hidden="true" tabindex="-1"></a><span class="co"># holding the other predictor constant at its mean value (zero in both cases). </span></span>
<span id="cb795-5432"><a href="#cb795-5432" aria-hidden="true" tabindex="-1"></a><span class="co"># Shaded regions show 89% percentile intervals of the mean (dark, narrow) and </span></span>
<span id="cb795-5433"><a href="#cb795-5433" aria-hidden="true" tabindex="-1"></a><span class="co"># 89% prediction intervals (light, wide).</span></span>
<span id="cb795-5434"><a href="#cb795-5434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5435"><a href="#cb795-5435" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5436"><a href="#cb795-5436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5437"><a href="#cb795-5437" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5438"><a href="#cb795-5438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5439"><a href="#cb795-5439" aria-hidden="true" tabindex="-1"></a>In this example, the difficulty of separately manipulating marriage rate and marriage age doesn’t impede inference much, only because marriage rate has almost no effect on prediction, once median age of marriage is taken into account. But in many problems, more than one predictor variable has a sizable impact on the outcome. In that case, while these counterfactual plots always help in understanding the model, they may also mislead by displaying predictions for impossible combinations of predictor values. If our goal is to intervene in the world, there may not be any realistic way to manipulate each predictor without also manipulating the others. </span>
<span id="cb795-5440"><a href="#cb795-5440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5441"><a href="#cb795-5441" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5442"><a href="#cb795-5442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5443"><a href="#cb795-5443" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Posterior prediction plots</span></span>
<span id="cb795-5444"><a href="#cb795-5444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5445"><a href="#cb795-5445" aria-hidden="true" tabindex="-1"></a>Checking the model fit against the observed data is useful in many ways. Two uses among them are:</span>
<span id="cb795-5446"><a href="#cb795-5446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5447"><a href="#cb795-5447" aria-hidden="true" tabindex="-1"></a>(1) Did the model fit correctly?</span>
<span id="cb795-5448"><a href="#cb795-5448" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Many common software and user errors can be more easily diagnosed by comparing implied predictions to the raw data. Some caution is required, because not all models try to exactly match the sample.</span>
<span id="cb795-5449"><a href="#cb795-5449" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-5450"><a href="#cb795-5450" aria-hidden="true" tabindex="-1"></a>(2) How does the model fail?</span>
<span id="cb795-5451"><a href="#cb795-5451" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Sometimes, the model fits correctly but is still so poor for our purposes that it must be discarded. More often, a model predicts well in some respects, but not in others. By inspecting the individual cases where the model makes poor predictions, you might get an idea of how to improve the model.</span>
<span id="cb795-5452"><a href="#cb795-5452" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-5453"><a href="#cb795-5453" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5454"><a href="#cb795-5454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5455"><a href="#cb795-5455" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Posterior predictive plots for the multivariate divorce model, m5.3***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-5456"><a href="#cb795-5456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5457"><a href="#cb795-5457" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.11}</span></span>
<span id="cb795-5458"><a href="#cb795-5458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5459"><a href="#cb795-5459" aria-hidden="true" tabindex="-1"></a><span class="do">## begin by simulating predictions, averaging over the posterior</span></span>
<span id="cb795-5460"><a href="#cb795-5460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5461"><a href="#cb795-5461" aria-hidden="true" tabindex="-1"></a><span class="co"># call link without specifying new data</span></span>
<span id="cb795-5462"><a href="#cb795-5462" aria-hidden="true" tabindex="-1"></a><span class="co"># so it uses original data</span></span>
<span id="cb795-5463"><a href="#cb795-5463" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.3</span> )</span>
<span id="cb795-5464"><a href="#cb795-5464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5465"><a href="#cb795-5465" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize samples across cases</span></span>
<span id="cb795-5466"><a href="#cb795-5466" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5467"><a href="#cb795-5467" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5468"><a href="#cb795-5468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5469"><a href="#cb795-5469" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate observations</span></span>
<span id="cb795-5470"><a href="#cb795-5470" aria-hidden="true" tabindex="-1"></a><span class="co"># again no new data, so uses original data</span></span>
<span id="cb795-5471"><a href="#cb795-5471" aria-hidden="true" tabindex="-1"></a>divorce.sim <span class="ot">&lt;-</span> <span class="fu">sim</span>( m5<span class="fl">.3</span> , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5472"><a href="#cb795-5472" aria-hidden="true" tabindex="-1"></a>divorce.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( divorce.sim , <span class="dv">2</span> , PI )</span>
<span id="cb795-5473"><a href="#cb795-5473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5474"><a href="#cb795-5474" aria-hidden="true" tabindex="-1"></a><span class="co"># plot predictions against observed</span></span>
<span id="cb795-5475"><a href="#cb795-5475" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( mu.mean <span class="sc">~</span> d<span class="sc">$</span>Divorce , <span class="at">col=</span>rangi2 , <span class="at">ylim=</span><span class="fu">range</span>(mu.PI) ,</span>
<span id="cb795-5476"><a href="#cb795-5476" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">"Observed divorce"</span> , <span class="at">ylab=</span><span class="st">"Predicted divorce"</span>)</span>
<span id="cb795-5477"><a href="#cb795-5477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5478"><a href="#cb795-5478" aria-hidden="true" tabindex="-1"></a><span class="co">#  add a line to show perfect prediction and </span></span>
<span id="cb795-5479"><a href="#cb795-5479" aria-hidden="true" tabindex="-1"></a><span class="co"># line segments for the confidence interval of each prediction</span></span>
<span id="cb795-5480"><a href="#cb795-5480" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">a=</span><span class="dv">0</span> , <span class="at">b=</span><span class="dv">1</span> , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5481"><a href="#cb795-5481" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(d) )</span>
<span id="cb795-5482"><a href="#cb795-5482" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">rep</span>(d<span class="sc">$</span>Divorce[i],<span class="dv">2</span>) , <span class="fu">c</span>(mu.PI[<span class="dv">1</span>,i],mu.PI[<span class="dv">2</span>,i]) ,</span>
<span id="cb795-5483"><a href="#cb795-5483" aria-hidden="true" tabindex="-1"></a>        <span class="at">col=</span>rangi2 )</span>
<span id="cb795-5484"><a href="#cb795-5484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5485"><a href="#cb795-5485" aria-hidden="true" tabindex="-1"></a><span class="co"># label a few select points using 'identify' (only work in R Script)</span></span>
<span id="cb795-5486"><a href="#cb795-5486" aria-hidden="true" tabindex="-1"></a><span class="co"># identify( x=d$Divorce , y=mu.mean , labels=d$Loc , cex=0.8 )</span></span>
<span id="cb795-5487"><a href="#cb795-5487" aria-hidden="true" tabindex="-1"></a><span class="co"># rmarkdown doesn't allow to select data points </span></span>
<span id="cb795-5488"><a href="#cb795-5488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5489"><a href="#cb795-5489" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the indices of the points to label</span></span>
<span id="cb795-5490"><a href="#cb795-5490" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">13</span>, <span class="dv">44</span>)  </span>
<span id="cb795-5491"><a href="#cb795-5491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5492"><a href="#cb795-5492" aria-hidden="true" tabindex="-1"></a><span class="co"># Add text labels to specific points</span></span>
<span id="cb795-5493"><a href="#cb795-5493" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> d<span class="sc">$</span>Divorce[indices], <span class="at">y =</span> mu.mean[indices], <span class="at">labels =</span> d<span class="sc">$</span>Loc[indices], <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">pos =</span> <span class="dv">2</span>)</span>
<span id="cb795-5494"><a href="#cb795-5494" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted divorce rate against observed, with 89% confidence in- tervals of the average prediction. </span></span>
<span id="cb795-5495"><a href="#cb795-5495" aria-hidden="true" tabindex="-1"></a><span class="co"># The dashed line shows perfect prediction. The model under-predicts for States with very high divorce </span></span>
<span id="cb795-5496"><a href="#cb795-5496" aria-hidden="true" tabindex="-1"></a><span class="co"># rates while it over-predicts for States with very low divorce rates- e.g., Idaho (ID) and Utah (UT), </span></span>
<span id="cb795-5497"><a href="#cb795-5497" aria-hidden="true" tabindex="-1"></a><span class="co"># both of which have much lower divorce rates than the model expects them to have.</span></span>
<span id="cb795-5498"><a href="#cb795-5498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5499"><a href="#cb795-5499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5500"><a href="#cb795-5500" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5501"><a href="#cb795-5501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5502"><a href="#cb795-5502" aria-hidden="true" tabindex="-1"></a>The plot above makes it hard to see the amount of prediction error, in many cases. For this reason, lots of people also use residual plots that show the mean prediction error for each row. </span>
<span id="cb795-5503"><a href="#cb795-5503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5504"><a href="#cb795-5504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5505"><a href="#cb795-5505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.14, fig.height=8}</span></span>
<span id="cb795-5506"><a href="#cb795-5506" aria-hidden="true" tabindex="-1"></a><span class="co"># compute residuals</span></span>
<span id="cb795-5507"><a href="#cb795-5507" aria-hidden="true" tabindex="-1"></a>divorce.resid <span class="ot">&lt;-</span> d<span class="sc">$</span>Divorce <span class="sc">-</span> mu.mean</span>
<span id="cb795-5508"><a href="#cb795-5508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5509"><a href="#cb795-5509" aria-hidden="true" tabindex="-1"></a><span class="co"># get ordering by divorce rate</span></span>
<span id="cb795-5510"><a href="#cb795-5510" aria-hidden="true" tabindex="-1"></a>o <span class="ot">&lt;-</span> <span class="fu">order</span>(divorce.resid)</span>
<span id="cb795-5511"><a href="#cb795-5511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5512"><a href="#cb795-5512" aria-hidden="true" tabindex="-1"></a><span class="co"># make the plot</span></span>
<span id="cb795-5513"><a href="#cb795-5513" aria-hidden="true" tabindex="-1"></a><span class="fu">dotchart</span>( divorce.resid[o] , <span class="at">labels=</span>d<span class="sc">$</span>Loc[o] , <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">6</span>,<span class="dv">5</span>) , <span class="at">cex=</span><span class="fl">0.7</span>)</span>
<span id="cb795-5514"><a href="#cb795-5514" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>( <span class="at">v=</span><span class="dv">0</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"black"</span>,<span class="fl">0.2</span>) )</span>
<span id="cb795-5515"><a href="#cb795-5515" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(d) ) {</span>
<span id="cb795-5516"><a href="#cb795-5516" aria-hidden="true" tabindex="-1"></a>    j <span class="ot">&lt;-</span> o[i] <span class="co"># which State in order</span></span>
<span id="cb795-5517"><a href="#cb795-5517" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( d<span class="sc">$</span>Divorce[j]<span class="sc">-</span><span class="fu">c</span>(mu.PI[<span class="dv">1</span>,j],mu.PI[<span class="dv">2</span>,j]) , <span class="fu">rep</span>(i,<span class="dv">2</span>) )</span>
<span id="cb795-5518"><a href="#cb795-5518" aria-hidden="true" tabindex="-1"></a>    <span class="fu">points</span>( d<span class="sc">$</span>Divorce[j]<span class="sc">-</span><span class="fu">c</span>(divorce.PI[<span class="dv">1</span>,j],divorce.PI[<span class="dv">2</span>,j]) , <span class="fu">rep</span>(i,<span class="dv">2</span>),</span>
<span id="cb795-5519"><a href="#cb795-5519" aria-hidden="true" tabindex="-1"></a>            <span class="at">pch=</span><span class="dv">3</span> , <span class="at">cex=</span><span class="fl">0.6</span> , <span class="at">col=</span><span class="st">"gray"</span> )</span>
<span id="cb795-5520"><a href="#cb795-5520" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-5521"><a href="#cb795-5521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5522"><a href="#cb795-5522" aria-hidden="true" tabindex="-1"></a><span class="co"># Average prediction error for each State, with 89% interval of the mean (black line) </span></span>
<span id="cb795-5523"><a href="#cb795-5523" aria-hidden="true" tabindex="-1"></a><span class="co"># and 89% prediction interval (gray +). </span></span>
<span id="cb795-5524"><a href="#cb795-5524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5525"><a href="#cb795-5525" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5526"><a href="#cb795-5526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5527"><a href="#cb795-5527" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5528"><a href="#cb795-5528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5529"><a href="#cb795-5529" aria-hidden="true" tabindex="-1"></a>Yet another common use for these simulations is to construct novel predictor residual plots. Once you’ve computed the divorce residuals, as you did just above, you can plot those residuals against new predictor variables. This is a quick way to see if remaining variation in the outcome is associated with another predictor.</span>
<span id="cb795-5530"><a href="#cb795-5530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5531"><a href="#cb795-5531" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.14a}</span></span>
<span id="cb795-5532"><a href="#cb795-5532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5533"><a href="#cb795-5533" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate waffle houses per capita</span></span>
<span id="cb795-5534"><a href="#cb795-5534" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>Wafflehouse_per_capita <span class="ot">&lt;-</span> d<span class="sc">$</span>WaffleHouses<span class="sc">/</span>d<span class="sc">$</span>Population</span>
<span id="cb795-5535"><a href="#cb795-5535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5536"><a href="#cb795-5536" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the map model </span></span>
<span id="cb795-5537"><a href="#cb795-5537" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.6</span>c <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5538"><a href="#cb795-5538" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-5539"><a href="#cb795-5539" aria-hidden="true" tabindex="-1"></a>    divorce.resid <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-5540"><a href="#cb795-5540" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>d<span class="sc">$</span>Wafflehouse_per_capita,</span>
<span id="cb795-5541"><a href="#cb795-5541" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-5542"><a href="#cb795-5542" aria-hidden="true" tabindex="-1"></a>    b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-5543"><a href="#cb795-5543" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-5544"><a href="#cb795-5544" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-5545"><a href="#cb795-5545" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-5546"><a href="#cb795-5546" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5547"><a href="#cb795-5547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5548"><a href="#cb795-5548" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.6</span>c</span>
<span id="cb795-5549"><a href="#cb795-5549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5550"><a href="#cb795-5550" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot divorce residue against waffle house per capita</span></span>
<span id="cb795-5551"><a href="#cb795-5551" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(divorce.resid <span class="sc">~</span> Wafflehouse_per_capita, <span class="at">data =</span> d, <span class="at">col =</span> rangi2,</span>
<span id="cb795-5552"><a href="#cb795-5552" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Waffles per capita"</span>, <span class="at">ylab =</span> <span class="st">"Divorce error"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">4</span>))</span>
<span id="cb795-5553"><a href="#cb795-5553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5554"><a href="#cb795-5554" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line</span></span>
<span id="cb795-5555"><a href="#cb795-5555" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coef</span>(m5<span class="fl">.6</span>c)[<span class="dv">1</span>], <span class="fu">coef</span>(m5<span class="fl">.6</span>c)[<span class="dv">2</span>])</span>
<span id="cb795-5556"><a href="#cb795-5556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5557"><a href="#cb795-5557" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the indices of the points to label</span></span>
<span id="cb795-5558"><a href="#cb795-5558" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">25</span>, <span class="dv">11</span>, <span class="dv">40</span>, <span class="dv">13</span>)  </span>
<span id="cb795-5559"><a href="#cb795-5559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5560"><a href="#cb795-5560" aria-hidden="true" tabindex="-1"></a><span class="co"># Add text labels to specific points</span></span>
<span id="cb795-5561"><a href="#cb795-5561" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x =</span> d<span class="sc">$</span>Wafflehouse_per_capita[indices], <span class="at">y =</span> divorce.resid[indices], </span>
<span id="cb795-5562"><a href="#cb795-5562" aria-hidden="true" tabindex="-1"></a>     <span class="at">labels =</span> d<span class="sc">$</span>Loc[indices], <span class="at">cex =</span> <span class="fl">0.8</span>, <span class="at">pos =</span> <span class="dv">3</span>)</span>
<span id="cb795-5563"><a href="#cb795-5563" aria-hidden="true" tabindex="-1"></a><span class="co"># I couldn't use PI function to get the CI of the abline. I think it is because the calculation</span></span>
<span id="cb795-5564"><a href="#cb795-5564" aria-hidden="true" tabindex="-1"></a><span class="co"># of PI  considers divorce.resid as samples and treat them as such, while in reality, they are</span></span>
<span id="cb795-5565"><a href="#cb795-5565" aria-hidden="true" tabindex="-1"></a><span class="co"># prediction error of each sample. </span></span>
<span id="cb795-5566"><a href="#cb795-5566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5567"><a href="#cb795-5567" aria-hidden="true" tabindex="-1"></a><span class="do">## So, I will use lm function and ggplot to recreate the plot in textbook</span></span>
<span id="cb795-5568"><a href="#cb795-5568" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> Wafflehouse_per_capita, <span class="at">y =</span> divorce.resid)) <span class="sc">+</span></span>
<span id="cb795-5569"><a href="#cb795-5569" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-5570"><a href="#cb795-5570" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-5571"><a href="#cb795-5571" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-5572"><a href="#cb795-5572" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"gray"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb795-5573"><a href="#cb795-5573" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-5574"><a href="#cb795-5574" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label=</span><span class="fu">ifelse</span>(divorce.resid <span class="sc">&gt;</span> <span class="fl">2.33022867</span>,<span class="fu">as.character</span>(Loc),<span class="st">''</span>)), </span>
<span id="cb795-5575"><a href="#cb795-5575" aria-hidden="true" tabindex="-1"></a>            <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-5576"><a href="#cb795-5576" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-5577"><a href="#cb795-5577" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">ifelse</span>(divorce.resid <span class="sc">&gt;</span> <span class="fl">1.73858361</span> <span class="sc">&amp;</span> divorce.resid <span class="sc">&lt;=</span> <span class="fl">1.8</span>, </span>
<span id="cb795-5578"><a href="#cb795-5578" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">as.character</span>(Loc), <span class="st">""</span>)), <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">vjust =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb795-5579"><a href="#cb795-5579" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-5580"><a href="#cb795-5580" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">ifelse</span>(divorce.resid <span class="sc">&gt;</span> <span class="dv">1</span> <span class="sc">&amp;</span> divorce.resid <span class="sc">&lt;=</span> <span class="fl">1.15377608</span>, </span>
<span id="cb795-5581"><a href="#cb795-5581" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">as.character</span>(Loc), <span class="st">""</span>)), <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-5582"><a href="#cb795-5582" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-5583"><a href="#cb795-5583" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">ifelse</span>(divorce.resid <span class="sc">&gt;</span> <span class="sc">-</span><span class="fl">1.34199783</span> <span class="sc">&amp;</span> divorce.resid <span class="sc">&lt;=</span> <span class="sc">-</span><span class="fl">1.3</span>, </span>
<span id="cb795-5584"><a href="#cb795-5584" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">as.character</span>(Loc), <span class="st">""</span>)), <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-5585"><a href="#cb795-5585" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-5586"><a href="#cb795-5586" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">ifelse</span>(divorce.resid <span class="sc">&gt;</span> <span class="fl">1.15</span> <span class="sc">&amp;</span> divorce.resid <span class="sc">&lt;=</span> <span class="fl">1.16</span>, </span>
<span id="cb795-5587"><a href="#cb795-5587" aria-hidden="true" tabindex="-1"></a>                               <span class="fu">as.character</span>(Loc), <span class="st">""</span>)), <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-5588"><a href="#cb795-5588" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-5589"><a href="#cb795-5589" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label=</span><span class="fu">ifelse</span>(divorce.resid <span class="sc">&lt;</span> <span class="sc">-</span><span class="fl">4.38753672</span>,<span class="fu">as.character</span>(Loc),<span class="st">''</span>)), </span>
<span id="cb795-5590"><a href="#cb795-5590" aria-hidden="true" tabindex="-1"></a>            <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">vjust =</span> <span class="sc">-</span><span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb795-5591"><a href="#cb795-5591" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-5592"><a href="#cb795-5592" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Waffles per capita"</span>, <span class="at">y =</span> <span class="st">"Divorce error"</span>) <span class="sc">+</span></span>
<span id="cb795-5593"><a href="#cb795-5593" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() </span>
<span id="cb795-5594"><a href="#cb795-5594" aria-hidden="true" tabindex="-1"></a><span class="co"># Average prediction error (residuals) against number of Waffle Houses per capita, with </span></span>
<span id="cb795-5595"><a href="#cb795-5595" aria-hidden="true" tabindex="-1"></a><span class="co"># superimposed regression of the two variables.</span></span>
<span id="cb795-5596"><a href="#cb795-5596" aria-hidden="true" tabindex="-1"></a><span class="co"># A small positive correlation remains between divorce rate and Waffle House, despite already </span></span>
<span id="cb795-5597"><a href="#cb795-5597" aria-hidden="true" tabindex="-1"></a><span class="co"># “controlling” for marriage rate and median age at marriage in each State. This does not mean </span></span>
<span id="cb795-5598"><a href="#cb795-5598" aria-hidden="true" tabindex="-1"></a><span class="co"># that the correlation is real. No matter how many predictors you’ve already included in a </span></span>
<span id="cb795-5599"><a href="#cb795-5599" aria-hidden="true" tabindex="-1"></a><span class="co"># regression, it’s still possible to find spurious correlations with the remaining variation.</span></span>
<span id="cb795-5600"><a href="#cb795-5600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5601"><a href="#cb795-5601" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5602"><a href="#cb795-5602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5603"><a href="#cb795-5603" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5604"><a href="#cb795-5604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5605"><a href="#cb795-5605" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Simulating spurious association**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-5606"><a href="#cb795-5606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5607"><a href="#cb795-5607" aria-hidden="true" tabindex="-1"></a>One way that spurious associations between a predictor and outcome can arise is when a truly causal predictor, call it x~real~, influences both the outcome, y, and a spurious predictor, x~spur~.</span>
<span id="cb795-5608"><a href="#cb795-5608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5609"><a href="#cb795-5609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5610"><a href="#cb795-5610" aria-hidden="true" tabindex="-1"></a><span class="in">```{r paired_plot}</span></span>
<span id="cb795-5611"><a href="#cb795-5611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5612"><a href="#cb795-5612" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span>                                          <span class="co"># number of cases                       </span></span>
<span id="cb795-5613"><a href="#cb795-5613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5614"><a href="#cb795-5614" aria-hidden="true" tabindex="-1"></a>x_real <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)                                <span class="co"># x_real as Gaussian with mean 0 and stddev 1</span></span>
<span id="cb795-5615"><a href="#cb795-5615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5616"><a href="#cb795-5616" aria-hidden="true" tabindex="-1"></a>x_spur <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, x_real)                        <span class="co"># x_spur as Gaussian with mean = x_real</span></span>
<span id="cb795-5617"><a href="#cb795-5617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5618"><a href="#cb795-5618" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, x_real)                             <span class="co"># y as Gaussian with mean = x_real</span></span>
<span id="cb795-5619"><a href="#cb795-5619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5620"><a href="#cb795-5620" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x_real, x_spur)                <span class="co"># bind all together in data frame</span></span>
<span id="cb795-5621"><a href="#cb795-5621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5622"><a href="#cb795-5622" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(d)</span>
<span id="cb795-5623"><a href="#cb795-5623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5624"><a href="#cb795-5624" aria-hidden="true" tabindex="-1"></a><span class="co"># The data frame d has 100 simulated cases. Because x_real influences both y and x_spur, </span></span>
<span id="cb795-5625"><a href="#cb795-5625" aria-hidden="true" tabindex="-1"></a><span class="co"># you can think of x_spur as another outcome of x_real, but one which we mistake as a </span></span>
<span id="cb795-5626"><a href="#cb795-5626" aria-hidden="true" tabindex="-1"></a><span class="co"># potential predictor of y. As a result, both x_real and x_spur are correlated with y. </span></span>
<span id="cb795-5627"><a href="#cb795-5627" aria-hidden="true" tabindex="-1"></a><span class="co"># You can see this in the scatterplots from pairs(d). But when you include both x variables </span></span>
<span id="cb795-5628"><a href="#cb795-5628" aria-hidden="true" tabindex="-1"></a><span class="co"># in a linear regression predicting y, the posterior mean for the association between y and</span></span>
<span id="cb795-5629"><a href="#cb795-5629" aria-hidden="true" tabindex="-1"></a><span class="co"># x_spur will be close to zero, while the comparable mean for xreal will be closer to 1.</span></span>
<span id="cb795-5630"><a href="#cb795-5630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5631"><a href="#cb795-5631" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5632"><a href="#cb795-5632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5633"><a href="#cb795-5633" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5634"><a href="#cb795-5634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5635"><a href="#cb795-5635" aria-hidden="true" tabindex="-1"></a><span class="fu">## Masked relationship</span></span>
<span id="cb795-5636"><a href="#cb795-5636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5637"><a href="#cb795-5637" aria-hidden="true" tabindex="-1"></a>A second reason to use more than one predictor variable is to measure the direct influences of multiple factors on an outcome, when none of those influences is apparent from bivariate relationships. This kind of problem tends to arise when there are two predictor variables that are correlated with one another. However, one of these is positively correlated with the outcome and the other is negatively correlated with it.</span>
<span id="cb795-5638"><a href="#cb795-5638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5639"><a href="#cb795-5639" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.16}</span></span>
<span id="cb795-5640"><a href="#cb795-5640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5641"><a href="#cb795-5641" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data on composition of milk across primate species</span></span>
<span id="cb795-5642"><a href="#cb795-5642" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb795-5643"><a href="#cb795-5643" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk</span>
<span id="cb795-5644"><a href="#cb795-5644" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d) <span class="co">#  29 rows (cases) for 8 variables (columns)</span></span>
<span id="cb795-5645"><a href="#cb795-5645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5646"><a href="#cb795-5646" aria-hidden="true" tabindex="-1"></a><span class="do">## First, simple bivariate regression between kilocalories and neocortex percent</span></span>
<span id="cb795-5647"><a href="#cb795-5647" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the neocortex column to see any missing (NA) values</span></span>
<span id="cb795-5648"><a href="#cb795-5648" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>neocortex.perc</span>
<span id="cb795-5649"><a href="#cb795-5649" aria-hidden="true" tabindex="-1"></a><span class="co"># If you pass a vector like this to a likelihood function like dnorm, it doesn’t know what to do.</span></span>
<span id="cb795-5650"><a href="#cb795-5650" aria-hidden="true" tabindex="-1"></a><span class="co"># After all, what’s the probability of a missing value? Whatever the answer, it isn’t a number, </span></span>
<span id="cb795-5651"><a href="#cb795-5651" aria-hidden="true" tabindex="-1"></a><span class="co"># and so dnorm returns a NaN. </span></span>
<span id="cb795-5652"><a href="#cb795-5652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5653"><a href="#cb795-5653" aria-hidden="true" tabindex="-1"></a><span class="co"># Manually drop all the cases with missing values</span></span>
<span id="cb795-5654"><a href="#cb795-5654" aria-hidden="true" tabindex="-1"></a>dcc <span class="ot">&lt;-</span> d[<span class="fu">complete.cases</span>(d), ] <span class="co"># gives new data frame with 17 rows</span></span>
<span id="cb795-5655"><a href="#cb795-5655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5656"><a href="#cb795-5656" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.5</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5657"><a href="#cb795-5657" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-5658"><a href="#cb795-5658" aria-hidden="true" tabindex="-1"></a>    kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-5659"><a href="#cb795-5659" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bn<span class="sc">*</span>neocortex.perc,</span>
<span id="cb795-5660"><a href="#cb795-5660" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb795-5661"><a href="#cb795-5661" aria-hidden="true" tabindex="-1"></a>    bn <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-5662"><a href="#cb795-5662" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb795-5663"><a href="#cb795-5663" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-5664"><a href="#cb795-5664" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dcc</span>
<span id="cb795-5665"><a href="#cb795-5665" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5666"><a href="#cb795-5666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5667"><a href="#cb795-5667" aria-hidden="true" tabindex="-1"></a><span class="co"># Check precis and add digits=3 to the precis call. The reason is that the posterior mean for </span></span>
<span id="cb795-5668"><a href="#cb795-5668" aria-hidden="true" tabindex="-1"></a><span class="co"># bn is very small. Need more digits to see that it’s not exactly zero—a change from the smallest</span></span>
<span id="cb795-5669"><a href="#cb795-5669" aria-hidden="true" tabindex="-1"></a><span class="co"># neocortex percent in the data, 55%, to the largest, 76%, would result in an expected change of</span></span>
<span id="cb795-5670"><a href="#cb795-5670" aria-hidden="true" tabindex="-1"></a><span class="co"># only: less than 0.1 kilocalories (0.09008296 kcal)</span></span>
<span id="cb795-5671"><a href="#cb795-5671" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.5</span>, <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb795-5672"><a href="#cb795-5672" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(m5<span class="fl">.5</span>)[<span class="st">"bn"</span>] <span class="sc">*</span> (<span class="dv">75</span> <span class="sc">-</span> <span class="dv">55</span>)</span>
<span id="cb795-5673"><a href="#cb795-5673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5674"><a href="#cb795-5674" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5675"><a href="#cb795-5675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5676"><a href="#cb795-5676" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5677"><a href="#cb795-5677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5678"><a href="#cb795-5678" aria-hidden="true" tabindex="-1"></a>The kilocalories in the data range from less than 0.5 to more than 0.9 per gram, so this association isn’t so impressive. More importantly, it isn’t very precise. The 89% interval of the parameter extends a good distance on both sides of zero.</span>
<span id="cb795-5679"><a href="#cb795-5679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5680"><a href="#cb795-5680" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.23}</span></span>
<span id="cb795-5681"><a href="#cb795-5681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5682"><a href="#cb795-5682" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the predicted mean and 89% interval for the mean to see this more easily</span></span>
<span id="cb795-5683"><a href="#cb795-5683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5684"><a href="#cb795-5684" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb795-5685"><a href="#cb795-5685" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">neocortex.perc=</span>np.seq )</span>
<span id="cb795-5686"><a href="#cb795-5686" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.5</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5687"><a href="#cb795-5687" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5688"><a href="#cb795-5688" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5689"><a href="#cb795-5689" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> neocortex.perc , <span class="at">data=</span>dcc , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-5690"><a href="#cb795-5690" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5691"><a href="#cb795-5691" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5692"><a href="#cb795-5692" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5693"><a href="#cb795-5693" aria-hidden="true" tabindex="-1"></a><span class="co"># The MAP line is weakly positive, but it is highly imprecise. A lot of mildly positive </span></span>
<span id="cb795-5694"><a href="#cb795-5694" aria-hidden="true" tabindex="-1"></a><span class="co"># and negative slopes are plausible, given this model and these data.</span></span>
<span id="cb795-5695"><a href="#cb795-5695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5696"><a href="#cb795-5696" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5697"><a href="#cb795-5697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5698"><a href="#cb795-5698" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5699"><a href="#cb795-5699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5700"><a href="#cb795-5700" aria-hidden="true" tabindex="-1"></a>Now consider another predictor variable, adult female body mass, mass in the data frame.</span>
<span id="cb795-5701"><a href="#cb795-5701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5702"><a href="#cb795-5702" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.24}</span></span>
<span id="cb795-5703"><a href="#cb795-5703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5704"><a href="#cb795-5704" aria-hidden="true" tabindex="-1"></a><span class="do">## Use logarithm of mass, log(mass), as a predictor instead of the raw mass in kilograms</span></span>
<span id="cb795-5705"><a href="#cb795-5705" aria-hidden="true" tabindex="-1"></a><span class="co"># Taking the log of a measure translates the measure into magnitudes. So by using the </span></span>
<span id="cb795-5706"><a href="#cb795-5706" aria-hidden="true" tabindex="-1"></a><span class="co"># logarithm of body mass here, we’re saying that we suspect that the magnitude of a </span></span>
<span id="cb795-5707"><a href="#cb795-5707" aria-hidden="true" tabindex="-1"></a><span class="co"># mother’s body mass is related to milk energy, in a linear fashion.</span></span>
<span id="cb795-5708"><a href="#cb795-5708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5709"><a href="#cb795-5709" aria-hidden="true" tabindex="-1"></a><span class="co"># Transforms mass first to make a new column in the data</span></span>
<span id="cb795-5710"><a href="#cb795-5710" aria-hidden="true" tabindex="-1"></a>dcc<span class="sc">$</span>log.mass <span class="ot">&lt;-</span> <span class="fu">log</span>(dcc<span class="sc">$</span>mass)</span>
<span id="cb795-5711"><a href="#cb795-5711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5712"><a href="#cb795-5712" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb795-5713"><a href="#cb795-5713" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.6</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5714"><a href="#cb795-5714" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5715"><a href="#cb795-5715" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5716"><a href="#cb795-5716" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bm<span class="sc">*</span>log.mass ,</span>
<span id="cb795-5717"><a href="#cb795-5717" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-5718"><a href="#cb795-5718" aria-hidden="true" tabindex="-1"></a>        bm <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5719"><a href="#cb795-5719" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ),</span>
<span id="cb795-5720"><a href="#cb795-5720" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>dcc )</span>
<span id="cb795-5721"><a href="#cb795-5721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5722"><a href="#cb795-5722" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.6</span>)</span>
<span id="cb795-5723"><a href="#cb795-5723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5724"><a href="#cb795-5724" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb795-5725"><a href="#cb795-5725" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb795-5726"><a href="#cb795-5726" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">log.mass=</span>np.seq )</span>
<span id="cb795-5727"><a href="#cb795-5727" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.6</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5728"><a href="#cb795-5728" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5729"><a href="#cb795-5729" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5730"><a href="#cb795-5730" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> log.mass , <span class="at">data=</span>dcc , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-5731"><a href="#cb795-5731" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5732"><a href="#cb795-5732" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5733"><a href="#cb795-5733" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5734"><a href="#cb795-5734" aria-hidden="true" tabindex="-1"></a><span class="co"># log-mass is negatively correlated with kilocalories. This influence does seem stronger than </span></span>
<span id="cb795-5735"><a href="#cb795-5735" aria-hidden="true" tabindex="-1"></a><span class="co"># that of neocortex percent, although in the opposite direction. It is quite uncertain though, </span></span>
<span id="cb795-5736"><a href="#cb795-5736" aria-hidden="true" tabindex="-1"></a><span class="co"># with a wide confidence interval that is consistent with a wide range of both weak and </span></span>
<span id="cb795-5737"><a href="#cb795-5737" aria-hidden="true" tabindex="-1"></a><span class="co"># stronger relationships.</span></span>
<span id="cb795-5738"><a href="#cb795-5738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5739"><a href="#cb795-5739" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5740"><a href="#cb795-5740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5741"><a href="#cb795-5741" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5742"><a href="#cb795-5742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5743"><a href="#cb795-5743" aria-hidden="true" tabindex="-1"></a>Now let’s see what happens when we add both predictor variables at the same time to the regression. This is the multivariate model, in math form:</span>
<span id="cb795-5744"><a href="#cb795-5744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5745"><a href="#cb795-5745" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-5746"><a href="#cb795-5746" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-5747"><a href="#cb795-5747" aria-hidden="true" tabindex="-1"></a>\text{k}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-5748"><a href="#cb795-5748" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_n \text{n}_i + \beta_m \text{log}(\text{m}_i)<span class="sc">\\</span></span>
<span id="cb795-5749"><a href="#cb795-5749" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(0, 100)<span class="sc">\\</span></span>
<span id="cb795-5750"><a href="#cb795-5750" aria-hidden="true" tabindex="-1"></a>\beta_n &amp;\sim \text{Normal}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-5751"><a href="#cb795-5751" aria-hidden="true" tabindex="-1"></a>\beta_m &amp;\sim \text{Normal}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-5752"><a href="#cb795-5752" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 10)</span>
<span id="cb795-5753"><a href="#cb795-5753" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-5754"><a href="#cb795-5754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5755"><a href="#cb795-5755" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-5756"><a href="#cb795-5756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5757"><a href="#cb795-5757" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-5758"><a href="#cb795-5758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5759"><a href="#cb795-5759" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5760"><a href="#cb795-5760" aria-hidden="true" tabindex="-1"></a><span class="in">k   = kcal.per.g</span></span>
<span id="cb795-5761"><a href="#cb795-5761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5762"><a href="#cb795-5762" aria-hidden="true" tabindex="-1"></a><span class="in">n   = neocortex.perc</span></span>
<span id="cb795-5763"><a href="#cb795-5763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5764"><a href="#cb795-5764" aria-hidden="true" tabindex="-1"></a><span class="in">m   = mass</span></span>
<span id="cb795-5765"><a href="#cb795-5765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5766"><a href="#cb795-5766" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5767"><a href="#cb795-5767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5768"><a href="#cb795-5768" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.26}</span></span>
<span id="cb795-5769"><a href="#cb795-5769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5770"><a href="#cb795-5770" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the joint model</span></span>
<span id="cb795-5771"><a href="#cb795-5771" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.7</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5772"><a href="#cb795-5772" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5773"><a href="#cb795-5773" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5774"><a href="#cb795-5774" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bn<span class="sc">*</span>neocortex.perc <span class="sc">+</span> bm<span class="sc">*</span>log.mass ,</span>
<span id="cb795-5775"><a href="#cb795-5775" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-5776"><a href="#cb795-5776" aria-hidden="true" tabindex="-1"></a>        bn <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5777"><a href="#cb795-5777" aria-hidden="true" tabindex="-1"></a>        bm <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5778"><a href="#cb795-5778" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">1</span> )</span>
<span id="cb795-5779"><a href="#cb795-5779" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-5780"><a href="#cb795-5780" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>dcc )</span>
<span id="cb795-5781"><a href="#cb795-5781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5782"><a href="#cb795-5782" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.7</span>)</span>
<span id="cb795-5783"><a href="#cb795-5783" aria-hidden="true" tabindex="-1"></a><span class="co"># By incorporating both predictor variables in the regression, the estimated association </span></span>
<span id="cb795-5784"><a href="#cb795-5784" aria-hidden="true" tabindex="-1"></a><span class="co"># of both with the outcome has increased. The posterior mean for the association of </span></span>
<span id="cb795-5785"><a href="#cb795-5785" aria-hidden="true" tabindex="-1"></a><span class="co"># neocortex percent has increased more than sixfold, and its 89% interval is now entirely </span></span>
<span id="cb795-5786"><a href="#cb795-5786" aria-hidden="true" tabindex="-1"></a><span class="co"># above zero. The posterior mean for log body mass is more strongly negative.</span></span>
<span id="cb795-5787"><a href="#cb795-5787" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5788"><a href="#cb795-5788" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the the intervals for the predicted mean kilocalories</span></span>
<span id="cb795-5789"><a href="#cb795-5789" aria-hidden="true" tabindex="-1"></a><span class="do">## For necortex.perc</span></span>
<span id="cb795-5790"><a href="#cb795-5790" aria-hidden="true" tabindex="-1"></a><span class="co"># Use mean log body mass because they are counterfactual plots showing only how predicted </span></span>
<span id="cb795-5791"><a href="#cb795-5791" aria-hidden="true" tabindex="-1"></a><span class="co"># energy varies as a function of neocortex percent</span></span>
<span id="cb795-5792"><a href="#cb795-5792" aria-hidden="true" tabindex="-1"></a>mean.log.mass <span class="ot">&lt;-</span> <span class="fu">mean</span>( <span class="fu">log</span>(dcc<span class="sc">$</span>mass) ) </span>
<span id="cb795-5793"><a href="#cb795-5793" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb795-5794"><a href="#cb795-5794" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-5795"><a href="#cb795-5795" aria-hidden="true" tabindex="-1"></a>    <span class="at">neocortex.perc=</span>np.seq,</span>
<span id="cb795-5796"><a href="#cb795-5796" aria-hidden="true" tabindex="-1"></a>    <span class="at">log.mass=</span>mean.log.mass</span>
<span id="cb795-5797"><a href="#cb795-5797" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5798"><a href="#cb795-5798" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.7</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5799"><a href="#cb795-5799" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5800"><a href="#cb795-5800" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5801"><a href="#cb795-5801" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> neocortex.perc , <span class="at">data=</span>dcc , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-5802"><a href="#cb795-5802" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5803"><a href="#cb795-5803" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5804"><a href="#cb795-5804" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5805"><a href="#cb795-5805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5806"><a href="#cb795-5806" aria-hidden="true" tabindex="-1"></a><span class="do">## For log(mass)</span></span>
<span id="cb795-5807"><a href="#cb795-5807" aria-hidden="true" tabindex="-1"></a>mean.neocortex.perc <span class="ot">&lt;-</span> <span class="fu">mean</span>(dcc<span class="sc">$</span>neocortex.perc)</span>
<span id="cb795-5808"><a href="#cb795-5808" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">3</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb795-5809"><a href="#cb795-5809" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-5810"><a href="#cb795-5810" aria-hidden="true" tabindex="-1"></a>    <span class="at">neocortex.perc=</span>mean.neocortex.perc,</span>
<span id="cb795-5811"><a href="#cb795-5811" aria-hidden="true" tabindex="-1"></a>    <span class="at">log.mass=</span>np.seq</span>
<span id="cb795-5812"><a href="#cb795-5812" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5813"><a href="#cb795-5813" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.7</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5814"><a href="#cb795-5814" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5815"><a href="#cb795-5815" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5816"><a href="#cb795-5816" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> log.mass , <span class="at">data=</span>dcc , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-5817"><a href="#cb795-5817" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5818"><a href="#cb795-5818" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5819"><a href="#cb795-5819" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5820"><a href="#cb795-5820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5821"><a href="#cb795-5821" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5822"><a href="#cb795-5822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5823"><a href="#cb795-5823" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5824"><a href="#cb795-5824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5825"><a href="#cb795-5825" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Why did adding neocortex and body mass to the same model lead to larger estimated effects of both?***<span class="kw">&lt;/span&gt;</span> </span>
<span id="cb795-5826"><a href="#cb795-5826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5827"><a href="#cb795-5827" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>There are two variables correlated with the outcome, but one is positively correlated with it and the other is negatively correlated with it. </span>
<span id="cb795-5828"><a href="#cb795-5828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5829"><a href="#cb795-5829" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Both of the explanatory variables are positively correlated with one another. As a result, they tend to cancel one another out.</span>
<span id="cb795-5830"><a href="#cb795-5830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5831"><a href="#cb795-5831" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>This is another case in which regression automatically finds the most revealing cases and uses them to produce estimates. What the regression model does is ask if species that have high neocortex percent for their body mass have higher milk energy.</span>
<span id="cb795-5832"><a href="#cb795-5832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5833"><a href="#cb795-5833" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Likewise, the model asks if species with high body mass for their neocortex percent have higher milk energy. Bigger species, like apes, have milk with less energy. But species with more neocortex tend to have richer milk. </span>
<span id="cb795-5834"><a href="#cb795-5834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5835"><a href="#cb795-5835" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The fact that these two variables, body size and neocortex, are correlated across species makes it hard to see these relationships, unless we statistically account for both.</span>
<span id="cb795-5836"><a href="#cb795-5836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5837"><a href="#cb795-5837" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5838"><a href="#cb795-5838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5839"><a href="#cb795-5839" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:green"</span><span class="kw">&gt;</span>***Compound figure for milk energy and neocortex among primates***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-5840"><a href="#cb795-5840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5841"><a href="#cb795-5841" aria-hidden="true" tabindex="-1"></a>In the top two plots, simple bivariate regressions of kilocalories per gram of milk on (left) neocortex percent and (right) log female body mass show weak and uncertain associations. </span>
<span id="cb795-5842"><a href="#cb795-5842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5843"><a href="#cb795-5843" aria-hidden="true" tabindex="-1"></a>However, on the bottom, a single regression with both neocortex percent and log body mass suggests strong association with both variables. Both neocortex and body mass are associated with milk energy, but in opposite directions. This masks each variable’s relationship with the outcome, unless both are considered simultaneously.</span>
<span id="cb795-5844"><a href="#cb795-5844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5845"><a href="#cb795-5845" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.7cf, echo=FALSE}</span></span>
<span id="cb795-5846"><a href="#cb795-5846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5847"><a href="#cb795-5847" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>))</span>
<span id="cb795-5848"><a href="#cb795-5848" aria-hidden="true" tabindex="-1"></a><span class="co"># Fig 1</span></span>
<span id="cb795-5849"><a href="#cb795-5849" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb795-5850"><a href="#cb795-5850" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">neocortex.perc=</span>np.seq )</span>
<span id="cb795-5851"><a href="#cb795-5851" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.5</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5852"><a href="#cb795-5852" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5853"><a href="#cb795-5853" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5854"><a href="#cb795-5854" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> neocortex.perc , <span class="at">data=</span>dcc , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-5855"><a href="#cb795-5855" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5856"><a href="#cb795-5856" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5857"><a href="#cb795-5857" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5858"><a href="#cb795-5858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5859"><a href="#cb795-5859" aria-hidden="true" tabindex="-1"></a><span class="co"># Fig 2</span></span>
<span id="cb795-5860"><a href="#cb795-5860" aria-hidden="true" tabindex="-1"></a>dcc<span class="sc">$</span>log.mass <span class="ot">&lt;-</span> <span class="fu">log</span>(dcc<span class="sc">$</span>mass)</span>
<span id="cb795-5861"><a href="#cb795-5861" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.6</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-5862"><a href="#cb795-5862" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-5863"><a href="#cb795-5863" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-5864"><a href="#cb795-5864" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bm<span class="sc">*</span>log.mass ,</span>
<span id="cb795-5865"><a href="#cb795-5865" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-5866"><a href="#cb795-5866" aria-hidden="true" tabindex="-1"></a>        bm <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-5867"><a href="#cb795-5867" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ),</span>
<span id="cb795-5868"><a href="#cb795-5868" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>dcc )</span>
<span id="cb795-5869"><a href="#cb795-5869" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">4</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb795-5870"><a href="#cb795-5870" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">log.mass=</span>np.seq )</span>
<span id="cb795-5871"><a href="#cb795-5871" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.6</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5872"><a href="#cb795-5872" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5873"><a href="#cb795-5873" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5874"><a href="#cb795-5874" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> log.mass , <span class="at">data=</span>dcc , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-5875"><a href="#cb795-5875" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5876"><a href="#cb795-5876" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5877"><a href="#cb795-5877" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5878"><a href="#cb795-5878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5879"><a href="#cb795-5879" aria-hidden="true" tabindex="-1"></a><span class="co"># Fig 3</span></span>
<span id="cb795-5880"><a href="#cb795-5880" aria-hidden="true" tabindex="-1"></a>mean.log.mass <span class="ot">&lt;-</span> <span class="fu">mean</span>( <span class="fu">log</span>(dcc<span class="sc">$</span>mass) ) </span>
<span id="cb795-5881"><a href="#cb795-5881" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb795-5882"><a href="#cb795-5882" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-5883"><a href="#cb795-5883" aria-hidden="true" tabindex="-1"></a>    <span class="at">neocortex.perc=</span>np.seq,</span>
<span id="cb795-5884"><a href="#cb795-5884" aria-hidden="true" tabindex="-1"></a>    <span class="at">log.mass=</span>mean.log.mass</span>
<span id="cb795-5885"><a href="#cb795-5885" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5886"><a href="#cb795-5886" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.7</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5887"><a href="#cb795-5887" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5888"><a href="#cb795-5888" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5889"><a href="#cb795-5889" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> neocortex.perc , <span class="at">data=</span>dcc , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-5890"><a href="#cb795-5890" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5891"><a href="#cb795-5891" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5892"><a href="#cb795-5892" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5893"><a href="#cb795-5893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5894"><a href="#cb795-5894" aria-hidden="true" tabindex="-1"></a><span class="co"># Fig 4</span></span>
<span id="cb795-5895"><a href="#cb795-5895" aria-hidden="true" tabindex="-1"></a>mean.neocortex.perc <span class="ot">&lt;-</span> <span class="fu">mean</span>(dcc<span class="sc">$</span>neocortex.perc)</span>
<span id="cb795-5896"><a href="#cb795-5896" aria-hidden="true" tabindex="-1"></a>np.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">3</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb795-5897"><a href="#cb795-5897" aria-hidden="true" tabindex="-1"></a>pred.data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-5898"><a href="#cb795-5898" aria-hidden="true" tabindex="-1"></a>    <span class="at">neocortex.perc=</span>mean.neocortex.perc,</span>
<span id="cb795-5899"><a href="#cb795-5899" aria-hidden="true" tabindex="-1"></a>    <span class="at">log.mass=</span>np.seq</span>
<span id="cb795-5900"><a href="#cb795-5900" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-5901"><a href="#cb795-5901" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m5<span class="fl">.7</span> , <span class="at">data=</span>pred.data , <span class="at">n=</span><span class="fl">1e4</span> )</span>
<span id="cb795-5902"><a href="#cb795-5902" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-5903"><a href="#cb795-5903" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI )</span>
<span id="cb795-5904"><a href="#cb795-5904" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> log.mass , <span class="at">data=</span>dcc , <span class="at">type=</span><span class="st">"n"</span> )</span>
<span id="cb795-5905"><a href="#cb795-5905" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.mean )</span>
<span id="cb795-5906"><a href="#cb795-5906" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5907"><a href="#cb795-5907" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( np.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-5908"><a href="#cb795-5908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5909"><a href="#cb795-5909" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5910"><a href="#cb795-5910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5911"><a href="#cb795-5911" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5912"><a href="#cb795-5912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5913"><a href="#cb795-5913" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Simulating a masking relationship**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-5914"><a href="#cb795-5914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5915"><a href="#cb795-5915" aria-hidden="true" tabindex="-1"></a>It may help to simulate data in which two meaningful predictors act to mask one another. Suppose again a single outcome, y, and two predictors, x~pos~ and x~neg~. The predictor x~pos~ is positively associated with y, while x~neg~ is negatively associated with y. Furthermore, the two predictors are positively correlated with one another. </span>
<span id="cb795-5916"><a href="#cb795-5916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5917"><a href="#cb795-5917" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.28}</span></span>
<span id="cb795-5918"><a href="#cb795-5918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5919"><a href="#cb795-5919" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span>                              <span class="co"># number of cases</span></span>
<span id="cb795-5920"><a href="#cb795-5920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5921"><a href="#cb795-5921" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.7</span>                            <span class="co"># correlation btw x_pos and x_neg</span></span>
<span id="cb795-5922"><a href="#cb795-5922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5923"><a href="#cb795-5923" aria-hidden="true" tabindex="-1"></a>x_pos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)                     <span class="co"># x_pos Gaussian</span></span>
<span id="cb795-5924"><a href="#cb795-5924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5925"><a href="#cb795-5925" aria-hidden="true" tabindex="-1"></a>x_neg <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, rho<span class="sc">*</span>x_pos,          <span class="co"># x_neg correlated with x_pos</span></span>
<span id="cb795-5926"><a href="#cb795-5926" aria-hidden="true" tabindex="-1"></a>               <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">-</span>rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb795-5927"><a href="#cb795-5927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5928"><a href="#cb795-5928" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, x_pos <span class="sc">-</span> x_neg)          <span class="co"># y equally associated with x_pos, x_neg</span></span>
<span id="cb795-5929"><a href="#cb795-5929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5930"><a href="#cb795-5930" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x_pos, x_neg)      <span class="co"># bind all together in data frame</span></span>
<span id="cb795-5931"><a href="#cb795-5931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5932"><a href="#cb795-5932" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(d, <span class="at">main =</span> <span class="st">"(a) Rho = 0.7"</span>)</span>
<span id="cb795-5933"><a href="#cb795-5933" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting y using either x_pos or x_neg gives posterior distributions that underestimate </span></span>
<span id="cb795-5934"><a href="#cb795-5934" aria-hidden="true" tabindex="-1"></a><span class="co"># the true association (which should be about 1 or −1, respectively). </span></span>
<span id="cb795-5935"><a href="#cb795-5935" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting a model predicting y using both predictors gives a posterior distribution that </span></span>
<span id="cb795-5936"><a href="#cb795-5936" aria-hidden="true" tabindex="-1"></a><span class="co"># better matches the underlying truth.</span></span>
<span id="cb795-5937"><a href="#cb795-5937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5938"><a href="#cb795-5938" aria-hidden="true" tabindex="-1"></a><span class="do">## Move rho closer to 0</span></span>
<span id="cb795-5939"><a href="#cb795-5939" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span>                              </span>
<span id="cb795-5940"><a href="#cb795-5940" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.1</span>                          </span>
<span id="cb795-5941"><a href="#cb795-5941" aria-hidden="true" tabindex="-1"></a>x_pos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)                    </span>
<span id="cb795-5942"><a href="#cb795-5942" aria-hidden="true" tabindex="-1"></a>x_neg <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, rho<span class="sc">*</span>x_pos,          </span>
<span id="cb795-5943"><a href="#cb795-5943" aria-hidden="true" tabindex="-1"></a>               <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">-</span>rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb795-5944"><a href="#cb795-5944" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, x_pos <span class="sc">-</span> x_neg)         </span>
<span id="cb795-5945"><a href="#cb795-5945" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x_pos, x_neg)  </span>
<span id="cb795-5946"><a href="#cb795-5946" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(d, <span class="at">main =</span> <span class="st">"(b) Rho closer to zero"</span>)</span>
<span id="cb795-5947"><a href="#cb795-5947" aria-hidden="true" tabindex="-1"></a><span class="co"># If you move the value of rho closer to zero, this masking phenomenon will diminish.</span></span>
<span id="cb795-5948"><a href="#cb795-5948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5949"><a href="#cb795-5949" aria-hidden="true" tabindex="-1"></a><span class="do">## Make rho closer to 1</span></span>
<span id="cb795-5950"><a href="#cb795-5950" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span>                              </span>
<span id="cb795-5951"><a href="#cb795-5951" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.99</span>                         </span>
<span id="cb795-5952"><a href="#cb795-5952" aria-hidden="true" tabindex="-1"></a>x_pos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)                    </span>
<span id="cb795-5953"><a href="#cb795-5953" aria-hidden="true" tabindex="-1"></a>x_neg <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, rho<span class="sc">*</span>x_pos,          </span>
<span id="cb795-5954"><a href="#cb795-5954" aria-hidden="true" tabindex="-1"></a>               <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">-</span>rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb795-5955"><a href="#cb795-5955" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, x_pos <span class="sc">-</span> x_neg)         </span>
<span id="cb795-5956"><a href="#cb795-5956" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x_pos, x_neg)  </span>
<span id="cb795-5957"><a href="#cb795-5957" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(d, <span class="at">main =</span> <span class="st">"(c) Rho closer to 1"</span>)</span>
<span id="cb795-5958"><a href="#cb795-5958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5959"><a href="#cb795-5959" aria-hidden="true" tabindex="-1"></a><span class="do">## Make rho closer to -1</span></span>
<span id="cb795-5960"><a href="#cb795-5960" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span>                              </span>
<span id="cb795-5961"><a href="#cb795-5961" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.99</span>                         </span>
<span id="cb795-5962"><a href="#cb795-5962" aria-hidden="true" tabindex="-1"></a>x_pos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)                    </span>
<span id="cb795-5963"><a href="#cb795-5963" aria-hidden="true" tabindex="-1"></a>x_neg <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, rho<span class="sc">*</span>x_pos,          </span>
<span id="cb795-5964"><a href="#cb795-5964" aria-hidden="true" tabindex="-1"></a>               <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">-</span>rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb795-5965"><a href="#cb795-5965" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, x_pos <span class="sc">-</span> x_neg)         </span>
<span id="cb795-5966"><a href="#cb795-5966" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x_pos, x_neg)  </span>
<span id="cb795-5967"><a href="#cb795-5967" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(d, <span class="at">main =</span> <span class="st">"(d) Rho closer to -1"</span>)</span>
<span id="cb795-5968"><a href="#cb795-5968" aria-hidden="true" tabindex="-1"></a><span class="co"># If you make rho closer to 1 or −1, the masking relationship will magnify. </span></span>
<span id="cb795-5969"><a href="#cb795-5969" aria-hidden="true" tabindex="-1"></a><span class="co"># But if rho gets very close to 1 or −1, then the two predictors contain exactly </span></span>
<span id="cb795-5970"><a href="#cb795-5970" aria-hidden="true" tabindex="-1"></a><span class="co"># the same information, and there’s no hope for any statistical model to tease out </span></span>
<span id="cb795-5971"><a href="#cb795-5971" aria-hidden="true" tabindex="-1"></a><span class="co"># the true underlying association used in the simulation.</span></span>
<span id="cb795-5972"><a href="#cb795-5972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5973"><a href="#cb795-5973" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-5974"><a href="#cb795-5974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5975"><a href="#cb795-5975" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5976"><a href="#cb795-5976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5977"><a href="#cb795-5977" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Why should two predictors be correlated in this way?***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-5978"><a href="#cb795-5978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5979"><a href="#cb795-5979" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>They might both be influenced by another, unmeasured variable. </span>
<span id="cb795-5980"><a href="#cb795-5980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5981"><a href="#cb795-5981" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Or one of them, say x~neg~, is influenced partly by x~pos~, but also by its own unique processes. </span>
<span id="cb795-5982"><a href="#cb795-5982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5983"><a href="#cb795-5983" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>They might both partly influence one another, in a case of reciprocal causation.</span>
<span id="cb795-5984"><a href="#cb795-5984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5985"><a href="#cb795-5985" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-5986"><a href="#cb795-5986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5987"><a href="#cb795-5987" aria-hidden="true" tabindex="-1"></a><span class="fu">## When adding variables hurts</span></span>
<span id="cb795-5988"><a href="#cb795-5988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5989"><a href="#cb795-5989" aria-hidden="true" tabindex="-1"></a>It is commonly true that there are many potential predictor variables to add to a regression model. Why not just fit a model that includes all potential predictor variables? There are several good, purely statistical reasons to avoid doing this. Three of them are:</span>
<span id="cb795-5990"><a href="#cb795-5990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5991"><a href="#cb795-5991" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multicollinearity</span>
<span id="cb795-5992"><a href="#cb795-5992" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>very strong correlation between two or more predictor variables. </span>
<span id="cb795-5993"><a href="#cb795-5993" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>The consequence of it is that the posterior distribution will say that a very large range of parameter values are plausible, from tiny associations to massive ones, even if all of the variables are in reality strongly associated with the outcome variable.</span>
<span id="cb795-5994"><a href="#cb795-5994" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-5995"><a href="#cb795-5995" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-5996"><a href="#cb795-5996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-5997"><a href="#cb795-5997" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Post-treatment bias</span>
<span id="cb795-5998"><a href="#cb795-5998" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>statistically controlling for consequences of a causal factor.</span>
<span id="cb795-5999"><a href="#cb795-5999" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-6000"><a href="#cb795-6000" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-6001"><a href="#cb795-6001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6002"><a href="#cb795-6002" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Overfitting</span>
<span id="cb795-6003"><a href="#cb795-6003" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>a huge and perspective-changing problem</span>
<span id="cb795-6004"><a href="#cb795-6004" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-6005"><a href="#cb795-6005" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6006"><a href="#cb795-6006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6007"><a href="#cb795-6007" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multicollinear legs</span></span>
<span id="cb795-6008"><a href="#cb795-6008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6009"><a href="#cb795-6009" aria-hidden="true" tabindex="-1"></a>The simulation example is predicting an individual’s height using the length of his or her legs as predictor variables. Surely height is positively associated with leg length, or at least the simulation will assume it is. Nevertheless, once you put both leg lengths into the model, something vexing will happen.</span>
<span id="cb795-6010"><a href="#cb795-6010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6011"><a href="#cb795-6011" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.29}</span></span>
<span id="cb795-6012"><a href="#cb795-6012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6013"><a href="#cb795-6013" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb795-6014"><a href="#cb795-6014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6015"><a href="#cb795-6015" aria-hidden="true" tabindex="-1"></a><span class="do">## Simulate the heights and leg lengths of 100 individuals</span></span>
<span id="cb795-6016"><a href="#cb795-6016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6017"><a href="#cb795-6017" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span>                           <span class="co"># number of individuals</span></span>
<span id="cb795-6018"><a href="#cb795-6018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6019"><a href="#cb795-6019" aria-hidden="true" tabindex="-1"></a><span class="co"># For each, first a height is simulated from a Gaussian distribution</span></span>
<span id="cb795-6020"><a href="#cb795-6020" aria-hidden="true" tabindex="-1"></a>height <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="dv">10</span>, <span class="dv">2</span>)         <span class="co"># sim total height of each</span></span>
<span id="cb795-6021"><a href="#cb795-6021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6022"><a href="#cb795-6022" aria-hidden="true" tabindex="-1"></a><span class="co"># Each individual gets a simulated proportion of height for their legs, ranging from 0.4 to 0.5</span></span>
<span id="cb795-6023"><a href="#cb795-6023" aria-hidden="true" tabindex="-1"></a>leg_prop <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, <span class="fl">0.4</span>, <span class="fl">0.5</span>)    <span class="co"># leg as proportion of height</span></span>
<span id="cb795-6024"><a href="#cb795-6024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6025"><a href="#cb795-6025" aria-hidden="true" tabindex="-1"></a><span class="co"># Each leg is salted with a little measurement or developmental error, so the left and right legs </span></span>
<span id="cb795-6026"><a href="#cb795-6026" aria-hidden="true" tabindex="-1"></a><span class="co"># are not exactly the same length, as is typical in real populations</span></span>
<span id="cb795-6027"><a href="#cb795-6027" aria-hidden="true" tabindex="-1"></a>leg_left <span class="ot">&lt;-</span> leg_prop<span class="sc">*</span>height <span class="sc">+</span>     <span class="co"># sim left leg as proportion + error</span></span>
<span id="cb795-6028"><a href="#cb795-6028" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="fl">0.02</span>)</span>
<span id="cb795-6029"><a href="#cb795-6029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6030"><a href="#cb795-6030" aria-hidden="true" tabindex="-1"></a>leg_right <span class="ot">&lt;-</span> leg_prop<span class="sc">*</span>height <span class="sc">+</span>    <span class="co"># sim right leg as proportion + error </span></span>
<span id="cb795-6031"><a href="#cb795-6031" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rnorm</span>(N, <span class="dv">0</span>, <span class="fl">0.02</span>)</span>
<span id="cb795-6032"><a href="#cb795-6032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6033"><a href="#cb795-6033" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(height, leg_left, <span class="co"># combine into data frame</span></span>
<span id="cb795-6034"><a href="#cb795-6034" aria-hidden="true" tabindex="-1"></a>                leg_right)</span>
<span id="cb795-6035"><a href="#cb795-6035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6036"><a href="#cb795-6036" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(d, <span class="at">col =</span> <span class="st">"pink"</span>)</span>
<span id="cb795-6037"><a href="#cb795-6037" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6038"><a href="#cb795-6038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6039"><a href="#cb795-6039" aria-hidden="true" tabindex="-1"></a>On average, an individual’s legs are 45% of his or her height (in these simulated data). So we should expect the beta coefficient that measures the association of a leg with height to end up around the average height (10) divided by 45% of the average height (4.5). This is 10/4.5 ≈ 2.2. Now let’s see what happens instead:</span>
<span id="cb795-6040"><a href="#cb795-6040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6041"><a href="#cb795-6041" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.30}</span></span>
<span id="cb795-6042"><a href="#cb795-6042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6043"><a href="#cb795-6043" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.8</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6044"><a href="#cb795-6044" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6045"><a href="#cb795-6045" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6046"><a href="#cb795-6046" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bl<span class="sc">*</span>leg_left <span class="sc">+</span> br<span class="sc">*</span>leg_right ,</span>
<span id="cb795-6047"><a href="#cb795-6047" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-6048"><a href="#cb795-6048" aria-hidden="true" tabindex="-1"></a>        bl <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6049"><a href="#cb795-6049" aria-hidden="true" tabindex="-1"></a>        br <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6050"><a href="#cb795-6050" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-6051"><a href="#cb795-6051" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-6052"><a href="#cb795-6052" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6053"><a href="#cb795-6053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6054"><a href="#cb795-6054" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.8</span>)</span>
<span id="cb795-6055"><a href="#cb795-6055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6056"><a href="#cb795-6056" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m5<span class="fl">.8</span>))</span>
<span id="cb795-6057"><a href="#cb795-6057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6058"><a href="#cb795-6058" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6059"><a href="#cb795-6059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6060"><a href="#cb795-6060" aria-hidden="true" tabindex="-1"></a>If both legs have almost identical lengths, and height is so strongly associated with leg length, then why is this posterior distribution so weird? Did the model fitting work correctly? The question for the model to answer is: *What is the value of knowing each leg’s length, after already knowing the other leg’s length?* </span>
<span id="cb795-6061"><a href="#cb795-6061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6062"><a href="#cb795-6062" aria-hidden="true" tabindex="-1"></a>The model did fit correctly. The posterior distribution is the answer to this question, considering every possible combination of the parameters and assigning relative plausibilities to every combination, conditional on this model and these data.</span>
<span id="cb795-6063"><a href="#cb795-6063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6064"><a href="#cb795-6064" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.32}</span></span>
<span id="cb795-6065"><a href="#cb795-6065" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">35</span>)</span>
<span id="cb795-6066"><a href="#cb795-6066" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at the bivariate posterior distribution for bl and br</span></span>
<span id="cb795-6067"><a href="#cb795-6067" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.8</span>)</span>
<span id="cb795-6068"><a href="#cb795-6068" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( bl <span class="sc">~</span> br , post , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.1</span>) , <span class="at">pch=</span><span class="dv">16</span> )</span>
<span id="cb795-6069"><a href="#cb795-6069" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior distribution of the association of each leg with height, from model m5.8. </span></span>
<span id="cb795-6070"><a href="#cb795-6070" aria-hidden="true" tabindex="-1"></a><span class="co"># Since both variables contain almost identical information, the posterior is a narrow </span></span>
<span id="cb795-6071"><a href="#cb795-6071" aria-hidden="true" tabindex="-1"></a><span class="co"># ridge of negatively correlated values.</span></span>
<span id="cb795-6072"><a href="#cb795-6072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6073"><a href="#cb795-6073" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6074"><a href="#cb795-6074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6075"><a href="#cb795-6075" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6076"><a href="#cb795-6076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6077"><a href="#cb795-6077" aria-hidden="true" tabindex="-1"></a>One way to think of this phenomenon is that you have approximated this likelihood:</span>
<span id="cb795-6078"><a href="#cb795-6078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6079"><a href="#cb795-6079" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6080"><a href="#cb795-6080" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6081"><a href="#cb795-6081" aria-hidden="true" tabindex="-1"></a>\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6082"><a href="#cb795-6082" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_1 \text{x}_i + \beta_2 \text{x}_i</span>
<span id="cb795-6083"><a href="#cb795-6083" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6084"><a href="#cb795-6084" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6085"><a href="#cb795-6085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6086"><a href="#cb795-6086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6087"><a href="#cb795-6087" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6088"><a href="#cb795-6088" aria-hidden="true" tabindex="-1"></a><span class="in">y   = outcome (height)</span></span>
<span id="cb795-6089"><a href="#cb795-6089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6090"><a href="#cb795-6090" aria-hidden="true" tabindex="-1"></a><span class="in">x   = single predictor (leg lengths)</span></span>
<span id="cb795-6091"><a href="#cb795-6091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6092"><a href="#cb795-6092" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6093"><a href="#cb795-6093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6094"><a href="#cb795-6094" aria-hidden="true" tabindex="-1"></a>Here x is used twice, which is a perfect example of the problem caused by using the almost-identical leg lengths. From the computer’s perspective, this likelihood is really:</span>
<span id="cb795-6095"><a href="#cb795-6095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6096"><a href="#cb795-6096" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6097"><a href="#cb795-6097" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6098"><a href="#cb795-6098" aria-hidden="true" tabindex="-1"></a>\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6099"><a href="#cb795-6099" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + (\beta_1 + \beta_2) \text{x}_i</span>
<span id="cb795-6100"><a href="#cb795-6100" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6101"><a href="#cb795-6101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6102"><a href="#cb795-6102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6103"><a href="#cb795-6103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6104"><a href="#cb795-6104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6105"><a href="#cb795-6105" aria-hidden="true" tabindex="-1"></a>This means the posterior distribution ends up reporting the practically infinite combinations of $\beta_1$ and $\beta_2$ that make their sum close to the actual association of x with y.</span>
<span id="cb795-6106"><a href="#cb795-6106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6107"><a href="#cb795-6107" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.33}</span></span>
<span id="cb795-6108"><a href="#cb795-6108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6109"><a href="#cb795-6109" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the posterior distribution of the sum of bl and br</span></span>
<span id="cb795-6110"><a href="#cb795-6110" aria-hidden="true" tabindex="-1"></a>sum_blbr <span class="ot">&lt;-</span> post<span class="sc">$</span>bl <span class="sc">+</span> post<span class="sc">$</span>br</span>
<span id="cb795-6111"><a href="#cb795-6111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6112"><a href="#cb795-6112" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(sum_blbr)</span>
<span id="cb795-6113"><a href="#cb795-6113" aria-hidden="true" tabindex="-1"></a><span class="co"># The posterior mean is in the right neighborhood, around 2, and the standard deviation </span></span>
<span id="cb795-6114"><a href="#cb795-6114" aria-hidden="true" tabindex="-1"></a><span class="co"># is much smaller than it is for either component of the sum, bl or br.</span></span>
<span id="cb795-6115"><a href="#cb795-6115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6116"><a href="#cb795-6116" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the posterior distribution </span></span>
<span id="cb795-6117"><a href="#cb795-6117" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>( sum_blbr , <span class="at">col=</span>rangi2 , <span class="at">lwd=</span><span class="dv">2</span> , <span class="at">xlab=</span><span class="st">"sum of bl and br"</span> )</span>
<span id="cb795-6118"><a href="#cb795-6118" aria-hidden="true" tabindex="-1"></a><span class="co"># The posterior distribution of the sum of the two parameters is centered on the </span></span>
<span id="cb795-6119"><a href="#cb795-6119" aria-hidden="true" tabindex="-1"></a><span class="co"># proper association of either leg with height.</span></span>
<span id="cb795-6120"><a href="#cb795-6120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6121"><a href="#cb795-6121" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6122"><a href="#cb795-6122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6123"><a href="#cb795-6123" aria-hidden="true" tabindex="-1"></a>If you fit a regression with only one of the leg length variables, you’ll get approximately the same posterior mean:</span>
<span id="cb795-6124"><a href="#cb795-6124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6125"><a href="#cb795-6125" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.34}</span></span>
<span id="cb795-6126"><a href="#cb795-6126" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-6127"><a href="#cb795-6127" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">36</span>)</span>
<span id="cb795-6128"><a href="#cb795-6128" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.9</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6129"><a href="#cb795-6129" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6130"><a href="#cb795-6130" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6131"><a href="#cb795-6131" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bl<span class="sc">*</span>leg_left,</span>
<span id="cb795-6132"><a href="#cb795-6132" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-6133"><a href="#cb795-6133" aria-hidden="true" tabindex="-1"></a>        bl <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6134"><a href="#cb795-6134" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-6135"><a href="#cb795-6135" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6136"><a href="#cb795-6136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6137"><a href="#cb795-6137" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.9</span>)</span>
<span id="cb795-6138"><a href="#cb795-6138" aria-hidden="true" tabindex="-1"></a><span class="co"># 1.94 is almost identical to the mean value of sum_blbr.</span></span>
<span id="cb795-6139"><a href="#cb795-6139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6140"><a href="#cb795-6140" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m5<span class="fl">.9</span>), <span class="at">main =</span> <span class="st">"Left leg"</span>)</span>
<span id="cb795-6141"><a href="#cb795-6141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6142"><a href="#cb795-6142" aria-hidden="true" tabindex="-1"></a><span class="do">## For right leg</span></span>
<span id="cb795-6143"><a href="#cb795-6143" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.9</span>b <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6144"><a href="#cb795-6144" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6145"><a href="#cb795-6145" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6146"><a href="#cb795-6146" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> br<span class="sc">*</span>leg_right,</span>
<span id="cb795-6147"><a href="#cb795-6147" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">10</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-6148"><a href="#cb795-6148" aria-hidden="true" tabindex="-1"></a>        br <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">2</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6149"><a href="#cb795-6149" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-6150"><a href="#cb795-6150" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6151"><a href="#cb795-6151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6152"><a href="#cb795-6152" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.9</span>b)</span>
<span id="cb795-6153"><a href="#cb795-6153" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m5<span class="fl">.9</span>b), <span class="at">main =</span> <span class="st">"Right leg"</span>)</span>
<span id="cb795-6154"><a href="#cb795-6154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6155"><a href="#cb795-6155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6156"><a href="#cb795-6156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6157"><a href="#cb795-6157" aria-hidden="true" tabindex="-1"></a>***When two predictor variables are very strongly correlated, including both in a model may lead to confusion.***</span>
<span id="cb795-6158"><a href="#cb795-6158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6159"><a href="#cb795-6159" aria-hidden="true" tabindex="-1"></a>The posterior distribution isn’t wrong, in such cases. It’s telling you that the question you asked cannot be answered with these data. And that’s a great thing for a model to say, that it cannot answer your question. And if you are just interested in prediction, you’ll find that this leg model makes fine predictions. It just doesn’t make any claims about which leg is more important.</span>
<span id="cb795-6160"><a href="#cb795-6160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6161"><a href="#cb795-6161" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6162"><a href="#cb795-6162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6163"><a href="#cb795-6163" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multicollinear milk</span></span>
<span id="cb795-6164"><a href="#cb795-6164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6165"><a href="#cb795-6165" aria-hidden="true" tabindex="-1"></a>In the leg length example, it’s easy to see that including both legs in the model is a little silly. But the problem that arises in real data sets is that we may not anticipate a clash between highly correlated predictors. And therefore we may mistakenly read the posterior distribution to say that neither predictor is important.</span>
<span id="cb795-6166"><a href="#cb795-6166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6167"><a href="#cb795-6167" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.35}</span></span>
<span id="cb795-6168"><a href="#cb795-6168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6169"><a href="#cb795-6169" aria-hidden="true" tabindex="-1"></a><span class="do">### Look at the issue with real data</span></span>
<span id="cb795-6170"><a href="#cb795-6170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6171"><a href="#cb795-6171" aria-hidden="true" tabindex="-1"></a><span class="co"># Load milk data</span></span>
<span id="cb795-6172"><a href="#cb795-6172" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb795-6173"><a href="#cb795-6173" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk</span>
<span id="cb795-6174"><a href="#cb795-6174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6175"><a href="#cb795-6175" aria-hidden="true" tabindex="-1"></a><span class="do">## Start by modeling kcal.per.g as a function of perc.fat and perc.lactose, </span></span>
<span id="cb795-6176"><a href="#cb795-6176" aria-hidden="true" tabindex="-1"></a><span class="do">## but in two bivariate regressions</span></span>
<span id="cb795-6177"><a href="#cb795-6177" aria-hidden="true" tabindex="-1"></a><span class="co"># kcal.per.g regressed on perc.fat</span></span>
<span id="cb795-6178"><a href="#cb795-6178" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.10</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6179"><a href="#cb795-6179" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6180"><a href="#cb795-6180" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6181"><a href="#cb795-6181" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bf<span class="sc">*</span>perc.fat ,</span>
<span id="cb795-6182"><a href="#cb795-6182" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="fl">0.6</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6183"><a href="#cb795-6183" aria-hidden="true" tabindex="-1"></a>        bf <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-6184"><a href="#cb795-6184" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-6185"><a href="#cb795-6185" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-6186"><a href="#cb795-6186" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d )</span>
<span id="cb795-6187"><a href="#cb795-6187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6188"><a href="#cb795-6188" aria-hidden="true" tabindex="-1"></a><span class="co"># kcal.per.g regressed on perc.lactose</span></span>
<span id="cb795-6189"><a href="#cb795-6189" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.11</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6190"><a href="#cb795-6190" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6191"><a href="#cb795-6191" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6192"><a href="#cb795-6192" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bl<span class="sc">*</span>perc.lactose ,</span>
<span id="cb795-6193"><a href="#cb795-6193" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="fl">0.6</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6194"><a href="#cb795-6194" aria-hidden="true" tabindex="-1"></a>        bl <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-6195"><a href="#cb795-6195" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-6196"><a href="#cb795-6196" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>d )</span>
<span id="cb795-6197"><a href="#cb795-6197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6198"><a href="#cb795-6198" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m5<span class="fl">.10</span> , <span class="at">digits=</span><span class="dv">3</span> )</span>
<span id="cb795-6199"><a href="#cb795-6199" aria-hidden="true" tabindex="-1"></a><span class="co"># The posterior mean for bf, the association of percent fat with milk energy, is 0.01, </span></span>
<span id="cb795-6200"><a href="#cb795-6200" aria-hidden="true" tabindex="-1"></a><span class="co"># with 89% interval [0.008, 0.012].</span></span>
<span id="cb795-6201"><a href="#cb795-6201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6202"><a href="#cb795-6202" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m5<span class="fl">.11</span> , <span class="at">digits=</span><span class="dv">3</span> )</span>
<span id="cb795-6203"><a href="#cb795-6203" aria-hidden="true" tabindex="-1"></a><span class="co"># The posterior mean in the second model for percent lactose is −0.01, </span></span>
<span id="cb795-6204"><a href="#cb795-6204" aria-hidden="true" tabindex="-1"></a><span class="co"># with 89% interval [−0.012, −0.009].</span></span>
<span id="cb795-6205"><a href="#cb795-6205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6206"><a href="#cb795-6206" aria-hidden="true" tabindex="-1"></a><span class="co"># These posterior means are essentially mirror images of one another, with the posterior mean </span></span>
<span id="cb795-6207"><a href="#cb795-6207" aria-hidden="true" tabindex="-1"></a><span class="co"># of bf being as positive as the mean of bl is negative. Both are narrow posterior </span></span>
<span id="cb795-6208"><a href="#cb795-6208" aria-hidden="true" tabindex="-1"></a><span class="co"># distributions that lie almost entirely on one side or the other of zero.</span></span>
<span id="cb795-6209"><a href="#cb795-6209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6210"><a href="#cb795-6210" aria-hidden="true" tabindex="-1"></a><span class="co"># Note the parameter values for the slopes bf and bl are small in absolute value.</span></span>
<span id="cb795-6211"><a href="#cb795-6211" aria-hidden="true" tabindex="-1"></a><span class="co"># Both predictors are percents, so are potentially large numbers- these associations really </span></span>
<span id="cb795-6212"><a href="#cb795-6212" aria-hidden="true" tabindex="-1"></a><span class="co"># have much influence on the outcome, milk energy. Given the strong association of each </span></span>
<span id="cb795-6213"><a href="#cb795-6213" aria-hidden="true" tabindex="-1"></a><span class="co"># predictor with the outcome, we might conclude that both variables are reliable predictors </span></span>
<span id="cb795-6214"><a href="#cb795-6214" aria-hidden="true" tabindex="-1"></a><span class="co"># of total energy in milk, across species. </span></span>
<span id="cb795-6215"><a href="#cb795-6215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6216"><a href="#cb795-6216" aria-hidden="true" tabindex="-1"></a><span class="do">## Place both predictor variables in the same regression model</span></span>
<span id="cb795-6217"><a href="#cb795-6217" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.12</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6218"><a href="#cb795-6218" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6219"><a href="#cb795-6219" aria-hidden="true" tabindex="-1"></a>      kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6220"><a href="#cb795-6220" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bf<span class="sc">*</span>perc.fat <span class="sc">+</span> bl<span class="sc">*</span>perc.lactose ,</span>
<span id="cb795-6221"><a href="#cb795-6221" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="fl">0.6</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6222"><a href="#cb795-6222" aria-hidden="true" tabindex="-1"></a>        bf <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-6223"><a href="#cb795-6223" aria-hidden="true" tabindex="-1"></a>        bl <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-6224"><a href="#cb795-6224" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-6225"><a href="#cb795-6225" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-6226"><a href="#cb795-6226" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6227"><a href="#cb795-6227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6228"><a href="#cb795-6228" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m5<span class="fl">.12</span> , <span class="at">digits=</span><span class="dv">3</span> )</span>
<span id="cb795-6229"><a href="#cb795-6229" aria-hidden="true" tabindex="-1"></a><span class="co"># Now the posterior means of both bf and bl are closer to zero. And the standard deviations </span></span>
<span id="cb795-6230"><a href="#cb795-6230" aria-hidden="true" tabindex="-1"></a><span class="co"># for both parameters are twice as large as in the bivariate models (m5.10 and m5.11). </span></span>
<span id="cb795-6231"><a href="#cb795-6231" aria-hidden="true" tabindex="-1"></a><span class="co"># In the case of percent fat, the posterior mean is essentially zero.</span></span>
<span id="cb795-6232"><a href="#cb795-6232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6233"><a href="#cb795-6233" aria-hidden="true" tabindex="-1"></a><span class="co"># What has happened is that the variables perc.fat and perc.lactose contain much of the </span></span>
<span id="cb795-6234"><a href="#cb795-6234" aria-hidden="true" tabindex="-1"></a><span class="co"># same information. They are substitutes for one another. As a result, when you include both </span></span>
<span id="cb795-6235"><a href="#cb795-6235" aria-hidden="true" tabindex="-1"></a><span class="co"># in a regression, the posterior distribution ends up describing a long ridge of combinations </span></span>
<span id="cb795-6236"><a href="#cb795-6236" aria-hidden="true" tabindex="-1"></a><span class="co"># of bf and bl that are equally plausible.</span></span>
<span id="cb795-6237"><a href="#cb795-6237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6238"><a href="#cb795-6238" aria-hidden="true" tabindex="-1"></a><span class="co"># See results with pairs plot</span></span>
<span id="cb795-6239"><a href="#cb795-6239" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>( <span class="sc">~</span> kcal.per.g <span class="sc">+</span> perc.fat <span class="sc">+</span> perc.lactose ,</span>
<span id="cb795-6240"><a href="#cb795-6240" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-6241"><a href="#cb795-6241" aria-hidden="true" tabindex="-1"></a><span class="co"># A pairs plot of the total energy, percent fat, and percent lactose variables from the primate </span></span>
<span id="cb795-6242"><a href="#cb795-6242" aria-hidden="true" tabindex="-1"></a><span class="co"># milk data. Percent fat and percent lactose are strongly negatively correlated with one another, </span></span>
<span id="cb795-6243"><a href="#cb795-6243" aria-hidden="true" tabindex="-1"></a><span class="co"># providing mostly the same information- these two variables form essentially a single axis of variation.</span></span>
<span id="cb795-6244"><a href="#cb795-6244" aria-hidden="true" tabindex="-1"></a><span class="co"># These two variables are negatively correlated, and so strongly so that they are nearly redundant. </span></span>
<span id="cb795-6245"><a href="#cb795-6245" aria-hidden="true" tabindex="-1"></a><span class="co"># Either helps in predicting kcal.per.g, but neither helps much once you already know the other.</span></span>
<span id="cb795-6246"><a href="#cb795-6246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6247"><a href="#cb795-6247" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the correlation between the two variables with cor</span></span>
<span id="cb795-6248"><a href="#cb795-6248" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>( d<span class="sc">$</span>perc.fat , d<span class="sc">$</span>perc.lactose )</span>
<span id="cb795-6249"><a href="#cb795-6249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6250"><a href="#cb795-6250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6251"><a href="#cb795-6251" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6252"><a href="#cb795-6252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6253"><a href="#cb795-6253" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6254"><a href="#cb795-6254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6255"><a href="#cb795-6255" aria-hidden="true" tabindex="-1"></a>Correlations do have to get pretty high before this problem interferes with your analysis. But, ***what matters isn’t just the correlation between a pair of variables. Rather, what matters is the correlation that remains after accounting for any other predictors.***</span>
<span id="cb795-6256"><a href="#cb795-6256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6257"><a href="#cb795-6257" aria-hidden="true" tabindex="-1"></a>But with only two predictors here, we can address the correlation question directly. Suppose we have only kcal.per.g and perc.fat:</span>
<span id="cb795-6258"><a href="#cb795-6258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6259"><a href="#cb795-6259" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.10a}</span></span>
<span id="cb795-6260"><a href="#cb795-6260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6261"><a href="#cb795-6261" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct a random predictor variable, call it x, that is correlated with perc.fat </span></span>
<span id="cb795-6262"><a href="#cb795-6262" aria-hidden="true" tabindex="-1"></a><span class="co"># at some predetermined level</span></span>
<span id="cb795-6263"><a href="#cb795-6263" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fu">nrow</span>(milk)</span>
<span id="cb795-6264"><a href="#cb795-6264" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.6</span></span>
<span id="cb795-6265"><a href="#cb795-6265" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, rho<span class="sc">*</span>milk<span class="sc">$</span>perc.fat, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb795-6266"><a href="#cb795-6266" aria-hidden="true" tabindex="-1"></a>kcal.per.g <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, milk<span class="sc">$</span>perc.fat <span class="sc">-</span> x)</span>
<span id="cb795-6267"><a href="#cb795-6267" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(kcal.per.g, milk<span class="sc">$</span>perc.fat, x)</span>
<span id="cb795-6268"><a href="#cb795-6268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6269"><a href="#cb795-6269" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(d, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb795-6270"><a href="#cb795-6270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6271"><a href="#cb795-6271" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the regression model that tries to predict kcal.per.g using both perc.fat </span></span>
<span id="cb795-6272"><a href="#cb795-6272" aria-hidden="true" tabindex="-1"></a><span class="co"># and our random fake variable x</span></span>
<span id="cb795-6273"><a href="#cb795-6273" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.10</span>a <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6274"><a href="#cb795-6274" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-6275"><a href="#cb795-6275" aria-hidden="true" tabindex="-1"></a>    kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-6276"><a href="#cb795-6276" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bf<span class="sc">*</span>milk<span class="sc">$</span>perc.fat <span class="sc">+</span> bx<span class="sc">*</span>x,</span>
<span id="cb795-6277"><a href="#cb795-6277" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="fl">0.4</span>, <span class="dv">10</span>),</span>
<span id="cb795-6278"><a href="#cb795-6278" aria-hidden="true" tabindex="-1"></a>    bf <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-6279"><a href="#cb795-6279" aria-hidden="true" tabindex="-1"></a>    bx <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-6280"><a href="#cb795-6280" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-6281"><a href="#cb795-6281" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-6282"><a href="#cb795-6282" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-6283"><a href="#cb795-6283" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-6284"><a href="#cb795-6284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6285"><a href="#cb795-6285" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.10</span>a, <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb795-6286"><a href="#cb795-6286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6287"><a href="#cb795-6287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6288"><a href="#cb795-6288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6289"><a href="#cb795-6289" aria-hidden="true" tabindex="-1"></a>Now repeat this procedure many times, at different levels of correlation between perc.fat and x:</span>
<span id="cb795-6290"><a href="#cb795-6290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6291"><a href="#cb795-6291" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.40}</span></span>
<span id="cb795-6292"><a href="#cb795-6292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6293"><a href="#cb795-6293" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb795-6294"><a href="#cb795-6294" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk</span>
<span id="cb795-6295"><a href="#cb795-6295" aria-hidden="true" tabindex="-1"></a>sim.coll <span class="ot">&lt;-</span> <span class="cf">function</span>( <span class="at">r=</span><span class="fl">0.9</span> ) {</span>
<span id="cb795-6296"><a href="#cb795-6296" aria-hidden="true" tabindex="-1"></a>    d<span class="sc">$</span>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>( <span class="fu">nrow</span>(d) , <span class="at">mean=</span>r<span class="sc">*</span>d<span class="sc">$</span>perc.fat ,</span>
<span id="cb795-6297"><a href="#cb795-6297" aria-hidden="true" tabindex="-1"></a>        <span class="at">sd=</span><span class="fu">sqrt</span>( (<span class="dv">1</span><span class="sc">-</span>r<span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">var</span>(d<span class="sc">$</span>perc.fat) ) )</span>
<span id="cb795-6298"><a href="#cb795-6298" aria-hidden="true" tabindex="-1"></a>    m <span class="ot">&lt;-</span> <span class="fu">lm</span>( kcal.per.g <span class="sc">~</span> perc.fat <span class="sc">+</span> x , <span class="at">data=</span>d )</span>
<span id="cb795-6299"><a href="#cb795-6299" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sqrt</span>( <span class="fu">diag</span>( <span class="fu">vcov</span>(m) ) )[<span class="dv">2</span>] <span class="co"># stddev of parameter</span></span>
<span id="cb795-6300"><a href="#cb795-6300" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-6301"><a href="#cb795-6301" aria-hidden="true" tabindex="-1"></a>rep.sim.coll <span class="ot">&lt;-</span> <span class="cf">function</span>( <span class="at">r=</span><span class="fl">0.9</span> , <span class="at">n=</span><span class="dv">100</span> ) { <span class="co"># 100 regressions</span></span>
<span id="cb795-6302"><a href="#cb795-6302" aria-hidden="true" tabindex="-1"></a>    stddev <span class="ot">&lt;-</span> <span class="fu">replicate</span>( n , <span class="fu">sim.coll</span>(r) )</span>
<span id="cb795-6303"><a href="#cb795-6303" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(stddev)</span>
<span id="cb795-6304"><a href="#cb795-6304" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-6305"><a href="#cb795-6305" aria-hidden="true" tabindex="-1"></a>r.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="dv">0</span>,<span class="at">to=</span><span class="fl">0.99</span>,<span class="at">by=</span><span class="fl">0.01</span>)</span>
<span id="cb795-6306"><a href="#cb795-6306" aria-hidden="true" tabindex="-1"></a>stddev <span class="ot">&lt;-</span> <span class="fu">sapply</span>( r.seq , <span class="cf">function</span>(z) <span class="fu">rep.sim.coll</span>(<span class="at">r=</span>z,<span class="at">n=</span><span class="dv">100</span>) )</span>
<span id="cb795-6307"><a href="#cb795-6307" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( stddev <span class="sc">~</span> r.seq , <span class="at">type=</span><span class="st">"l"</span> , <span class="at">col=</span>rangi2, <span class="at">lwd=</span><span class="dv">2</span> , <span class="at">xlab=</span><span class="st">"correlation"</span> )</span>
<span id="cb795-6308"><a href="#cb795-6308" aria-hidden="true" tabindex="-1"></a><span class="co"># The effect of correlated predictor variables on the narrowness of the posterior distribution. </span></span>
<span id="cb795-6309"><a href="#cb795-6309" aria-hidden="true" tabindex="-1"></a><span class="co"># The vertical axis shows the standard deviation of the posterior distribution of the slope. </span></span>
<span id="cb795-6310"><a href="#cb795-6310" aria-hidden="true" tabindex="-1"></a><span class="co"># The horizontal axis is the correlation between the predictor of interest (perc.fat) and another</span></span>
<span id="cb795-6311"><a href="#cb795-6311" aria-hidden="true" tabindex="-1"></a><span class="co"># predictor (x) added to the model. As the correlation increases, the standard deviation inflates.</span></span>
<span id="cb795-6312"><a href="#cb795-6312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6313"><a href="#cb795-6313" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6314"><a href="#cb795-6314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6315"><a href="#cb795-6315" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6316"><a href="#cb795-6316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6317"><a href="#cb795-6317" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***What can be done about multicollinearity***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-6318"><a href="#cb795-6318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6319"><a href="#cb795-6319" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Be aware of it.</span>
<span id="cb795-6320"><a href="#cb795-6320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6321"><a href="#cb795-6321" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Check the predictor variables against one another in a pairs plot.</span>
<span id="cb795-6322"><a href="#cb795-6322" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Any pair or cluster of variables with very large correlations, over about 0.9, may be problematic, once included as main effects in the same model.</span>
<span id="cb795-6323"><a href="#cb795-6323" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>However, it isn’t always true that highly correlated variables are completely redundant— other predictors might be correlated with only one of the pair, and so help extract the unique information each predictor provides.</span>
<span id="cb795-6324"><a href="#cb795-6324" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>So, you can’t know just from a table of correlations nor from a matrix of scatterplots whether multicollinearity will prevent you from including sets of variables in the same model.</span>
<span id="cb795-6325"><a href="#cb795-6325" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Still, you can usually diagnose the problem by looking for a big inflation of standard deviation, when both variables are included in the same model.</span>
<span id="cb795-6326"><a href="#cb795-6326" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-6327"><a href="#cb795-6327" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-6328"><a href="#cb795-6328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6329"><a href="#cb795-6329" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Principle components or Factor analysis</span>
<span id="cb795-6330"><a href="#cb795-6330" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>A data reduction procedure, and then to use the components/factors as predictor variables</span>
<span id="cb795-6331"><a href="#cb795-6331" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>may be considered voodoo</span>
<span id="cb795-6332"><a href="#cb795-6332" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-6333"><a href="#cb795-6333" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-6334"><a href="#cb795-6334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6335"><a href="#cb795-6335" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>***It’s usually helpful to check the covariation among parameters, especially when intervals are extremely wide, so you don’t misinterpret what the model is trying to tell you.***</span>
<span id="cb795-6336"><a href="#cb795-6336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6337"><a href="#cb795-6337" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6338"><a href="#cb795-6338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6339"><a href="#cb795-6339" aria-hidden="true" tabindex="-1"></a><span class="fu">### Post-treatment bias</span></span>
<span id="cb795-6340"><a href="#cb795-6340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6341"><a href="#cb795-6341" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Omitted variable bias</span>
<span id="cb795-6342"><a href="#cb795-6342" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>mistaken inferences that arise from omitting predictor variables</span>
<span id="cb795-6343"><a href="#cb795-6343" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-6344"><a href="#cb795-6344" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-6345"><a href="#cb795-6345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6346"><a href="#cb795-6346" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Post-treatment bias</span>
<span id="cb795-6347"><a href="#cb795-6347" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>mistaken inferences arising from including variables that are consequences of other variables</span>
<span id="cb795-6348"><a href="#cb795-6348" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-6349"><a href="#cb795-6349" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6350"><a href="#cb795-6350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6351"><a href="#cb795-6351" aria-hidden="true" tabindex="-1"></a>Simulate post-treatment bias in plant growth vs. different anti-fungal soil treatments model. There are four variables of interest here: initial height, final height, treatment, and presence of fungus. Final height is the outcome of interest. But which of the other variables should be in the model? If your goal is to make a causal inference about the treatment, you shouldn’t include the presence of fungus, because it is a post-treatment effect.</span>
<span id="cb795-6352"><a href="#cb795-6352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6353"><a href="#cb795-6353" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.41}</span></span>
<span id="cb795-6354"><a href="#cb795-6354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6355"><a href="#cb795-6355" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">54</span>)</span>
<span id="cb795-6356"><a href="#cb795-6356" aria-hidden="true" tabindex="-1"></a><span class="co"># number of plants</span></span>
<span id="cb795-6357"><a href="#cb795-6357" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb795-6358"><a href="#cb795-6358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6359"><a href="#cb795-6359" aria-hidden="true" tabindex="-1"></a><span class="co"># simulate initial heights</span></span>
<span id="cb795-6360"><a href="#cb795-6360" aria-hidden="true" tabindex="-1"></a>h0 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">10</span>,<span class="dv">2</span>)</span>
<span id="cb795-6361"><a href="#cb795-6361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6362"><a href="#cb795-6362" aria-hidden="true" tabindex="-1"></a><span class="co"># assign treatments and simulate fungus and growth</span></span>
<span id="cb795-6363"><a href="#cb795-6363" aria-hidden="true" tabindex="-1"></a>treatment <span class="ot">&lt;-</span> <span class="fu">rep</span>( <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span> , <span class="at">each=</span>N<span class="sc">/</span><span class="dv">2</span> )</span>
<span id="cb795-6364"><a href="#cb795-6364" aria-hidden="true" tabindex="-1"></a>fungus <span class="ot">&lt;-</span> <span class="fu">rbinom</span>( N , <span class="at">size=</span><span class="dv">1</span> , <span class="at">prob=</span><span class="fl">0.5</span> <span class="sc">-</span> treatment<span class="sc">*</span><span class="fl">0.4</span> )</span>
<span id="cb795-6365"><a href="#cb795-6365" aria-hidden="true" tabindex="-1"></a>h1 <span class="ot">&lt;-</span> h0 <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="dv">5</span> <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>fungus)</span>
<span id="cb795-6366"><a href="#cb795-6366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6367"><a href="#cb795-6367" aria-hidden="true" tabindex="-1"></a><span class="co"># compose a clean data frame</span></span>
<span id="cb795-6368"><a href="#cb795-6368" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">h0=</span>h0 , <span class="at">h1=</span>h1 , <span class="at">treatment=</span>treatment , <span class="at">fungus=</span>fungus )</span>
<span id="cb795-6369"><a href="#cb795-6369" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-6370"><a href="#cb795-6370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6371"><a href="#cb795-6371" aria-hidden="true" tabindex="-1"></a><span class="co"># fit the model that includes all of the available variables</span></span>
<span id="cb795-6372"><a href="#cb795-6372" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.13</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6373"><a href="#cb795-6373" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6374"><a href="#cb795-6374" aria-hidden="true" tabindex="-1"></a>        h1 <span class="sc">~</span> <span class="fu">dnorm</span>(mu,sigma),</span>
<span id="cb795-6375"><a href="#cb795-6375" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bh<span class="sc">*</span>h0 <span class="sc">+</span> bt<span class="sc">*</span>treatment <span class="sc">+</span> bf<span class="sc">*</span>fungus,</span>
<span id="cb795-6376"><a href="#cb795-6376" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">100</span>),</span>
<span id="cb795-6377"><a href="#cb795-6377" aria-hidden="true" tabindex="-1"></a>        <span class="fu">c</span>(bh,bt,bf) <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-6378"><a href="#cb795-6378" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb795-6379"><a href="#cb795-6379" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-6380"><a href="#cb795-6380" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6381"><a href="#cb795-6381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6382"><a href="#cb795-6382" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.13</span>)</span>
<span id="cb795-6383"><a href="#cb795-6383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6384"><a href="#cb795-6384" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6385"><a href="#cb795-6385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6386"><a href="#cb795-6386" aria-hidden="true" tabindex="-1"></a>The marginal posterior for bt, the effect of treatment, is actually negative here. But it mainly had very little effect. The other two predictors, h0 and fungus, have important effects. Given that we know the treatment matters, because we built the simulation that way, what happened here? The problem is that fungus is mostly a consequence of treatment- fungus is a post-treatment variable. When we control for fungus, the soil treatment doesn't matter because soil treatment has its effects on growth through reducing fungus. </span>
<span id="cb795-6387"><a href="#cb795-6387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6388"><a href="#cb795-6388" aria-hidden="true" tabindex="-1"></a>*Model m5.13 misleads because it asks the wrong question, not because it would make poor predictions- the model that includes fungus both fits the sample better and would make better out-of-sample predictions. No statistical procedure can substitute for scientific knowledge and attention to it.*</span>
<span id="cb795-6389"><a href="#cb795-6389" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-6390"><a href="#cb795-6390" aria-hidden="true" tabindex="-1"></a>What we actually want to know, based on the design of the experiment, is the impact of treatment on growth. To measure this properly, we should omit the post-treatment variable fungus. </span>
<span id="cb795-6391"><a href="#cb795-6391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6392"><a href="#cb795-6392" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.43}</span></span>
<span id="cb795-6393"><a href="#cb795-6393" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb795-6394"><a href="#cb795-6394" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.14</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6395"><a href="#cb795-6395" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6396"><a href="#cb795-6396" aria-hidden="true" tabindex="-1"></a>        h1 <span class="sc">~</span> <span class="fu">dnorm</span>(mu,sigma),</span>
<span id="cb795-6397"><a href="#cb795-6397" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bh<span class="sc">*</span>h0 <span class="sc">+</span> bt<span class="sc">*</span>treatment,</span>
<span id="cb795-6398"><a href="#cb795-6398" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">100</span>),</span>
<span id="cb795-6399"><a href="#cb795-6399" aria-hidden="true" tabindex="-1"></a>        <span class="fu">c</span>(bh,bt) <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-6400"><a href="#cb795-6400" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb795-6401"><a href="#cb795-6401" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-6402"><a href="#cb795-6402" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6403"><a href="#cb795-6403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6404"><a href="#cb795-6404" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.14</span>)</span>
<span id="cb795-6405"><a href="#cb795-6405" aria-hidden="true" tabindex="-1"></a><span class="co"># Now the impact of treatment is strong and positive, as it should be. It makes sense to </span></span>
<span id="cb795-6406"><a href="#cb795-6406" aria-hidden="true" tabindex="-1"></a><span class="co"># control for pre-treatment differences, like the initial height h0, that might mask the </span></span>
<span id="cb795-6407"><a href="#cb795-6407" aria-hidden="true" tabindex="-1"></a><span class="co"># causal influence of treatment. But including post-treatment variables can actually mask </span></span>
<span id="cb795-6408"><a href="#cb795-6408" aria-hidden="true" tabindex="-1"></a><span class="co"># the treatment itself.</span></span>
<span id="cb795-6409"><a href="#cb795-6409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6410"><a href="#cb795-6410" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6411"><a href="#cb795-6411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6412"><a href="#cb795-6412" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6413"><a href="#cb795-6413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6414"><a href="#cb795-6414" aria-hidden="true" tabindex="-1"></a><span class="fu">## Categorical variables</span></span>
<span id="cb795-6415"><a href="#cb795-6415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6416"><a href="#cb795-6416" aria-hidden="true" tabindex="-1"></a>A common question for statistical methods is to what extent an outcome changes as a result of presence or absence of a category. Common examples of categorical variables (factors) include:</span>
<span id="cb795-6417"><a href="#cb795-6417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6418"><a href="#cb795-6418" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sex: male, female</span>
<span id="cb795-6419"><a href="#cb795-6419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6420"><a href="#cb795-6420" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Developmental status: infant, juvenile, adult</span>
<span id="cb795-6421"><a href="#cb795-6421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6422"><a href="#cb795-6422" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Geographic region: Africa, Europe, Melanesia</span>
<span id="cb795-6423"><a href="#cb795-6423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6424"><a href="#cb795-6424" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Taxonomic group: Ape, Monkeys</span>
<span id="cb795-6425"><a href="#cb795-6425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6426"><a href="#cb795-6426" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6427"><a href="#cb795-6427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6428"><a href="#cb795-6428" aria-hidden="true" tabindex="-1"></a><span class="fu">### Binary categories</span></span>
<span id="cb795-6429"><a href="#cb795-6429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6430"><a href="#cb795-6430" aria-hidden="true" tabindex="-1"></a>In the simplest case, the variable of interest has only two categories, like male and female. </span>
<span id="cb795-6431"><a href="#cb795-6431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6432"><a href="#cb795-6432" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.44}</span></span>
<span id="cb795-6433"><a href="#cb795-6433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6434"><a href="#cb795-6434" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data Howell1</span></span>
<span id="cb795-6435"><a href="#cb795-6435" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Howell1)</span>
<span id="cb795-6436"><a href="#cb795-6436" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Howell1</span>
<span id="cb795-6437"><a href="#cb795-6437" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-6438"><a href="#cb795-6438" aria-hidden="true" tabindex="-1"></a><span class="co"># The male variable is our new predictor, an example of a dummy variable.</span></span>
<span id="cb795-6439"><a href="#cb795-6439" aria-hidden="true" tabindex="-1"></a><span class="co"># Dummy variables are devices for encoding categories into quantitative models.</span></span>
<span id="cb795-6440"><a href="#cb795-6440" aria-hidden="true" tabindex="-1"></a><span class="co"># e.g. 1 for male, 0 for female</span></span>
<span id="cb795-6441"><a href="#cb795-6441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6442"><a href="#cb795-6442" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6443"><a href="#cb795-6443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6444"><a href="#cb795-6444" aria-hidden="true" tabindex="-1"></a>The effect of a dummy variable is to turn a parameter on for those cases in the category. Simultaneously, the variable turns the same parameter off for those cases in another category. The model to fit is:</span>
<span id="cb795-6445"><a href="#cb795-6445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6446"><a href="#cb795-6446" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6447"><a href="#cb795-6447" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6448"><a href="#cb795-6448" aria-hidden="true" tabindex="-1"></a>\text{h}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6449"><a href="#cb795-6449" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_m \text{m}_i<span class="sc">\\</span></span>
<span id="cb795-6450"><a href="#cb795-6450" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(178, 100)<span class="sc">\\</span></span>
<span id="cb795-6451"><a href="#cb795-6451" aria-hidden="true" tabindex="-1"></a>\beta_m &amp;\sim \text{Normal}(0, 10)<span class="sc">\\</span></span>
<span id="cb795-6452"><a href="#cb795-6452" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 50)</span>
<span id="cb795-6453"><a href="#cb795-6453" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6454"><a href="#cb795-6454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6455"><a href="#cb795-6455" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6456"><a href="#cb795-6456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6457"><a href="#cb795-6457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6458"><a href="#cb795-6458" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6459"><a href="#cb795-6459" aria-hidden="true" tabindex="-1"></a><span class="in">h   = height</span></span>
<span id="cb795-6460"><a href="#cb795-6460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6461"><a href="#cb795-6461" aria-hidden="true" tabindex="-1"></a><span class="in">m   = dummy variable indicating a male individual</span></span>
<span id="cb795-6462"><a href="#cb795-6462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6463"><a href="#cb795-6463" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6464"><a href="#cb795-6464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6465"><a href="#cb795-6465" aria-hidden="true" tabindex="-1"></a>The parameter $\beta_m$ influences prediction only for those cases where $\text{m}_i$ = 1. When $\text{m}_i$ = 0, it has no effect on prediction, because it is multiplied by zero inside the linear model, $\alpha + \beta_m \text{m}_i$, canceling it out, whatever its value.</span>
<span id="cb795-6466"><a href="#cb795-6466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6467"><a href="#cb795-6467" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.45}</span></span>
<span id="cb795-6468"><a href="#cb795-6468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6469"><a href="#cb795-6469" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb795-6470"><a href="#cb795-6470" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.15</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6471"><a href="#cb795-6471" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6472"><a href="#cb795-6472" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6473"><a href="#cb795-6473" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bm<span class="sc">*</span>male , </span>
<span id="cb795-6474"><a href="#cb795-6474" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-6475"><a href="#cb795-6475" aria-hidden="true" tabindex="-1"></a>        bm <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6476"><a href="#cb795-6476" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> ) ),</span>
<span id="cb795-6477"><a href="#cb795-6477" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6478"><a href="#cb795-6478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6479"><a href="#cb795-6479" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.15</span>)</span>
<span id="cb795-6480"><a href="#cb795-6480" aria-hidden="true" tabindex="-1"></a><span class="co"># The parameter α (a) is now the average height among females. Because when mi = 0, </span></span>
<span id="cb795-6481"><a href="#cb795-6481" aria-hidden="true" tabindex="-1"></a><span class="co"># indicating a female, the predicted mean height is just μi = α + βm(0) = α. </span></span>
<span id="cb795-6482"><a href="#cb795-6482" aria-hidden="true" tabindex="-1"></a><span class="co"># So the estimate says that the expected average female height is 135 cm. </span></span>
<span id="cb795-6483"><a href="#cb795-6483" aria-hidden="true" tabindex="-1"></a><span class="co"># The parameter βm then tells us the average difference between males and females, 7.3 cm. </span></span>
<span id="cb795-6484"><a href="#cb795-6484" aria-hidden="true" tabindex="-1"></a><span class="co"># So to compute the average male height, you just add these two estimates: 135 + 7.3 = 142.3.</span></span>
<span id="cb795-6485"><a href="#cb795-6485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6486"><a href="#cb795-6486" aria-hidden="true" tabindex="-1"></a><span class="co"># You’ll also need to consider the width of the posterior distribution. And because the </span></span>
<span id="cb795-6487"><a href="#cb795-6487" aria-hidden="true" tabindex="-1"></a><span class="co"># parameters α and βm are correlated with one another, you can’t just add together </span></span>
<span id="cb795-6488"><a href="#cb795-6488" aria-hidden="true" tabindex="-1"></a><span class="co"># the boundaries in the precis output and get correct boundaries for their sum. </span></span>
<span id="cb795-6489"><a href="#cb795-6489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6490"><a href="#cb795-6490" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample from the posterior to derive a percentile interval for average male height</span></span>
<span id="cb795-6491"><a href="#cb795-6491" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.15</span>)</span>
<span id="cb795-6492"><a href="#cb795-6492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6493"><a href="#cb795-6493" aria-hidden="true" tabindex="-1"></a><span class="co"># Add samples of a and bm together to get the posterior distribution of their sum</span></span>
<span id="cb795-6494"><a href="#cb795-6494" aria-hidden="true" tabindex="-1"></a>mu.male <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>bm</span>
<span id="cb795-6495"><a href="#cb795-6495" aria-hidden="true" tabindex="-1"></a><span class="fu">PI</span>(mu.male)</span>
<span id="cb795-6496"><a href="#cb795-6496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6497"><a href="#cb795-6497" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6498"><a href="#cb795-6498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6499"><a href="#cb795-6499" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6500"><a href="#cb795-6500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6501"><a href="#cb795-6501" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Re-parameterizing the model**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-6502"><a href="#cb795-6502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6503"><a href="#cb795-6503" aria-hidden="true" tabindex="-1"></a>Instead of using a parameter for the difference between males and females, we can make parameters specific to males and females:</span>
<span id="cb795-6504"><a href="#cb795-6504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6505"><a href="#cb795-6505" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6506"><a href="#cb795-6506" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6507"><a href="#cb795-6507" aria-hidden="true" tabindex="-1"></a>\text{h}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6508"><a href="#cb795-6508" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha_f(1 - \text{m}_i) + \alpha_m \text{m}_i<span class="sc">\\</span></span>
<span id="cb795-6509"><a href="#cb795-6509" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6510"><a href="#cb795-6510" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6511"><a href="#cb795-6511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6512"><a href="#cb795-6512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6513"><a href="#cb795-6513" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6514"><a href="#cb795-6514" aria-hidden="true" tabindex="-1"></a><span class="in">alpha_f   = average female height</span></span>
<span id="cb795-6515"><a href="#cb795-6515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6516"><a href="#cb795-6516" aria-hidden="true" tabindex="-1"></a><span class="in">alpha_m   = average male height</span></span>
<span id="cb795-6517"><a href="#cb795-6517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6518"><a href="#cb795-6518" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6519"><a href="#cb795-6519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6520"><a href="#cb795-6520" aria-hidden="true" tabindex="-1"></a>Plug in $\text{m}_i$ = 0 and $\text{m}_i$ = 1 to verify that either $\alpha_f$ or $\alpha_m$, but never both, is turned on for any individual case i. </span>
<span id="cb795-6521"><a href="#cb795-6521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6522"><a href="#cb795-6522" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.47}</span></span>
<span id="cb795-6523"><a href="#cb795-6523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6524"><a href="#cb795-6524" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb795-6525"><a href="#cb795-6525" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.15</span>b <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6526"><a href="#cb795-6526" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6527"><a href="#cb795-6527" aria-hidden="true" tabindex="-1"></a>        height <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6528"><a href="#cb795-6528" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> af<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>male) <span class="sc">+</span> am<span class="sc">*</span>male ,</span>
<span id="cb795-6529"><a href="#cb795-6529" aria-hidden="true" tabindex="-1"></a>        af <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-6530"><a href="#cb795-6530" aria-hidden="true" tabindex="-1"></a>        am <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">178</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-6531"><a href="#cb795-6531" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">50</span> )</span>
<span id="cb795-6532"><a href="#cb795-6532" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>d )</span>
<span id="cb795-6533"><a href="#cb795-6533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6534"><a href="#cb795-6534" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.15</span>b)</span>
<span id="cb795-6535"><a href="#cb795-6535" aria-hidden="true" tabindex="-1"></a><span class="co"># The results are inferentially equivalent to the original m5.15.</span></span>
<span id="cb795-6536"><a href="#cb795-6536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6537"><a href="#cb795-6537" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6538"><a href="#cb795-6538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6539"><a href="#cb795-6539" aria-hidden="true" tabindex="-1"></a>The mathematical model can be rearranged where the old $\beta_m$ as the difference between the average male and female, $\alpha_m - \alpha_f$:</span>
<span id="cb795-6540"><a href="#cb795-6540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6541"><a href="#cb795-6541" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha_f + (\alpha_m - \alpha_f) \text{m}_i $$</span>
<span id="cb795-6542"><a href="#cb795-6542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6543"><a href="#cb795-6543" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6544"><a href="#cb795-6544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6545"><a href="#cb795-6545" aria-hidden="true" tabindex="-1"></a><span class="fu">### Many categories</span></span>
<span id="cb795-6546"><a href="#cb795-6546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6547"><a href="#cb795-6547" aria-hidden="true" tabindex="-1"></a>When there are more than two categories, you’ll need more than one dummy variable. To include k categories in a linear model, you require k − 1 dummy variables. Each dummy variable indicates, with the value 1, a unique category. The category with no dummy variable assigned to it ends up again as the “intercept” category.</span>
<span id="cb795-6548"><a href="#cb795-6548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6549"><a href="#cb795-6549" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.48}</span></span>
<span id="cb795-6550"><a href="#cb795-6550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6551"><a href="#cb795-6551" aria-hidden="true" tabindex="-1"></a><span class="co"># Load milk data and extract clade variable</span></span>
<span id="cb795-6552"><a href="#cb795-6552" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb795-6553"><a href="#cb795-6553" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk</span>
<span id="cb795-6554"><a href="#cb795-6554" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(d<span class="sc">$</span>clade)</span>
<span id="cb795-6555"><a href="#cb795-6555" aria-hidden="true" tabindex="-1"></a><span class="co"># There are more than two categories and none of them have yet been coded into dummy variables.</span></span>
<span id="cb795-6556"><a href="#cb795-6556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6557"><a href="#cb795-6557" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dummy for the New World Monkey category</span></span>
<span id="cb795-6558"><a href="#cb795-6558" aria-hidden="true" tabindex="-1"></a>( d<span class="sc">$</span>clade.NWM <span class="ot">&lt;-</span> <span class="fu">ifelse</span>( d<span class="sc">$</span>clade<span class="sc">==</span><span class="st">"New World Monkey"</span> , <span class="dv">1</span> , <span class="dv">0</span> ) )</span>
<span id="cb795-6559"><a href="#cb795-6559" aria-hidden="true" tabindex="-1"></a><span class="co"># Only those rows (cases) where clade is New World Monkey get a 1 for this new variable.</span></span>
<span id="cb795-6560"><a href="#cb795-6560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6561"><a href="#cb795-6561" aria-hidden="true" tabindex="-1"></a><span class="co"># Make two more dummy variables with the same strategy</span></span>
<span id="cb795-6562"><a href="#cb795-6562" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>clade.OWM <span class="ot">&lt;-</span> <span class="fu">ifelse</span>( d<span class="sc">$</span>clade<span class="sc">==</span><span class="st">"Old World Monkey"</span> , <span class="dv">1</span> , <span class="dv">0</span> )</span>
<span id="cb795-6563"><a href="#cb795-6563" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>clade.S <span class="ot">&lt;-</span> <span class="fu">ifelse</span>( d<span class="sc">$</span>clade<span class="sc">==</span><span class="st">"Strepsirrhine"</span> , <span class="dv">1</span> , <span class="dv">0</span> )</span>
<span id="cb795-6564"><a href="#cb795-6564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6565"><a href="#cb795-6565" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6566"><a href="#cb795-6566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6567"><a href="#cb795-6567" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6568"><a href="#cb795-6568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6569"><a href="#cb795-6569" aria-hidden="true" tabindex="-1"></a>The category <span class="in">`Ape`</span> will be the default "intercept" category. In fact, if you try to include a dummy variable for apes, you’ll up with a non-identifiable model. </span>
<span id="cb795-6570"><a href="#cb795-6570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6571"><a href="#cb795-6571" aria-hidden="true" tabindex="-1"></a>The model we aim to fit to the data is kcal.per.g regressed on the dummy variables for clade:</span>
<span id="cb795-6572"><a href="#cb795-6572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6573"><a href="#cb795-6573" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6574"><a href="#cb795-6574" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6575"><a href="#cb795-6575" aria-hidden="true" tabindex="-1"></a>\text{k}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6576"><a href="#cb795-6576" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_{NWM} \text{NWM}_i + \beta_{OWM} \text{OWM}_i + \beta_S \text{S}_i<span class="sc">\\</span></span>
<span id="cb795-6577"><a href="#cb795-6577" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(0.6, 10)<span class="sc">\\</span></span>
<span id="cb795-6578"><a href="#cb795-6578" aria-hidden="true" tabindex="-1"></a>\beta_{NWM} &amp;\sim \text{Normal}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-6579"><a href="#cb795-6579" aria-hidden="true" tabindex="-1"></a>\beta_{OWM} &amp;\sim \text{Normal}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-6580"><a href="#cb795-6580" aria-hidden="true" tabindex="-1"></a>\beta_S &amp;\sim \text{Normal}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-6581"><a href="#cb795-6581" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 10)</span>
<span id="cb795-6582"><a href="#cb795-6582" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6583"><a href="#cb795-6583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6584"><a href="#cb795-6584" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6585"><a href="#cb795-6585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6586"><a href="#cb795-6586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6587"><a href="#cb795-6587" aria-hidden="true" tabindex="-1"></a>A linear model like this really defines four different linear models, each corresponding to a different category.</span>
<span id="cb795-6588"><a href="#cb795-6588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6589"><a href="#cb795-6589" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.51}</span></span>
<span id="cb795-6590"><a href="#cb795-6590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6591"><a href="#cb795-6591" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the model</span></span>
<span id="cb795-6592"><a href="#cb795-6592" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.16</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6593"><a href="#cb795-6593" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6594"><a href="#cb795-6594" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6595"><a href="#cb795-6595" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b.NWM<span class="sc">*</span>clade.NWM <span class="sc">+</span> b.OWM<span class="sc">*</span>clade.OWM <span class="sc">+</span> b.S<span class="sc">*</span>clade.S ,</span>
<span id="cb795-6596"><a href="#cb795-6596" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="fl">0.6</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6597"><a href="#cb795-6597" aria-hidden="true" tabindex="-1"></a>        b.NWM <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-6598"><a href="#cb795-6598" aria-hidden="true" tabindex="-1"></a>        b.OWM <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-6599"><a href="#cb795-6599" aria-hidden="true" tabindex="-1"></a>        b.S <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-6600"><a href="#cb795-6600" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-6601"><a href="#cb795-6601" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-6602"><a href="#cb795-6602" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6603"><a href="#cb795-6603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6604"><a href="#cb795-6604" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.16</span>)</span>
<span id="cb795-6605"><a href="#cb795-6605" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate a is the average milk energy for apes, and the estimates for the other </span></span>
<span id="cb795-6606"><a href="#cb795-6606" aria-hidden="true" tabindex="-1"></a><span class="co"># categories are differences from apes.</span></span>
<span id="cb795-6607"><a href="#cb795-6607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6608"><a href="#cb795-6608" aria-hidden="true" tabindex="-1"></a><span class="do">## Use samples to get posterior distributions of the average milk energy in each category</span></span>
<span id="cb795-6609"><a href="#cb795-6609" aria-hidden="true" tabindex="-1"></a><span class="co"># sample posterior</span></span>
<span id="cb795-6610"><a href="#cb795-6610" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5<span class="fl">.16</span>)</span>
<span id="cb795-6611"><a href="#cb795-6611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6612"><a href="#cb795-6612" aria-hidden="true" tabindex="-1"></a><span class="co"># compute averages for each category</span></span>
<span id="cb795-6613"><a href="#cb795-6613" aria-hidden="true" tabindex="-1"></a>mu.ape <span class="ot">&lt;-</span> post<span class="sc">$</span>a</span>
<span id="cb795-6614"><a href="#cb795-6614" aria-hidden="true" tabindex="-1"></a>mu.NWM <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b.NWM</span>
<span id="cb795-6615"><a href="#cb795-6615" aria-hidden="true" tabindex="-1"></a>mu.OWM <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b.OWM</span>
<span id="cb795-6616"><a href="#cb795-6616" aria-hidden="true" tabindex="-1"></a>mu.S <span class="ot">&lt;-</span> post<span class="sc">$</span>a <span class="sc">+</span> post<span class="sc">$</span>b.S</span>
<span id="cb795-6617"><a href="#cb795-6617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6618"><a href="#cb795-6618" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize using precis</span></span>
<span id="cb795-6619"><a href="#cb795-6619" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( <span class="fu">data.frame</span>(mu.ape,mu.NWM,mu.OWM,mu.S) )</span>
<span id="cb795-6620"><a href="#cb795-6620" aria-hidden="true" tabindex="-1"></a><span class="co"># The most plausible (conditional on data and model) average milk energies in each category </span></span>
<span id="cb795-6621"><a href="#cb795-6621" aria-hidden="true" tabindex="-1"></a><span class="co"># are 0.55, 0.71, 0.79, and 0.51.</span></span>
<span id="cb795-6622"><a href="#cb795-6622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6623"><a href="#cb795-6623" aria-hidden="true" tabindex="-1"></a><span class="do">## Re-parameterize model after fitting it to data to know the estimate difference between</span></span>
<span id="cb795-6624"><a href="#cb795-6624" aria-hidden="true" tabindex="-1"></a><span class="do">## two monkey groups- rather than a difference from apes. </span></span>
<span id="cb795-6625"><a href="#cb795-6625" aria-hidden="true" tabindex="-1"></a><span class="co"># Substract the estimated means to get a difference</span></span>
<span id="cb795-6626"><a href="#cb795-6626" aria-hidden="true" tabindex="-1"></a>diff.NWM.OWM <span class="ot">&lt;-</span> mu.NWM <span class="sc">-</span> mu.OWM</span>
<span id="cb795-6627"><a href="#cb795-6627" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>( diff.NWM.OWM , <span class="at">probs=</span><span class="fu">c</span>(<span class="fl">0.025</span>,<span class="fl">0.5</span>,<span class="fl">0.975</span>) )</span>
<span id="cb795-6628"><a href="#cb795-6628" aria-hidden="true" tabindex="-1"></a><span class="co"># The values are the posterior lower 95% boundary, the median, and the upper 95% boundary </span></span>
<span id="cb795-6629"><a href="#cb795-6629" aria-hidden="true" tabindex="-1"></a><span class="co"># for the difference between New World and Old World monkeys.</span></span>
<span id="cb795-6630"><a href="#cb795-6630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6631"><a href="#cb795-6631" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6632"><a href="#cb795-6632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6633"><a href="#cb795-6633" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6634"><a href="#cb795-6634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6635"><a href="#cb795-6635" aria-hidden="true" tabindex="-1"></a><span class="fu">### Adding regular predictor variables</span></span>
<span id="cb795-6636"><a href="#cb795-6636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6637"><a href="#cb795-6637" aria-hidden="true" tabindex="-1"></a>Just add the predictor variables to the equation for the mean, as you normally would. For example, to add the influence of perc.fat to the model with dummies for the clades:</span>
<span id="cb795-6638"><a href="#cb795-6638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6639"><a href="#cb795-6639" aria-hidden="true" tabindex="-1"></a>$$\mu_i = \alpha + \beta_{NWM} \text{NWM}_i + \beta_{OWM} \text{OWM}_i + \beta_S \text{S}_i + \beta_F \text{F}_i$$</span>
<span id="cb795-6640"><a href="#cb795-6640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6641"><a href="#cb795-6641" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6642"><a href="#cb795-6642" aria-hidden="true" tabindex="-1"></a><span class="in">Fi    = the percent fat for the i-th case in the data </span></span>
<span id="cb795-6643"><a href="#cb795-6643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6644"><a href="#cb795-6644" aria-hidden="true" tabindex="-1"></a><span class="in">βF    = the slope that measures the influence of F on predictions about the mean milk energy.</span></span>
<span id="cb795-6645"><a href="#cb795-6645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6646"><a href="#cb795-6646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6647"><a href="#cb795-6647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6648"><a href="#cb795-6648" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6649"><a href="#cb795-6649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6650"><a href="#cb795-6650" aria-hidden="true" tabindex="-1"></a><span class="fu">### Another approach: Unique intercepts</span></span>
<span id="cb795-6651"><a href="#cb795-6651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6652"><a href="#cb795-6652" aria-hidden="true" tabindex="-1"></a>Another way to conceptualize categorical variables is to construct a vector of intercept parameters, one parameter for each category. Then you can create an ***index variable*** in your data frame that says which parameter goes with each case.</span>
<span id="cb795-6653"><a href="#cb795-6653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6654"><a href="#cb795-6654" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.54}</span></span>
<span id="cb795-6655"><a href="#cb795-6655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6656"><a href="#cb795-6656" aria-hidden="true" tabindex="-1"></a><span class="co"># Make an index variable for clade in the primate milk data</span></span>
<span id="cb795-6657"><a href="#cb795-6657" aria-hidden="true" tabindex="-1"></a>( d<span class="sc">$</span>clade_id <span class="ot">&lt;-</span> <span class="fu">coerce_index</span>(d<span class="sc">$</span>clade) )</span>
<span id="cb795-6658"><a href="#cb795-6658" aria-hidden="true" tabindex="-1"></a><span class="co"># This variable just gives the number of each unique clade value. There are four different clades, </span></span>
<span id="cb795-6659"><a href="#cb795-6659" aria-hidden="true" tabindex="-1"></a><span class="co"># and it doesn’t matter which is “1” or “4,” because they are unordered.</span></span>
<span id="cb795-6660"><a href="#cb795-6660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6661"><a href="#cb795-6661" aria-hidden="true" tabindex="-1"></a><span class="co"># Use map to make a vector of intercepts, one intercept for each unique value in clade_id</span></span>
<span id="cb795-6662"><a href="#cb795-6662" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.16</span>_alt <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-6663"><a href="#cb795-6663" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-6664"><a href="#cb795-6664" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-6665"><a href="#cb795-6665" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a[clade_id] ,</span>
<span id="cb795-6666"><a href="#cb795-6666" aria-hidden="true" tabindex="-1"></a>        a[clade_id] <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="fl">0.6</span> , <span class="dv">10</span> ) ,</span>
<span id="cb795-6667"><a href="#cb795-6667" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-6668"><a href="#cb795-6668" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-6669"><a href="#cb795-6669" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-6670"><a href="#cb795-6670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6671"><a href="#cb795-6671" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>( m5<span class="fl">.16</span>_alt , <span class="at">depth=</span><span class="dv">2</span> )</span>
<span id="cb795-6672"><a href="#cb795-6672" aria-hidden="true" tabindex="-1"></a><span class="co"># Same averages for each clade as earlier (m5.16), but this time directly from the fit model.</span></span>
<span id="cb795-6673"><a href="#cb795-6673" aria-hidden="true" tabindex="-1"></a><span class="co"># Need to add depth=2 to the precis call in order to print out vector parameters like these.</span></span>
<span id="cb795-6674"><a href="#cb795-6674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6675"><a href="#cb795-6675" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6676"><a href="#cb795-6676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6677"><a href="#cb795-6677" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6678"><a href="#cb795-6678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6679"><a href="#cb795-6679" aria-hidden="true" tabindex="-1"></a><span class="fu">## Ordinary least squares and `lm`</span></span>
<span id="cb795-6680"><a href="#cb795-6680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6681"><a href="#cb795-6681" aria-hidden="true" tabindex="-1"></a>Gaussian regression models or ordinary least squares regression (OLS) is a way of estimating the parameters of a linear regression. Instead of searching for the combination of parameter values that maximizes the posterior probability, OLS instead solves for the parameter values that minimize the sum of the squared residuals. This procedure is often functionally equivalent to maximizing the posterior probability or maximizing the likelihood. *Provided you are happy with flat priors, you’ll get the same estimates with `lm` that you got with `map`.*</span>
<span id="cb795-6682"><a href="#cb795-6682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6683"><a href="#cb795-6683" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6684"><a href="#cb795-6684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6685"><a href="#cb795-6685" aria-hidden="true" tabindex="-1"></a><span class="fu">### Design formulas</span></span>
<span id="cb795-6686"><a href="#cb795-6686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6687"><a href="#cb795-6687" aria-hidden="true" tabindex="-1"></a>Design formulas (input format for models) take the expression for $\mu_i$ in the detailed mathematical form of a model and strip out the parameters, leaving only a series of predictor names, separated by + signs. These formulas are sufficient to describe the model’s design, provided all priors are flat.</span>
<span id="cb795-6688"><a href="#cb795-6688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6689"><a href="#cb795-6689" aria-hidden="true" tabindex="-1"></a>The linear regression model:</span>
<span id="cb795-6690"><a href="#cb795-6690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6691"><a href="#cb795-6691" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6692"><a href="#cb795-6692" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6693"><a href="#cb795-6693" aria-hidden="true" tabindex="-1"></a>\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6694"><a href="#cb795-6694" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta \text{x}_i</span>
<span id="cb795-6695"><a href="#cb795-6695" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6696"><a href="#cb795-6696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6697"><a href="#cb795-6697" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6698"><a href="#cb795-6698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6699"><a href="#cb795-6699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6700"><a href="#cb795-6700" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6701"><a href="#cb795-6701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6702"><a href="#cb795-6702" aria-hidden="true" tabindex="-1"></a>The corresponding design formula with the leading 1 on the right-hand side indicates the intercept, $\alpha$:</span>
<span id="cb795-6703"><a href="#cb795-6703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6704"><a href="#cb795-6704" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6705"><a href="#cb795-6705" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6706"><a href="#cb795-6706" aria-hidden="true" tabindex="-1"></a>\text{y} \sim 1 + \text{x}</span>
<span id="cb795-6707"><a href="#cb795-6707" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6708"><a href="#cb795-6708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6709"><a href="#cb795-6709" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6710"><a href="#cb795-6710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6711"><a href="#cb795-6711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6712"><a href="#cb795-6712" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span> </span>
<span id="cb795-6713"><a href="#cb795-6713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6714"><a href="#cb795-6714" aria-hidden="true" tabindex="-1"></a>The linear regression model with three predictors:</span>
<span id="cb795-6715"><a href="#cb795-6715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6716"><a href="#cb795-6716" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6717"><a href="#cb795-6717" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6718"><a href="#cb795-6718" aria-hidden="true" tabindex="-1"></a>\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6719"><a href="#cb795-6719" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_x \text{x}_i + \beta_z \text{Z}_i + \beta_w \text{W}_i</span>
<span id="cb795-6720"><a href="#cb795-6720" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6721"><a href="#cb795-6721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6722"><a href="#cb795-6722" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6723"><a href="#cb795-6723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6724"><a href="#cb795-6724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6725"><a href="#cb795-6725" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6726"><a href="#cb795-6726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6727"><a href="#cb795-6727" aria-hidden="true" tabindex="-1"></a>The corresponding design formula:</span>
<span id="cb795-6728"><a href="#cb795-6728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6729"><a href="#cb795-6729" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6730"><a href="#cb795-6730" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6731"><a href="#cb795-6731" aria-hidden="true" tabindex="-1"></a>\text{y} \sim 1 + \text{x} + \text{z} + \text{w}</span>
<span id="cb795-6732"><a href="#cb795-6732" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6733"><a href="#cb795-6733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6734"><a href="#cb795-6734" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6735"><a href="#cb795-6735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6736"><a href="#cb795-6736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6737"><a href="#cb795-6737" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6738"><a href="#cb795-6738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6739"><a href="#cb795-6739" aria-hidden="true" tabindex="-1"></a><span class="fu">### Using `lm`</span></span>
<span id="cb795-6740"><a href="#cb795-6740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6741"><a href="#cb795-6741" aria-hidden="true" tabindex="-1"></a>To fit a linear regression using OLS, just provide the design formula and the name of the data frame.</span>
<span id="cb795-6742"><a href="#cb795-6742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6743"><a href="#cb795-6743" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.56}</span></span>
<span id="cb795-6744"><a href="#cb795-6744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6745"><a href="#cb795-6745" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb795-6746"><a href="#cb795-6746" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb795-6747"><a href="#cb795-6747" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>)</span>
<span id="cb795-6748"><a href="#cb795-6748" aria-hidden="true" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb795-6749"><a href="#cb795-6749" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(y, x, z, w)</span>
<span id="cb795-6750"><a href="#cb795-6750" aria-hidden="true" tabindex="-1"></a><span class="co"># For first example above</span></span>
<span id="cb795-6751"><a href="#cb795-6751" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.17</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x , <span class="at">data=</span>d ) <span class="co"># assume data are in a frame named d</span></span>
<span id="cb795-6752"><a href="#cb795-6752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6753"><a href="#cb795-6753" aria-hidden="true" tabindex="-1"></a><span class="co"># For second example above</span></span>
<span id="cb795-6754"><a href="#cb795-6754" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.18</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x <span class="sc">+</span> z <span class="sc">+</span> w , <span class="at">data=</span>d )</span>
<span id="cb795-6755"><a href="#cb795-6755" aria-hidden="true" tabindex="-1"></a><span class="co"># The parameter estimates will be named after the predictors, since you didn’t provide any </span></span>
<span id="cb795-6756"><a href="#cb795-6756" aria-hidden="true" tabindex="-1"></a><span class="co"># explicit parameter names. You can sample from the posterior and process estimates as usual.</span></span>
<span id="cb795-6757"><a href="#cb795-6757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6758"><a href="#cb795-6758" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6759"><a href="#cb795-6759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6760"><a href="#cb795-6760" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6761"><a href="#cb795-6761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6762"><a href="#cb795-6762" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Intercepts are optional</span></span>
<span id="cb795-6763"><a href="#cb795-6763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6764"><a href="#cb795-6764" aria-hidden="true" tabindex="-1"></a>These two model fits return exactly the same estimates:</span>
<span id="cb795-6765"><a href="#cb795-6765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6766"><a href="#cb795-6766" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.57}</span></span>
<span id="cb795-6767"><a href="#cb795-6767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6768"><a href="#cb795-6768" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.17</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x , <span class="at">data=</span>d )</span>
<span id="cb795-6769"><a href="#cb795-6769" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.19</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> x , <span class="at">data=</span>d )</span>
<span id="cb795-6770"><a href="#cb795-6770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6771"><a href="#cb795-6771" aria-hidden="true" tabindex="-1"></a><span class="co"># Test with milk data</span></span>
<span id="cb795-6772"><a href="#cb795-6772" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb795-6773"><a href="#cb795-6773" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk</span>
<span id="cb795-6774"><a href="#cb795-6774" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.17</span>a <span class="ot">&lt;-</span> <span class="fu">lm</span>(milk<span class="sc">$</span>kcal.per.g <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> milk<span class="sc">$</span>perc.protein, <span class="at">data =</span> d)</span>
<span id="cb795-6775"><a href="#cb795-6775" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.18</span>a <span class="ot">&lt;-</span> <span class="fu">lm</span>(milk<span class="sc">$</span>kcal.per.g <span class="sc">~</span>  milk<span class="sc">$</span>perc.protein, <span class="at">data =</span> d)</span>
<span id="cb795-6776"><a href="#cb795-6776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6777"><a href="#cb795-6777" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.17</span>a)</span>
<span id="cb795-6778"><a href="#cb795-6778" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.18</span>a)</span>
<span id="cb795-6779"><a href="#cb795-6779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6780"><a href="#cb795-6780" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6781"><a href="#cb795-6781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6782"><a href="#cb795-6782" aria-hidden="true" tabindex="-1"></a>When you omit the explicit intercept, <span class="in">`lm`</span> assumes you wanted one. If you really do not want an intercept— equivalent to fixing $\alpha = 0$— then you can use one of these forms:</span>
<span id="cb795-6783"><a href="#cb795-6783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6784"><a href="#cb795-6784" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.58}</span></span>
<span id="cb795-6785"><a href="#cb795-6785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6786"><a href="#cb795-6786" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.20</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> x , <span class="at">data=</span>d )</span>
<span id="cb795-6787"><a href="#cb795-6787" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.21</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> x <span class="sc">-</span> <span class="dv">1</span> , <span class="at">data=</span>d )</span>
<span id="cb795-6788"><a href="#cb795-6788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6789"><a href="#cb795-6789" aria-hidden="true" tabindex="-1"></a><span class="co"># Test with milk data</span></span>
<span id="cb795-6790"><a href="#cb795-6790" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.20</span>a <span class="ot">&lt;-</span> <span class="fu">lm</span>(milk<span class="sc">$</span>kcal.per.g <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> milk<span class="sc">$</span>perc.protein)</span>
<span id="cb795-6791"><a href="#cb795-6791" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.21</span>a <span class="ot">&lt;-</span> <span class="fu">lm</span>(milk<span class="sc">$</span>kcal.per.g <span class="sc">~</span> milk<span class="sc">$</span>perc.protein <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb795-6792"><a href="#cb795-6792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6793"><a href="#cb795-6793" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.20</span>a)</span>
<span id="cb795-6794"><a href="#cb795-6794" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5<span class="fl">.21</span>a)</span>
<span id="cb795-6795"><a href="#cb795-6795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6796"><a href="#cb795-6796" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6797"><a href="#cb795-6797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6798"><a href="#cb795-6798" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6799"><a href="#cb795-6799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6800"><a href="#cb795-6800" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Categorical variables</span></span>
<span id="cb795-6801"><a href="#cb795-6801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6802"><a href="#cb795-6802" aria-hidden="true" tabindex="-1"></a>Black-box functions like <span class="in">`lm`</span> will automatically expand categorical factors into the necessary number of dummy variables. But R is not a mind reader, and sometimes the same variable can be treated as categories or rather as continuous. To prevent R from getting confused, and therefore confusing yourself, best to get into the habit of explicitly telling lm when you mean to use a variable as categories.</span>
<span id="cb795-6803"><a href="#cb795-6803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6804"><a href="#cb795-6804" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.59}</span></span>
<span id="cb795-6805"><a href="#cb795-6805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6806"><a href="#cb795-6806" aria-hidden="true" tabindex="-1"></a><span class="co"># R can think seasons (1,2,3,4) as categorical (different seasons) or </span></span>
<span id="cb795-6807"><a href="#cb795-6807" aria-hidden="true" tabindex="-1"></a><span class="co"># continuous variable marking the passage of time</span></span>
<span id="cb795-6808"><a href="#cb795-6808" aria-hidden="true" tabindex="-1"></a>season <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb795-6809"><a href="#cb795-6809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6810"><a href="#cb795-6810" aria-hidden="true" tabindex="-1"></a><span class="co"># Tell R to use variable as categories</span></span>
<span id="cb795-6811"><a href="#cb795-6811" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.22</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">as.factor</span>(season) , <span class="at">data=</span>d )</span>
<span id="cb795-6812"><a href="#cb795-6812" aria-hidden="true" tabindex="-1"></a><span class="co"># The function as.factor makes sure that lm knows to treat the values in season </span></span>
<span id="cb795-6813"><a href="#cb795-6813" aria-hidden="true" tabindex="-1"></a><span class="co"># as unordered categories.</span></span>
<span id="cb795-6814"><a href="#cb795-6814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6815"><a href="#cb795-6815" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6816"><a href="#cb795-6816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6817"><a href="#cb795-6817" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6818"><a href="#cb795-6818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6819"><a href="#cb795-6819" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Transform variables first</span></span>
<span id="cb795-6820"><a href="#cb795-6820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6821"><a href="#cb795-6821" aria-hidden="true" tabindex="-1"></a>Black-box functions like <span class="in">`lm`</span> sometimes have problems understanding the transformations(logarithms, squares, cubes, centering, standardizing), when they are included in the design formula. So it’s best to make new variables that hold the transformed values. Then include those new variables instead.</span>
<span id="cb795-6822"><a href="#cb795-6822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6823"><a href="#cb795-6823" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.60}</span></span>
<span id="cb795-6824"><a href="#cb795-6824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6825"><a href="#cb795-6825" aria-hidden="true" tabindex="-1"></a><span class="co"># Make up a data frame d to run the code</span></span>
<span id="cb795-6826"><a href="#cb795-6826" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="at">by =</span> <span class="dv">1</span>), <span class="at">y =</span><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="at">by =</span><span class="dv">1</span>))</span>
<span id="cb795-6827"><a href="#cb795-6827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6828"><a href="#cb795-6828" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a cubic regression of y on x</span></span>
<span id="cb795-6829"><a href="#cb795-6829" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>x2 <span class="ot">&lt;-</span> d<span class="sc">$</span>x<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb795-6830"><a href="#cb795-6830" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>x3 <span class="ot">&lt;-</span> d<span class="sc">$</span>x<span class="sc">^</span><span class="dv">3</span></span>
<span id="cb795-6831"><a href="#cb795-6831" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.23</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x <span class="sc">+</span> x2 <span class="sc">+</span> x3 , <span class="at">data=</span>d )</span>
<span id="cb795-6832"><a href="#cb795-6832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6833"><a href="#cb795-6833" aria-hidden="true" tabindex="-1"></a><span class="co"># Use 'as is' function I() to fit the same cubic model</span></span>
<span id="cb795-6834"><a href="#cb795-6834" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that I() can't be used inside map </span></span>
<span id="cb795-6835"><a href="#cb795-6835" aria-hidden="true" tabindex="-1"></a>m5<span class="fl">.24</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> x <span class="sc">+</span> <span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(x<span class="sc">^</span><span class="dv">3</span>) , <span class="at">data=</span>d )</span>
<span id="cb795-6836"><a href="#cb795-6836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6837"><a href="#cb795-6837" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6838"><a href="#cb795-6838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6839"><a href="#cb795-6839" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6840"><a href="#cb795-6840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6841"><a href="#cb795-6841" aria-hidden="true" tabindex="-1"></a><span class="fu">#### No estimate for $\sigma$</span></span>
<span id="cb795-6842"><a href="#cb795-6842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6843"><a href="#cb795-6843" aria-hidden="true" tabindex="-1"></a>Using <span class="in">`lm`</span> will not provide a posterior distribution for the standard deviation $\sigma$— it won’t be reported in the table of estimates. If you ask for a summary of the model fit, <span class="in">`lm`</span> will report the “residual standard error,” which is a slightly different estimate of $\sigma$, but without any uncertainty information like a standard deviation (or standard error).</span>
<span id="cb795-6844"><a href="#cb795-6844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6845"><a href="#cb795-6845" aria-hidden="true" tabindex="-1"></a>Use <span class="in">`map`</span> if you need $\sigma$- get some sense of the uncertainty of the estimate. As a bonus, you can use informative priors then, as well.</span>
<span id="cb795-6846"><a href="#cb795-6846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6847"><a href="#cb795-6847" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6848"><a href="#cb795-6848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6849"><a href="#cb795-6849" aria-hidden="true" tabindex="-1"></a><span class="fu">### Building `map` formulas from `lm` formulas</span></span>
<span id="cb795-6850"><a href="#cb795-6850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6851"><a href="#cb795-6851" aria-hidden="true" tabindex="-1"></a>The <span class="in">`rethinking`</span> package provides a function, <span class="in">`glimmer`</span>, that translates design formulas into <span class="in">`map`</span>-style model formulas.</span>
<span id="cb795-6852"><a href="#cb795-6852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6853"><a href="#cb795-6853" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5.62}</span></span>
<span id="cb795-6854"><a href="#cb795-6854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6855"><a href="#cb795-6855" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(cars)</span>
<span id="cb795-6856"><a href="#cb795-6856" aria-hidden="true" tabindex="-1"></a><span class="fu">glimmer</span>( dist <span class="sc">~</span> speed , <span class="at">data=</span>cars )</span>
<span id="cb795-6857"><a href="#cb795-6857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6858"><a href="#cb795-6858" aria-hidden="true" tabindex="-1"></a><span class="co"># The function glimmer automatically adds default priors. You can change these to suit your </span></span>
<span id="cb795-6859"><a href="#cb795-6859" aria-hidden="true" tabindex="-1"></a><span class="co"># tastes, or remove them all together, if you just want maximum likelihood estimation. </span></span>
<span id="cb795-6860"><a href="#cb795-6860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6861"><a href="#cb795-6861" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6862"><a href="#cb795-6862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6863"><a href="#cb795-6863" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6864"><a href="#cb795-6864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6865"><a href="#cb795-6865" aria-hidden="true" tabindex="-1"></a><span class="fu">## Summary</span></span>
<span id="cb795-6866"><a href="#cb795-6866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6867"><a href="#cb795-6867" aria-hidden="true" tabindex="-1"></a>The defining question of multiple regression is: </span>
<span id="cb795-6868"><a href="#cb795-6868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6869"><a href="#cb795-6869" aria-hidden="true" tabindex="-1"></a>$$\text{What is the value of knowing each predictor, once we already know the other predictors?}$$</span>
<span id="cb795-6870"><a href="#cb795-6870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6871"><a href="#cb795-6871" aria-hidden="true" tabindex="-1"></a>Implicit in this question are: </span>
<span id="cb795-6872"><a href="#cb795-6872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6873"><a href="#cb795-6873" aria-hidden="true" tabindex="-1"></a>(1) a focus on the value of the predictors for description of the sample, instead of forecasting a future sample</span>
<span id="cb795-6874"><a href="#cb795-6874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6875"><a href="#cb795-6875" aria-hidden="true" tabindex="-1"></a>(2) the assumption that the value of each predictor does not depend upon the values of the other predictors</span>
<span id="cb795-6876"><a href="#cb795-6876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6877"><a href="#cb795-6877" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6878"><a href="#cb795-6878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6879"><a href="#cb795-6879" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice</span></span>
<span id="cb795-6880"><a href="#cb795-6880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6881"><a href="#cb795-6881" aria-hidden="true" tabindex="-1"></a><span class="fu">### Easy</span></span>
<span id="cb795-6882"><a href="#cb795-6882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6883"><a href="#cb795-6883" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6884"><a href="#cb795-6884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6885"><a href="#cb795-6885" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5E1. Which of the linear models below are multiple linear regressions?</span></span>
<span id="cb795-6886"><a href="#cb795-6886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6887"><a href="#cb795-6887" aria-hidden="true" tabindex="-1"></a>(2) $\mu_i = \beta_x \text{x}_i + \beta_z \text{Z}_i$</span>
<span id="cb795-6888"><a href="#cb795-6888" aria-hidden="true" tabindex="-1"></a>(4) $\mu_i = \alpha + \beta_x \text{x}_i + \beta_z \text{Z}_i$</span>
<span id="cb795-6889"><a href="#cb795-6889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6890"><a href="#cb795-6890" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6891"><a href="#cb795-6891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6892"><a href="#cb795-6892" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5E2. Write down a multiple regression to evaluate the claim: Animal diversity is linearly related to latitude, but only after controlling for plant diversity. You just need to write down the model definition.</span></span>
<span id="cb795-6893"><a href="#cb795-6893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6894"><a href="#cb795-6894" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6895"><a href="#cb795-6895" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6896"><a href="#cb795-6896" aria-hidden="true" tabindex="-1"></a>\text{AD_i} &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6897"><a href="#cb795-6897" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_L \text{L}_i + \beta_D \text{D}_i</span>
<span id="cb795-6898"><a href="#cb795-6898" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6899"><a href="#cb795-6899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6900"><a href="#cb795-6900" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6901"><a href="#cb795-6901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6902"><a href="#cb795-6902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6903"><a href="#cb795-6903" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6904"><a href="#cb795-6904" aria-hidden="true" tabindex="-1"></a><span class="in">AD    = Animal diversity</span></span>
<span id="cb795-6905"><a href="#cb795-6905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6906"><a href="#cb795-6906" aria-hidden="true" tabindex="-1"></a><span class="in">L     = Latitude</span></span>
<span id="cb795-6907"><a href="#cb795-6907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6908"><a href="#cb795-6908" aria-hidden="true" tabindex="-1"></a><span class="in">D     = Plant diversity</span></span>
<span id="cb795-6909"><a href="#cb795-6909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6910"><a href="#cb795-6910" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6911"><a href="#cb795-6911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6912"><a href="#cb795-6912" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6913"><a href="#cb795-6913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6914"><a href="#cb795-6914" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5E3. Write down a multiple regression to evaluate the claim: Neither amount of funding nor size of laboratory is by itself a good predictor of time to PhD degree; but together these variables are both positively associated with time to degree. Write down the model definition and indicate which side of zero each slope parameter should be on.</span></span>
<span id="cb795-6915"><a href="#cb795-6915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6916"><a href="#cb795-6916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6917"><a href="#cb795-6917" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6918"><a href="#cb795-6918" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-6919"><a href="#cb795-6919" aria-hidden="true" tabindex="-1"></a>T_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-6920"><a href="#cb795-6920" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_F \text{F}_i + \beta_S \text{S}_i</span>
<span id="cb795-6921"><a href="#cb795-6921" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-6922"><a href="#cb795-6922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6923"><a href="#cb795-6923" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-6924"><a href="#cb795-6924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6925"><a href="#cb795-6925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6926"><a href="#cb795-6926" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6927"><a href="#cb795-6927" aria-hidden="true" tabindex="-1"></a><span class="in">T   = Time to PhD degree</span></span>
<span id="cb795-6928"><a href="#cb795-6928" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6929"><a href="#cb795-6929" aria-hidden="true" tabindex="-1"></a><span class="in">F   = Amount of funding</span></span>
<span id="cb795-6930"><a href="#cb795-6930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6931"><a href="#cb795-6931" aria-hidden="true" tabindex="-1"></a><span class="in">S   = Size of laboratory</span></span>
<span id="cb795-6932"><a href="#cb795-6932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6933"><a href="#cb795-6933" aria-hidden="true" tabindex="-1"></a><span class="in">Both beta_F and beta_S should be on the positive size of zero if considered together.</span></span>
<span id="cb795-6934"><a href="#cb795-6934" aria-hidden="true" tabindex="-1"></a><span class="in">If considered individually, both will be almost zero. </span></span>
<span id="cb795-6935"><a href="#cb795-6935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6936"><a href="#cb795-6936" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-6937"><a href="#cb795-6937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6938"><a href="#cb795-6938" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-6939"><a href="#cb795-6939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6940"><a href="#cb795-6940" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5E4. Suppose you have a single categorical predictor with 4 levels (unique values), labeled A, B, C and D. Let Ai be an indicator variable that is 1 where case i is in category A. Also suppose Bi, Ci, and Di for the other categories. Now which of the following linear models are inferentially equivalent ways to include the categorical variable in a regression? Models are inferentially equivalent when it’s possible to compute one posterior distribution from the posterior distribution of another model.</span></span>
<span id="cb795-6941"><a href="#cb795-6941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6942"><a href="#cb795-6942" aria-hidden="true" tabindex="-1"></a>I exclude choice 2 as it contains all variables plus one extra unidentified interceptor variable. I use <span class="in">`Accident`</span> dataset to check the similarity among posterior distributions of the models in choices 1, 3, 4, and 5. As seen below, the mean ($\mu$) values of dummy variables A, B, C and D are similar across the models 1, 3, 4 and 5. Hence, choice 1, 3, 4 and 5 are the correct answers to the question. The slight difference between model 1,3 and model 4,5 is because I used informative priors for model 4 and 5, and flat priors for model 1 and 3. </span>
<span id="cb795-6943"><a href="#cb795-6943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6944"><a href="#cb795-6944" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5E4}</span></span>
<span id="cb795-6945"><a href="#cb795-6945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6946"><a href="#cb795-6946" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>))</span>
<span id="cb795-6947"><a href="#cb795-6947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6948"><a href="#cb795-6948" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data to test the posteriors of each model </span></span>
<span id="cb795-6949"><a href="#cb795-6949" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"Accident"</span>)</span>
<span id="cb795-6950"><a href="#cb795-6950" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> Accident</span>
<span id="cb795-6951"><a href="#cb795-6951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6952"><a href="#cb795-6952" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract categorical variables</span></span>
<span id="cb795-6953"><a href="#cb795-6953" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(d<span class="sc">$</span>type)</span>
<span id="cb795-6954"><a href="#cb795-6954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6955"><a href="#cb795-6955" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove level E because we only need A, B, C, D</span></span>
<span id="cb795-6956"><a href="#cb795-6956" aria-hidden="true" tabindex="-1"></a>dn <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"E"</span>, ])</span>
<span id="cb795-6957"><a href="#cb795-6957" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(dn)</span>
<span id="cb795-6958"><a href="#cb795-6958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6959"><a href="#cb795-6959" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract again</span></span>
<span id="cb795-6960"><a href="#cb795-6960" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(dn<span class="sc">$</span>type)</span>
<span id="cb795-6961"><a href="#cb795-6961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6962"><a href="#cb795-6962" aria-hidden="true" tabindex="-1"></a><span class="co"># I want to see correlation between ship type and number of accident</span></span>
<span id="cb795-6963"><a href="#cb795-6963" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if got NA values in accident</span></span>
<span id="cb795-6964"><a href="#cb795-6964" aria-hidden="true" tabindex="-1"></a>dn<span class="sc">$</span>acc</span>
<span id="cb795-6965"><a href="#cb795-6965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6966"><a href="#cb795-6966" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop the 4 NA values</span></span>
<span id="cb795-6967"><a href="#cb795-6967" aria-hidden="true" tabindex="-1"></a>dnc <span class="ot">&lt;-</span> dn[<span class="fu">complete.cases</span>(dn), ]</span>
<span id="cb795-6968"><a href="#cb795-6968" aria-hidden="true" tabindex="-1"></a>dnc<span class="sc">$</span>acc</span>
<span id="cb795-6969"><a href="#cb795-6969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6970"><a href="#cb795-6970" aria-hidden="true" tabindex="-1"></a><span class="co"># Make dummy variables for A, B, C, D</span></span>
<span id="cb795-6971"><a href="#cb795-6971" aria-hidden="true" tabindex="-1"></a><span class="co"># The question doesn't specify which label is the intercept one, so I will do all</span></span>
<span id="cb795-6972"><a href="#cb795-6972" aria-hidden="true" tabindex="-1"></a>dnc<span class="sc">$</span>type.A <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(dnc<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"A"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb795-6973"><a href="#cb795-6973" aria-hidden="true" tabindex="-1"></a>dnc<span class="sc">$</span>type.B <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(dnc<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"B"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb795-6974"><a href="#cb795-6974" aria-hidden="true" tabindex="-1"></a>dnc<span class="sc">$</span>type.C <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(dnc<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"C"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb795-6975"><a href="#cb795-6975" aria-hidden="true" tabindex="-1"></a>dnc<span class="sc">$</span>type.D <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(dnc<span class="sc">$</span>type <span class="sc">==</span> <span class="st">"D"</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb795-6976"><a href="#cb795-6976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6977"><a href="#cb795-6977" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1</span></span>
<span id="cb795-6978"><a href="#cb795-6978" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(dnc<span class="sc">$</span>acc <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> type.A <span class="sc">+</span> type.B <span class="sc">+</span> type.D, <span class="at">data =</span> dnc)</span>
<span id="cb795-6979"><a href="#cb795-6979" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m1)</span>
<span id="cb795-6980"><a href="#cb795-6980" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m1), <span class="at">main =</span> <span class="st">"Model 1"</span>)</span>
<span id="cb795-6981"><a href="#cb795-6981" aria-hidden="true" tabindex="-1"></a>post1 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m1)</span>
<span id="cb795-6982"><a href="#cb795-6982" aria-hidden="true" tabindex="-1"></a>mu.C <span class="ot">&lt;-</span> post1<span class="sc">$</span>Intercept</span>
<span id="cb795-6983"><a href="#cb795-6983" aria-hidden="true" tabindex="-1"></a>mu.A <span class="ot">&lt;-</span> post1<span class="sc">$</span>Intercept <span class="sc">+</span> post1<span class="sc">$</span>type.A</span>
<span id="cb795-6984"><a href="#cb795-6984" aria-hidden="true" tabindex="-1"></a>mu.B <span class="ot">&lt;-</span> post1<span class="sc">$</span>Intercept <span class="sc">+</span> post1<span class="sc">$</span>type.B</span>
<span id="cb795-6985"><a href="#cb795-6985" aria-hidden="true" tabindex="-1"></a>mu.D <span class="ot">&lt;-</span> post1<span class="sc">$</span>Intercept <span class="sc">+</span> post1<span class="sc">$</span>type.D</span>
<span id="cb795-6986"><a href="#cb795-6986" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(<span class="fu">data.frame</span>(mu.A, mu.B, mu.C, mu.D))</span>
<span id="cb795-6987"><a href="#cb795-6987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6988"><a href="#cb795-6988" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2 is skipped because it contains two intercepts.</span></span>
<span id="cb795-6989"><a href="#cb795-6989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-6990"><a href="#cb795-6990" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 3</span></span>
<span id="cb795-6991"><a href="#cb795-6991" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(dnc<span class="sc">$</span>acc <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> type.B <span class="sc">+</span> type.C <span class="sc">+</span> type.D, <span class="at">data =</span> dnc)</span>
<span id="cb795-6992"><a href="#cb795-6992" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m3)</span>
<span id="cb795-6993"><a href="#cb795-6993" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m3), <span class="at">main =</span> <span class="st">"Model 3"</span>)</span>
<span id="cb795-6994"><a href="#cb795-6994" aria-hidden="true" tabindex="-1"></a>post3 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m3)</span>
<span id="cb795-6995"><a href="#cb795-6995" aria-hidden="true" tabindex="-1"></a>mu.A <span class="ot">&lt;-</span> post3<span class="sc">$</span>Intercept</span>
<span id="cb795-6996"><a href="#cb795-6996" aria-hidden="true" tabindex="-1"></a>mu.C <span class="ot">&lt;-</span> post3<span class="sc">$</span>Intercept <span class="sc">+</span> post3<span class="sc">$</span>type.C</span>
<span id="cb795-6997"><a href="#cb795-6997" aria-hidden="true" tabindex="-1"></a>mu.B <span class="ot">&lt;-</span> post3<span class="sc">$</span>Intercept <span class="sc">+</span> post3<span class="sc">$</span>type.B</span>
<span id="cb795-6998"><a href="#cb795-6998" aria-hidden="true" tabindex="-1"></a>mu.D <span class="ot">&lt;-</span> post3<span class="sc">$</span>Intercept <span class="sc">+</span> post3<span class="sc">$</span>type.D</span>
<span id="cb795-6999"><a href="#cb795-6999" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(<span class="fu">data.frame</span>(mu.A, mu.B, mu.C, mu.D))</span>
<span id="cb795-7000"><a href="#cb795-7000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7001"><a href="#cb795-7001" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 4</span></span>
<span id="cb795-7002"><a href="#cb795-7002" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7003"><a href="#cb795-7003" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7004"><a href="#cb795-7004" aria-hidden="true" tabindex="-1"></a>    acc <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7005"><a href="#cb795-7005" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> aA<span class="sc">*</span>type.A <span class="sc">+</span> aB<span class="sc">*</span>type.B <span class="sc">+</span> aC<span class="sc">*</span>type.C <span class="sc">+</span> aD<span class="sc">*</span>type.D,</span>
<span id="cb795-7006"><a href="#cb795-7006" aria-hidden="true" tabindex="-1"></a>    aA <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">5</span>, <span class="dv">5</span>),</span>
<span id="cb795-7007"><a href="#cb795-7007" aria-hidden="true" tabindex="-1"></a>    aB <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">30</span>, <span class="dv">9</span>),</span>
<span id="cb795-7008"><a href="#cb795-7008" aria-hidden="true" tabindex="-1"></a>    aC <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">1</span>, <span class="dv">5</span>),</span>
<span id="cb795-7009"><a href="#cb795-7009" aria-hidden="true" tabindex="-1"></a>    aD <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">2</span>, <span class="dv">5</span>),</span>
<span id="cb795-7010"><a href="#cb795-7010" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7011"><a href="#cb795-7011" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-7012"><a href="#cb795-7012" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dnc</span>
<span id="cb795-7013"><a href="#cb795-7013" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7014"><a href="#cb795-7014" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m4)</span>
<span id="cb795-7015"><a href="#cb795-7015" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m4), <span class="at">main =</span> <span class="st">"Model 4"</span>)</span>
<span id="cb795-7016"><a href="#cb795-7016" aria-hidden="true" tabindex="-1"></a>post4 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m4)</span>
<span id="cb795-7017"><a href="#cb795-7017" aria-hidden="true" tabindex="-1"></a>mu.A <span class="ot">&lt;-</span> post4<span class="sc">$</span>aA</span>
<span id="cb795-7018"><a href="#cb795-7018" aria-hidden="true" tabindex="-1"></a>mu.B <span class="ot">&lt;-</span> post4<span class="sc">$</span>aB</span>
<span id="cb795-7019"><a href="#cb795-7019" aria-hidden="true" tabindex="-1"></a>mu.C <span class="ot">&lt;-</span> post4<span class="sc">$</span>aC</span>
<span id="cb795-7020"><a href="#cb795-7020" aria-hidden="true" tabindex="-1"></a>mu.D <span class="ot">&lt;-</span> post4<span class="sc">$</span>aD</span>
<span id="cb795-7021"><a href="#cb795-7021" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(<span class="fu">data.frame</span>(mu.A, mu.B, mu.C, mu.D))</span>
<span id="cb795-7022"><a href="#cb795-7022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7023"><a href="#cb795-7023" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 5</span></span>
<span id="cb795-7024"><a href="#cb795-7024" aria-hidden="true" tabindex="-1"></a>m5 <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7025"><a href="#cb795-7025" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7026"><a href="#cb795-7026" aria-hidden="true" tabindex="-1"></a>    acc <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7027"><a href="#cb795-7027" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> aA<span class="sc">*</span>(<span class="dv">1</span> <span class="sc">-</span> type.B <span class="sc">-</span> type.C <span class="sc">-</span> type.D) <span class="sc">+</span> aB<span class="sc">*</span>type.B <span class="sc">+</span> aC<span class="sc">*</span>type.C <span class="sc">+</span> aD<span class="sc">*</span>type.D,</span>
<span id="cb795-7028"><a href="#cb795-7028" aria-hidden="true" tabindex="-1"></a>    aA <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">5</span>, <span class="dv">5</span>),</span>
<span id="cb795-7029"><a href="#cb795-7029" aria-hidden="true" tabindex="-1"></a>    aB <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">30</span>, <span class="dv">9</span>),</span>
<span id="cb795-7030"><a href="#cb795-7030" aria-hidden="true" tabindex="-1"></a>    aC <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">1</span>, <span class="dv">5</span>),</span>
<span id="cb795-7031"><a href="#cb795-7031" aria-hidden="true" tabindex="-1"></a>    aD <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">2</span>, <span class="dv">5</span>),</span>
<span id="cb795-7032"><a href="#cb795-7032" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7033"><a href="#cb795-7033" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb795-7034"><a href="#cb795-7034" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dnc</span>
<span id="cb795-7035"><a href="#cb795-7035" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7036"><a href="#cb795-7036" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m5)</span>
<span id="cb795-7037"><a href="#cb795-7037" aria-hidden="true" tabindex="-1"></a>post5 <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m5)</span>
<span id="cb795-7038"><a href="#cb795-7038" aria-hidden="true" tabindex="-1"></a>mu.A <span class="ot">&lt;-</span> post5<span class="sc">$</span>aA</span>
<span id="cb795-7039"><a href="#cb795-7039" aria-hidden="true" tabindex="-1"></a>mu.B <span class="ot">&lt;-</span> post5<span class="sc">$</span>aB</span>
<span id="cb795-7040"><a href="#cb795-7040" aria-hidden="true" tabindex="-1"></a>mu.C <span class="ot">&lt;-</span> post5<span class="sc">$</span>aC</span>
<span id="cb795-7041"><a href="#cb795-7041" aria-hidden="true" tabindex="-1"></a>mu.D <span class="ot">&lt;-</span> post5<span class="sc">$</span>aD</span>
<span id="cb795-7042"><a href="#cb795-7042" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(<span class="fu">data.frame</span>(mu.A, mu.B, mu.C, mu.D))</span>
<span id="cb795-7043"><a href="#cb795-7043" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">precis</span>(m5), <span class="at">main =</span> <span class="st">"Model 5"</span>)</span>
<span id="cb795-7044"><a href="#cb795-7044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7045"><a href="#cb795-7045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7046"><a href="#cb795-7046" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7047"><a href="#cb795-7047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7048"><a href="#cb795-7048" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7049"><a href="#cb795-7049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7050"><a href="#cb795-7050" aria-hidden="true" tabindex="-1"></a><span class="fu">### Medium</span></span>
<span id="cb795-7051"><a href="#cb795-7051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7052"><a href="#cb795-7052" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7053"><a href="#cb795-7053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7054"><a href="#cb795-7054" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5M1. Invent your own example of a spurious correlation. An outcome variable should be correlated with both predictor variables. But when both predictors are entered in the same model, the correlation between the outcome and one of the predictors should mostly vanish (or at least be greatly reduced).</span></span>
<span id="cb795-7055"><a href="#cb795-7055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7056"><a href="#cb795-7056" aria-hidden="true" tabindex="-1"></a>I invented a data set that contains rate of rainfall (rain.ppt), percent probability of seeing stars in the night sky (chance.star) and percent increase in sales of umbrella (umbrella.sales). The outcome variable <span class="in">`chance.star`</span> and predictor variable <span class="in">`rain.ppt`</span> were fitted in model <span class="in">`m.rs`</span>, and the model predicts the chance of seeing stars would be decreased by 1.4% for every inch of increased rainfall. </span>
<span id="cb795-7057"><a href="#cb795-7057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7058"><a href="#cb795-7058" aria-hidden="true" tabindex="-1"></a>Another predictor variable <span class="in">`umbrella.sales`</span> was fitted to the same outcome variable in model <span class="in">`m.us`</span>, and the model showed the chance of seeing star would be decreased by approximate 1.5% for every percent increase in umbrella sales. So, the correlation between chance of seeing stars and umbrella sales was stronger by about 0.1% when two predictors were put into model separately.</span>
<span id="cb795-7059"><a href="#cb795-7059" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7060"><a href="#cb795-7060" aria-hidden="true" tabindex="-1"></a>But, when the two predictor variables were fitted together to the outcome variable, the correlation between rate of rain fall and chance of seeing stars remained the same at -1.4%, while the correlation dropped to -0.07% for umbrella sales. </span>
<span id="cb795-7061"><a href="#cb795-7061" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7062"><a href="#cb795-7062" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5M1}</span></span>
<span id="cb795-7063"><a href="#cb795-7063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7064"><a href="#cb795-7064" aria-hidden="true" tabindex="-1"></a>rain.ppt <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fl">0.1</span>, <span class="fl">0.6</span>, <span class="fl">0.4</span>, <span class="fl">0.2</span>, <span class="fl">0.27</span>, <span class="fl">0.33</span>, <span class="fl">0.35</span>)</span>
<span id="cb795-7065"><a href="#cb795-7065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7066"><a href="#cb795-7066" aria-hidden="true" tabindex="-1"></a>chance.star <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.6</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span>, <span class="fl">0.2</span>, <span class="fl">0.28</span>, <span class="fl">0.7</span>, <span class="fl">0.65</span>, <span class="fl">0.55</span>, <span class="fl">0.52</span>)</span>
<span id="cb795-7067"><a href="#cb795-7067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7068"><a href="#cb795-7068" aria-hidden="true" tabindex="-1"></a>umbrella.sales <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.15</span>, <span class="fl">0.05</span>, <span class="fl">0.3</span>, <span class="fl">0.25</span>, <span class="fl">0.15</span>, <span class="fl">0.13</span>, <span class="fl">0.18</span>, <span class="fl">0.2</span>)</span>
<span id="cb795-7069"><a href="#cb795-7069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7070"><a href="#cb795-7070" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(rain.ppt, chance.star, umbrella.sales)</span>
<span id="cb795-7071"><a href="#cb795-7071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7072"><a href="#cb795-7072" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-7073"><a href="#cb795-7073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7074"><a href="#cb795-7074" aria-hidden="true" tabindex="-1"></a><span class="co"># Check correlation between rainfall rate and probability of seeing stars</span></span>
<span id="cb795-7075"><a href="#cb795-7075" aria-hidden="true" tabindex="-1"></a>m.rs <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7076"><a href="#cb795-7076" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7077"><a href="#cb795-7077" aria-hidden="true" tabindex="-1"></a>    d<span class="sc">$</span>chance.star <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7078"><a href="#cb795-7078" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR <span class="sc">*</span> d<span class="sc">$</span>rain.ppt,</span>
<span id="cb795-7079"><a href="#cb795-7079" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7080"><a href="#cb795-7080" aria-hidden="true" tabindex="-1"></a>    bR <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7081"><a href="#cb795-7081" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7082"><a href="#cb795-7082" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-7083"><a href="#cb795-7083" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-7084"><a href="#cb795-7084" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7085"><a href="#cb795-7085" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.rs)</span>
<span id="cb795-7086"><a href="#cb795-7086" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> rain.ppt, <span class="at">y =</span> chance.star)) <span class="sc">+</span></span>
<span id="cb795-7087"><a href="#cb795-7087" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(<span class="st">"firebrick3"</span>, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7088"><a href="#cb795-7088" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7089"><a href="#cb795-7089" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"firebrick4"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-7090"><a href="#cb795-7090" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"firebrick1"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb795-7091"><a href="#cb795-7091" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Rate of rainfall"</span>, <span class="at">y =</span> <span class="st">"Chance of seeing stars"</span>) <span class="sc">+</span></span>
<span id="cb795-7092"><a href="#cb795-7092" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb795-7093"><a href="#cb795-7093" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7094"><a href="#cb795-7094" aria-hidden="true" tabindex="-1"></a><span class="co"># Check correlation between umbrella sales and probability of seeing stars</span></span>
<span id="cb795-7095"><a href="#cb795-7095" aria-hidden="true" tabindex="-1"></a>m.us <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7096"><a href="#cb795-7096" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7097"><a href="#cb795-7097" aria-hidden="true" tabindex="-1"></a>    d<span class="sc">$</span>chance.star <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7098"><a href="#cb795-7098" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bU <span class="sc">*</span> d<span class="sc">$</span>umbrella.sales,</span>
<span id="cb795-7099"><a href="#cb795-7099" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7100"><a href="#cb795-7100" aria-hidden="true" tabindex="-1"></a>    bU <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-7101"><a href="#cb795-7101" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7102"><a href="#cb795-7102" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-7103"><a href="#cb795-7103" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-7104"><a href="#cb795-7104" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7105"><a href="#cb795-7105" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.us)</span>
<span id="cb795-7106"><a href="#cb795-7106" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> umbrella.sales, <span class="at">y =</span> chance.star)) <span class="sc">+</span></span>
<span id="cb795-7107"><a href="#cb795-7107" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(<span class="st">"#73a5c6"</span>, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7108"><a href="#cb795-7108" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7109"><a href="#cb795-7109" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"#528aae"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-7110"><a href="#cb795-7110" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"#bcd2e8"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb795-7111"><a href="#cb795-7111" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Percent increase in umbrella sales"</span>, <span class="at">y =</span> <span class="st">"Chance of seeing stars"</span>) <span class="sc">+</span></span>
<span id="cb795-7112"><a href="#cb795-7112" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb795-7113"><a href="#cb795-7113" aria-hidden="true" tabindex="-1"></a> <span class="fu">grid.arrange</span>(d1, d2, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb795-7114"><a href="#cb795-7114" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7115"><a href="#cb795-7115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7116"><a href="#cb795-7116" aria-hidden="true" tabindex="-1"></a> <span class="co"># Consider both predictors to the outcome</span></span>
<span id="cb795-7117"><a href="#cb795-7117" aria-hidden="true" tabindex="-1"></a> m.b <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7118"><a href="#cb795-7118" aria-hidden="true" tabindex="-1"></a>   <span class="fu">alist</span>(</span>
<span id="cb795-7119"><a href="#cb795-7119" aria-hidden="true" tabindex="-1"></a>     d<span class="sc">$</span>chance.star <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7120"><a href="#cb795-7120" aria-hidden="true" tabindex="-1"></a>     mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR <span class="sc">*</span> d<span class="sc">$</span>rain.ppt <span class="sc">+</span> bU <span class="sc">*</span> d<span class="sc">$</span>umbrella.sales,</span>
<span id="cb795-7121"><a href="#cb795-7121" aria-hidden="true" tabindex="-1"></a>     a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7122"><a href="#cb795-7122" aria-hidden="true" tabindex="-1"></a>     bR <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7123"><a href="#cb795-7123" aria-hidden="true" tabindex="-1"></a>     bU <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-7124"><a href="#cb795-7124" aria-hidden="true" tabindex="-1"></a>     sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7125"><a href="#cb795-7125" aria-hidden="true" tabindex="-1"></a>   ),</span>
<span id="cb795-7126"><a href="#cb795-7126" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> d</span>
<span id="cb795-7127"><a href="#cb795-7127" aria-hidden="true" tabindex="-1"></a> )</span>
<span id="cb795-7128"><a href="#cb795-7128" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.b)</span>
<span id="cb795-7129"><a href="#cb795-7129" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(<span class="sc">~</span> chance.star <span class="sc">+</span> rain.ppt <span class="sc">+</span> umbrella.sales, <span class="at">data =</span> d, <span class="at">col =</span> <span class="st">"firebrick"</span>)</span>
<span id="cb795-7130"><a href="#cb795-7130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7131"><a href="#cb795-7131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7132"><a href="#cb795-7132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7133"><a href="#cb795-7133" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7134"><a href="#cb795-7134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7135"><a href="#cb795-7135" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5M2. Invent your own example of a masked relationship. An outcome variable should be correlated with both predictor variables, but in opposite directions. And the two predictor variables should be correlated with one another.</span></span>
<span id="cb795-7136"><a href="#cb795-7136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7137"><a href="#cb795-7137" aria-hidden="true" tabindex="-1"></a>Instead of adjusting each data point to get the desired relationship (like in 5M1 which took quite a while to manipulate the data), I used the book's code to create a data set for simulating a masked relationship. In the example below, the number of trees in the area (<span class="in">`tree.number`</span>) is positively associated with good air quality (<span class="in">`pm.air`</span>), while the number of factory in the area (<span class="in">`factory.number`</span>) is negatively associated with good air quality(<span class="in">`pm.air`</span>). The <span class="in">`factory.number`</span> and <span class="in">`tree.number`</span> have a correlation strength of 0.5.</span>
<span id="cb795-7138"><a href="#cb795-7138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7139"><a href="#cb795-7139" aria-hidden="true" tabindex="-1"></a>When the predictors are fitted separately to the model, the $\beta$ coefficients for <span class="in">`tree.number`</span> and <span class="in">`factory.number`</span> are 0.52 and -0.47, in relation to the outcome <span class="in">`pm.air`</span>. But when the predictors are fitted together in the model, stronger associations with outcome variable are seen with each of the predictors (0.99 for <span class="in">`tree.number`</span> and -0.97 for <span class="in">`factory.number`</span>). </span>
<span id="cb795-7140"><a href="#cb795-7140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7141"><a href="#cb795-7141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7142"><a href="#cb795-7142" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5M2}</span></span>
<span id="cb795-7143"><a href="#cb795-7143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7144"><a href="#cb795-7144" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data set</span></span>
<span id="cb795-7145"><a href="#cb795-7145" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span>                             </span>
<span id="cb795-7146"><a href="#cb795-7146" aria-hidden="true" tabindex="-1"></a>rho <span class="ot">&lt;-</span> <span class="fl">0.5</span>                         </span>
<span id="cb795-7147"><a href="#cb795-7147" aria-hidden="true" tabindex="-1"></a>tree.number <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N)                     </span>
<span id="cb795-7148"><a href="#cb795-7148" aria-hidden="true" tabindex="-1"></a>factory.number <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, rho<span class="sc">*</span>tree.number, <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">-</span>rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb795-7149"><a href="#cb795-7149" aria-hidden="true" tabindex="-1"></a>pm.air <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, tree.number <span class="sc">-</span> factory.number)        </span>
<span id="cb795-7150"><a href="#cb795-7150" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(pm.air, tree.number, factory.number)  </span>
<span id="cb795-7151"><a href="#cb795-7151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7152"><a href="#cb795-7152" aria-hidden="true" tabindex="-1"></a><span class="co"># Air quality vs. trees</span></span>
<span id="cb795-7153"><a href="#cb795-7153" aria-hidden="true" tabindex="-1"></a>m.at <span class="ot">&lt;-</span> <span class="fu">lm</span>(pm.air <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> tree.number, <span class="at">data =</span> d)</span>
<span id="cb795-7154"><a href="#cb795-7154" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.at)</span>
<span id="cb795-7155"><a href="#cb795-7155" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> tree.number, <span class="at">y =</span> pm.air)) <span class="sc">+</span></span>
<span id="cb795-7156"><a href="#cb795-7156" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(<span class="st">"green3"</span>, <span class="fl">0.2</span>), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7157"><a href="#cb795-7157" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7158"><a href="#cb795-7158" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"green4"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-7159"><a href="#cb795-7159" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"green"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb795-7160"><a href="#cb795-7160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Trees per hectare (x100)"</span>, <span class="at">y =</span> <span class="st">"Particulate matter (ug/m^3)"</span>) <span class="sc">+</span></span>
<span id="cb795-7161"><a href="#cb795-7161" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb795-7162"><a href="#cb795-7162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7163"><a href="#cb795-7163" aria-hidden="true" tabindex="-1"></a><span class="co"># Air quality vs. factory</span></span>
<span id="cb795-7164"><a href="#cb795-7164" aria-hidden="true" tabindex="-1"></a>m.af <span class="ot">&lt;-</span> <span class="fu">lm</span>(pm.air <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> factory.number, <span class="at">data =</span> d)</span>
<span id="cb795-7165"><a href="#cb795-7165" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.af)</span>
<span id="cb795-7166"><a href="#cb795-7166" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> factory.number, <span class="at">y =</span> pm.air)) <span class="sc">+</span></span>
<span id="cb795-7167"><a href="#cb795-7167" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(<span class="st">"red3"</span>, <span class="fl">0.2</span>), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7168"><a href="#cb795-7168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7169"><a href="#cb795-7169" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"red4"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-7170"><a href="#cb795-7170" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"red"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb795-7171"><a href="#cb795-7171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Number of factories"</span>, <span class="at">y =</span> <span class="st">"Particulate matter (ug/m^3)"</span>) <span class="sc">+</span></span>
<span id="cb795-7172"><a href="#cb795-7172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb795-7173"><a href="#cb795-7173" aria-hidden="true" tabindex="-1"></a> <span class="fu">grid.arrange</span>(d1, d2, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb795-7174"><a href="#cb795-7174" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7175"><a href="#cb795-7175" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7176"><a href="#cb795-7176" aria-hidden="true" tabindex="-1"></a> <span class="co"># Air quality vs. number of trees and number of factories</span></span>
<span id="cb795-7177"><a href="#cb795-7177" aria-hidden="true" tabindex="-1"></a> m.atf <span class="ot">&lt;-</span> <span class="fu">lm</span>(pm.air <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> tree.number <span class="sc">+</span> factory.number, <span class="at">data =</span> d)</span>
<span id="cb795-7178"><a href="#cb795-7178" aria-hidden="true" tabindex="-1"></a> <span class="fu">precis</span>(m.atf)</span>
<span id="cb795-7179"><a href="#cb795-7179" aria-hidden="true" tabindex="-1"></a> <span class="fu">pairs</span>(<span class="sc">~</span> pm.air <span class="sc">+</span> tree.number <span class="sc">+</span> factory.number, <span class="at">data =</span> d, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"skyblue"</span>, <span class="fl">0.4</span>))</span>
<span id="cb795-7180"><a href="#cb795-7180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7181"><a href="#cb795-7181" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7182"><a href="#cb795-7182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7183"><a href="#cb795-7183" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7184"><a href="#cb795-7184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7185"><a href="#cb795-7185" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5M3. It is sometimes observed that the best predictor of fire risk is the presence of firefighters— States and localities with many firefighters also have more fires. Presumably firefighters do not cause fires. Nevertheless, this is not a spurious correlation. Instead fires cause firefighters. Consider the same reversal of causal inference in the context of the divorce and marriage data. How might a high divorce rate cause a higher marriage rate? Can you think of a way to evaluate this relationship, using multiple regression?</span></span>
<span id="cb795-7186"><a href="#cb795-7186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7187"><a href="#cb795-7187" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5M3}</span></span>
<span id="cb795-7188"><a href="#cb795-7188" aria-hidden="true" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb795-7189"><a href="#cb795-7189" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"WaffleDivorce"</span>)</span>
<span id="cb795-7190"><a href="#cb795-7190" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> WaffleDivorce</span>
<span id="cb795-7191"><a href="#cb795-7191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7192"><a href="#cb795-7192" aria-hidden="true" tabindex="-1"></a><span class="do">## Try fitting divorce rate vs. marriage.rate first</span></span>
<span id="cb795-7193"><a href="#cb795-7193" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize the variable</span></span>
<span id="cb795-7194"><a href="#cb795-7194" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>Divorce.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>Divorce <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>Divorce))<span class="sc">/</span> <span class="fu">sd</span>(d<span class="sc">$</span>Divorce)</span>
<span id="cb795-7195"><a href="#cb795-7195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7196"><a href="#cb795-7196" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model</span></span>
<span id="cb795-7197"><a href="#cb795-7197" aria-hidden="true" tabindex="-1"></a>m<span class="fl">.5</span>m3.a <span class="ot">&lt;-</span> <span class="fu">lm</span>(Marriage <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> Divorce.s, <span class="at">data =</span> d)</span>
<span id="cb795-7198"><a href="#cb795-7198" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m<span class="fl">.5</span>m3.a)</span>
<span id="cb795-7199"><a href="#cb795-7199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7200"><a href="#cb795-7200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7201"><a href="#cb795-7201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7202"><a href="#cb795-7202" aria-hidden="true" tabindex="-1"></a>So, with every sd increase in divorces, there is 1.42 increase in marriage cases. Since this is not a spurious relationship, a logical explanation of this phenomenon would be people remarry after divorce. In order to analyse this using multiple regression, the marriage data needs to be split into first marriage, second marriage, etc (Divorce rate may not correlate with first marriages but with remarriages). But then, the marriage and divorce data are for the year 2009 only. How likely for the couples to remarry within the same year of divorce? It is possible, but it's not typically considered a norm. So, that means within the year 2009, it is possible that increased divorce cases did not result in more marriages<span class="dv">&amp;mdash;</span> more people were actually getting married for the first time. To assume a causal inference between divorce and marriage rate, we need to analyse data for more years (longitudinal data). Even then, the term causal inference sounds quite easy for divorce and remarriage rate. Of course, people can only remarry after divorce, but does divorce cause people to remarry? This is different from the assumption *"fire causes firefighters."* Fire can cause an increased in firefighters because firefighters are necessary to put out the fire (a danger). But, is it necessary for people to remarry after divorce? Is being a divorcee a social disadvantage that people must remarry (is remarriage an inevitable consequence of getting divorced)? </span>
<span id="cb795-7203"><a href="#cb795-7203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7204"><a href="#cb795-7204" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7205"><a href="#cb795-7205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7206"><a href="#cb795-7206" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5M4. In the divorce data, States with high numbers of Mormons (members of The Church of Jesus Christ of Latter-day Saints, LDS) have much lower divorce rates than the regression models expected. Find a list of LDS population by State and use those numbers as a predictor variable, predicting divorce rate using marriage rate, median age at marriage, and percent LDS population (possibly standardized). You may want to consider transformations of the raw percent LDS variable.</span></span>
<span id="cb795-7207"><a href="#cb795-7207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7208"><a href="#cb795-7208" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5M4}</span></span>
<span id="cb795-7209"><a href="#cb795-7209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7210"><a href="#cb795-7210" aria-hidden="true" tabindex="-1"></a><span class="co"># I don't know which states have Mormons, so I copy the data from answer sheet</span></span>
<span id="cb795-7211"><a href="#cb795-7211" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(WaffleDivorce)</span>
<span id="cb795-7212"><a href="#cb795-7212" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> WaffleDivorce</span>
<span id="cb795-7213"><a href="#cb795-7213" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>pct_LDS <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.75</span>, <span class="fl">4.53</span>, <span class="fl">6.18</span>, <span class="dv">1</span>, <span class="fl">2.01</span>, <span class="fl">2.82</span>, <span class="fl">0.43</span>, <span class="fl">0.55</span>, <span class="fl">0.38</span>,</span>
<span id="cb795-7214"><a href="#cb795-7214" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.75</span>, <span class="fl">0.82</span>, <span class="fl">5.18</span>, <span class="fl">26.35</span>, <span class="fl">0.44</span>, <span class="fl">0.66</span>, <span class="fl">0.87</span>, <span class="fl">1.25</span>, <span class="fl">0.77</span>, <span class="fl">0.64</span>, <span class="fl">0.81</span>,</span>
<span id="cb795-7215"><a href="#cb795-7215" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.72</span>, <span class="fl">0.39</span>, <span class="fl">0.44</span>, <span class="fl">0.58</span>, <span class="fl">0.72</span>, <span class="fl">1.14</span>, <span class="fl">4.78</span>, <span class="fl">1.29</span>, <span class="fl">0.61</span>, <span class="fl">0.37</span>, <span class="fl">3.34</span>,</span>
<span id="cb795-7216"><a href="#cb795-7216" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.41</span>, <span class="fl">0.82</span>, <span class="fl">1.48</span>, <span class="fl">0.52</span>, <span class="fl">1.2</span>, <span class="fl">3.85</span>, <span class="fl">0.4</span>, <span class="fl">0.37</span>, <span class="fl">0.83</span>, <span class="fl">1.27</span>, <span class="fl">0.75</span>,</span>
<span id="cb795-7217"><a href="#cb795-7217" aria-hidden="true" tabindex="-1"></a>  <span class="fl">1.21</span>, <span class="fl">67.97</span>, <span class="fl">0.74</span>, <span class="fl">1.13</span>, <span class="fl">3.99</span>, <span class="fl">0.92</span>, <span class="fl">0.44</span>, <span class="fl">11.5</span> )</span>
<span id="cb795-7218"><a href="#cb795-7218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7219"><a href="#cb795-7219" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize the variables</span></span>
<span id="cb795-7220"><a href="#cb795-7220" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>pct_LDS.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>pct_LDS <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>pct_LDS))<span class="sc">/</span> <span class="fu">sd</span>(d<span class="sc">$</span>pct_LDS)</span>
<span id="cb795-7221"><a href="#cb795-7221" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>Marriage.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>Marriage <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>Marriage))<span class="sc">/</span> <span class="fu">sd</span>(d<span class="sc">$</span>Marriage)</span>
<span id="cb795-7222"><a href="#cb795-7222" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>MedianAgeMarriage.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>MedianAgeMarriage <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>MedianAgeMarriage))<span class="sc">/</span> <span class="fu">sd</span>(d<span class="sc">$</span>MedianAgeMarriage)</span>
<span id="cb795-7223"><a href="#cb795-7223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7224"><a href="#cb795-7224" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict divorce rate using marriage rate, median age at marriage, and percent LDS population</span></span>
<span id="cb795-7225"><a href="#cb795-7225" aria-hidden="true" tabindex="-1"></a>m<span class="fl">.5</span>m4.s <span class="ot">&lt;-</span> <span class="fu">lm</span>(d<span class="sc">$</span>Divorce <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> d<span class="sc">$</span>Marriage.s <span class="sc">+</span> d<span class="sc">$</span>MedianAgeMarriage.s <span class="sc">+</span> d<span class="sc">$</span>pct_LDS.s )</span>
<span id="cb795-7226"><a href="#cb795-7226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7227"><a href="#cb795-7227" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m<span class="fl">.5</span>m4.s)</span>
<span id="cb795-7228"><a href="#cb795-7228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7229"><a href="#cb795-7229" aria-hidden="true" tabindex="-1"></a><span class="co"># Each standard deviation increase in percent of Mormons, the divorce rate will be reduced by </span></span>
<span id="cb795-7230"><a href="#cb795-7230" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.62 divorces per 1000 adults.  </span></span>
<span id="cb795-7231"><a href="#cb795-7231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7232"><a href="#cb795-7232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7233"><a href="#cb795-7233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7234"><a href="#cb795-7234" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7235"><a href="#cb795-7235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7236"><a href="#cb795-7236" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5M5. One way to reason through multiple causation hypotheses is to imagine detailed mechanisms through which predictor variables may influence outcomes. For example, it is sometimes argued that the price of gasoline (predictor variable) is positively associated with lower obesity rates (outcome variable). However, there are at least two important mechanisms by which the price of gas could reduce obesity. First, it could lead to less driving and therefore more exercise. Second, it could lead to less driving, which leads to less eating out, which leads to less consumption of huge restaurant meals. Can you outline one or more multiple regressions that address these two mechanisms? Assume you can have any predictor data you need.</span></span>
<span id="cb795-7237"><a href="#cb795-7237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7238"><a href="#cb795-7238" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:navy"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>***First mechanism***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-7239"><a href="#cb795-7239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7240"><a href="#cb795-7240" aria-hidden="true" tabindex="-1"></a>Higher gasoline price leads to people using public transportation more and less driving. That reduces traffic congestion, leading to lower air pollution which can cause people to go out more and exercise during free time (fresh air and more spaces). Those who don't use public transportation may walk or ride bicycle, resulting in more exercise. This can result in reduce obesity. The assumptions are:</span>
<span id="cb795-7241"><a href="#cb795-7241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7242"><a href="#cb795-7242" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gasoline price (G) increases usage of public transportation (T).</span>
<span id="cb795-7243"><a href="#cb795-7243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7244"><a href="#cb795-7244" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gasoline price (G) reduces driving (D).</span>
<span id="cb795-7245"><a href="#cb795-7245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7246"><a href="#cb795-7246" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>T and D reduces traffic congestion (C).</span>
<span id="cb795-7247"><a href="#cb795-7247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7248"><a href="#cb795-7248" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>C increases air quality (F) and space (S).</span>
<span id="cb795-7249"><a href="#cb795-7249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7250"><a href="#cb795-7250" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>F, S, T, and D increases exercise (E).</span>
<span id="cb795-7251"><a href="#cb795-7251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7252"><a href="#cb795-7252" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>E reduces obesity (O). </span>
<span id="cb795-7253"><a href="#cb795-7253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7254"><a href="#cb795-7254" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7255"><a href="#cb795-7255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7256"><a href="#cb795-7256" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:navy"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>***Second mechanism***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-7257"><a href="#cb795-7257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7258"><a href="#cb795-7258" aria-hidden="true" tabindex="-1"></a>High gasoline price leads to less driving, which leads to less eating out. Also, high gasoline price increases food food prices (higher cost of food production and transportation), leading to less eating out. </span>
<span id="cb795-7259"><a href="#cb795-7259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7260"><a href="#cb795-7260" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>D reduces eating out at restaurants (R).</span>
<span id="cb795-7261"><a href="#cb795-7261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7262"><a href="#cb795-7262" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>G increases food prices (P).</span>
<span id="cb795-7263"><a href="#cb795-7263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7264"><a href="#cb795-7264" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>P reduces R.</span>
<span id="cb795-7265"><a href="#cb795-7265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7266"><a href="#cb795-7266" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>R reduces O. </span>
<span id="cb795-7267"><a href="#cb795-7267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7268"><a href="#cb795-7268" aria-hidden="true" tabindex="-1"></a>***Here I included many predictor variables I could think of at the moment. Using all predictors to fit multiple regressions is a bad idea. So, predictor variables need to be thoroughly checked and weeded out before building the regression model.***</span>
<span id="cb795-7269"><a href="#cb795-7269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7270"><a href="#cb795-7270" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7271"><a href="#cb795-7271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7272"><a href="#cb795-7272" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hard</span></span>
<span id="cb795-7273"><a href="#cb795-7273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7274"><a href="#cb795-7274" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5H1. Fit two bivariate Gaussian regressions, using map: (1) body weight as a linear function of territory size (area), and (2) body weight as a linear function of groupsize. Plot the results of these regressions, displaying the MAP regression line and the 95% interval of the mean. Is either variable important for predicting fox body weight?</span></span>
<span id="cb795-7275"><a href="#cb795-7275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7276"><a href="#cb795-7276" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5H1}</span></span>
<span id="cb795-7277"><a href="#cb795-7277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7278"><a href="#cb795-7278" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb795-7279"><a href="#cb795-7279" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(foxes)</span>
<span id="cb795-7280"><a href="#cb795-7280" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> foxes</span>
<span id="cb795-7281"><a href="#cb795-7281" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-7282"><a href="#cb795-7282" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-7283"><a href="#cb795-7283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7284"><a href="#cb795-7284" aria-hidden="true" tabindex="-1"></a><span class="co">#  body weight as a linear function of territory size (area)</span></span>
<span id="cb795-7285"><a href="#cb795-7285" aria-hidden="true" tabindex="-1"></a>m.ts <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7286"><a href="#cb795-7286" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7287"><a href="#cb795-7287" aria-hidden="true" tabindex="-1"></a>    weight <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7288"><a href="#cb795-7288" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bT <span class="sc">*</span> area,</span>
<span id="cb795-7289"><a href="#cb795-7289" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb795-7290"><a href="#cb795-7290" aria-hidden="true" tabindex="-1"></a>    bT <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7291"><a href="#cb795-7291" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7292"><a href="#cb795-7292" aria-hidden="true" tabindex="-1"></a>  ), </span>
<span id="cb795-7293"><a href="#cb795-7293" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-7294"><a href="#cb795-7294" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7295"><a href="#cb795-7295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7296"><a href="#cb795-7296" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.ts)</span>
<span id="cb795-7297"><a href="#cb795-7297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7298"><a href="#cb795-7298" aria-hidden="true" tabindex="-1"></a>a.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb795-7299"><a href="#cb795-7299" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m.ts, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">area =</span> a.seq))</span>
<span id="cb795-7300"><a href="#cb795-7300" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span> , mean)</span>
<span id="cb795-7301"><a href="#cb795-7301" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-7302"><a href="#cb795-7302" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(weight <span class="sc">~</span> area, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"brown3"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>), <span class="at">data =</span> d, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb795-7303"><a href="#cb795-7303" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(a.seq, mu.mean, <span class="at">col =</span> <span class="st">"brown4"</span>)</span>
<span id="cb795-7304"><a href="#cb795-7304" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, a.seq, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"brown"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>))</span>
<span id="cb795-7305"><a href="#cb795-7305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7306"><a href="#cb795-7306" aria-hidden="true" tabindex="-1"></a><span class="co"># body weight as a linear function of groupsize</span></span>
<span id="cb795-7307"><a href="#cb795-7307" aria-hidden="true" tabindex="-1"></a>m.gs <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7308"><a href="#cb795-7308" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7309"><a href="#cb795-7309" aria-hidden="true" tabindex="-1"></a>    weight <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7310"><a href="#cb795-7310" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bG <span class="sc">*</span> groupsize,</span>
<span id="cb795-7311"><a href="#cb795-7311" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb795-7312"><a href="#cb795-7312" aria-hidden="true" tabindex="-1"></a>    bG <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7313"><a href="#cb795-7313" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7314"><a href="#cb795-7314" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-7315"><a href="#cb795-7315" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-7316"><a href="#cb795-7316" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7317"><a href="#cb795-7317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7318"><a href="#cb795-7318" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.gs)</span>
<span id="cb795-7319"><a href="#cb795-7319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7320"><a href="#cb795-7320" aria-hidden="true" tabindex="-1"></a>g.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb795-7321"><a href="#cb795-7321" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m.gs, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">groupsize =</span> g.seq))</span>
<span id="cb795-7322"><a href="#cb795-7322" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, mean)</span>
<span id="cb795-7323"><a href="#cb795-7323" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-7324"><a href="#cb795-7324" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(weight <span class="sc">~</span> groupsize, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"slateblue3"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>), <span class="at">data =</span> d, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb795-7325"><a href="#cb795-7325" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(g.seq, mu.mean, <span class="at">col =</span> <span class="st">"slateblue4"</span>)</span>
<span id="cb795-7326"><a href="#cb795-7326" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, g.seq, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"slateblue"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>))</span>
<span id="cb795-7327"><a href="#cb795-7327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7328"><a href="#cb795-7328" aria-hidden="true" tabindex="-1"></a><span class="co"># The regression line between area and body weight is almost linear and data points are</span></span>
<span id="cb795-7329"><a href="#cb795-7329" aria-hidden="true" tabindex="-1"></a><span class="co"># quite scattered in the plot, showing there's almost no correlation between area and body weight. </span></span>
<span id="cb795-7330"><a href="#cb795-7330" aria-hidden="true" tabindex="-1"></a><span class="co"># The effect of group size on body weight seems a bit larger than that of area, but does not show </span></span>
<span id="cb795-7331"><a href="#cb795-7331" aria-hidden="true" tabindex="-1"></a><span class="co"># strong association. Both variables are not a strong predictor of the outcome, but group size seems </span></span>
<span id="cb795-7332"><a href="#cb795-7332" aria-hidden="true" tabindex="-1"></a><span class="co"># more promising than area. </span></span>
<span id="cb795-7333"><a href="#cb795-7333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7334"><a href="#cb795-7334" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7335"><a href="#cb795-7335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7336"><a href="#cb795-7336" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7337"><a href="#cb795-7337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7338"><a href="#cb795-7338" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5H2. Now fit a multiple linear regression with weight as the outcome and both area and groupsize as predictor variables. Plot the predictions of the model for each predictor, holding the other predictor constant at its mean. What does this model say about the importance of each variable? Why do you get different results than you got in the exercise just above?</span></span>
<span id="cb795-7339"><a href="#cb795-7339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7340"><a href="#cb795-7340" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5H2}</span></span>
<span id="cb795-7341"><a href="#cb795-7341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7342"><a href="#cb795-7342" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb795-7343"><a href="#cb795-7343" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"foxes"</span>)</span>
<span id="cb795-7344"><a href="#cb795-7344" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> foxes</span>
<span id="cb795-7345"><a href="#cb795-7345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7346"><a href="#cb795-7346" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model</span></span>
<span id="cb795-7347"><a href="#cb795-7347" aria-hidden="true" tabindex="-1"></a>m.ag <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7348"><a href="#cb795-7348" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7349"><a href="#cb795-7349" aria-hidden="true" tabindex="-1"></a>    weight <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7350"><a href="#cb795-7350" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bT <span class="sc">*</span> area <span class="sc">+</span> bG <span class="sc">*</span> groupsize,</span>
<span id="cb795-7351"><a href="#cb795-7351" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb795-7352"><a href="#cb795-7352" aria-hidden="true" tabindex="-1"></a>    bT <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7353"><a href="#cb795-7353" aria-hidden="true" tabindex="-1"></a>    bG <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb795-7354"><a href="#cb795-7354" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7355"><a href="#cb795-7355" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-7356"><a href="#cb795-7356" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-7357"><a href="#cb795-7357" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7358"><a href="#cb795-7358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7359"><a href="#cb795-7359" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.ag)</span>
<span id="cb795-7360"><a href="#cb795-7360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7361"><a href="#cb795-7361" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-7362"><a href="#cb795-7362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7363"><a href="#cb795-7363" aria-hidden="true" tabindex="-1"></a><span class="do">## When group size is constant</span></span>
<span id="cb795-7364"><a href="#cb795-7364" aria-hidden="true" tabindex="-1"></a>a.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb795-7365"><a href="#cb795-7365" aria-hidden="true" tabindex="-1"></a>g.avg <span class="ot">&lt;-</span> <span class="fu">mean</span>(d<span class="sc">$</span>groupsize)</span>
<span id="cb795-7366"><a href="#cb795-7366" aria-hidden="true" tabindex="-1"></a>pred.area <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-7367"><a href="#cb795-7367" aria-hidden="true" tabindex="-1"></a>  <span class="at">area =</span> a.seq,</span>
<span id="cb795-7368"><a href="#cb795-7368" aria-hidden="true" tabindex="-1"></a>  <span class="at">groupsize =</span> g.avg</span>
<span id="cb795-7369"><a href="#cb795-7369" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7370"><a href="#cb795-7370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7371"><a href="#cb795-7371" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m.ag, <span class="at">data =</span> pred.area)</span>
<span id="cb795-7372"><a href="#cb795-7372" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, mean)</span>
<span id="cb795-7373"><a href="#cb795-7373" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-7374"><a href="#cb795-7374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7375"><a href="#cb795-7375" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot data</span></span>
<span id="cb795-7376"><a href="#cb795-7376" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(weight <span class="sc">~</span> area, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"brown3"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>), <span class="at">data =</span> d, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb795-7377"><a href="#cb795-7377" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(a.seq, mu.mean, <span class="at">col =</span> <span class="st">"brown4"</span>)</span>
<span id="cb795-7378"><a href="#cb795-7378" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, a.seq, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"brown"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>))</span>
<span id="cb795-7379"><a href="#cb795-7379" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Group size is constant at mean value"</span>, <span class="at">col =</span> <span class="st">"brown"</span>)</span>
<span id="cb795-7380"><a href="#cb795-7380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7381"><a href="#cb795-7381" aria-hidden="true" tabindex="-1"></a><span class="do">## When area is held constant</span></span>
<span id="cb795-7382"><a href="#cb795-7382" aria-hidden="true" tabindex="-1"></a>g.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb795-7383"><a href="#cb795-7383" aria-hidden="true" tabindex="-1"></a>a.avg <span class="ot">&lt;-</span> <span class="fu">mean</span>(d<span class="sc">$</span>area)</span>
<span id="cb795-7384"><a href="#cb795-7384" aria-hidden="true" tabindex="-1"></a>pred.group <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-7385"><a href="#cb795-7385" aria-hidden="true" tabindex="-1"></a>  <span class="at">groupsize =</span> g.seq,</span>
<span id="cb795-7386"><a href="#cb795-7386" aria-hidden="true" tabindex="-1"></a>  <span class="at">area =</span> a.avg</span>
<span id="cb795-7387"><a href="#cb795-7387" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7388"><a href="#cb795-7388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7389"><a href="#cb795-7389" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m.ag, <span class="at">data =</span> pred.group)</span>
<span id="cb795-7390"><a href="#cb795-7390" aria-hidden="true" tabindex="-1"></a>mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, mean)</span>
<span id="cb795-7391"><a href="#cb795-7391" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI, <span class="at">prob =</span> <span class="fl">0.95</span>)</span>
<span id="cb795-7392"><a href="#cb795-7392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7393"><a href="#cb795-7393" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb795-7394"><a href="#cb795-7394" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(weight <span class="sc">~</span> groupsize, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"slateblue3"</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>), <span class="at">data =</span> d, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb795-7395"><a href="#cb795-7395" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(g.seq, mu.mean, <span class="at">col =</span> <span class="st">"slateblue4"</span>)</span>
<span id="cb795-7396"><a href="#cb795-7396" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, g.seq, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"slateblue"</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>))</span>
<span id="cb795-7397"><a href="#cb795-7397" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">"Area is constant at mean value"</span>, <span class="at">col =</span> <span class="st">"slateblue"</span>)</span>
<span id="cb795-7398"><a href="#cb795-7398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7399"><a href="#cb795-7399" aria-hidden="true" tabindex="-1"></a><span class="co"># The correlations become a lot stronger for both predictors. This is an example of </span></span>
<span id="cb795-7400"><a href="#cb795-7400" aria-hidden="true" tabindex="-1"></a><span class="co"># masked relationship where predictors are correlated with one another but have opposite </span></span>
<span id="cb795-7401"><a href="#cb795-7401" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation with the outcome variable. Both variables are strong predictors of outcome </span></span>
<span id="cb795-7402"><a href="#cb795-7402" aria-hidden="true" tabindex="-1"></a><span class="co"># in this model, but the raw (observed) data points don't seem to fit well with the model- </span></span>
<span id="cb795-7403"><a href="#cb795-7403" aria-hidden="true" tabindex="-1"></a><span class="co"># maybe because we hold a predictor constant in the model where this is impossible in raw </span></span>
<span id="cb795-7404"><a href="#cb795-7404" aria-hidden="true" tabindex="-1"></a><span class="co"># observed data. </span></span>
<span id="cb795-7405"><a href="#cb795-7405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7406"><a href="#cb795-7406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7407"><a href="#cb795-7407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7408"><a href="#cb795-7408" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7409"><a href="#cb795-7409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7410"><a href="#cb795-7410" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 5H3. Finally, consider the avgfood variable. Fit two more multiple regressions: (1) body weight as an additive function of avgfood and groupsize, and (2) body weight as an additive function of all three variables, avgfood and groupsize and area. Compare the results of these models to the previous models you’ve fit, in the first two exercises. (a) Is avgfood or area a better predictor of body weight? If you had to choose one or the other to include in a model, which would it be? Support your assessment with any tables or plots you choose. (b) When both avgfood or area are in the same model, their effects are reduced (closer to zero) and their standard errors are larger than when they are included in separate models. Can you explain this result?</span></span>
<span id="cb795-7411"><a href="#cb795-7411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7412"><a href="#cb795-7412" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 5H3}</span></span>
<span id="cb795-7413"><a href="#cb795-7413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7414"><a href="#cb795-7414" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb795-7415"><a href="#cb795-7415" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(foxes)</span>
<span id="cb795-7416"><a href="#cb795-7416" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> foxes</span>
<span id="cb795-7417"><a href="#cb795-7417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7418"><a href="#cb795-7418" aria-hidden="true" tabindex="-1"></a><span class="co"># body weight as an additive function of avgfood and groupsize</span></span>
<span id="cb795-7419"><a href="#cb795-7419" aria-hidden="true" tabindex="-1"></a>m.fg <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7420"><a href="#cb795-7420" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7421"><a href="#cb795-7421" aria-hidden="true" tabindex="-1"></a>    weight <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7422"><a href="#cb795-7422" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bF <span class="sc">*</span> avgfood <span class="sc">+</span> bG <span class="sc">*</span> groupsize,</span>
<span id="cb795-7423"><a href="#cb795-7423" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb795-7424"><a href="#cb795-7424" aria-hidden="true" tabindex="-1"></a>    bF <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-7425"><a href="#cb795-7425" aria-hidden="true" tabindex="-1"></a>    bG <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-7426"><a href="#cb795-7426" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7427"><a href="#cb795-7427" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-7428"><a href="#cb795-7428" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-7429"><a href="#cb795-7429" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7430"><a href="#cb795-7430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7431"><a href="#cb795-7431" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.fg)</span>
<span id="cb795-7432"><a href="#cb795-7432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7433"><a href="#cb795-7433" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(<span class="sc">~</span> weight <span class="sc">+</span> avgfood <span class="sc">+</span> groupsize, <span class="at">data =</span> d, <span class="at">col =</span> <span class="st">"brown3"</span>)</span>
<span id="cb795-7434"><a href="#cb795-7434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7435"><a href="#cb795-7435" aria-hidden="true" tabindex="-1"></a><span class="co"># body weight as an additive function of avgfood and groupsize and area</span></span>
<span id="cb795-7436"><a href="#cb795-7436" aria-hidden="true" tabindex="-1"></a>m.fga <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-7437"><a href="#cb795-7437" aria-hidden="true" tabindex="-1"></a>  <span class="fu">alist</span>(</span>
<span id="cb795-7438"><a href="#cb795-7438" aria-hidden="true" tabindex="-1"></a>    weight <span class="sc">~</span> <span class="fu">dnorm</span>(mu, sigma),</span>
<span id="cb795-7439"><a href="#cb795-7439" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bF <span class="sc">*</span> avgfood <span class="sc">+</span> bG <span class="sc">*</span> groupsize <span class="sc">+</span> bT <span class="sc">*</span> area,</span>
<span id="cb795-7440"><a href="#cb795-7440" aria-hidden="true" tabindex="-1"></a>    a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">100</span>),</span>
<span id="cb795-7441"><a href="#cb795-7441" aria-hidden="true" tabindex="-1"></a>    bG <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-7442"><a href="#cb795-7442" aria-hidden="true" tabindex="-1"></a>    bF <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-7443"><a href="#cb795-7443" aria-hidden="true" tabindex="-1"></a>    bT <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">10</span>),</span>
<span id="cb795-7444"><a href="#cb795-7444" aria-hidden="true" tabindex="-1"></a>    sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb795-7445"><a href="#cb795-7445" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb795-7446"><a href="#cb795-7446" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> d</span>
<span id="cb795-7447"><a href="#cb795-7447" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-7448"><a href="#cb795-7448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7449"><a href="#cb795-7449" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m.fga)</span>
<span id="cb795-7450"><a href="#cb795-7450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7451"><a href="#cb795-7451" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(<span class="sc">~</span> weight <span class="sc">+</span> avgfood <span class="sc">+</span> groupsize <span class="sc">+</span> area, <span class="at">data =</span> d, <span class="at">col =</span> <span class="st">"slateblue3"</span>)</span>
<span id="cb795-7452"><a href="#cb795-7452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7453"><a href="#cb795-7453" aria-hidden="true" tabindex="-1"></a><span class="co"># (a) Average food because a bit higher increase in weight per unit of average food increase,</span></span>
<span id="cb795-7454"><a href="#cb795-7454" aria-hidden="true" tabindex="-1"></a><span class="co"># as seen in the table (model m.fga). </span></span>
<span id="cb795-7455"><a href="#cb795-7455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7456"><a href="#cb795-7456" aria-hidden="true" tabindex="-1"></a><span class="co"># (b) It could be because average food and area are highly correlated with each other.</span></span>
<span id="cb795-7457"><a href="#cb795-7457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7458"><a href="#cb795-7458" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7459"><a href="#cb795-7459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7460"><a href="#cb795-7460" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7461"><a href="#cb795-7461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7462"><a href="#cb795-7462" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 6: Overfitting, Regularization, and Information Criteria</span></span>
<span id="cb795-7463"><a href="#cb795-7463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7464"><a href="#cb795-7464" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7465"><a href="#cb795-7465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7466"><a href="#cb795-7466" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Two fundamental kinds of statistical error:**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-7467"><a href="#cb795-7467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7468"><a href="#cb795-7468" aria-hidden="true" tabindex="-1"></a>(1) ***Overfitting:*** leads to poor prediction by learning too much from the data</span>
<span id="cb795-7469"><a href="#cb795-7469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7470"><a href="#cb795-7470" aria-hidden="true" tabindex="-1"></a>(2) ***Underfitting:*** leads to poor prediction by learning too little from the data</span>
<span id="cb795-7471"><a href="#cb795-7471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7472"><a href="#cb795-7472" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7473"><a href="#cb795-7473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7474"><a href="#cb795-7474" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Two approaches to address the errors:**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-7475"><a href="#cb795-7475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7476"><a href="#cb795-7476" aria-hidden="true" tabindex="-1"></a>(1) ***Regularizing prior:*** tells the model not to get too excited by the data (penalized likelihood)</span>
<span id="cb795-7477"><a href="#cb795-7477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7478"><a href="#cb795-7478" aria-hidden="true" tabindex="-1"></a>(2) ***Information criteria:*** scoring device to model the prediction task and estimate predictive accuracy for some purpose </span>
<span id="cb795-7479"><a href="#cb795-7479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7480"><a href="#cb795-7480" aria-hidden="true" tabindex="-1"></a>*Both can be&amp;mdash; maybe should be&amp;mdash; used in combination.*</span>
<span id="cb795-7481"><a href="#cb795-7481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7482"><a href="#cb795-7482" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7483"><a href="#cb795-7483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7484"><a href="#cb795-7484" aria-hidden="true" tabindex="-1"></a><span class="fu">## The problem with parameters</span></span>
<span id="cb795-7485"><a href="#cb795-7485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7486"><a href="#cb795-7486" aria-hidden="true" tabindex="-1"></a>There are two principle concerns with just adding variables. </span>
<span id="cb795-7487"><a href="#cb795-7487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7488"><a href="#cb795-7488" aria-hidden="true" tabindex="-1"></a>The first is that adding parameters<span class="dv">&amp;mdash;</span> making the model more complex<span class="dv">&amp;mdash;</span> nearly always improves the fit of a model to the data. For example, like other measures of fit to sample, *R^2^* increases as more predictor variables are added. This is true even when the variables added to a model are just random numbers, with no relation to the outcome. So it’s no good to choose among models using only fit to the data.</span>
<span id="cb795-7489"><a href="#cb795-7489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7490"><a href="#cb795-7490" aria-hidden="true" tabindex="-1"></a>Second, while more complex models fit the data better, they often predict new data worse. Models that have many parameters tend to overfit more than do simpler models. This means that a complex model will be very sensitive to the exact sample used to fit it, leading to potentially large mistakes when future data is not exactly like the past data. But simple models, with too few parameters, tend instead to underfit, systematically over-predicting or under-predicting the data, regardless of how well future data resemble past data. So we can’t always favor either simple models or complex models.</span>
<span id="cb795-7491"><a href="#cb795-7491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7492"><a href="#cb795-7492" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7493"><a href="#cb795-7493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7494"><a href="#cb795-7494" aria-hidden="true" tabindex="-1"></a><span class="fu">## More parameters always improve fit</span></span>
<span id="cb795-7495"><a href="#cb795-7495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7496"><a href="#cb795-7496" aria-hidden="true" tabindex="-1"></a>Overfitting occurs when a model learns too much from the sample. This is a general phenomenon: If you adopt a model family with enough parameters, you can fit the data exactly. But such a model will make rather absurd predictions for yet-to-be-observed cases.</span>
<span id="cb795-7497"><a href="#cb795-7497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7498"><a href="#cb795-7498" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.1, fig.height=10}</span></span>
<span id="cb795-7499"><a href="#cb795-7499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7500"><a href="#cb795-7500" aria-hidden="true" tabindex="-1"></a><span class="do">## Create data set for average brain volumes and body masses for seven hominin species</span></span>
<span id="cb795-7501"><a href="#cb795-7501" aria-hidden="true" tabindex="-1"></a>sppnames <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">"afarensis"</span>,<span class="st">"africanus"</span>,<span class="st">"habilis"</span>,<span class="st">"boisei"</span>,</span>
<span id="cb795-7502"><a href="#cb795-7502" aria-hidden="true" tabindex="-1"></a>    <span class="st">"rudolfensis"</span>,<span class="st">"ergaster"</span>,<span class="st">"sapiens"</span>)</span>
<span id="cb795-7503"><a href="#cb795-7503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7504"><a href="#cb795-7504" aria-hidden="true" tabindex="-1"></a>brainvolcc <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="dv">438</span> , <span class="dv">452</span> , <span class="dv">612</span>, <span class="dv">521</span>, <span class="dv">752</span>, <span class="dv">871</span>, <span class="dv">1350</span> )</span>
<span id="cb795-7505"><a href="#cb795-7505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7506"><a href="#cb795-7506" aria-hidden="true" tabindex="-1"></a>masskg <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fl">37.0</span> , <span class="fl">35.5</span> , <span class="fl">34.5</span> , <span class="fl">41.5</span> , <span class="fl">55.5</span> , <span class="fl">61.0</span> , <span class="fl">53.5</span> )</span>
<span id="cb795-7507"><a href="#cb795-7507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7508"><a href="#cb795-7508" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">species=</span>sppnames , <span class="at">brain=</span>brainvolcc , <span class="at">mass=</span>masskg )</span>
<span id="cb795-7509"><a href="#cb795-7509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7510"><a href="#cb795-7510" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit model that relates brain size to body size </span></span>
<span id="cb795-7511"><a href="#cb795-7511" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass , <span class="at">data=</span>d )</span>
<span id="cb795-7512"><a href="#cb795-7512" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m6<span class="fl">.1</span>)</span>
<span id="cb795-7513"><a href="#cb795-7513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7514"><a href="#cb795-7514" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R^2</span></span>
<span id="cb795-7515"><a href="#cb795-7515" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">var</span>(<span class="fu">resid</span>(m6<span class="fl">.1</span>))<span class="sc">/</span><span class="fu">var</span>(d<span class="sc">$</span>brain)</span>
<span id="cb795-7516"><a href="#cb795-7516" aria-hidden="true" tabindex="-1"></a><span class="co"># Same number as 'multipled R-squared' from summary(m6.1)</span></span>
<span id="cb795-7517"><a href="#cb795-7517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7518"><a href="#cb795-7518" aria-hidden="true" tabindex="-1"></a><span class="do">## Create other models to compare to the fit of m6.1</span></span>
<span id="cb795-7519"><a href="#cb795-7519" aria-hidden="true" tabindex="-1"></a><span class="co"># Second-degree polynomial (parabola) that relates body size to brain size</span></span>
<span id="cb795-7520"><a href="#cb795-7520" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">2</span>) , <span class="at">data=</span>d )</span>
<span id="cb795-7521"><a href="#cb795-7521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7522"><a href="#cb795-7522" aria-hidden="true" tabindex="-1"></a><span class="co"># Third-degree polynomial</span></span>
<span id="cb795-7523"><a href="#cb795-7523" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">3</span>) , <span class="at">data=</span>d )</span>
<span id="cb795-7524"><a href="#cb795-7524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7525"><a href="#cb795-7525" aria-hidden="true" tabindex="-1"></a><span class="co"># Fourth-degree polynomial</span></span>
<span id="cb795-7526"><a href="#cb795-7526" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.4</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">3</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">4</span>) ,</span>
<span id="cb795-7527"><a href="#cb795-7527" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-7528"><a href="#cb795-7528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7529"><a href="#cb795-7529" aria-hidden="true" tabindex="-1"></a><span class="co"># Fifth-degree polynomial</span></span>
<span id="cb795-7530"><a href="#cb795-7530" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.5</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">3</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb795-7531"><a href="#cb795-7531" aria-hidden="true" tabindex="-1"></a>    <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">5</span>) , <span class="at">data=</span>d )</span>
<span id="cb795-7532"><a href="#cb795-7532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7533"><a href="#cb795-7533" aria-hidden="true" tabindex="-1"></a><span class="co"># Sixth-degree polynomial</span></span>
<span id="cb795-7534"><a href="#cb795-7534" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.6</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">3</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb795-7535"><a href="#cb795-7535" aria-hidden="true" tabindex="-1"></a>    <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">5</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">6</span>) , <span class="at">data=</span>d )</span>
<span id="cb795-7536"><a href="#cb795-7536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7537"><a href="#cb795-7537" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the data</span></span>
<span id="cb795-7538"><a href="#cb795-7538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7539"><a href="#cb795-7539" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model</span></span>
<span id="cb795-7540"><a href="#cb795-7540" aria-hidden="true" tabindex="-1"></a> d1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> masskg, <span class="at">y =</span> brainvolcc)) <span class="sc">+</span></span>
<span id="cb795-7541"><a href="#cb795-7541" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">stroke =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7542"><a href="#cb795-7542" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7543"><a href="#cb795-7543" aria-hidden="true" tabindex="-1"></a>               <span class="at">level =</span> <span class="fl">0.89</span>, </span>
<span id="cb795-7544"><a href="#cb795-7544" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-7545"><a href="#cb795-7545" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"grey"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>,</span>
<span id="cb795-7546"><a href="#cb795-7546" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> x) <span class="sc">+</span></span>
<span id="cb795-7547"><a href="#cb795-7547" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">300</span>, <span class="dv">1500</span>)) <span class="sc">+</span></span>
<span id="cb795-7548"><a href="#cb795-7548" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7549"><a href="#cb795-7549" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"body mass (kg)"</span>, <span class="at">y =</span> <span class="st">"brain volume (cc)"</span>, <span class="at">title =</span> <span class="st">"R^2 = 0.49"</span>) <span class="sc">+</span></span>
<span id="cb795-7550"><a href="#cb795-7550" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7551"><a href="#cb795-7551" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb795-7552"><a href="#cb795-7552" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>)) <span class="sc">+</span></span>
<span id="cb795-7553"><a href="#cb795-7553" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-7554"><a href="#cb795-7554" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7555"><a href="#cb795-7555" aria-hidden="true" tabindex="-1"></a><span class="co"># Second-degree polynomial</span></span>
<span id="cb795-7556"><a href="#cb795-7556" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> masskg, <span class="at">y =</span> brainvolcc)) <span class="sc">+</span></span>
<span id="cb795-7557"><a href="#cb795-7557" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">21</span>,</span>
<span id="cb795-7558"><a href="#cb795-7558" aria-hidden="true" tabindex="-1"></a>             <span class="at">stroke =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7559"><a href="#cb795-7559" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7560"><a href="#cb795-7560" aria-hidden="true" tabindex="-1"></a>               <span class="at">level =</span> <span class="fl">0.89</span>, </span>
<span id="cb795-7561"><a href="#cb795-7561" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-7562"><a href="#cb795-7562" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"grey"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>,</span>
<span id="cb795-7563"><a href="#cb795-7563" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb795-7564"><a href="#cb795-7564" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">300</span>, <span class="dv">1500</span>)) <span class="sc">+</span></span>
<span id="cb795-7565"><a href="#cb795-7565" aria-hidden="true" tabindex="-1"></a>   <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7566"><a href="#cb795-7566" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"body mass (kg)"</span>, <span class="at">y =</span> <span class="st">"brain volume (cc)"</span>, <span class="at">title =</span> <span class="st">"R^2 = 0.54"</span>) <span class="sc">+</span></span>
<span id="cb795-7567"><a href="#cb795-7567" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7568"><a href="#cb795-7568" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb795-7569"><a href="#cb795-7569" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>)) <span class="sc">+</span></span>
<span id="cb795-7570"><a href="#cb795-7570" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-7571"><a href="#cb795-7571" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7572"><a href="#cb795-7572" aria-hidden="true" tabindex="-1"></a><span class="co"># Third-degree polynomial</span></span>
<span id="cb795-7573"><a href="#cb795-7573" aria-hidden="true" tabindex="-1"></a> d3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> masskg, <span class="at">y =</span> brainvolcc)) <span class="sc">+</span></span>
<span id="cb795-7574"><a href="#cb795-7574" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">21</span>, </span>
<span id="cb795-7575"><a href="#cb795-7575" aria-hidden="true" tabindex="-1"></a>              <span class="at">stroke =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7576"><a href="#cb795-7576" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7577"><a href="#cb795-7577" aria-hidden="true" tabindex="-1"></a>                <span class="at">level =</span> <span class="fl">0.89</span>, </span>
<span id="cb795-7578"><a href="#cb795-7578" aria-hidden="true" tabindex="-1"></a>               <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb795-7579"><a href="#cb795-7579" aria-hidden="true" tabindex="-1"></a>               <span class="at">fill =</span> <span class="st">"grey"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>,</span>
<span id="cb795-7580"><a href="#cb795-7580" aria-hidden="true" tabindex="-1"></a>               <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="dv">3</span>)) <span class="sc">+</span></span>
<span id="cb795-7581"><a href="#cb795-7581" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">300</span>, <span class="dv">1500</span>)) <span class="sc">+</span></span>
<span id="cb795-7582"><a href="#cb795-7582" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7583"><a href="#cb795-7583" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"body mass (kg)"</span>, <span class="at">y =</span> <span class="st">"brain volume (cc)"</span>, <span class="at">title =</span> <span class="st">"R^2 = 0.68"</span>) <span class="sc">+</span></span>
<span id="cb795-7584"><a href="#cb795-7584" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7585"><a href="#cb795-7585" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb795-7586"><a href="#cb795-7586" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>)) <span class="sc">+</span></span>
<span id="cb795-7587"><a href="#cb795-7587" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-7588"><a href="#cb795-7588" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7589"><a href="#cb795-7589" aria-hidden="true" tabindex="-1"></a> <span class="co"># Fourth-degree polynomial</span></span>
<span id="cb795-7590"><a href="#cb795-7590" aria-hidden="true" tabindex="-1"></a> d4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> masskg, <span class="at">y =</span> brainvolcc)) <span class="sc">+</span></span>
<span id="cb795-7591"><a href="#cb795-7591" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">21</span>,</span>
<span id="cb795-7592"><a href="#cb795-7592" aria-hidden="true" tabindex="-1"></a>              <span class="at">stroke =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7593"><a href="#cb795-7593" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7594"><a href="#cb795-7594" aria-hidden="true" tabindex="-1"></a>                <span class="at">level =</span> <span class="fl">0.89</span>, </span>
<span id="cb795-7595"><a href="#cb795-7595" aria-hidden="true" tabindex="-1"></a>               <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb795-7596"><a href="#cb795-7596" aria-hidden="true" tabindex="-1"></a>               <span class="at">fill =</span> <span class="st">"grey"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>,</span>
<span id="cb795-7597"><a href="#cb795-7597" aria-hidden="true" tabindex="-1"></a>               <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="dv">4</span>)) <span class="sc">+</span></span>
<span id="cb795-7598"><a href="#cb795-7598" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">300</span>, <span class="dv">1500</span>)) <span class="sc">+</span></span>
<span id="cb795-7599"><a href="#cb795-7599" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7600"><a href="#cb795-7600" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"body mass (kg)"</span>, <span class="at">y =</span> <span class="st">"brain volume (cc)"</span>, <span class="at">title =</span> <span class="st">"R^2 = 0.81"</span>) <span class="sc">+</span></span>
<span id="cb795-7601"><a href="#cb795-7601" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7602"><a href="#cb795-7602" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb795-7603"><a href="#cb795-7603" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>)) <span class="sc">+</span></span>
<span id="cb795-7604"><a href="#cb795-7604" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-7605"><a href="#cb795-7605" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7606"><a href="#cb795-7606" aria-hidden="true" tabindex="-1"></a><span class="co"># Fifth-degree polynomial</span></span>
<span id="cb795-7607"><a href="#cb795-7607" aria-hidden="true" tabindex="-1"></a> d5 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> masskg, <span class="at">y =</span> brainvolcc)) <span class="sc">+</span></span>
<span id="cb795-7608"><a href="#cb795-7608" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">21</span>, </span>
<span id="cb795-7609"><a href="#cb795-7609" aria-hidden="true" tabindex="-1"></a>              <span class="at">stroke =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7610"><a href="#cb795-7610" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> <span class="cn">TRUE</span>,</span>
<span id="cb795-7611"><a href="#cb795-7611" aria-hidden="true" tabindex="-1"></a>                <span class="at">level =</span> <span class="fl">0.89</span>, </span>
<span id="cb795-7612"><a href="#cb795-7612" aria-hidden="true" tabindex="-1"></a>               <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb795-7613"><a href="#cb795-7613" aria-hidden="true" tabindex="-1"></a>               <span class="at">fill =</span> <span class="st">"grey"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>,</span>
<span id="cb795-7614"><a href="#cb795-7614" aria-hidden="true" tabindex="-1"></a>               <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="dv">5</span>)) <span class="sc">+</span></span>
<span id="cb795-7615"><a href="#cb795-7615" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">150</span>, <span class="dv">1900</span>)) <span class="sc">+</span></span>
<span id="cb795-7616"><a href="#cb795-7616" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7617"><a href="#cb795-7617" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"body mass (kg)"</span>, <span class="at">y =</span> <span class="st">"brain volume (cc)"</span>, <span class="at">title =</span> <span class="st">"R^2 = 0.99"</span>) <span class="sc">+</span></span>
<span id="cb795-7618"><a href="#cb795-7618" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7619"><a href="#cb795-7619" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb795-7620"><a href="#cb795-7620" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>)) <span class="sc">+</span></span>
<span id="cb795-7621"><a href="#cb795-7621" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-7622"><a href="#cb795-7622" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7623"><a href="#cb795-7623" aria-hidden="true" tabindex="-1"></a> <span class="co"># Sixth-degree polynomial</span></span>
<span id="cb795-7624"><a href="#cb795-7624" aria-hidden="true" tabindex="-1"></a> d6 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> masskg, <span class="at">y =</span> brainvolcc)) <span class="sc">+</span></span>
<span id="cb795-7625"><a href="#cb795-7625" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">21</span>, </span>
<span id="cb795-7626"><a href="#cb795-7626" aria-hidden="true" tabindex="-1"></a>              <span class="at">stroke =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7627"><a href="#cb795-7627" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> <span class="cn">TRUE</span>,</span>
<span id="cb795-7628"><a href="#cb795-7628" aria-hidden="true" tabindex="-1"></a>               <span class="at">level =</span> <span class="fl">0.89</span>, </span>
<span id="cb795-7629"><a href="#cb795-7629" aria-hidden="true" tabindex="-1"></a>               <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb795-7630"><a href="#cb795-7630" aria-hidden="true" tabindex="-1"></a>               <span class="at">fill =</span> <span class="st">"grey"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>,</span>
<span id="cb795-7631"><a href="#cb795-7631" aria-hidden="true" tabindex="-1"></a>               <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x, <span class="dv">6</span>)) <span class="sc">+</span></span>
<span id="cb795-7632"><a href="#cb795-7632" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7633"><a href="#cb795-7633" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">300</span>, <span class="dv">1500</span>)) <span class="sc">+</span></span>
<span id="cb795-7634"><a href="#cb795-7634" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">34</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7635"><a href="#cb795-7635" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"body mass (kg)"</span>, <span class="at">y =</span> <span class="st">"brain volume (cc)"</span>, <span class="at">title =</span> <span class="st">"R^2 = 1.00"</span>) <span class="sc">+</span></span>
<span id="cb795-7636"><a href="#cb795-7636" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7637"><a href="#cb795-7637" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb795-7638"><a href="#cb795-7638" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>)) <span class="sc">+</span></span>
<span id="cb795-7639"><a href="#cb795-7639" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-7640"><a href="#cb795-7640" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7641"><a href="#cb795-7641" aria-hidden="true" tabindex="-1"></a> <span class="fu">grid.arrange</span>(d1, d2, d3, d4, d5, d6, <span class="at">layout_matrix =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>), </span>
<span id="cb795-7642"><a href="#cb795-7642" aria-hidden="true" tabindex="-1"></a>                                                             <span class="at">ncol =</span> <span class="dv">2</span>, </span>
<span id="cb795-7643"><a href="#cb795-7643" aria-hidden="true" tabindex="-1"></a>                                                             <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb795-7644"><a href="#cb795-7644" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7645"><a href="#cb795-7645" aria-hidden="true" tabindex="-1"></a> <span class="co"># As the degree of the polynomial defining the mean increases, the fit always improves. </span></span>
<span id="cb795-7646"><a href="#cb795-7646" aria-hidden="true" tabindex="-1"></a> <span class="co"># However, you can see from looking at the paths of the predicted means that the </span></span>
<span id="cb795-7647"><a href="#cb795-7647" aria-hidden="true" tabindex="-1"></a> <span class="co"># higher-degree polynomials are increasingly absurd. </span></span>
<span id="cb795-7648"><a href="#cb795-7648" aria-hidden="true" tabindex="-1"></a> <span class="co"># The sixth-degree polynomial fit perfectly because it has enough parameters to assign</span></span>
<span id="cb795-7649"><a href="#cb795-7649" aria-hidden="true" tabindex="-1"></a> <span class="co"># one to each point of data. The model’s equation for the mean has 7 parameters and there </span></span>
<span id="cb795-7650"><a href="#cb795-7650" aria-hidden="true" tabindex="-1"></a> <span class="co"># are 7 species to predict brain sizes for.</span></span>
<span id="cb795-7651"><a href="#cb795-7651" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-7652"><a href="#cb795-7652" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7653"><a href="#cb795-7653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7654"><a href="#cb795-7654" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7655"><a href="#cb795-7655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7656"><a href="#cb795-7656" aria-hidden="true" tabindex="-1"></a><span class="fu">## Too few parameters hurts, too</span></span>
<span id="cb795-7657"><a href="#cb795-7657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7658"><a href="#cb795-7658" aria-hidden="true" tabindex="-1"></a>The overfit polynomial models manage to fit the data extremely well, but they suffer for this within-sample accuracy by making nonsensical out-of-sample predictions. In contrast, underfitting produces models that are inaccurate both within and out of sample. They have learned too little, failing to recover regular features of the sample.</span>
<span id="cb795-7659"><a href="#cb795-7659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7660"><a href="#cb795-7660" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.6}</span></span>
<span id="cb795-7661"><a href="#cb795-7661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7662"><a href="#cb795-7662" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data </span></span>
<span id="cb795-7663"><a href="#cb795-7663" aria-hidden="true" tabindex="-1"></a>sppnames <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">"afarensis"</span>,<span class="st">"africanus"</span>,<span class="st">"habilis"</span>,<span class="st">"boisei"</span>,</span>
<span id="cb795-7664"><a href="#cb795-7664" aria-hidden="true" tabindex="-1"></a>    <span class="st">"rudolfensis"</span>,<span class="st">"ergaster"</span>,<span class="st">"sapiens"</span>)</span>
<span id="cb795-7665"><a href="#cb795-7665" aria-hidden="true" tabindex="-1"></a>brainvolcc <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="dv">438</span> , <span class="dv">452</span> , <span class="dv">612</span>, <span class="dv">521</span>, <span class="dv">752</span>, <span class="dv">871</span>, <span class="dv">1350</span> )</span>
<span id="cb795-7666"><a href="#cb795-7666" aria-hidden="true" tabindex="-1"></a>masskg <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fl">37.0</span> , <span class="fl">35.5</span> , <span class="fl">34.5</span> , <span class="fl">41.5</span> , <span class="fl">55.5</span> , <span class="fl">61.0</span> , <span class="fl">53.5</span> )</span>
<span id="cb795-7667"><a href="#cb795-7667" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">species=</span>sppnames , <span class="at">brain=</span>brainvolcc , <span class="at">mass=</span>masskg )</span>
<span id="cb795-7668"><a href="#cb795-7668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7669"><a href="#cb795-7669" aria-hidden="true" tabindex="-1"></a><span class="co"># Consider a model of brain volume where mu = a (no predictor variable, just intercept a)</span></span>
<span id="cb795-7670"><a href="#cb795-7670" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.7</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> <span class="dv">1</span> , <span class="at">data=</span>d )</span>
<span id="cb795-7671"><a href="#cb795-7671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7672"><a href="#cb795-7672" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb795-7673"><a href="#cb795-7673" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> masskg, <span class="at">y =</span> brainvolcc)) <span class="sc">+</span></span>
<span id="cb795-7674"><a href="#cb795-7674" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="fu">col.alpha</span>(rangi2, <span class="fl">0.8</span>), <span class="at">size =</span> <span class="dv">2</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">stroke =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7675"><a href="#cb795-7675" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">fullrange =</span> T,</span>
<span id="cb795-7676"><a href="#cb795-7676" aria-hidden="true" tabindex="-1"></a>               <span class="at">level =</span> <span class="fl">0.89</span>, </span>
<span id="cb795-7677"><a href="#cb795-7677" aria-hidden="true" tabindex="-1"></a>              <span class="at">color  =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb795-7678"><a href="#cb795-7678" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill   =</span> <span class="st">"grey"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>,</span>
<span id="cb795-7679"><a href="#cb795-7679" aria-hidden="true" tabindex="-1"></a>              <span class="at">formula =</span> y <span class="sc">~</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7680"><a href="#cb795-7680" aria-hidden="true" tabindex="-1"></a>   <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">65</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7681"><a href="#cb795-7681" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"body mass (kg)"</span>, <span class="at">y =</span> <span class="st">"brain volume (cc)"</span>, <span class="at">title =</span> <span class="st">"R^2 = 0"</span>) <span class="sc">+</span></span>
<span id="cb795-7682"><a href="#cb795-7682" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7683"><a href="#cb795-7683" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb795-7684"><a href="#cb795-7684" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size=</span><span class="dv">11</span>)) <span class="sc">+</span></span>
<span id="cb795-7685"><a href="#cb795-7685" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-7686"><a href="#cb795-7686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7687"><a href="#cb795-7687" aria-hidden="true" tabindex="-1"></a><span class="co"># An underfit model of hominin brain volume. This model ignores any association between </span></span>
<span id="cb795-7688"><a href="#cb795-7688" aria-hidden="true" tabindex="-1"></a><span class="co"># body mass and brain volume, producing a horizontal line of predictions. As a result, </span></span>
<span id="cb795-7689"><a href="#cb795-7689" aria-hidden="true" tabindex="-1"></a><span class="co"># the model fits badly and (presumably) predicts badly.</span></span>
<span id="cb795-7690"><a href="#cb795-7690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7691"><a href="#cb795-7691" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7692"><a href="#cb795-7692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7693"><a href="#cb795-7693" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7694"><a href="#cb795-7694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7695"><a href="#cb795-7695" aria-hidden="true" tabindex="-1"></a>Another way to conceptualize an underfit model is to notice that it is insensitive to the sample. We could remove any one point from the sample and get pretty much the same regression line. In contrast, the most complex model, m6.6, is very sensitive to the sample. The predicted mean would change course a lot, if we removed any one point from the sample.</span>
<span id="cb795-7696"><a href="#cb795-7696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7697"><a href="#cb795-7697" aria-hidden="true" tabindex="-1"></a><span class="in">```{r f6.5}</span></span>
<span id="cb795-7698"><a href="#cb795-7698" aria-hidden="true" tabindex="-1"></a><span class="co"># Create seven sets of data by dropping a row each time</span></span>
<span id="cb795-7699"><a href="#cb795-7699" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>species <span class="sc">==</span> <span class="st">"sapiens"</span>, ])</span>
<span id="cb795-7700"><a href="#cb795-7700" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>species <span class="sc">==</span> <span class="st">"ergaster"</span>, ])</span>
<span id="cb795-7701"><a href="#cb795-7701" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>species <span class="sc">==</span> <span class="st">"rudolfensis"</span>, ])</span>
<span id="cb795-7702"><a href="#cb795-7702" aria-hidden="true" tabindex="-1"></a>d4 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>species <span class="sc">==</span> <span class="st">"boisei"</span>, ])</span>
<span id="cb795-7703"><a href="#cb795-7703" aria-hidden="true" tabindex="-1"></a>d5 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>species <span class="sc">==</span> <span class="st">"habilis"</span>, ])</span>
<span id="cb795-7704"><a href="#cb795-7704" aria-hidden="true" tabindex="-1"></a>d6 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>species <span class="sc">==</span> <span class="st">"africanus"</span>, ])</span>
<span id="cb795-7705"><a href="#cb795-7705" aria-hidden="true" tabindex="-1"></a>d7 <span class="ot">&lt;-</span> <span class="fu">droplevels</span>(d[<span class="sc">!</span>d<span class="sc">$</span>species <span class="sc">==</span> <span class="st">"afarenis"</span>, ])</span>
<span id="cb795-7706"><a href="#cb795-7706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7707"><a href="#cb795-7707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7708"><a href="#cb795-7708" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the models (First- degree polynomials: Underfit example) </span></span>
<span id="cb795-7709"><a href="#cb795-7709" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(brain <span class="sc">~</span> mass, <span class="at">data =</span> d1)</span>
<span id="cb795-7710"><a href="#cb795-7710" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(brain <span class="sc">~</span> mass, <span class="at">data =</span> d2)</span>
<span id="cb795-7711"><a href="#cb795-7711" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(brain <span class="sc">~</span> mass, <span class="at">data =</span> d3)</span>
<span id="cb795-7712"><a href="#cb795-7712" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(brain <span class="sc">~</span> mass, <span class="at">data =</span> d4)</span>
<span id="cb795-7713"><a href="#cb795-7713" aria-hidden="true" tabindex="-1"></a>m5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(brain <span class="sc">~</span> mass, <span class="at">data =</span> d5)</span>
<span id="cb795-7714"><a href="#cb795-7714" aria-hidden="true" tabindex="-1"></a>m6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(brain <span class="sc">~</span> mass, <span class="at">data =</span> d6)</span>
<span id="cb795-7715"><a href="#cb795-7715" aria-hidden="true" tabindex="-1"></a>m7 <span class="ot">&lt;-</span> <span class="fu">lm</span>(brain <span class="sc">~</span> mass, <span class="at">data =</span> d7)</span>
<span id="cb795-7716"><a href="#cb795-7716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7717"><a href="#cb795-7717" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-7718"><a href="#cb795-7718" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb795-7719"><a href="#cb795-7719" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d<span class="sc">$</span>mass, d<span class="sc">$</span>brain,</span>
<span id="cb795-7720"><a href="#cb795-7720" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlim =</span> <span class="fu">range</span>(d<span class="sc">$</span>mass), <span class="at">ylim =</span> <span class="fu">range</span>(d<span class="sc">$</span>brain), <span class="at">pch =</span> <span class="dv">1</span>,</span>
<span id="cb795-7721"><a href="#cb795-7721" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">xlab =</span> <span class="st">"body mass (kg)"</span>, <span class="at">ylab =</span> <span class="st">"brain volume (cc)"</span>,</span>
<span id="cb795-7722"><a href="#cb795-7722" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"My plot"</span>)</span>
<span id="cb795-7723"><a href="#cb795-7723" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m1)</span>
<span id="cb795-7724"><a href="#cb795-7724" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m2)</span>
<span id="cb795-7725"><a href="#cb795-7725" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m3)</span>
<span id="cb795-7726"><a href="#cb795-7726" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m4)</span>
<span id="cb795-7727"><a href="#cb795-7727" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m5)</span>
<span id="cb795-7728"><a href="#cb795-7728" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m6)</span>
<span id="cb795-7729"><a href="#cb795-7729" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m7)</span>
<span id="cb795-7730"><a href="#cb795-7730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7731"><a href="#cb795-7731" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( brain <span class="sc">~</span> mass , d , <span class="at">col=</span><span class="st">"slateblue"</span> , <span class="at">main =</span> <span class="st">"Given example"</span>)</span>
<span id="cb795-7732"><a href="#cb795-7732" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(d) ) {</span>
<span id="cb795-7733"><a href="#cb795-7733" aria-hidden="true" tabindex="-1"></a>    d.new <span class="ot">&lt;-</span> d[ <span class="sc">-</span>i , ]</span>
<span id="cb795-7734"><a href="#cb795-7734" aria-hidden="true" tabindex="-1"></a>    m0 <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass, d.new )</span>
<span id="cb795-7735"><a href="#cb795-7735" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>( m0 , <span class="at">col=</span><span class="fu">col.alpha</span>(<span class="st">"black"</span>,<span class="fl">0.5</span>) )</span>
<span id="cb795-7736"><a href="#cb795-7736" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-7737"><a href="#cb795-7737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7738"><a href="#cb795-7738" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7739"><a href="#cb795-7739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7740"><a href="#cb795-7740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7741"><a href="#cb795-7741" aria-hidden="true" tabindex="-1"></a><span class="in">```{r f6.5a}</span></span>
<span id="cb795-7742"><a href="#cb795-7742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7743"><a href="#cb795-7743" aria-hidden="true" tabindex="-1"></a><span class="do">### Use codes from "ajkurz"</span></span>
<span id="cb795-7744"><a href="#cb795-7744" aria-hidden="true" tabindex="-1"></a><span class="co"># Create base plot</span></span>
<span id="cb795-7745"><a href="#cb795-7745" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span></span>
<span id="cb795-7746"><a href="#cb795-7746" aria-hidden="true" tabindex="-1"></a>  d <span class="sc">%&gt;%</span> </span>
<span id="cb795-7747"><a href="#cb795-7747" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mass, <span class="at">y =</span> brain)) <span class="sc">+</span></span>
<span id="cb795-7748"><a href="#cb795-7748" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"slateblue"</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">shape =</span> <span class="dv">21</span>)  <span class="sc">+</span></span>
<span id="cb795-7749"><a href="#cb795-7749" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"body mass (kg)"</span>, <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7750"><a href="#cb795-7750" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">300</span>, <span class="dv">1500</span>)) <span class="sc">+</span></span>
<span id="cb795-7751"><a href="#cb795-7751" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"brain volume (cc)"</span>) <span class="sc">+</span></span>
<span id="cb795-7752"><a href="#cb795-7752" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"(a)"</span>) <span class="sc">+</span></span>
<span id="cb795-7753"><a href="#cb795-7753" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7754"><a href="#cb795-7754" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb795-7755"><a href="#cb795-7755" aria-hidden="true" tabindex="-1"></a>        <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb795-7756"><a href="#cb795-7756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7757"><a href="#cb795-7757" aria-hidden="true" tabindex="-1"></a><span class="co"># If drop second row</span></span>
<span id="cb795-7758"><a href="#cb795-7758" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span></span>
<span id="cb795-7759"><a href="#cb795-7759" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">row_number</span>() <span class="sc">!=</span> <span class="dv">2</span>)</span>
<span id="cb795-7760"><a href="#cb795-7760" aria-hidden="true" tabindex="-1"></a><span class="co"># We can then extend that logic into a custom function, make_lines(), that will drop a </span></span>
<span id="cb795-7761"><a href="#cb795-7761" aria-hidden="true" tabindex="-1"></a><span class="co"># row from d, fit the simple model brain ~ mass, and then use base R predict() to return </span></span>
<span id="cb795-7762"><a href="#cb795-7762" aria-hidden="true" tabindex="-1"></a><span class="co"># the model-implied trajectory over new data values.</span></span>
<span id="cb795-7763"><a href="#cb795-7763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7764"><a href="#cb795-7764" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the models (First- degree polynomials: Underfit example) </span></span>
<span id="cb795-7765"><a href="#cb795-7765" aria-hidden="true" tabindex="-1"></a><span class="co"># because these lines are straight, we only need new data over two points of `mass`</span></span>
<span id="cb795-7766"><a href="#cb795-7766" aria-hidden="true" tabindex="-1"></a>nd <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">mass =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">70</span>))</span>
<span id="cb795-7767"><a href="#cb795-7767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7768"><a href="#cb795-7768" aria-hidden="true" tabindex="-1"></a>make_lines <span class="ot">&lt;-</span> <span class="cf">function</span>(row){</span>
<span id="cb795-7769"><a href="#cb795-7769" aria-hidden="true" tabindex="-1"></a>  my_fit <span class="ot">&lt;-</span></span>
<span id="cb795-7770"><a href="#cb795-7770" aria-hidden="true" tabindex="-1"></a>    d <span class="sc">%&gt;%</span></span>
<span id="cb795-7771"><a href="#cb795-7771" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(<span class="fu">row_number</span>() <span class="sc">!=</span> row) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7772"><a href="#cb795-7772" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lm</span>(<span class="at">formula =</span> brain <span class="sc">~</span> mass)</span>
<span id="cb795-7773"><a href="#cb795-7773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7774"><a href="#cb795-7774" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(my_fit, nd) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7775"><a href="#cb795-7775" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb795-7776"><a href="#cb795-7776" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rename</span>(<span class="at">brain =</span> value) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7777"><a href="#cb795-7777" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(nd)</span>
<span id="cb795-7778"><a href="#cb795-7778" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-7779"><a href="#cb795-7779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7780"><a href="#cb795-7780" aria-hidden="true" tabindex="-1"></a><span class="co"># Here we’ll make a tibble, lines, which will specify rows 1 through 7 in the row column.</span></span>
<span id="cb795-7781"><a href="#cb795-7781" aria-hidden="true" tabindex="-1"></a><span class="co"># We’ll then feed those row numbers into our custom make_lines() function, which will return </span></span>
<span id="cb795-7782"><a href="#cb795-7782" aria-hidden="true" tabindex="-1"></a><span class="co"># the predicted values and their corresponding mass values, per model.</span></span>
<span id="cb795-7783"><a href="#cb795-7783" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb795-7784"><a href="#cb795-7784" aria-hidden="true" tabindex="-1"></a>  lines <span class="ot">&lt;-</span></span>
<span id="cb795-7785"><a href="#cb795-7785" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">row =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7786"><a href="#cb795-7786" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p =</span> <span class="fu">map</span>(row, make_lines)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7787"><a href="#cb795-7787" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(p)</span>
<span id="cb795-7788"><a href="#cb795-7788" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb795-7789"><a href="#cb795-7789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7790"><a href="#cb795-7790" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb795-7791"><a href="#cb795-7791" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p <span class="sc">+</span> </span>
<span id="cb795-7792"><a href="#cb795-7792" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7793"><a href="#cb795-7793" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> lines, </span>
<span id="cb795-7794"><a href="#cb795-7794" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> mass, <span class="at">y =</span> brain, <span class="at">group =</span> row),</span>
<span id="cb795-7795"><a href="#cb795-7795" aria-hidden="true" tabindex="-1"></a>            <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb795-7796"><a href="#cb795-7796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7797"><a href="#cb795-7797" aria-hidden="true" tabindex="-1"></a><span class="do">## Fit the models (Sixth-order polynomials: Overfit example)</span></span>
<span id="cb795-7798"><a href="#cb795-7798" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span></span>
<span id="cb795-7799"><a href="#cb795-7799" aria-hidden="true" tabindex="-1"></a>  d <span class="sc">%&gt;%</span> </span>
<span id="cb795-7800"><a href="#cb795-7800" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mass, <span class="at">y =</span> brain)) <span class="sc">+</span></span>
<span id="cb795-7801"><a href="#cb795-7801" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"slateblue"</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">shape =</span> <span class="dv">21</span>)  <span class="sc">+</span></span>
<span id="cb795-7802"><a href="#cb795-7802" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="st">"body mass (kg)"</span>, <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-7803"><a href="#cb795-7803" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">300</span>, <span class="dv">1500</span>)) <span class="sc">+</span></span>
<span id="cb795-7804"><a href="#cb795-7804" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"brain volume (cc)"</span>) <span class="sc">+</span></span>
<span id="cb795-7805"><a href="#cb795-7805" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"(b)"</span>) <span class="sc">+</span></span>
<span id="cb795-7806"><a href="#cb795-7806" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7807"><a href="#cb795-7807" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb795-7808"><a href="#cb795-7808" aria-hidden="true" tabindex="-1"></a>        <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb795-7809"><a href="#cb795-7809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7810"><a href="#cb795-7810" aria-hidden="true" tabindex="-1"></a><span class="co"># We’ll need to increase the number of mass points in our nd data and redefine the </span></span>
<span id="cb795-7811"><a href="#cb795-7811" aria-hidden="true" tabindex="-1"></a><span class="co"># make_lines() function to fit the sixth-order-polynomial model.</span></span>
<span id="cb795-7812"><a href="#cb795-7812" aria-hidden="true" tabindex="-1"></a><span class="co"># because these lines will be very curvy, we'll need new data over many points of `mass`</span></span>
<span id="cb795-7813"><a href="#cb795-7813" aria-hidden="true" tabindex="-1"></a>nd <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">mass =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">30</span>, <span class="at">to =</span> <span class="dv">65</span>, <span class="at">length.out =</span> <span class="dv">200</span>))</span>
<span id="cb795-7814"><a href="#cb795-7814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7815"><a href="#cb795-7815" aria-hidden="true" tabindex="-1"></a><span class="co"># redifine the function</span></span>
<span id="cb795-7816"><a href="#cb795-7816" aria-hidden="true" tabindex="-1"></a>make_lines <span class="ot">&lt;-</span> <span class="cf">function</span>(row){</span>
<span id="cb795-7817"><a href="#cb795-7817" aria-hidden="true" tabindex="-1"></a>  my_fit <span class="ot">&lt;-</span></span>
<span id="cb795-7818"><a href="#cb795-7818" aria-hidden="true" tabindex="-1"></a>    d <span class="sc">%&gt;%</span></span>
<span id="cb795-7819"><a href="#cb795-7819" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(<span class="fu">row_number</span>() <span class="sc">!=</span> row) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7820"><a href="#cb795-7820" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lm</span>(<span class="at">formula =</span> brain <span class="sc">~</span> mass <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">3</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">4</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">5</span>) <span class="sc">+</span> <span class="fu">I</span>(mass<span class="sc">^</span><span class="dv">6</span>))</span>
<span id="cb795-7821"><a href="#cb795-7821" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-7822"><a href="#cb795-7822" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(my_fit, nd) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7823"><a href="#cb795-7823" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb795-7824"><a href="#cb795-7824" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rename</span>(<span class="at">brain =</span> value) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7825"><a href="#cb795-7825" aria-hidden="true" tabindex="-1"></a>    <span class="fu">bind_cols</span>(nd)</span>
<span id="cb795-7826"><a href="#cb795-7826" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-7827"><a href="#cb795-7827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7828"><a href="#cb795-7828" aria-hidden="true" tabindex="-1"></a><span class="co"># make our new tibble</span></span>
<span id="cb795-7829"><a href="#cb795-7829" aria-hidden="true" tabindex="-1"></a>lines <span class="ot">&lt;-</span></span>
<span id="cb795-7830"><a href="#cb795-7830" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">row =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7831"><a href="#cb795-7831" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p =</span> <span class="fu">map</span>(row, make_lines)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-7832"><a href="#cb795-7832" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(p)</span>
<span id="cb795-7833"><a href="#cb795-7833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7834"><a href="#cb795-7834" aria-hidden="true" tabindex="-1"></a><span class="co"># plot!</span></span>
<span id="cb795-7835"><a href="#cb795-7835" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p <span class="sc">+</span></span>
<span id="cb795-7836"><a href="#cb795-7836" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> lines, </span>
<span id="cb795-7837"><a href="#cb795-7837" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">group =</span> row),</span>
<span id="cb795-7838"><a href="#cb795-7838" aria-hidden="true" tabindex="-1"></a>            <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>, <span class="at">size =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7839"><a href="#cb795-7839" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">300</span>, <span class="dv">2000</span>))</span>
<span id="cb795-7840"><a href="#cb795-7840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7841"><a href="#cb795-7841" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb795-7842"><a href="#cb795-7842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7843"><a href="#cb795-7843" aria-hidden="true" tabindex="-1"></a><span class="co"># Underfitting and overfitting as under-sensitivity and over-sensitivity to sample. </span></span>
<span id="cb795-7844"><a href="#cb795-7844" aria-hidden="true" tabindex="-1"></a><span class="co"># In both plots, a regression is fit to the seven sets of data made by dropping one row </span></span>
<span id="cb795-7845"><a href="#cb795-7845" aria-hidden="true" tabindex="-1"></a><span class="co"># from the original data. (a) An underfit model is insensitive to the sample, changing </span></span>
<span id="cb795-7846"><a href="#cb795-7846" aria-hidden="true" tabindex="-1"></a><span class="co"># little as individual points are dropped. (b) An overfit model is sensitive to the sample, </span></span>
<span id="cb795-7847"><a href="#cb795-7847" aria-hidden="true" tabindex="-1"></a><span class="co"># changing dramatically as points are dropped.</span></span>
<span id="cb795-7848"><a href="#cb795-7848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7849"><a href="#cb795-7849" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7850"><a href="#cb795-7850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7851"><a href="#cb795-7851" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7852"><a href="#cb795-7852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7853"><a href="#cb795-7853" aria-hidden="true" tabindex="-1"></a><span class="fu">## Information theory and model performance</span></span>
<span id="cb795-7854"><a href="#cb795-7854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7855"><a href="#cb795-7855" aria-hidden="true" tabindex="-1"></a>The information theory provides a common and useful target (criterion of model performance), the *out-of-sample deviance* to navigate between overfitting and underfitting. The steps to out-of-sample deviance:</span>
<span id="cb795-7856"><a href="#cb795-7856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7857"><a href="#cb795-7857" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>First, we need to establish that joint probability, not average probability, is the right way to judge model accuracy. </span>
<span id="cb795-7858"><a href="#cb795-7858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7859"><a href="#cb795-7859" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Second, we need to establish a measurement scale for distance from perfect accuracy. This will require a little *information theory*, as it will provide a natural measurement scale for the distance between two probability distributions. </span>
<span id="cb795-7860"><a href="#cb795-7860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7861"><a href="#cb795-7861" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Third, we need to establish deviance as an approximation of relative distance from perfect accuracy. </span>
<span id="cb795-7862"><a href="#cb795-7862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7863"><a href="#cb795-7863" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Finally, we must establish that it is only deviance out-of-sample that is of interest.</span>
<span id="cb795-7864"><a href="#cb795-7864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7865"><a href="#cb795-7865" aria-hidden="true" tabindex="-1"></a>Once you have deviance in hand as a measure model performance, both regularizing priors and information criteria help you improve and estimate the out-of-sample deviance of a model.</span>
<span id="cb795-7866"><a href="#cb795-7866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7867"><a href="#cb795-7867" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7868"><a href="#cb795-7868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7869"><a href="#cb795-7869" aria-hidden="true" tabindex="-1"></a><span class="fu">### Firing the weatherperson</span></span>
<span id="cb795-7870"><a href="#cb795-7870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7871"><a href="#cb795-7871" aria-hidden="true" tabindex="-1"></a>Accuracy depends upon the definition of the target, and there is no unique best target. In defining a target, there are two major dimensions to worry about:</span>
<span id="cb795-7872"><a href="#cb795-7872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7873"><a href="#cb795-7873" aria-hidden="true" tabindex="-1"></a>(1) ***Cost-benefit analysis***</span>
<span id="cb795-7874"><a href="#cb795-7874" aria-hidden="true" tabindex="-1"></a><span class="ss">          - </span>How much does it cost when we’re wrong? How much do we win when we’re right? </span>
<span id="cb795-7875"><a href="#cb795-7875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7876"><a href="#cb795-7876" aria-hidden="true" tabindex="-1"></a>(2) ***Accuracy in context*** </span>
<span id="cb795-7877"><a href="#cb795-7877" aria-hidden="true" tabindex="-1"></a><span class="ss">          - </span>Some prediction tasks are inherently easier than others. So even if we ignore costs and benefits, we still need a way to judge “accuracy” that accounts for how much a model could possibly improve prediction.</span>
<span id="cb795-7878"><a href="#cb795-7878" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb795-7879"><a href="#cb795-7879" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7880"><a href="#cb795-7880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7881"><a href="#cb795-7881" aria-hidden="true" tabindex="-1"></a><span class="fu">### Information and uncertainty</span></span>
<span id="cb795-7882"><a href="#cb795-7882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7883"><a href="#cb795-7883" aria-hidden="true" tabindex="-1"></a>The information theory provides a solution to the problem of how to measure distance of a model’s accuracy from a target. The basic insight is to ask: *How much is our uncertainty reduced by learning an outcome?*</span>
<span id="cb795-7884"><a href="#cb795-7884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7885"><a href="#cb795-7885" aria-hidden="true" tabindex="-1"></a>$$\textit{Information:}~\text{The reduction in uncertainty derived from learning an outcome.}$$</span>
<span id="cb795-7886"><a href="#cb795-7886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7887"><a href="#cb795-7887" aria-hidden="true" tabindex="-1"></a>To use this definition, what we need is a principled way to quantify the uncertainty inherent in a probability distribution. There are many possible ways to measure uncertainty. The most common way begins by naming some properties a measure of uncertainty should possess. These are the three intuitive desiderata:</span>
<span id="cb795-7888"><a href="#cb795-7888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7889"><a href="#cb795-7889" aria-hidden="true" tabindex="-1"></a>(1) The measure of uncertainty should be continuous.</span>
<span id="cb795-7890"><a href="#cb795-7890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7891"><a href="#cb795-7891" aria-hidden="true" tabindex="-1"></a>(2) The measure of uncertainty should increase as the number of possible events increases.</span>
<span id="cb795-7892"><a href="#cb795-7892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7893"><a href="#cb795-7893" aria-hidden="true" tabindex="-1"></a>(3) The measure of uncertainty should be additive. </span>
<span id="cb795-7894"><a href="#cb795-7894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7895"><a href="#cb795-7895" aria-hidden="true" tabindex="-1"></a>Only one function ***Information Theory*** satisfies these desiderata. If there are *n* different possible events and each event *i* has probability *p~i~*, and we call the list of probabilities *p*, then the unique measure of uncertainty we seek is:</span>
<span id="cb795-7896"><a href="#cb795-7896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7897"><a href="#cb795-7897" aria-hidden="true" tabindex="-1"></a>$$H(p) = ~- \text{E log}(p_i) = -\sum_{i=1}^{n} p_i ~\text{log}(p_i)$$</span>
<span id="cb795-7898"><a href="#cb795-7898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7899"><a href="#cb795-7899" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7900"><a href="#cb795-7900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7901"><a href="#cb795-7901" aria-hidden="true" tabindex="-1"></a><span class="in">The uncertainty contained in a probability distribution is the average log-probability of an event.</span></span>
<span id="cb795-7902"><a href="#cb795-7902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7903"><a href="#cb795-7903" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7904"><a href="#cb795-7904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7905"><a href="#cb795-7905" aria-hidden="true" tabindex="-1"></a>To compute the information entropy for the weather, suppose the true probabilities of rain and shine are p~1~ = 0.3 and p~2~ = 0.7, respectively. Then:</span>
<span id="cb795-7906"><a href="#cb795-7906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7907"><a href="#cb795-7907" aria-hidden="true" tabindex="-1"></a>$$H(p) = ~-(p_1 ~\text{log}(p_1) ~+~ p_2 ~\text{log}(p_2)) \approx 0.61 $$</span>
<span id="cb795-7908"><a href="#cb795-7908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7909"><a href="#cb795-7909" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.9}</span></span>
<span id="cb795-7910"><a href="#cb795-7910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7911"><a href="#cb795-7911" aria-hidden="true" tabindex="-1"></a><span class="co"># In R calculation for the value of entropy:</span></span>
<span id="cb795-7912"><a href="#cb795-7912" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fl">0.3</span> , <span class="fl">0.7</span> )</span>
<span id="cb795-7913"><a href="#cb795-7913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7914"><a href="#cb795-7914" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fu">sum</span>( p<span class="sc">*</span><span class="fu">log</span>(p) )</span>
<span id="cb795-7915"><a href="#cb795-7915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7916"><a href="#cb795-7916" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-7917"><a href="#cb795-7917" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7918"><a href="#cb795-7918" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7919"><a href="#cb795-7919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7920"><a href="#cb795-7920" aria-hidden="true" tabindex="-1"></a>The entropy values by themselves don’t mean much to us, though. Instead we can use them to build a measure of accuracy. The information entropy is the average log-probability. But there’s also a −1 in the definition. Multiplying the average log-probability by −1 just makes the entropy H increase from zero, rather than decrease from zero. </span>
<span id="cb795-7921"><a href="#cb795-7921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7922"><a href="#cb795-7922" aria-hidden="true" tabindex="-1"></a>The logarithms above are natural logs (base *e*), but changing the base rescales without any effect on inference. Binary logarithms, base 2, are just as common. As long as all of the entropies you compare use the same base, you’ll be fine.</span>
<span id="cb795-7923"><a href="#cb795-7923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7924"><a href="#cb795-7924" aria-hidden="true" tabindex="-1"></a>The only trick in computing *H* is to deal with the inevitable question of what to do when *p~i~* = 0. The log(0) = −$\infty$, which won’t do. So just assume that 0 log(0) = 0, when you compute *H*. In other words, events that never happen drop out. It may make more sense to just remember that when an event never happens, there’s no point in keeping it in the model.</span>
<span id="cb795-7925"><a href="#cb795-7925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7926"><a href="#cb795-7926" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7927"><a href="#cb795-7927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7928"><a href="#cb795-7928" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**The benefits of maximizing uncertainty**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-7929"><a href="#cb795-7929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7930"><a href="#cb795-7930" aria-hidden="true" tabindex="-1"></a>**Maximum entropy**, also known as **maxent**, is a family of techniques for finding probability distributions that are most consistent with states of knowledge. In other words, given what we know, what is the *least surprising* distribution? It turns out that one answer to this question maximizes the information entropy, using the prior knowledge as constraint.</span>
<span id="cb795-7931"><a href="#cb795-7931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7932"><a href="#cb795-7932" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-7933"><a href="#cb795-7933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7934"><a href="#cb795-7934" aria-hidden="true" tabindex="-1"></a><span class="fu">### From entropy to accuracy</span></span>
<span id="cb795-7935"><a href="#cb795-7935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7936"><a href="#cb795-7936" aria-hidden="true" tabindex="-1"></a>How can we use information entropy to say how far a model is from the target? The key lies in divergence:</span>
<span id="cb795-7937"><a href="#cb795-7937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7938"><a href="#cb795-7938" aria-hidden="true" tabindex="-1"></a>$$\textit{Divergence:} ~\text{The additional uncertainty induced by using probabilities from one distribution to describe another distribution.}$$</span>
<span id="cb795-7939"><a href="#cb795-7939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7940"><a href="#cb795-7940" aria-hidden="true" tabindex="-1"></a>Suppose for example that the true distribution of events is *p~1~* = 0.3, *p~2~* = 0.7. If we believe instead that these events happen with probabilities *q~1~* = 0.25, *q~2~* = 0.75, how much additional uncertainty have we introduced, as a consequence of using *q* = {*q~1~*, *q~2~*} to approximate *p* = {*p~1~*, *p~2~*}? The formal answer to this question is based upon *H*, and has a similarly simple formula:</span>
<span id="cb795-7941"><a href="#cb795-7941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7942"><a href="#cb795-7942" aria-hidden="true" tabindex="-1"></a>$$D_{KL} (p, q) = \sum_i~ p_i ~(~\text{log}(p_i) - \text{log}(q_i)) = \sum_i~p_i ~\text{log} \left(\frac{p_i}{q_i}\right)$$</span>
<span id="cb795-7943"><a href="#cb795-7943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7944"><a href="#cb795-7944" aria-hidden="true" tabindex="-1"></a>In plainer language, the divergence is *the average difference in log probability between the target (p) and model (q)*. This divergence is just the difference between two entropies: The entropy of the target distribution *p* and the cross entropy arising from using *q* to predict *p*. When *p* = *q*, we know the actual probabilities of the events. In that case:</span>
<span id="cb795-7945"><a href="#cb795-7945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7946"><a href="#cb795-7946" aria-hidden="true" tabindex="-1"></a>$$D_{KL} (p, q) = D_{KL} (p, p) = \sum_i ~p_i  ~(~\text{log} (p_i) - \text{log}(p_i)) = 0$$</span>
<span id="cb795-7947"><a href="#cb795-7947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7948"><a href="#cb795-7948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7949"><a href="#cb795-7949" aria-hidden="true" tabindex="-1"></a>There is no additional uncertainty induced when we use a probability distribution to represent itself. But more importantly, as *q* grows more different from *p*, the divergence $D_{KL}$ also grows. Suppose the true target distribution is p = {0.3, 0.7}. Suppose the approximating distribution *q* can be anything from *q* = {0.01, 0.99} to *q* = {0.99, 0.01}. The first of these probabilities, *q~1~*, is displayed on the horizontal axis, and the vertical displays the divergence $D_{KL}$(*p*, *q*). Only exactly where *q* = *p*, at *q~1~* = 0.3, does the divergence achieve a value of zero. Everyplace else, it grows.</span>
<span id="cb795-7950"><a href="#cb795-7950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7951"><a href="#cb795-7951" aria-hidden="true" tabindex="-1"></a>Divergence can help us contrast different approximations to *p*. As an approximating function *q* becomes more accurate, $D_{KL}$(*p*, *q*) will shrink. So if we have a pair of candidate distributions, then the candidate that minimizes the divergence will be closest to the target. Since predictive models specify probabilities of events (observations), we can use divergence to compare the accuracy of models.</span>
<span id="cb795-7952"><a href="#cb795-7952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7953"><a href="#cb795-7953" aria-hidden="true" tabindex="-1"></a><span class="in">```{r f6.6}</span></span>
<span id="cb795-7954"><a href="#cb795-7954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7955"><a href="#cb795-7955" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataframe for figure 6.6</span></span>
<span id="cb795-7956"><a href="#cb795-7956" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fl">0.3</span></span>
<span id="cb795-7957"><a href="#cb795-7957" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fl">0.7</span></span>
<span id="cb795-7958"><a href="#cb795-7958" aria-hidden="true" tabindex="-1"></a>q1 <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.01</span>, <span class="at">to =</span> <span class="fl">0.99</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb795-7959"><a href="#cb795-7959" aria-hidden="true" tabindex="-1"></a>q2 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span>q1</span>
<span id="cb795-7960"><a href="#cb795-7960" aria-hidden="true" tabindex="-1"></a>dkl <span class="ot">&lt;-</span> (p1<span class="sc">*</span><span class="fu">log</span>(p1<span class="sc">/</span>q1)) <span class="sc">+</span> (p2<span class="sc">*</span><span class="fu">log</span>(p2<span class="sc">/</span>q2))</span>
<span id="cb795-7961"><a href="#cb795-7961" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(p1, p2, q1, q2, dkl)</span>
<span id="cb795-7962"><a href="#cb795-7962" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-7963"><a href="#cb795-7963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7964"><a href="#cb795-7964" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot data for true p at 0.3</span></span>
<span id="cb795-7965"><a href="#cb795-7965" aria-hidden="true" tabindex="-1"></a>f1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> q1, <span class="at">y =</span> dkl)) <span class="sc">+</span></span>
<span id="cb795-7966"><a href="#cb795-7966" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> .<span class="dv">3</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7967"><a href="#cb795-7967" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="fu">col.alpha</span>(<span class="st">"black"</span>, <span class="fl">0.4</span>), <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7968"><a href="#cb795-7968" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"slateblue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7969"><a href="#cb795-7969" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="at">geom =</span> <span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">4</span>, <span class="at">y =</span> <span class="fl">1.5</span>, <span class="at">label =</span> <span class="st">"q = p"</span>,</span>
<span id="cb795-7970"><a href="#cb795-7970" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb795-7971"><a href="#cb795-7971" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"True target distribution p = 0.3"</span>) <span class="sc">+</span></span>
<span id="cb795-7972"><a href="#cb795-7972" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"q[1]"</span>,</span>
<span id="cb795-7973"><a href="#cb795-7973" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Divergence of q from p"</span>) <span class="sc">+</span></span>
<span id="cb795-7974"><a href="#cb795-7974" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7975"><a href="#cb795-7975" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb795-7976"><a href="#cb795-7976" aria-hidden="true" tabindex="-1"></a>         <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb795-7977"><a href="#cb795-7977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7978"><a href="#cb795-7978" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot data for true p at 0.7</span></span>
<span id="cb795-7979"><a href="#cb795-7979" aria-hidden="true" tabindex="-1"></a>f2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(d, <span class="fu">aes</span>(<span class="at">x =</span> q2, <span class="at">y =</span> dkl)) <span class="sc">+</span></span>
<span id="cb795-7980"><a href="#cb795-7980" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> .<span class="dv">7</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7981"><a href="#cb795-7981" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="fu">col.alpha</span>(<span class="st">"black"</span>, <span class="fl">0.4</span>), <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-7982"><a href="#cb795-7982" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"slateblue"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-7983"><a href="#cb795-7983" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="at">geom =</span> <span class="st">"text"</span>, <span class="at">x =</span> .<span class="dv">8</span>, <span class="at">y =</span> <span class="fl">1.5</span>, <span class="at">label =</span> <span class="st">"q = p"</span>,</span>
<span id="cb795-7984"><a href="#cb795-7984" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb795-7985"><a href="#cb795-7985" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"True target distribution p = 0.7"</span>) <span class="sc">+</span></span>
<span id="cb795-7986"><a href="#cb795-7986" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"q[2]"</span>,</span>
<span id="cb795-7987"><a href="#cb795-7987" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Divergence of q from p"</span>) <span class="sc">+</span></span>
<span id="cb795-7988"><a href="#cb795-7988" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-7989"><a href="#cb795-7989" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb795-7990"><a href="#cb795-7990" aria-hidden="true" tabindex="-1"></a>         <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb795-7991"><a href="#cb795-7991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7992"><a href="#cb795-7992" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(f1, f2, <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb795-7993"><a href="#cb795-7993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-7994"><a href="#cb795-7994" aria-hidden="true" tabindex="-1"></a><span class="co"># Information divergence of an approximating distribution q from a true distribution p. </span></span>
<span id="cb795-7995"><a href="#cb795-7995" aria-hidden="true" tabindex="-1"></a><span class="co"># Divergence can only equal zero when q = p (dashed line). Otherwise, the divergence is </span></span>
<span id="cb795-7996"><a href="#cb795-7996" aria-hidden="true" tabindex="-1"></a><span class="co"># positive and grows as q becomes more dissimilar from p. When we have more than one </span></span>
<span id="cb795-7997"><a href="#cb795-7997" aria-hidden="true" tabindex="-1"></a><span class="co"># candidate approximation q, the q with the smallest divergence is the most accurate </span></span>
<span id="cb795-7998"><a href="#cb795-7998" aria-hidden="true" tabindex="-1"></a><span class="co"># approximation, in the sense that it induces the least additional uncertainty.</span></span>
<span id="cb795-7999"><a href="#cb795-7999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8000"><a href="#cb795-8000" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8001"><a href="#cb795-8001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8002"><a href="#cb795-8002" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8003"><a href="#cb795-8003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8004"><a href="#cb795-8004" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Cross entropy and divergence**<span class="kw">&lt;/span&gt;&lt;/span&gt;</span></span>
<span id="cb795-8005"><a href="#cb795-8005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8006"><a href="#cb795-8006" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>***Cross entropy:*** </span>
<span id="cb795-8007"><a href="#cb795-8007" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>The use of a probability distribution *q* to predict events from another distribution *p* </span>
<span id="cb795-8008"><a href="#cb795-8008" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>$H(p, q) = ~-\sum_i p_i ~\text{log}(q_i)$</span>
<span id="cb795-8009"><a href="#cb795-8009" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Events arise according to the *p'*s, but they are expected according to the *q'*s, so the entropy is inflated, depending upon how different *p* and *q* are</span>
<span id="cb795-8010"><a href="#cb795-8010" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-8011"><a href="#cb795-8011" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-8012"><a href="#cb795-8012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8013"><a href="#cb795-8013" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>***Divergence:***</span>
<span id="cb795-8014"><a href="#cb795-8014" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>The *additional* entropy induced by using *q* (measuring how far *q* is from the target *p*, in units of entropy)</span>
<span id="cb795-8015"><a href="#cb795-8015" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Divergence depends upon direction: $H(p, q)$ does not in general equal $H(q, p)$</span>
<span id="cb795-8016"><a href="#cb795-8016" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>It's just the difference between $H(p)$, the actual entropy of events, and $H(p, q)$: </span>
<span id="cb795-8017"><a href="#cb795-8017" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-8018"><a href="#cb795-8018" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-8019"><a href="#cb795-8019" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-8020"><a href="#cb795-8020" aria-hidden="true" tabindex="-1"></a>\ D_{KL} (p, q) &amp;= H(p, q) ~- ~ H(p)<span class="sc">\\</span></span>
<span id="cb795-8021"><a href="#cb795-8021" aria-hidden="true" tabindex="-1"></a>&amp;= ~- \sum_i p_i ~\text{log}(q_i) ~-~ \left(- \sum_i p_i ~\text{log}(p_i) \right)<span class="sc">\\</span></span>
<span id="cb795-8022"><a href="#cb795-8022" aria-hidden="true" tabindex="-1"></a>&amp;= ~- \sum_i p_i ~\left( \text{log}(q_i) ~-~ \text{log}(p_i) \right)</span>
<span id="cb795-8023"><a href="#cb795-8023" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-8024"><a href="#cb795-8024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8025"><a href="#cb795-8025" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-8026"><a href="#cb795-8026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8027"><a href="#cb795-8027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8028"><a href="#cb795-8028" aria-hidden="true" tabindex="-1"></a>***If we use a distribution with high entropy to approximate an unknown true distribution of events, we will reduce the distance to the truth and therefore the error.***</span>
<span id="cb795-8029"><a href="#cb795-8029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8030"><a href="#cb795-8030" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8031"><a href="#cb795-8031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8032"><a href="#cb795-8032" aria-hidden="true" tabindex="-1"></a><span class="fu">### From divergence to deviance</span></span>
<span id="cb795-8033"><a href="#cb795-8033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8034"><a href="#cb795-8034" aria-hidden="true" tabindex="-1"></a>The point of all the preceding material about information theory and divergence is to establish both:</span>
<span id="cb795-8035"><a href="#cb795-8035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8036"><a href="#cb795-8036" aria-hidden="true" tabindex="-1"></a>(1) How to measure the distance of a model from our target. Information theory gives us the distance measure we need, the K-L divergence.</span>
<span id="cb795-8037"><a href="#cb795-8037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8038"><a href="#cb795-8038" aria-hidden="true" tabindex="-1"></a>(2) How to estimate the divergence. Having identified the right measure of distance, we now need a way to estimate it in real statistical modeling tasks<span class="dv">&amp;mdash;</span> a measure of model fit known as ***deviance*** which is defined as:</span>
<span id="cb795-8039"><a href="#cb795-8039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8040"><a href="#cb795-8040" aria-hidden="true" tabindex="-1"></a>$$D(q) = ~-2 \sum_i \text{log}(q_i)$$</span>
<span id="cb795-8041"><a href="#cb795-8041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8042"><a href="#cb795-8042" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8043"><a href="#cb795-8043" aria-hidden="true" tabindex="-1"></a><span class="in">i   = indexes each observation (case)</span></span>
<span id="cb795-8044"><a href="#cb795-8044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8045"><a href="#cb795-8045" aria-hidden="true" tabindex="-1"></a><span class="in">q_i =  the likelihood of case i</span></span>
<span id="cb795-8046"><a href="#cb795-8046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8047"><a href="#cb795-8047" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8048"><a href="#cb795-8048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8049"><a href="#cb795-8049" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8050"><a href="#cb795-8050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8051"><a href="#cb795-8051" aria-hidden="true" tabindex="-1"></a>In examples of divergence, p is known. In real world, p is unknown, but we can still estimate which models (q or r, etc.) is a better fit by using deviance<span class="dv">&amp;mdash;</span> like we don't know how far each archer is from hitting the target, but we can know which archer is closer and how far apart they are from each other. </span>
<span id="cb795-8052"><a href="#cb795-8052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8053"><a href="#cb795-8053" aria-hidden="true" tabindex="-1"></a>You can compute the deviance for any model you’ve fit already in this book, just by using the <span class="in">`MAP`</span> estimates to compute a log-probability of the observed data for each row. These probabilities are the *q* values. Then you add these log-probabilities together and multiply by −2. Most of the standard model fitting functions support <span class="in">`logLik`</span>, which will do the hard part: compute the sum of log-probabilities, usually known as the log-likelihood of the data. For example:</span>
<span id="cb795-8054"><a href="#cb795-8054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8055"><a href="#cb795-8055" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.10}</span></span>
<span id="cb795-8056"><a href="#cb795-8056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8057"><a href="#cb795-8057" aria-hidden="true" tabindex="-1"></a><span class="co"># Reload data</span></span>
<span id="cb795-8058"><a href="#cb795-8058" aria-hidden="true" tabindex="-1"></a>sppnames <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">"afarensis"</span>,<span class="st">"africanus"</span>,<span class="st">"habilis"</span>,<span class="st">"boisei"</span>,</span>
<span id="cb795-8059"><a href="#cb795-8059" aria-hidden="true" tabindex="-1"></a>    <span class="st">"rudolfensis"</span>,<span class="st">"ergaster"</span>,<span class="st">"sapiens"</span>)</span>
<span id="cb795-8060"><a href="#cb795-8060" aria-hidden="true" tabindex="-1"></a>brainvolcc <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="dv">438</span> , <span class="dv">452</span> , <span class="dv">612</span>, <span class="dv">521</span>, <span class="dv">752</span>, <span class="dv">871</span>, <span class="dv">1350</span> )</span>
<span id="cb795-8061"><a href="#cb795-8061" aria-hidden="true" tabindex="-1"></a>masskg <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fl">37.0</span> , <span class="fl">35.5</span> , <span class="fl">34.5</span> , <span class="fl">41.5</span> , <span class="fl">55.5</span> , <span class="fl">61.0</span> , <span class="fl">53.5</span> )</span>
<span id="cb795-8062"><a href="#cb795-8062" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">species=</span>sppnames , <span class="at">brain=</span>brainvolcc , <span class="at">mass=</span>masskg )</span>
<span id="cb795-8063"><a href="#cb795-8063" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8064"><a href="#cb795-8064" aria-hidden="true" tabindex="-1"></a><span class="co"># fit model with lm</span></span>
<span id="cb795-8065"><a href="#cb795-8065" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( brain <span class="sc">~</span> mass , d )</span>
<span id="cb795-8066"><a href="#cb795-8066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8067"><a href="#cb795-8067" aria-hidden="true" tabindex="-1"></a><span class="co"># compute deviance by cheating</span></span>
<span id="cb795-8068"><a href="#cb795-8068" aria-hidden="true" tabindex="-1"></a>(<span class="sc">-</span><span class="dv">2</span>) <span class="sc">*</span> <span class="fu">logLik</span>(m6<span class="fl">.1</span>)</span>
<span id="cb795-8069"><a href="#cb795-8069" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that, because there is uncertainty about the parameters, there is also uncertainty about </span></span>
<span id="cb795-8070"><a href="#cb795-8070" aria-hidden="true" tabindex="-1"></a><span class="co"># the deviance of a model. For any specific parameter values, deviance is defined exactly. </span></span>
<span id="cb795-8071"><a href="#cb795-8071" aria-hidden="true" tabindex="-1"></a><span class="co"># But since we have a posterior distribution of parameter values, there is also a posterior </span></span>
<span id="cb795-8072"><a href="#cb795-8072" aria-hidden="true" tabindex="-1"></a><span class="co"># distribution of the deviance.</span></span>
<span id="cb795-8073"><a href="#cb795-8073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8074"><a href="#cb795-8074" aria-hidden="true" tabindex="-1"></a><span class="do">## Raw calculation</span></span>
<span id="cb795-8075"><a href="#cb795-8075" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize the mass before fitting</span></span>
<span id="cb795-8076"><a href="#cb795-8076" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>mass.s <span class="ot">&lt;-</span> (d<span class="sc">$</span>mass<span class="sc">-</span><span class="fu">mean</span>(d<span class="sc">$</span>mass))<span class="sc">/</span><span class="fu">sd</span>(d<span class="sc">$</span>mass)</span>
<span id="cb795-8077"><a href="#cb795-8077" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.8</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-8078"><a href="#cb795-8078" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-8079"><a href="#cb795-8079" aria-hidden="true" tabindex="-1"></a>        brain <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-8080"><a href="#cb795-8080" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>mass.s</span>
<span id="cb795-8081"><a href="#cb795-8081" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-8082"><a href="#cb795-8082" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d , </span>
<span id="cb795-8083"><a href="#cb795-8083" aria-hidden="true" tabindex="-1"></a><span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span><span class="fu">mean</span>(d<span class="sc">$</span>brain),<span class="at">b=</span><span class="dv">0</span>,<span class="at">sigma=</span><span class="fu">sd</span>(d<span class="sc">$</span>brain)) ,</span>
<span id="cb795-8084"><a href="#cb795-8084" aria-hidden="true" tabindex="-1"></a><span class="at">method=</span><span class="st">"Nelder-Mead"</span> )</span>
<span id="cb795-8085"><a href="#cb795-8085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8086"><a href="#cb795-8086" aria-hidden="true" tabindex="-1"></a><span class="co"># extract MAP estimates</span></span>
<span id="cb795-8087"><a href="#cb795-8087" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">coef</span>(m6<span class="fl">.8</span>)</span>
<span id="cb795-8088"><a href="#cb795-8088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8089"><a href="#cb795-8089" aria-hidden="true" tabindex="-1"></a><span class="co"># compute deviance</span></span>
<span id="cb795-8090"><a href="#cb795-8090" aria-hidden="true" tabindex="-1"></a>dev <span class="ot">&lt;-</span> (<span class="sc">-</span><span class="dv">2</span>)<span class="sc">*</span><span class="fu">sum</span>( <span class="fu">dnorm</span>(</span>
<span id="cb795-8091"><a href="#cb795-8091" aria-hidden="true" tabindex="-1"></a>            d<span class="sc">$</span>brain ,</span>
<span id="cb795-8092"><a href="#cb795-8092" aria-hidden="true" tabindex="-1"></a>            <span class="at">mean=</span>theta[<span class="dv">1</span>]<span class="sc">+</span>theta[<span class="dv">2</span>]<span class="sc">*</span>d<span class="sc">$</span>mass.s ,</span>
<span id="cb795-8093"><a href="#cb795-8093" aria-hidden="true" tabindex="-1"></a>            <span class="at">sd=</span>theta[<span class="dv">3</span>] ,</span>
<span id="cb795-8094"><a href="#cb795-8094" aria-hidden="true" tabindex="-1"></a>            <span class="at">log=</span><span class="cn">TRUE</span> ) )</span>
<span id="cb795-8095"><a href="#cb795-8095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8096"><a href="#cb795-8096" aria-hidden="true" tabindex="-1"></a>dev</span>
<span id="cb795-8097"><a href="#cb795-8097" aria-hidden="true" tabindex="-1"></a><span class="co"># The same result you’d get with -2*logLik(m6.8). All that’s really required is to plug the </span></span>
<span id="cb795-8098"><a href="#cb795-8098" aria-hidden="true" tabindex="-1"></a><span class="co"># MAP estimates into the likelihood function. You compute the log-likelihood for each observation. </span></span>
<span id="cb795-8099"><a href="#cb795-8099" aria-hidden="true" tabindex="-1"></a><span class="co"># Then you add them all together. Finally, multiply the sum by −2. That yields the deviance. </span></span>
<span id="cb795-8100"><a href="#cb795-8100" aria-hidden="true" tabindex="-1"></a><span class="co"># R’s logLik function does everything except multiply by −2.</span></span>
<span id="cb795-8101"><a href="#cb795-8101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8102"><a href="#cb795-8102" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8103"><a href="#cb795-8103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8104"><a href="#cb795-8104" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8105"><a href="#cb795-8105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8106"><a href="#cb795-8106" aria-hidden="true" tabindex="-1"></a><span class="fu">### From deviance to out-of-sample</span></span>
<span id="cb795-8107"><a href="#cb795-8107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8108"><a href="#cb795-8108" aria-hidden="true" tabindex="-1"></a>When we usually have data and use it to fit a statistical model, the data comprise a *training sample*. Parameters are estimated from it, and then we can imagine using those estimates to predict outcomes in a new sample, called the *test sample*. R is going to do all of this for you. But here’s the full procedure, in outline:</span>
<span id="cb795-8109"><a href="#cb795-8109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8110"><a href="#cb795-8110" aria-hidden="true" tabindex="-1"></a>(1) Suppose there’s a training sample of size *N*.</span>
<span id="cb795-8111"><a href="#cb795-8111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8112"><a href="#cb795-8112" aria-hidden="true" tabindex="-1"></a>(2) Fit a model to the training sample, and compute the deviance on the training sample. Call this deviance D~train~.</span>
<span id="cb795-8113"><a href="#cb795-8113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8114"><a href="#cb795-8114" aria-hidden="true" tabindex="-1"></a>(3) Suppose another sample of size *N* from the same process. This is the test sample.</span>
<span id="cb795-8115"><a href="#cb795-8115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8116"><a href="#cb795-8116" aria-hidden="true" tabindex="-1"></a>(4) Compute the deviance on the test sample. This means using the MAP estimates from step (2) to compute the deviance for the data in the test sample. Call this deviance D~test~.</span>
<span id="cb795-8117"><a href="#cb795-8117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8118"><a href="#cb795-8118" aria-hidden="true" tabindex="-1"></a>The above is a thought experiment. It allows us to explore the distinction between deviance measured in and out of sample, using a simple prediction scenario.</span>
<span id="cb795-8119"><a href="#cb795-8119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8120"><a href="#cb795-8120" aria-hidden="true" tabindex="-1"></a>To visualize the results of the thought experiment, what we’ll do now is conduct the above thought experiment 10,000 times, for each of five different linear regression models. The model that generates the data is:</span>
<span id="cb795-8121"><a href="#cb795-8121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8122"><a href="#cb795-8122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-8123"><a href="#cb795-8123" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-8124"><a href="#cb795-8124" aria-hidden="true" tabindex="-1"></a>\text{y}_i &amp;\sim \text{Normal}(\mu_i, 1)<span class="sc">\\</span></span>
<span id="cb795-8125"><a href="#cb795-8125" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;\sim (0.15)\text{x}_{1,i} ~-~ (0.4)\text{x}_{2,i}</span>
<span id="cb795-8126"><a href="#cb795-8126" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-8127"><a href="#cb795-8127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8128"><a href="#cb795-8128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-8129"><a href="#cb795-8129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8130"><a href="#cb795-8130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8131"><a href="#cb795-8131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8132"><a href="#cb795-8132" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.12, eval=FALSE}</span></span>
<span id="cb795-8133"><a href="#cb795-8133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8134"><a href="#cb795-8134" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-8135"><a href="#cb795-8135" aria-hidden="true" tabindex="-1"></a><span class="do">## sim.train.test is run 10,000 (1e4) times for each of the 5 models</span></span>
<span id="cb795-8136"><a href="#cb795-8136" aria-hidden="true" tabindex="-1"></a><span class="co"># I will change to 1000 to load faster</span></span>
<span id="cb795-8137"><a href="#cb795-8137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8138"><a href="#cb795-8138" aria-hidden="true" tabindex="-1"></a><span class="do">## For N = 20</span></span>
<span id="cb795-8139"><a href="#cb795-8139" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb795-8140"><a href="#cb795-8140" aria-hidden="true" tabindex="-1"></a>kseq <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb795-8141"><a href="#cb795-8141" aria-hidden="true" tabindex="-1"></a>dev <span class="ot">&lt;-</span> <span class="fu">sapply</span>( kseq , <span class="cf">function</span>(k) {</span>
<span id="cb795-8142"><a href="#cb795-8142" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span>(k);</span>
<span id="cb795-8143"><a href="#cb795-8143" aria-hidden="true" tabindex="-1"></a>        <span class="co">#r &lt;- replicate( 1000 , sim.train.test( N=N, k=k ) ); </span></span>
<span id="cb795-8144"><a href="#cb795-8144" aria-hidden="true" tabindex="-1"></a><span class="co"># If you are Mac or Linux, you can parallelize the simulations by replacing the replicate line with:</span></span>
<span id="cb795-8145"><a href="#cb795-8145" aria-hidden="true" tabindex="-1"></a>        r <span class="ot">&lt;-</span> <span class="fu">mcreplicate</span>(<span class="dv">1000</span>, <span class="fu">sim.train.test</span>(<span class="at">N=</span>N, <span class="at">k=</span>k), <span class="at">mc.cores =</span> <span class="dv">4</span>);</span>
<span id="cb795-8146"><a href="#cb795-8146" aria-hidden="true" tabindex="-1"></a>        <span class="fu">c</span>( <span class="fu">mean</span>(r[<span class="dv">1</span>,]) , <span class="fu">mean</span>(r[<span class="dv">2</span>,]) , <span class="fu">sd</span>(r[<span class="dv">1</span>,]) , <span class="fu">sd</span>(r[<span class="dv">2</span>,]) )</span>
<span id="cb795-8147"><a href="#cb795-8147" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb795-8148"><a href="#cb795-8148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8149"><a href="#cb795-8149" aria-hidden="true" tabindex="-1"></a><span class="co"># Set mc.cores to the number of processor cores you want to use for the simulations. </span></span>
<span id="cb795-8150"><a href="#cb795-8150" aria-hidden="true" tabindex="-1"></a><span class="co"># Once the simulations complete, dev will be a 4-by-5 matrix of means and standard deviations. </span></span>
<span id="cb795-8151"><a href="#cb795-8151" aria-hidden="true" tabindex="-1"></a><span class="co"># By altering this code, you can simulate many different train-test scenarios.</span></span>
<span id="cb795-8152"><a href="#cb795-8152" aria-hidden="true" tabindex="-1"></a><span class="co"># See ?sim.train.test for additional options.</span></span>
<span id="cb795-8153"><a href="#cb795-8153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8154"><a href="#cb795-8154" aria-hidden="true" tabindex="-1"></a><span class="do">## To reproduce the plot:</span></span>
<span id="cb795-8155"><a href="#cb795-8155" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span> , dev[<span class="dv">1</span>,] , <span class="at">ylim=</span><span class="fu">c</span>( <span class="fu">min</span>(dev[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,])<span class="sc">-</span><span class="dv">5</span> , <span class="fu">max</span>(dev[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,])<span class="sc">+</span><span class="dv">10</span> ) ,</span>
<span id="cb795-8156"><a href="#cb795-8156" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">5.1</span>) , <span class="at">xlab=</span><span class="st">"number of parameters"</span> , <span class="at">ylab=</span><span class="st">"deviance"</span> ,</span>
<span id="cb795-8157"><a href="#cb795-8157" aria-hidden="true" tabindex="-1"></a>        <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-8158"><a href="#cb795-8158" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="fu">concat</span>( <span class="st">"N = "</span>,N ) )</span>
<span id="cb795-8159"><a href="#cb795-8159" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>( (<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)<span class="sc">+</span><span class="fl">0.1</span> , dev[<span class="dv">2</span>,] )</span>
<span id="cb795-8160"><a href="#cb795-8160" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> kseq ) {</span>
<span id="cb795-8161"><a href="#cb795-8161" aria-hidden="true" tabindex="-1"></a>    pts_in <span class="ot">&lt;-</span> dev[<span class="dv">1</span>,i] <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="sc">+</span><span class="dv">1</span>)<span class="sc">*</span>dev[<span class="dv">3</span>,i]</span>
<span id="cb795-8162"><a href="#cb795-8162" aria-hidden="true" tabindex="-1"></a>    pts_out <span class="ot">&lt;-</span> dev[<span class="dv">2</span>,i] <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="sc">+</span><span class="dv">1</span>)<span class="sc">*</span>dev[<span class="dv">4</span>,i]</span>
<span id="cb795-8163"><a href="#cb795-8163" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">c</span>(i,i) , pts_in , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-8164"><a href="#cb795-8164" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">c</span>(i,i)<span class="sc">+</span><span class="fl">0.1</span> , pts_out )</span>
<span id="cb795-8165"><a href="#cb795-8165" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-8166"><a href="#cb795-8166" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.8</span>, <span class="dv">55</span>, <span class="st">"in"</span>, <span class="at">col =</span> rangi2)</span>
<span id="cb795-8167"><a href="#cb795-8167" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.42</span>, <span class="dv">59</span>, <span class="st">"out"</span>)</span>
<span id="cb795-8168"><a href="#cb795-8168" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.42</span>, <span class="dv">51</span>, <span class="st">"-1SD"</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb795-8169"><a href="#cb795-8169" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.42</span>, <span class="dv">66</span>, <span class="st">"+1SD"</span>, <span class="at">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb795-8170"><a href="#cb795-8170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8171"><a href="#cb795-8171" aria-hidden="true" tabindex="-1"></a><span class="do">## For N = 100</span></span>
<span id="cb795-8172"><a href="#cb795-8172" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb795-8173"><a href="#cb795-8173" aria-hidden="true" tabindex="-1"></a>kseq <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb795-8174"><a href="#cb795-8174" aria-hidden="true" tabindex="-1"></a>dev <span class="ot">&lt;-</span> <span class="fu">sapply</span>( kseq , <span class="cf">function</span>(k) {</span>
<span id="cb795-8175"><a href="#cb795-8175" aria-hidden="true" tabindex="-1"></a>        <span class="fu">print</span>(k);</span>
<span id="cb795-8176"><a href="#cb795-8176" aria-hidden="true" tabindex="-1"></a>        r <span class="ot">&lt;-</span> <span class="fu">mcreplicate</span>(<span class="dv">1000</span>, <span class="fu">sim.train.test</span>(<span class="at">N=</span>N, <span class="at">k=</span>k), <span class="at">mc.cores =</span> <span class="dv">4</span>);</span>
<span id="cb795-8177"><a href="#cb795-8177" aria-hidden="true" tabindex="-1"></a>        <span class="fu">c</span>( <span class="fu">mean</span>(r[<span class="dv">1</span>,]) , <span class="fu">mean</span>(r[<span class="dv">2</span>,]) , <span class="fu">sd</span>(r[<span class="dv">1</span>,]) , <span class="fu">sd</span>(r[<span class="dv">2</span>,]) )</span>
<span id="cb795-8178"><a href="#cb795-8178" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb795-8179"><a href="#cb795-8179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8180"><a href="#cb795-8180" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span> , dev[<span class="dv">1</span>,] , <span class="at">ylim=</span><span class="fu">c</span>( <span class="fu">min</span>(dev[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,])<span class="sc">-</span><span class="dv">10</span> , <span class="fu">max</span>(dev[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,])<span class="sc">+</span><span class="dv">12</span> ) ,</span>
<span id="cb795-8181"><a href="#cb795-8181" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">5.1</span>) , <span class="at">xlab=</span><span class="st">"number of parameters"</span> , <span class="at">ylab=</span><span class="st">"deviance"</span> ,</span>
<span id="cb795-8182"><a href="#cb795-8182" aria-hidden="true" tabindex="-1"></a>        <span class="at">pch=</span><span class="dv">16</span> , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-8183"><a href="#cb795-8183" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="fu">concat</span>( <span class="st">"N = "</span>,N ) )</span>
<span id="cb795-8184"><a href="#cb795-8184" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>( (<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)<span class="sc">+</span><span class="fl">0.1</span> , dev[<span class="dv">2</span>,] )</span>
<span id="cb795-8185"><a href="#cb795-8185" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> kseq ) {</span>
<span id="cb795-8186"><a href="#cb795-8186" aria-hidden="true" tabindex="-1"></a>    pts_in <span class="ot">&lt;-</span> dev[<span class="dv">1</span>,i] <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="sc">+</span><span class="dv">1</span>)<span class="sc">*</span>dev[<span class="dv">3</span>,i]</span>
<span id="cb795-8187"><a href="#cb795-8187" aria-hidden="true" tabindex="-1"></a>    pts_out <span class="ot">&lt;-</span> dev[<span class="dv">2</span>,i] <span class="sc">+</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="sc">+</span><span class="dv">1</span>)<span class="sc">*</span>dev[<span class="dv">4</span>,i]</span>
<span id="cb795-8188"><a href="#cb795-8188" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">c</span>(i,i) , pts_in , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-8189"><a href="#cb795-8189" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( <span class="fu">c</span>(i,i)<span class="sc">+</span><span class="fl">0.1</span> , pts_out )</span>
<span id="cb795-8190"><a href="#cb795-8190" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-8191"><a href="#cb795-8191" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.8</span>, <span class="fl">280.1</span>, <span class="st">"in"</span>, <span class="at">col =</span> rangi2)</span>
<span id="cb795-8192"><a href="#cb795-8192" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.42</span>, <span class="dv">284</span>, <span class="st">"out"</span>)</span>
<span id="cb795-8193"><a href="#cb795-8193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8194"><a href="#cb795-8194" aria-hidden="true" tabindex="-1"></a><span class="co"># Deviance in and out of sample. In each plot, models with different numbers of predictor variables </span></span>
<span id="cb795-8195"><a href="#cb795-8195" aria-hidden="true" tabindex="-1"></a><span class="co"># are shown on the horizontal axis. Deviance across 10,000 simulations is shown on the vertical. </span></span>
<span id="cb795-8196"><a href="#cb795-8196" aria-hidden="true" tabindex="-1"></a><span class="co"># Blue shows deviance in-sample, the training data. Black shows deviance out-of-sample, the test data. </span></span>
<span id="cb795-8197"><a href="#cb795-8197" aria-hidden="true" tabindex="-1"></a><span class="co"># Points show means, and the line segments show ±1 standard deviation.</span></span>
<span id="cb795-8198"><a href="#cb795-8198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8199"><a href="#cb795-8199" aria-hidden="true" tabindex="-1"></a><span class="co"># Moving left to right with increasing numbers of parameters, the average deviance declines. </span></span>
<span id="cb795-8200"><a href="#cb795-8200" aria-hidden="true" tabindex="-1"></a><span class="co"># A smaller deviance means a better fit. So this decline with increasing model complexity.</span></span>
<span id="cb795-8201"><a href="#cb795-8201" aria-hidden="true" tabindex="-1"></a><span class="co"># While deviance keeps improving (declining) in the training sample, it gets worse on average in </span></span>
<span id="cb795-8202"><a href="#cb795-8202" aria-hidden="true" tabindex="-1"></a><span class="co"># the test sample.</span></span>
<span id="cb795-8203"><a href="#cb795-8203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8204"><a href="#cb795-8204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8205"><a href="#cb795-8205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8206"><a href="#cb795-8206" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8207"><a href="#cb795-8207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8208"><a href="#cb795-8208" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regularization</span></span>
<span id="cb795-8209"><a href="#cb795-8209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8210"><a href="#cb795-8210" aria-hidden="true" tabindex="-1"></a>The root of overfitting is a model’s tendency to get overexcited by the training sample. One way to prevent a model from getting too excited by the training sample is to give it a skeptical prior. By “skeptical,” I mean a prior that slows the rate of learning from the sample. The most common skeptical prior is a ***regularizing prior***, which is applied to a beta-coefficient, a “slope” in a linear model.</span>
<span id="cb795-8211"><a href="#cb795-8211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8212"><a href="#cb795-8212" aria-hidden="true" tabindex="-1"></a>The regularizing prior, when *tuned properly*, reduces overfitting while still allowing the model to learn the regular features of a sample. If the prior is too skeptical, however, then regular features will be missed, resulting in underfitting. For example, consider this Gaussian model:</span>
<span id="cb795-8213"><a href="#cb795-8213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8214"><a href="#cb795-8214" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-8215"><a href="#cb795-8215" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-8216"><a href="#cb795-8216" aria-hidden="true" tabindex="-1"></a>\text{y}_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-8217"><a href="#cb795-8217" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta \text{x}_i<span class="sc">\\</span></span>
<span id="cb795-8218"><a href="#cb795-8218" aria-hidden="true" tabindex="-1"></a>\alpha &amp;\sim \text{Normal}(0, 100)<span class="sc">\\</span></span>
<span id="cb795-8219"><a href="#cb795-8219" aria-hidden="true" tabindex="-1"></a>\beta &amp;\sim \text{Normal}(0, 1)<span class="sc">\\</span></span>
<span id="cb795-8220"><a href="#cb795-8220" aria-hidden="true" tabindex="-1"></a>\sigma &amp;\sim \text{Uniform}(0, 10)</span>
<span id="cb795-8221"><a href="#cb795-8221" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-8222"><a href="#cb795-8222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8223"><a href="#cb795-8223" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-8224"><a href="#cb795-8224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8225"><a href="#cb795-8225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8226"><a href="#cb795-8226" aria-hidden="true" tabindex="-1"></a>Assume, as is good practice, that the predictor x is standardized so that its standard deviation is 1 and its mean is zero. Then the prior on $\alpha$ is a nearly flat prior that has no practical effect on inference. </span>
<span id="cb795-8227"><a href="#cb795-8227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8228"><a href="#cb795-8228" aria-hidden="true" tabindex="-1"></a>But the prior on $\beta$ is narrower and is meant to regularize. The prior $\beta$ ∼ Normal(0, 1) says that, before seeing the data, the machine should be very skeptical of values above 2 and below −2, as a Gaussian prior with a standard deviation of 1 assigns only 5% plausibility to values above and below 2 standard deviations. Because the predictor variable x is standardized, you can interpret this as meaning that a change of 1 standard deviation in x is very unlikely to produce 2 units of change in the outcome.</span>
<span id="cb795-8229"><a href="#cb795-8229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8230"><a href="#cb795-8230" aria-hidden="true" tabindex="-1"></a><span class="in">```{r f6.8}</span></span>
<span id="cb795-8231"><a href="#cb795-8231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8232"><a href="#cb795-8232" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span> <span class="fl">3.5</span>, </span>
<span id="cb795-8233"><a href="#cb795-8233" aria-hidden="true" tabindex="-1"></a>               <span class="at">to   =</span> <span class="fl">3.5</span>, </span>
<span id="cb795-8234"><a href="#cb795-8234" aria-hidden="true" tabindex="-1"></a>               <span class="at">by   =</span> .<span class="dv">01</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb795-8235"><a href="#cb795-8235" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-8236"><a href="#cb795-8236" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">ymin =</span> <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-8237"><a href="#cb795-8237" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">0.2</span>)), </span>
<span id="cb795-8238"><a href="#cb795-8238" aria-hidden="true" tabindex="-1"></a>               <span class="at">fill =</span> <span class="st">"transparent"</span>, <span class="at">col =</span> <span class="st">"black"</span>,<span class="at">linetype =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-8239"><a href="#cb795-8239" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">0.5</span>)), </span>
<span id="cb795-8240"><a href="#cb795-8240" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"transparent"</span>, <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">linetype =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-8241"><a href="#cb795-8241" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymax =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)), </span>
<span id="cb795-8242"><a href="#cb795-8242" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">"transparent"</span>, <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-8243"><a href="#cb795-8243" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">2.2</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-8244"><a href="#cb795-8244" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"parameter value"</span>) <span class="sc">+</span></span>
<span id="cb795-8245"><a href="#cb795-8245" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb795-8246"><a href="#cb795-8246" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">by =</span> <span class="dv">1</span>), <span class="at">expand =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb795-8247"><a href="#cb795-8247" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb795-8248"><a href="#cb795-8248" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">panel.grid.major =</span> <span class="fu">element_blank</span>(), <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>())</span>
<span id="cb795-8249"><a href="#cb795-8249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8250"><a href="#cb795-8250" aria-hidden="true" tabindex="-1"></a><span class="co"># Regularizing priors, weak and strong. Three Gaussian priors of varying standard deviation. </span></span>
<span id="cb795-8251"><a href="#cb795-8251" aria-hidden="true" tabindex="-1"></a><span class="co"># These priors reduce overfitting, but with different strength. </span></span>
<span id="cb795-8252"><a href="#cb795-8252" aria-hidden="true" tabindex="-1"></a><span class="co"># Dashed: Normal(0, 1). Thin solid: Normal(0, 0.5). Thick solid: Normal(0, 0.2).</span></span>
<span id="cb795-8253"><a href="#cb795-8253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8254"><a href="#cb795-8254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8255"><a href="#cb795-8255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8256"><a href="#cb795-8256" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8257"><a href="#cb795-8257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8258"><a href="#cb795-8258" aria-hidden="true" tabindex="-1"></a>How strong or weak these skeptical priors will be in practice depends upon the data and model. So let’s explore a train-test example again, but this time we’ll use the regularizing priors. </span>
<span id="cb795-8259"><a href="#cb795-8259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8260"><a href="#cb795-8260" aria-hidden="true" tabindex="-1"></a><span class="in">```{r f6.9, eval=FALSE}</span></span>
<span id="cb795-8261"><a href="#cb795-8261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8262"><a href="#cb795-8262" aria-hidden="true" tabindex="-1"></a><span class="do">## Use Ajkurz's codes</span></span>
<span id="cb795-8263"><a href="#cb795-8263" aria-hidden="true" tabindex="-1"></a>n       <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb795-8264"><a href="#cb795-8264" aria-hidden="true" tabindex="-1"></a>kseq    <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb795-8265"><a href="#cb795-8265" aria-hidden="true" tabindex="-1"></a><span class="co"># I've reduced this number by one order of magnitude to reduce computation time</span></span>
<span id="cb795-8266"><a href="#cb795-8266" aria-hidden="true" tabindex="-1"></a>n_sim   <span class="ot">&lt;-</span> <span class="fl">1e3</span></span>
<span id="cb795-8267"><a href="#cb795-8267" aria-hidden="true" tabindex="-1"></a>n_cores <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb795-8268"><a href="#cb795-8268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8269"><a href="#cb795-8269" aria-hidden="true" tabindex="-1"></a><span class="co"># here's our dev object based on `N &lt;- 20`</span></span>
<span id="cb795-8270"><a href="#cb795-8270" aria-hidden="true" tabindex="-1"></a>dev_20 <span class="ot">&lt;-</span></span>
<span id="cb795-8271"><a href="#cb795-8271" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(kseq, <span class="cf">function</span>(k) {</span>
<span id="cb795-8272"><a href="#cb795-8272" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(k);</span>
<span id="cb795-8273"><a href="#cb795-8273" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> <span class="fu">mcreplicate</span>(n_sim, <span class="fu">sim.train.test</span>(<span class="at">N =</span> n, <span class="at">k =</span> k),</span>
<span id="cb795-8274"><a href="#cb795-8274" aria-hidden="true" tabindex="-1"></a>                     <span class="at">mc.cores =</span> n_cores);</span>
<span id="cb795-8275"><a href="#cb795-8275" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="fu">mean</span>(r[<span class="dv">1</span>, ]), <span class="fu">mean</span>(r[<span class="dv">2</span>, ]), <span class="fu">sd</span>(r[<span class="dv">1</span>, ]), <span class="fu">sd</span>(r[<span class="dv">2</span>, ]))</span>
<span id="cb795-8276"><a href="#cb795-8276" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb795-8277"><a href="#cb795-8277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8278"><a href="#cb795-8278" aria-hidden="true" tabindex="-1"></a><span class="co"># here's our dev object based on N &lt;- 100</span></span>
<span id="cb795-8279"><a href="#cb795-8279" aria-hidden="true" tabindex="-1"></a>n       <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb795-8280"><a href="#cb795-8280" aria-hidden="true" tabindex="-1"></a>dev_100 <span class="ot">&lt;-</span> </span>
<span id="cb795-8281"><a href="#cb795-8281" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(kseq, <span class="cf">function</span>(k) {</span>
<span id="cb795-8282"><a href="#cb795-8282" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(k);</span>
<span id="cb795-8283"><a href="#cb795-8283" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> <span class="fu">mcreplicate</span>(n_sim, <span class="fu">sim.train.test</span>(<span class="at">N =</span> n, <span class="at">k =</span> k), </span>
<span id="cb795-8284"><a href="#cb795-8284" aria-hidden="true" tabindex="-1"></a>                     <span class="at">mc.cores =</span> n_cores);</span>
<span id="cb795-8285"><a href="#cb795-8285" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="fu">mean</span>(r[<span class="dv">1</span>, ]), <span class="fu">mean</span>(r[<span class="dv">2</span>, ]), <span class="fu">sd</span>(r[<span class="dv">1</span>, ]), <span class="fu">sd</span>(r[<span class="dv">2</span>, ]))</span>
<span id="cb795-8286"><a href="#cb795-8286" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb795-8287"><a href="#cb795-8287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8288"><a href="#cb795-8288" aria-hidden="true" tabindex="-1"></a>dev_tibble <span class="ot">&lt;-</span></span>
<span id="cb795-8289"><a href="#cb795-8289" aria-hidden="true" tabindex="-1"></a>  dev_20 <span class="sc">%&gt;%</span> </span>
<span id="cb795-8290"><a href="#cb795-8290" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb795-8291"><a href="#cb795-8291" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb795-8292"><a href="#cb795-8292" aria-hidden="true" tabindex="-1"></a>    dev_100 <span class="sc">%&gt;%</span></span>
<span id="cb795-8293"><a href="#cb795-8293" aria-hidden="true" tabindex="-1"></a>      <span class="fu">as_tibble</span>()</span>
<span id="cb795-8294"><a href="#cb795-8294" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8295"><a href="#cb795-8295" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n         =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"n = 20"</span>, <span class="st">"n = 100"</span>), <span class="at">each =</span> <span class="dv">4</span>),</span>
<span id="cb795-8296"><a href="#cb795-8296" aria-hidden="true" tabindex="-1"></a>         <span class="at">statistic =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"mean"</span>, <span class="st">"sd"</span>), <span class="at">each =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="fu">rep</span>(., <span class="at">times =</span> <span class="dv">2</span>),</span>
<span id="cb795-8297"><a href="#cb795-8297" aria-hidden="true" tabindex="-1"></a>         <span class="at">sample    =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"in"</span>, <span class="st">"out"</span>), <span class="at">times =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="fu">rep</span>(., <span class="at">times =</span> <span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8298"><a href="#cb795-8298" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(n_par, value, <span class="sc">-</span>n, <span class="sc">-</span>statistic, <span class="sc">-</span>sample) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8299"><a href="#cb795-8299" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spread</span>(<span class="at">key =</span> statistic, <span class="at">value =</span> value) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8300"><a href="#cb795-8300" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n     =</span> <span class="fu">factor</span>(n, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"n = 20"</span>, <span class="st">"n = 100"</span>)),</span>
<span id="cb795-8301"><a href="#cb795-8301" aria-hidden="true" tabindex="-1"></a>         <span class="at">n_par =</span> <span class="fu">str_remove</span>(n_par, <span class="st">"V"</span>) <span class="sc">%&gt;%</span> <span class="fu">as.double</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8302"><a href="#cb795-8302" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n_par =</span> <span class="fu">ifelse</span>(sample <span class="sc">==</span> <span class="st">"in"</span>, n_par <span class="sc">-</span> .<span class="dv">075</span>, n_par <span class="sc">+</span> .<span class="dv">075</span>))</span>
<span id="cb795-8303"><a href="#cb795-8303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8304"><a href="#cb795-8304" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dev_tibble)</span>
<span id="cb795-8305"><a href="#cb795-8305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8306"><a href="#cb795-8306" aria-hidden="true" tabindex="-1"></a>make_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(n, b_sigma){</span>
<span id="cb795-8307"><a href="#cb795-8307" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(kseq, <span class="cf">function</span>(k) {</span>
<span id="cb795-8308"><a href="#cb795-8308" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(k);</span>
<span id="cb795-8309"><a href="#cb795-8309" aria-hidden="true" tabindex="-1"></a>    <span class="co"># this is an augmented line of code</span></span>
<span id="cb795-8310"><a href="#cb795-8310" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> <span class="fu">mcreplicate</span>(n_sim, <span class="fu">sim.train.test</span>(<span class="at">N =</span> n, <span class="at">k =</span> k, <span class="at">b_sigma =</span> b_sigma),</span>
<span id="cb795-8311"><a href="#cb795-8311" aria-hidden="true" tabindex="-1"></a>                     <span class="at">mc.cores =</span> n_cores);</span>
<span id="cb795-8312"><a href="#cb795-8312" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="fu">mean</span>(r[<span class="dv">1</span>, ]), <span class="fu">mean</span>(r[<span class="dv">2</span>, ]), <span class="fu">sd</span>(r[<span class="dv">1</span>, ]), <span class="fu">sd</span>(r[<span class="dv">2</span>, ])) }) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8313"><a href="#cb795-8313" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-8314"><a href="#cb795-8314" aria-hidden="true" tabindex="-1"></a>    <span class="co"># this is a new line of code</span></span>
<span id="cb795-8315"><a href="#cb795-8315" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>()</span>
<span id="cb795-8316"><a href="#cb795-8316" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-8317"><a href="#cb795-8317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8318"><a href="#cb795-8318" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span></span>
<span id="cb795-8319"><a href="#cb795-8319" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">n       =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">100</span>), <span class="at">each =</span> <span class="dv">3</span>),</span>
<span id="cb795-8320"><a href="#cb795-8320" aria-hidden="true" tabindex="-1"></a>         <span class="at">b_sigma =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">1</span>, .<span class="dv">5</span>, .<span class="dv">2</span>), <span class="at">times =</span> <span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8321"><a href="#cb795-8321" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sim     =</span> <span class="fu">map2</span>(n, b_sigma, make_sim)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8322"><a href="#cb795-8322" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>()</span>
<span id="cb795-8323"><a href="#cb795-8323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8324"><a href="#cb795-8324" aria-hidden="true" tabindex="-1"></a><span class="co"># wrangle the simulation data</span></span>
<span id="cb795-8325"><a href="#cb795-8325" aria-hidden="true" tabindex="-1"></a>s <span class="sc">%&gt;%</span> </span>
<span id="cb795-8326"><a href="#cb795-8326" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">statistic =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"mean"</span>, <span class="st">"sd"</span>), <span class="at">each =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="fu">rep</span>(., <span class="at">times =</span> <span class="dv">3</span> <span class="sc">*</span> <span class="dv">2</span>),</span>
<span id="cb795-8327"><a href="#cb795-8327" aria-hidden="true" tabindex="-1"></a>         <span class="at">sample    =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">"in"</span>, <span class="st">"out"</span>), <span class="at">times =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span> <span class="fu">rep</span>(., <span class="at">times =</span> <span class="dv">3</span> <span class="sc">*</span> <span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8328"><a href="#cb795-8328" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(n_par, value, <span class="sc">-</span>n, <span class="sc">-</span>b_sigma, <span class="sc">-</span>statistic, <span class="sc">-</span>sample) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8329"><a href="#cb795-8329" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spread</span>(<span class="at">key =</span> statistic, <span class="at">value =</span> value) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8330"><a href="#cb795-8330" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n     =</span> <span class="fu">str_c</span>(<span class="st">"n = "</span>, n) <span class="sc">%&gt;%</span> <span class="fu">factor</span>(., <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"n = 20"</span>, <span class="st">"n = 100"</span>)),</span>
<span id="cb795-8331"><a href="#cb795-8331" aria-hidden="true" tabindex="-1"></a>         <span class="at">n_par =</span> <span class="fu">str_remove</span>(n_par, <span class="st">"V"</span>) <span class="sc">%&gt;%</span> <span class="fu">as.double</span>())  <span class="sc">%&gt;%</span> </span>
<span id="cb795-8332"><a href="#cb795-8332" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-8333"><a href="#cb795-8333" aria-hidden="true" tabindex="-1"></a>  <span class="co"># now plot</span></span>
<span id="cb795-8334"><a href="#cb795-8334" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> n_par, <span class="at">y =</span> mean,</span>
<span id="cb795-8335"><a href="#cb795-8335" aria-hidden="true" tabindex="-1"></a>             <span class="at">group =</span> <span class="fu">interaction</span>(sample, b_sigma))) <span class="sc">+</span></span>
<span id="cb795-8336"><a href="#cb795-8336" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">color =</span> sample, <span class="at">size =</span> b_sigma <span class="sc">%&gt;%</span> <span class="fu">as.character</span>())) <span class="sc">+</span></span>
<span id="cb795-8337"><a href="#cb795-8337" aria-hidden="true" tabindex="-1"></a>  <span class="co"># this function contains the data from the previous simulation</span></span>
<span id="cb795-8338"><a href="#cb795-8338" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> dev_tibble, </span>
<span id="cb795-8339"><a href="#cb795-8339" aria-hidden="true" tabindex="-1"></a>             <span class="fu">aes</span>(<span class="at">group =</span> sample, <span class="at">fill =</span> sample),</span>
<span id="cb795-8340"><a href="#cb795-8340" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">shape =</span> <span class="dv">21</span>, <span class="at">size =</span> <span class="fl">2.5</span>, <span class="at">stroke =</span> .<span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-8341"><a href="#cb795-8341" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"slateblue"</span>, <span class="st">"black"</span>)) <span class="sc">+</span></span>
<span id="cb795-8342"><a href="#cb795-8342" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"slateblue"</span>, <span class="st">"black"</span>)) <span class="sc">+</span></span>
<span id="cb795-8343"><a href="#cb795-8343" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_size_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">1</span>, .<span class="dv">5</span>, .<span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb795-8344"><a href="#cb795-8344" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"number of parameters"</span>,</span>
<span id="cb795-8345"><a href="#cb795-8345" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"deviance"</span>) <span class="sc">+</span></span>
<span id="cb795-8346"><a href="#cb795-8346" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb795-8347"><a href="#cb795-8347" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">text             =</span> <span class="fu">element_text</span>(<span class="at">family =</span> <span class="st">"serif"</span>),</span>
<span id="cb795-8348"><a href="#cb795-8348" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position  =</span> <span class="st">"none"</span>,</span>
<span id="cb795-8349"><a href="#cb795-8349" aria-hidden="true" tabindex="-1"></a>        <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="fu">alpha</span>(<span class="st">"purple"</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>), <span class="at">color =</span> <span class="st">"white"</span>),</span>
<span id="cb795-8350"><a href="#cb795-8350" aria-hidden="true" tabindex="-1"></a>        <span class="at">panel.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="fu">alpha</span>(<span class="st">"white"</span>, <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>))) <span class="sc">+</span></span>
<span id="cb795-8351"><a href="#cb795-8351" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>n, <span class="at">scale =</span> <span class="st">"free_y"</span>)</span>
<span id="cb795-8352"><a href="#cb795-8352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8353"><a href="#cb795-8353" aria-hidden="true" tabindex="-1"></a><span class="co"># Regularizing priors and out-of-sample deviance. The points in both plots are the same as 6.12. </span></span>
<span id="cb795-8354"><a href="#cb795-8354" aria-hidden="true" tabindex="-1"></a><span class="co"># The lines show training (blue) and testing (black) deviance for the three regularizing priors in f6.8. </span></span>
<span id="cb795-8355"><a href="#cb795-8355" aria-hidden="true" tabindex="-1"></a><span class="co"># Thin solid: Each beta-coefficient is given a Normal(0, 1) prior. </span></span>
<span id="cb795-8356"><a href="#cb795-8356" aria-hidden="true" tabindex="-1"></a><span class="co"># Thick solid: Normal(0, 0.5). </span></span>
<span id="cb795-8357"><a href="#cb795-8357" aria-hidden="true" tabindex="-1"></a><span class="co"># Bold solid: Normal(0, 0.2).</span></span>
<span id="cb795-8358"><a href="#cb795-8358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8359"><a href="#cb795-8359" aria-hidden="true" tabindex="-1"></a><span class="do">## For left-hand plot</span></span>
<span id="cb795-8360"><a href="#cb795-8360" aria-hidden="true" tabindex="-1"></a><span class="co"># The training deviance always increases—gets worse—with tighter priors. The thick blue trend </span></span>
<span id="cb795-8361"><a href="#cb795-8361" aria-hidden="true" tabindex="-1"></a><span class="co"># is substantially larger than the others, and this is because the skeptical prior prevents </span></span>
<span id="cb795-8362"><a href="#cb795-8362" aria-hidden="true" tabindex="-1"></a><span class="co"># the model from adapting completely to the sample. But the test deviances, out-of-sample, </span></span>
<span id="cb795-8363"><a href="#cb795-8363" aria-hidden="true" tabindex="-1"></a><span class="co"># improve (get smaller) with the tighter priors. The model with three parameters is still the </span></span>
<span id="cb795-8364"><a href="#cb795-8364" aria-hidden="true" tabindex="-1"></a><span class="co"># best model out-of-sample, and the regularizing priors have little impact on its deviance.</span></span>
<span id="cb795-8365"><a href="#cb795-8365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8366"><a href="#cb795-8366" aria-hidden="true" tabindex="-1"></a><span class="co"># But also notice that as the prior gets more skeptical, the harm done by an overly complex model </span></span>
<span id="cb795-8367"><a href="#cb795-8367" aria-hidden="true" tabindex="-1"></a><span class="co"># is greatly reduced. For the Normal(0, 0.2) prior (thick line), the models with 4 and 5 parameters </span></span>
<span id="cb795-8368"><a href="#cb795-8368" aria-hidden="true" tabindex="-1"></a><span class="co"># are barely worse than the correct model with 3 parameters. If you can tune the regularizing prior </span></span>
<span id="cb795-8369"><a href="#cb795-8369" aria-hidden="true" tabindex="-1"></a><span class="co"># right, then overfitting can be greatly reduced.</span></span>
<span id="cb795-8370"><a href="#cb795-8370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8371"><a href="#cb795-8371" aria-hidden="true" tabindex="-1"></a><span class="do">## For right hand plot</span></span>
<span id="cb795-8372"><a href="#cb795-8372" aria-hidden="true" tabindex="-1"></a><span class="co"># The priors have much less of an effect here, because there is so much more evidence. </span></span>
<span id="cb795-8373"><a href="#cb795-8373" aria-hidden="true" tabindex="-1"></a><span class="co"># The priors do help. But overfitting was less of a concern to begin with, and there is </span></span>
<span id="cb795-8374"><a href="#cb795-8374" aria-hidden="true" tabindex="-1"></a><span class="co"># enough information in the data to overwhelm even the Normal(0, 0.2) prior (thick line).</span></span>
<span id="cb795-8375"><a href="#cb795-8375" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8376"><a href="#cb795-8376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8377"><a href="#cb795-8377" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8378"><a href="#cb795-8378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8379"><a href="#cb795-8379" aria-hidden="true" tabindex="-1"></a>Regularizing priors are great, because they reduce overfitting. But if they are too skeptical, they prevent the model from learning from the data. If you have enough data, you can split into “train” and “test” samples and then try different priors and select the one that provides the smallest deviance on the test sample. That is the essence of cross-validation, a common technique for reducing overfitting. But if you need to use all of the data to train the model, tuning the prior may not be so easy. </span>
<span id="cb795-8380"><a href="#cb795-8380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8381"><a href="#cb795-8381" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8382"><a href="#cb795-8382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8383"><a href="#cb795-8383" aria-hidden="true" tabindex="-1"></a><span class="fu">## Information criteria</span></span>
<span id="cb795-8384"><a href="#cb795-8384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8385"><a href="#cb795-8385" aria-hidden="true" tabindex="-1"></a>We’ve used simulations in which a model is fit to one sample, the training sample, and then used to predict a second sample of the same size, the testing sample. Let’s look at one of those thought experiments again, but now annotated with the difference between the training deviance (in-sample) and the testing deviance (out-of-sample).</span>
<span id="cb795-8386"><a href="#cb795-8386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8387"><a href="#cb795-8387" aria-hidden="true" tabindex="-1"></a><span class="in">```{r f6.10, eval=FALSE}</span></span>
<span id="cb795-8388"><a href="#cb795-8388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8389"><a href="#cb795-8389" aria-hidden="true" tabindex="-1"></a><span class="do">## Use ajkurz's codes</span></span>
<span id="cb795-8390"><a href="#cb795-8390" aria-hidden="true" tabindex="-1"></a><span class="co"># The data from our initial simulation isn’t formatted well to plot Figure 6.10. </span></span>
<span id="cb795-8391"><a href="#cb795-8391" aria-hidden="true" tabindex="-1"></a><span class="co"># We’ll have to wrangle a little.</span></span>
<span id="cb795-8392"><a href="#cb795-8392" aria-hidden="true" tabindex="-1"></a>dev_tibble1 <span class="ot">&lt;-</span> dev_tibble[, <span class="sc">!</span><span class="fu">names</span>(dev_tibble) <span class="sc">%in%</span> <span class="st">"sd"</span>]</span>
<span id="cb795-8393"><a href="#cb795-8393" aria-hidden="true" tabindex="-1"></a><span class="co"># He used select() to remove sd column but the function is not working for me</span></span>
<span id="cb795-8394"><a href="#cb795-8394" aria-hidden="true" tabindex="-1"></a><span class="co"># So, I use !name instead of select(-sd)</span></span>
<span id="cb795-8395"><a href="#cb795-8395" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb795-8396"><a href="#cb795-8396" aria-hidden="true" tabindex="-1"></a>  dev_tibble2 <span class="ot">&lt;-</span></span>
<span id="cb795-8397"><a href="#cb795-8397" aria-hidden="true" tabindex="-1"></a>    dev_tibble1 <span class="sc">%&gt;%</span> </span>
<span id="cb795-8398"><a href="#cb795-8398" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">n_par  =</span> <span class="fu">ifelse</span>(sample <span class="sc">==</span> <span class="st">"in"</span>, n_par <span class="sc">+</span> <span class="fl">0.075</span>, n_par <span class="sc">-</span> <span class="fl">0.075</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8399"><a href="#cb795-8399" aria-hidden="true" tabindex="-1"></a>    <span class="fu">spread</span>(<span class="at">key =</span> sample, <span class="at">value =</span> mean) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8400"><a href="#cb795-8400" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">height =</span> (out <span class="sc">-</span> <span class="st">`</span><span class="at">in</span><span class="st">`</span>) <span class="sc">%&gt;%</span> <span class="fu">round</span>(<span class="at">digits =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span> <span class="fu">as.character</span>(),</span>
<span id="cb795-8401"><a href="#cb795-8401" aria-hidden="true" tabindex="-1"></a>           <span class="at">dash   =</span> <span class="st">`</span><span class="at">in</span><span class="st">`</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> n_par)</span>
<span id="cb795-8402"><a href="#cb795-8402" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-8403"><a href="#cb795-8403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8404"><a href="#cb795-8404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8405"><a href="#cb795-8405" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb795-8406"><a href="#cb795-8406" aria-hidden="true" tabindex="-1"></a>dev_tibble2  <span class="sc">%&gt;%</span> </span>
<span id="cb795-8407"><a href="#cb795-8407" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> n_par)) <span class="sc">+</span></span>
<span id="cb795-8408"><a href="#cb795-8408" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> dash),</span>
<span id="cb795-8409"><a href="#cb795-8409" aria-hidden="true" tabindex="-1"></a>            <span class="at">linetype =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">5</span>]) <span class="sc">+</span></span>
<span id="cb795-8410"><a href="#cb795-8410" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="st">`</span><span class="at">in</span><span class="st">`</span>),</span>
<span id="cb795-8411"><a href="#cb795-8411" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">7</span>], <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-8412"><a href="#cb795-8412" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> out),</span>
<span id="cb795-8413"><a href="#cb795-8413" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">5</span>], <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb795-8414"><a href="#cb795-8414" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">x =</span> n_par <span class="sc">+</span> .<span class="dv">15</span>,</span>
<span id="cb795-8415"><a href="#cb795-8415" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ymin =</span> <span class="st">`</span><span class="at">in</span><span class="st">`</span>, <span class="at">ymax =</span> out),</span>
<span id="cb795-8416"><a href="#cb795-8416" aria-hidden="true" tabindex="-1"></a>                <span class="at">width =</span> .<span class="dv">1</span>, <span class="at">color =</span> <span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">6</span>]) <span class="sc">+</span></span>
<span id="cb795-8417"><a href="#cb795-8417" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x =</span> n_par <span class="sc">+</span> .<span class="dv">4</span>,</span>
<span id="cb795-8418"><a href="#cb795-8418" aria-hidden="true" tabindex="-1"></a>                <span class="at">y =</span> (out <span class="sc">+</span> <span class="st">`</span><span class="at">in</span><span class="st">`</span>) <span class="sc">/</span> <span class="dv">2</span>,</span>
<span id="cb795-8419"><a href="#cb795-8419" aria-hidden="true" tabindex="-1"></a>                <span class="at">label =</span> height),</span>
<span id="cb795-8420"><a href="#cb795-8420" aria-hidden="true" tabindex="-1"></a>            <span class="at">family =</span> <span class="st">"Courier"</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">color =</span> <span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">6</span>]) <span class="sc">+</span></span>
<span id="cb795-8421"><a href="#cb795-8421" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"number of parameters"</span>,</span>
<span id="cb795-8422"><a href="#cb795-8422" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"deviance"</span>) <span class="sc">+</span></span>
<span id="cb795-8423"><a href="#cb795-8423" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb795-8424"><a href="#cb795-8424" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">text             =</span> <span class="fu">element_text</span>(<span class="at">family =</span> <span class="st">"Courier"</span>),</span>
<span id="cb795-8425"><a href="#cb795-8425" aria-hidden="true" tabindex="-1"></a>        <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="fu">alpha</span>(<span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">1</span>], <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>), <span class="at">color =</span> <span class="st">"white"</span>),</span>
<span id="cb795-8426"><a href="#cb795-8426" aria-hidden="true" tabindex="-1"></a>        <span class="at">panel.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="fu">alpha</span>(<span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>))) <span class="sc">+</span></span>
<span id="cb795-8427"><a href="#cb795-8427" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>n, <span class="at">scale =</span> <span class="st">"free_y"</span>)</span>
<span id="cb795-8428"><a href="#cb795-8428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8429"><a href="#cb795-8429" aria-hidden="true" tabindex="-1"></a><span class="co"># Deviance in (dark red) and out (red) of sample, using flat priors. The vertical segments </span></span>
<span id="cb795-8430"><a href="#cb795-8430" aria-hidden="true" tabindex="-1"></a><span class="co"># measure the distance between each pair of deviances. For both N = 20 and N = 100, this distance </span></span>
<span id="cb795-8431"><a href="#cb795-8431" aria-hidden="true" tabindex="-1"></a><span class="co"># is approximately twice the number of parameters. The dashed lines show exactly the deviance </span></span>
<span id="cb795-8432"><a href="#cb795-8432" aria-hidden="true" tabindex="-1"></a><span class="co"># in-sample (training) plus twice the number of parameters on the horizontal axis. </span></span>
<span id="cb795-8433"><a href="#cb795-8433" aria-hidden="true" tabindex="-1"></a><span class="co"># These lines therefore show AIC for each model, an approximation of the out-of-sample deviance.</span></span>
<span id="cb795-8434"><a href="#cb795-8434" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb795-8435"><a href="#cb795-8435" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8436"><a href="#cb795-8436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8437"><a href="#cb795-8437" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8438"><a href="#cb795-8438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8439"><a href="#cb795-8439" aria-hidden="true" tabindex="-1"></a>This is the phenomenon behind ***information criteria***. The most known information criterion is the ***Akaike information criterion***, abbreviated **AIC**. AIC provides a surprisingly simple estimate of the average out-of-sample deviance:</span>
<span id="cb795-8440"><a href="#cb795-8440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8441"><a href="#cb795-8441" aria-hidden="true" tabindex="-1"></a>$$\text{AIC} = D_{train} ~+~ 2p $$</span>
<span id="cb795-8442"><a href="#cb795-8442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8443"><a href="#cb795-8443" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8444"><a href="#cb795-8444" aria-hidden="true" tabindex="-1"></a><span class="in">p   = the number of free parameters to be estimated in the model</span></span>
<span id="cb795-8445"><a href="#cb795-8445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8446"><a href="#cb795-8446" aria-hidden="true" tabindex="-1"></a><span class="in">This definition reflects the relationship between training and testing deviance in f6.10. </span></span>
<span id="cb795-8447"><a href="#cb795-8447" aria-hidden="true" tabindex="-1"></a><span class="in">The dashed lines in f6.10 trace out the AIC values of the models.</span></span>
<span id="cb795-8448"><a href="#cb795-8448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8449"><a href="#cb795-8449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8450"><a href="#cb795-8450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8451"><a href="#cb795-8451" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8452"><a href="#cb795-8452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8453"><a href="#cb795-8453" aria-hidden="true" tabindex="-1"></a>AIC provides an approximation of predictive accuracy, as measured by out-of-sample deviance. AIC is an approximation that is reliable only when:</span>
<span id="cb795-8454"><a href="#cb795-8454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8455"><a href="#cb795-8455" aria-hidden="true" tabindex="-1"></a>(1) The priors are flat or overwhelmed by the likelihood.</span>
<span id="cb795-8456"><a href="#cb795-8456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8457"><a href="#cb795-8457" aria-hidden="true" tabindex="-1"></a>(2) The posterior distribution is approximately multivariate Gaussian.</span>
<span id="cb795-8458"><a href="#cb795-8458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8459"><a href="#cb795-8459" aria-hidden="true" tabindex="-1"></a>(3) The sample size N is much greater than the number of parameters k.</span>
<span id="cb795-8460"><a href="#cb795-8460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8461"><a href="#cb795-8461" aria-hidden="true" tabindex="-1"></a>Since flat priors are hardly ever the best priors, we’ll want something more general.</span>
<span id="cb795-8462"><a href="#cb795-8462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8463"><a href="#cb795-8463" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8464"><a href="#cb795-8464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8465"><a href="#cb795-8465" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Two common and more-general criteria***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-8466"><a href="#cb795-8466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8467"><a href="#cb795-8467" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>***Deviance Information Criterion (DIC)***</span>
<span id="cb795-8468"><a href="#cb795-8468" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>accommodates informative priors, but still assumes that the posterior is multivariate Gaussian and that $N \gg k$</span>
<span id="cb795-8469"><a href="#cb795-8469" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-8470"><a href="#cb795-8470" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-8471"><a href="#cb795-8471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8472"><a href="#cb795-8472" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>***Widely Applicable Information Criterion (WAIC)***</span>
<span id="cb795-8473"><a href="#cb795-8473" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>more general yet, making no assumption about the shape of the posterior</span>
<span id="cb795-8474"><a href="#cb795-8474" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-8475"><a href="#cb795-8475" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8476"><a href="#cb795-8476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8477"><a href="#cb795-8477" aria-hidden="true" tabindex="-1"></a><span class="fu">### Deviance Information Criterion (DIC)</span></span>
<span id="cb795-8478"><a href="#cb795-8478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8479"><a href="#cb795-8479" aria-hidden="true" tabindex="-1"></a>DIC is essentially a version of AIC that is aware of informative priors. Like AIC, it assumes a multivariate Gaussian posterior distribution. This means if any parameter in the posterior is substantially skewed, and also has a substantial effect on prediction, then DIC like AIC can go horribly wrong.</span>
<span id="cb795-8480"><a href="#cb795-8480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8481"><a href="#cb795-8481" aria-hidden="true" tabindex="-1"></a>DIC is calculated from the posterior distribution of the training deviance. So define D now as the posterior distribution of deviance. This means we compute deviance (on the training sample) for each set of sampled parameter values in the posterior distribution.  So if we draw 10,000 samples from the posterior, we compute 10,000 deviance values.</span>
<span id="cb795-8482"><a href="#cb795-8482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8483"><a href="#cb795-8483" aria-hidden="true" tabindex="-1"></a>DIC is calculated as:</span>
<span id="cb795-8484"><a href="#cb795-8484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8485"><a href="#cb795-8485" aria-hidden="true" tabindex="-1"></a>$$\text{DIC} = D^{\overline{}} + (D^{\overline{}} - D\hat{}) = D^{\overline{}} + p_D $$</span>
<span id="cb795-8486"><a href="#cb795-8486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8487"><a href="#cb795-8487" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8488"><a href="#cb795-8488" aria-hidden="true" tabindex="-1"></a><span class="in">D ̄ = the average of D</span></span>
<span id="cb795-8489"><a href="#cb795-8489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8490"><a href="#cb795-8490" aria-hidden="true" tabindex="-1"></a><span class="in">Dˆ = the deviance calculated at the posterior mean</span></span>
<span id="cb795-8491"><a href="#cb795-8491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8492"><a href="#cb795-8492" aria-hidden="true" tabindex="-1"></a><span class="in">p_D = the expected distance between the deviance in-sample and the deviance out-of-sample </span></span>
<span id="cb795-8493"><a href="#cb795-8493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8494"><a href="#cb795-8494" aria-hidden="true" tabindex="-1"></a><span class="in">The difference D ̄ − Dˆ = p_D is analogous to the number of parameters used in computing AIC.</span></span>
<span id="cb795-8495"><a href="#cb795-8495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8496"><a href="#cb795-8496" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8497"><a href="#cb795-8497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8498"><a href="#cb795-8498" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8499"><a href="#cb795-8499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8500"><a href="#cb795-8500" aria-hidden="true" tabindex="-1"></a><span class="fu">### Widely Applicable Information Criterion(WAIC)</span></span>
<span id="cb795-8501"><a href="#cb795-8501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8502"><a href="#cb795-8502" aria-hidden="true" tabindex="-1"></a>WAIC is also calculated by taking averages of log-likelihood over the posterior distribution. And it is also just an estimate of out-of-sample deviance. But it does not require a multivariate Gaussian posterior, and it is often more accurate than DIC.</span>
<span id="cb795-8503"><a href="#cb795-8503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8504"><a href="#cb795-8504" aria-hidden="true" tabindex="-1"></a>The distinguishing feature of WAIC is that it is *pointwise*. This means that uncertainty in prediction is considered case-by-case, or point-by-point, in the data. WAIC assesses flexibility of a model with respect to fitting each observation, and then sums up across all observations.</span>
<span id="cb795-8505"><a href="#cb795-8505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8506"><a href="#cb795-8506" aria-hidden="true" tabindex="-1"></a>We compute the likelihood of $y_i$ for each set of parameters sampled from the posterior distribution. Then we average the likelihoods for each observation i and finally sum over all observations. This produces the first part of WAIC, the log-pointwise-predictive-density, lppd:</span>
<span id="cb795-8507"><a href="#cb795-8507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8508"><a href="#cb795-8508" aria-hidden="true" tabindex="-1"></a>$$\text{lppd} = \sum_{i=1}^N ~\text{log Pr}(y_i)$$</span>
<span id="cb795-8509"><a href="#cb795-8509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8510"><a href="#cb795-8510" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8511"><a href="#cb795-8511" aria-hidden="true" tabindex="-1"></a><span class="in">Pr(y_i)   =  the average likelihood of observation i in the training sample</span></span>
<span id="cb795-8512"><a href="#cb795-8512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8513"><a href="#cb795-8513" aria-hidden="true" tabindex="-1"></a><span class="in">The log-pointwise-predictive-density is the total across observations of the logarithm of </span></span>
<span id="cb795-8514"><a href="#cb795-8514" aria-hidden="true" tabindex="-1"></a><span class="in">the average likelihood of each observation.</span></span>
<span id="cb795-8515"><a href="#cb795-8515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8516"><a href="#cb795-8516" aria-hidden="true" tabindex="-1"></a><span class="in">The lppd is just a pointwise analog of deviance, averaged over the posterior distribution. </span></span>
<span id="cb795-8517"><a href="#cb795-8517" aria-hidden="true" tabindex="-1"></a><span class="in">If you multiplied it by −2, it’d be similar to the deviance, in fact.</span></span>
<span id="cb795-8518"><a href="#cb795-8518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8519"><a href="#cb795-8519" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8520"><a href="#cb795-8520" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8521"><a href="#cb795-8521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8522"><a href="#cb795-8522" aria-hidden="true" tabindex="-1"></a>The second piece of WAIC is the effective number of parameters $p_{WAIC}$. </span>
<span id="cb795-8523"><a href="#cb795-8523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8524"><a href="#cb795-8524" aria-hidden="true" tabindex="-1"></a>$$p_{WAIC} = \sum_{i=1}^N ~V(y_i)$$</span>
<span id="cb795-8525"><a href="#cb795-8525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8526"><a href="#cb795-8526" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8527"><a href="#cb795-8527" aria-hidden="true" tabindex="-1"></a><span class="in">p_WAIC    = the effective number of parameters</span></span>
<span id="cb795-8528"><a href="#cb795-8528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8529"><a href="#cb795-8529" aria-hidden="true" tabindex="-1"></a><span class="in">V(y_i)    = the variance in log-likelihood for observation i in the training sample</span></span>
<span id="cb795-8530"><a href="#cb795-8530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8531"><a href="#cb795-8531" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8532"><a href="#cb795-8532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8533"><a href="#cb795-8533" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8534"><a href="#cb795-8534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8535"><a href="#cb795-8535" aria-hidden="true" tabindex="-1"></a>Now WAIC is defined as:</span>
<span id="cb795-8536"><a href="#cb795-8536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8537"><a href="#cb795-8537" aria-hidden="true" tabindex="-1"></a>$$\text{WAIC} = ~-2 (\text{lppd}~-~ p_{WAIC})$$</span>
<span id="cb795-8538"><a href="#cb795-8538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8539"><a href="#cb795-8539" aria-hidden="true" tabindex="-1"></a>Because WAIC requires splitting up the data into independent observations i = 1...N, it is sometimes hard to define. Consider for example a model in which each prediction depends upon a previous observation. This happens, for example, in a *time series*. In a time series, a previous observation becomes a predictor variable for the next observation. So it’s not easy to think of each observation as independent of, or exchangeable with, the others. In such a case, you can of course compute WAIC as if each observation were independent of the others, but it’s not clear what the resulting value means.</span>
<span id="cb795-8540"><a href="#cb795-8540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8541"><a href="#cb795-8541" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8542"><a href="#cb795-8542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8543"><a href="#cb795-8543" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**WAIC calculations**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-8544"><a href="#cb795-8544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8545"><a href="#cb795-8545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8546"><a href="#cb795-8546" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.15}</span></span>
<span id="cb795-8547"><a href="#cb795-8547" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">615</span>)</span>
<span id="cb795-8548"><a href="#cb795-8548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8549"><a href="#cb795-8549" aria-hidden="true" tabindex="-1"></a><span class="co"># To see how the WAIC calculations actually work, consider a simple regression fit with map:</span></span>
<span id="cb795-8550"><a href="#cb795-8550" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(cars)</span>
<span id="cb795-8551"><a href="#cb795-8551" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-8552"><a href="#cb795-8552" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-8553"><a href="#cb795-8553" aria-hidden="true" tabindex="-1"></a>        dist <span class="sc">~</span> <span class="fu">dnorm</span>(mu,sigma),</span>
<span id="cb795-8554"><a href="#cb795-8554" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> b<span class="sc">*</span>speed,</span>
<span id="cb795-8555"><a href="#cb795-8555" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">100</span>),</span>
<span id="cb795-8556"><a href="#cb795-8556" aria-hidden="true" tabindex="-1"></a>        b <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-8557"><a href="#cb795-8557" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">30</span>)</span>
<span id="cb795-8558"><a href="#cb795-8558" aria-hidden="true" tabindex="-1"></a>    ) , <span class="at">data=</span>cars )</span>
<span id="cb795-8559"><a href="#cb795-8559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8560"><a href="#cb795-8560" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>(m,<span class="at">n=</span><span class="dv">1000</span>)</span>
<span id="cb795-8561"><a href="#cb795-8561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8562"><a href="#cb795-8562" aria-hidden="true" tabindex="-1"></a><span class="co"># We’ll need the log-likelihood of each observation i at each sample s from the posterior:</span></span>
<span id="cb795-8563"><a href="#cb795-8563" aria-hidden="true" tabindex="-1"></a>n_samples <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb795-8564"><a href="#cb795-8564" aria-hidden="true" tabindex="-1"></a>ll <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span>n_samples ,</span>
<span id="cb795-8565"><a href="#cb795-8565" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(s) {</span>
<span id="cb795-8566"><a href="#cb795-8566" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> post<span class="sc">$</span>a[s] <span class="sc">+</span> post<span class="sc">$</span>b[s]<span class="sc">*</span>cars<span class="sc">$</span>speed</span>
<span id="cb795-8567"><a href="#cb795-8567" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>( cars<span class="sc">$</span>dist , mu , post<span class="sc">$</span>sigma[s] , <span class="at">log=</span><span class="cn">TRUE</span> )</span>
<span id="cb795-8568"><a href="#cb795-8568" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb795-8569"><a href="#cb795-8569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8570"><a href="#cb795-8570" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(ll)</span>
<span id="cb795-8571"><a href="#cb795-8571" aria-hidden="true" tabindex="-1"></a><span class="co"># You end up with a 50-by-1000 matrix of log-likelihoods, with observations in rows </span></span>
<span id="cb795-8572"><a href="#cb795-8572" aria-hidden="true" tabindex="-1"></a><span class="co"># and samples in columns.</span></span>
<span id="cb795-8573"><a href="#cb795-8573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8574"><a href="#cb795-8574" aria-hidden="true" tabindex="-1"></a><span class="co"># Now to compute lppd, the Bayesian deviance, we average the samples in each row, </span></span>
<span id="cb795-8575"><a href="#cb795-8575" aria-hidden="true" tabindex="-1"></a><span class="co"># take the log, and add all of the logs together. However, to do this with precision, </span></span>
<span id="cb795-8576"><a href="#cb795-8576" aria-hidden="true" tabindex="-1"></a><span class="co"># we need to do all of the averaging on the log scale. This is made easy with a </span></span>
<span id="cb795-8577"><a href="#cb795-8577" aria-hidden="true" tabindex="-1"></a><span class="co"># function log_sum_exp, which computes the log of a sum of exponentiated terms. </span></span>
<span id="cb795-8578"><a href="#cb795-8578" aria-hidden="true" tabindex="-1"></a><span class="co"># Then we can just subtract the log of the number of samples. </span></span>
<span id="cb795-8579"><a href="#cb795-8579" aria-hidden="true" tabindex="-1"></a><span class="co"># This computes the log of the average.</span></span>
<span id="cb795-8580"><a href="#cb795-8580" aria-hidden="true" tabindex="-1"></a>n_cases <span class="ot">&lt;-</span> <span class="fu">nrow</span>(cars)</span>
<span id="cb795-8581"><a href="#cb795-8581" aria-hidden="true" tabindex="-1"></a>lppd <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span>n_cases , <span class="cf">function</span>(i) <span class="fu">log_sum_exp</span>(ll[i,]) <span class="sc">-</span> <span class="fu">log</span>(n_samples) )</span>
<span id="cb795-8582"><a href="#cb795-8582" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(lppd)</span>
<span id="cb795-8583"><a href="#cb795-8583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8584"><a href="#cb795-8584" aria-hidden="true" tabindex="-1"></a><span class="co"># Now for the effective number of parameters, pWAIC. This is more straightforward, as </span></span>
<span id="cb795-8585"><a href="#cb795-8585" aria-hidden="true" tabindex="-1"></a><span class="co"># we just compute the variance across samples for each observation, then add these together:</span></span>
<span id="cb795-8586"><a href="#cb795-8586" aria-hidden="true" tabindex="-1"></a>pWAIC <span class="ot">&lt;-</span> <span class="fu">sapply</span>( <span class="dv">1</span><span class="sc">:</span>n_cases , <span class="cf">function</span>(i) <span class="fu">var</span>(ll[i,]) )</span>
<span id="cb795-8587"><a href="#cb795-8587" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(pWAIC)</span>
<span id="cb795-8588"><a href="#cb795-8588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8589"><a href="#cb795-8589" aria-hidden="true" tabindex="-1"></a><span class="co"># To compute WAIC:</span></span>
<span id="cb795-8590"><a href="#cb795-8590" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>( <span class="fu">sum</span>(lppd) <span class="sc">-</span> <span class="fu">sum</span>(pWAIC) )</span>
<span id="cb795-8591"><a href="#cb795-8591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8592"><a href="#cb795-8592" aria-hidden="true" tabindex="-1"></a><span class="co"># You can compute the standard error by computing the square root of number of cases </span></span>
<span id="cb795-8593"><a href="#cb795-8593" aria-hidden="true" tabindex="-1"></a><span class="co"># multiplied by the variance over the individual observation terms in WAIC:</span></span>
<span id="cb795-8594"><a href="#cb795-8594" aria-hidden="true" tabindex="-1"></a>waic_vec <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">2</span><span class="sc">*</span>( lppd <span class="sc">-</span> pWAIC )</span>
<span id="cb795-8595"><a href="#cb795-8595" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(waic_vec)</span>
<span id="cb795-8596"><a href="#cb795-8596" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>( n_cases<span class="sc">*</span><span class="fu">var</span>(waic_vec) )</span>
<span id="cb795-8597"><a href="#cb795-8597" aria-hidden="true" tabindex="-1"></a><span class="co"># The variance remains much smaller than the standard error of WAIC itself. </span></span>
<span id="cb795-8598"><a href="#cb795-8598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8599"><a href="#cb795-8599" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8600"><a href="#cb795-8600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8601"><a href="#cb795-8601" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8602"><a href="#cb795-8602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8603"><a href="#cb795-8603" aria-hidden="true" tabindex="-1"></a><span class="fu">### DIC and WAIC as estimates of deviance</span></span>
<span id="cb795-8604"><a href="#cb795-8604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8605"><a href="#cb795-8605" aria-hidden="true" tabindex="-1"></a>Let's visualize the estimates of out-of-sample deviance that DIC and WAIC provide, in the same familiar context as earlier sections.</span>
<span id="cb795-8606"><a href="#cb795-8606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8607"><a href="#cb795-8607" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.11, eval=FALSE}</span></span>
<span id="cb795-8608"><a href="#cb795-8608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8609"><a href="#cb795-8609" aria-hidden="true" tabindex="-1"></a><span class="do">## Use akjurz's codes</span></span>
<span id="cb795-8610"><a href="#cb795-8610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8611"><a href="#cb795-8611" aria-hidden="true" tabindex="-1"></a>n_sim <span class="ot">&lt;-</span> <span class="fl">1e3</span></span>
<span id="cb795-8612"><a href="#cb795-8612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8613"><a href="#cb795-8613" aria-hidden="true" tabindex="-1"></a>make_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(b_sigma){</span>
<span id="cb795-8614"><a href="#cb795-8614" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(kseq, <span class="cf">function</span>(k) {</span>
<span id="cb795-8615"><a href="#cb795-8615" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(k);</span>
<span id="cb795-8616"><a href="#cb795-8616" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> <span class="fu">mcreplicate</span>(n_sim, </span>
<span id="cb795-8617"><a href="#cb795-8617" aria-hidden="true" tabindex="-1"></a>                     <span class="fu">sim.train.test</span>(<span class="at">N         =</span> <span class="dv">20</span>,</span>
<span id="cb795-8618"><a href="#cb795-8618" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">k         =</span> k,</span>
<span id="cb795-8619"><a href="#cb795-8619" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">b_sigma   =</span> b_sigma,</span>
<span id="cb795-8620"><a href="#cb795-8620" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">DIC       =</span> T,</span>
<span id="cb795-8621"><a href="#cb795-8621" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">WAIC      =</span> T, </span>
<span id="cb795-8622"><a href="#cb795-8622" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">devbar    =</span> T, </span>
<span id="cb795-8623"><a href="#cb795-8623" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">devbarout =</span> T),</span>
<span id="cb795-8624"><a href="#cb795-8624" aria-hidden="true" tabindex="-1"></a>                     <span class="at">mc.cores =</span> n_cores);</span>
<span id="cb795-8625"><a href="#cb795-8625" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-8626"><a href="#cb795-8626" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(<span class="at">dev_in    =</span> <span class="fu">mean</span>(r[<span class="dv">1</span>, ]),</span>
<span id="cb795-8627"><a href="#cb795-8627" aria-hidden="true" tabindex="-1"></a>      <span class="at">dev_out   =</span> <span class="fu">mean</span>(r[<span class="dv">2</span>, ]),</span>
<span id="cb795-8628"><a href="#cb795-8628" aria-hidden="true" tabindex="-1"></a>      <span class="at">DIC       =</span> <span class="fu">mean</span>(r[<span class="dv">3</span>, ]), </span>
<span id="cb795-8629"><a href="#cb795-8629" aria-hidden="true" tabindex="-1"></a>      <span class="at">WAIC      =</span> <span class="fu">mean</span>(r[<span class="dv">4</span>, ]), </span>
<span id="cb795-8630"><a href="#cb795-8630" aria-hidden="true" tabindex="-1"></a>      <span class="at">devbar    =</span> <span class="fu">mean</span>(r[<span class="dv">5</span>, ]), </span>
<span id="cb795-8631"><a href="#cb795-8631" aria-hidden="true" tabindex="-1"></a>      <span class="at">devbarout =</span> <span class="fu">mean</span>(r[<span class="dv">6</span>, ])) </span>
<span id="cb795-8632"><a href="#cb795-8632" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb795-8633"><a href="#cb795-8633" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8634"><a href="#cb795-8634" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb795-8635"><a href="#cb795-8635" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rownames_to_column</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb795-8636"><a href="#cb795-8636" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rename</span>(<span class="at">statistic =</span> rowname)</span>
<span id="cb795-8637"><a href="#cb795-8637" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-8638"><a href="#cb795-8638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8639"><a href="#cb795-8639" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span></span>
<span id="cb795-8640"><a href="#cb795-8640" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">b_sigma =</span> <span class="fu">c</span>(<span class="dv">100</span>, .<span class="dv">5</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8641"><a href="#cb795-8641" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sim =</span> purrr<span class="sc">::</span><span class="fu">map</span>(b_sigma, make_sim)) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8642"><a href="#cb795-8642" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>()</span>
<span id="cb795-8643"><a href="#cb795-8643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8644"><a href="#cb795-8644" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrangle and plot</span></span>
<span id="cb795-8645"><a href="#cb795-8645" aria-hidden="true" tabindex="-1"></a>s <span class="sc">%&gt;%</span> </span>
<span id="cb795-8646"><a href="#cb795-8646" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(n_par, value, <span class="sc">-</span>b_sigma, <span class="sc">-</span>statistic) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8647"><a href="#cb795-8647" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n_par =</span> <span class="fu">str_remove</span>(n_par, <span class="st">"X"</span>) <span class="sc">%&gt;%</span> <span class="fu">as.double</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8648"><a href="#cb795-8648" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(statistic <span class="sc">!=</span> <span class="st">"devbar"</span> <span class="sc">&amp;</span> statistic <span class="sc">!=</span> <span class="st">"devbarout"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8649"><a href="#cb795-8649" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spread</span>(<span class="at">key =</span> statistic, <span class="at">value =</span> value) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8650"><a href="#cb795-8650" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(ic, value, <span class="sc">-</span>b_sigma, <span class="sc">-</span>n_par, <span class="sc">-</span>dev_in, <span class="sc">-</span>dev_out) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8651"><a href="#cb795-8651" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(sample, deviance, <span class="sc">-</span>b_sigma, <span class="sc">-</span>n_par, <span class="sc">-</span>ic, <span class="sc">-</span>value) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8652"><a href="#cb795-8652" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(sample <span class="sc">==</span> <span class="st">"dev_out"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8653"><a href="#cb795-8653" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">b_sigma =</span> b_sigma <span class="sc">%&gt;%</span> <span class="fu">as.character</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb795-8654"><a href="#cb795-8654" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb795-8655"><a href="#cb795-8655" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> n_par)) <span class="sc">+</span></span>
<span id="cb795-8656"><a href="#cb795-8656" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> deviance, <span class="at">color =</span> b_sigma),</span>
<span id="cb795-8657"><a href="#cb795-8657" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb795-8658"><a href="#cb795-8658" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> value, <span class="at">group =</span> b_sigma, <span class="at">color =</span> b_sigma)) <span class="sc">+</span></span>
<span id="cb795-8659"><a href="#cb795-8659" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">7</span>], <span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">5</span>])) <span class="sc">+</span></span>
<span id="cb795-8660"><a href="#cb795-8660" aria-hidden="true" tabindex="-1"></a>  <span class="co"># scale_color_manual(values = c("steelblue", "black")) +</span></span>
<span id="cb795-8661"><a href="#cb795-8661" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">"n = 20"</span>,</span>
<span id="cb795-8662"><a href="#cb795-8662" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"number of parameters"</span>,</span>
<span id="cb795-8663"><a href="#cb795-8663" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"deviance"</span>) <span class="sc">+</span></span>
<span id="cb795-8664"><a href="#cb795-8664" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>() <span class="sc">+</span></span>
<span id="cb795-8665"><a href="#cb795-8665" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">text             =</span> <span class="fu">element_text</span>(<span class="at">family =</span> <span class="st">"Courier"</span>),</span>
<span id="cb795-8666"><a href="#cb795-8666" aria-hidden="true" tabindex="-1"></a>        <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="fu">alpha</span>(<span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">1</span>], <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>), <span class="at">color =</span> <span class="st">"white"</span>),</span>
<span id="cb795-8667"><a href="#cb795-8667" aria-hidden="true" tabindex="-1"></a>        <span class="at">panel.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="fu">alpha</span>(<span class="fu">carto_pal</span>(<span class="dv">7</span>, <span class="st">"BurgYl"</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>)),</span>
<span id="cb795-8668"><a href="#cb795-8668" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position  =</span> <span class="st">"none"</span>) <span class="sc">+</span></span>
<span id="cb795-8669"><a href="#cb795-8669" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>ic, <span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb795-8670"><a href="#cb795-8670" aria-hidden="true" tabindex="-1"></a><span class="co"># Out-of-sample deviance as estimated by DIC and WAIC. Points are average out-of-sample </span></span>
<span id="cb795-8671"><a href="#cb795-8671" aria-hidden="true" tabindex="-1"></a><span class="co"># deviance over 1000 simulations. The lines are average DIC (top) and WAIC (bottom) </span></span>
<span id="cb795-8672"><a href="#cb795-8672" aria-hidden="true" tabindex="-1"></a><span class="co"># computed from the same simulations. </span></span>
<span id="cb795-8673"><a href="#cb795-8673" aria-hidden="true" tabindex="-1"></a><span class="co"># The red (top) points and lines come from simulations with a nearly flat Normal(0, 100) prior. </span></span>
<span id="cb795-8674"><a href="#cb795-8674" aria-hidden="true" tabindex="-1"></a><span class="co"># The brown (bottom) points and lines used a regularizing Normal(0, 0.5) prior.</span></span>
<span id="cb795-8675"><a href="#cb795-8675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8676"><a href="#cb795-8676" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8677"><a href="#cb795-8677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8678"><a href="#cb795-8678" aria-hidden="true" tabindex="-1"></a>In the above figure, both DIC and WAIC are accurate on average, being within 1 point of deviance of the actual average in most cases. Both are useful estimates of the deviance, but WAIC is more accurate in this context.</span>
<span id="cb795-8679"><a href="#cb795-8679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8680"><a href="#cb795-8680" aria-hidden="true" tabindex="-1"></a>Also notice that the regularizing prior (brown) still helps, and that DIC and WAIC do track this help. This suggests that using both regularization and information criteria will always beat using only one or the other alone. Regularization, as long as it’s not too strong, reduces overfitting for any particular model. Information criteria instead help us measure overfitting across models fit to the same data.</span>
<span id="cb795-8681"><a href="#cb795-8681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8682"><a href="#cb795-8682" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8683"><a href="#cb795-8683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8684"><a href="#cb795-8684" aria-hidden="true" tabindex="-1"></a><span class="fu">## Using information criteria</span></span>
<span id="cb795-8685"><a href="#cb795-8685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8686"><a href="#cb795-8686" aria-hidden="true" tabindex="-1"></a>Once we have DIC or WAIC calculated for each plausible model, how do we use these values? </span>
<span id="cb795-8687"><a href="#cb795-8687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8688"><a href="#cb795-8688" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>***Model comparison***</span>
<span id="cb795-8689"><a href="#cb795-8689" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>means using DIC/WAIC in combination with the estimates and posterior predictive checks from each model</span>
<span id="cb795-8690"><a href="#cb795-8690" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>It is just as important to understand why a model outperforms another as it is to measure the performance difference. </span>
<span id="cb795-8691"><a href="#cb795-8691" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>DIC/WAIC alone says very little about such details. But in combination with other information, DIC/WAIC is a big help.</span>
<span id="cb795-8692"><a href="#cb795-8692" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb795-8693"><a href="#cb795-8693" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-8694"><a href="#cb795-8694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8695"><a href="#cb795-8695" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>***Model averaging***</span>
<span id="cb795-8696"><a href="#cb795-8696" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>means using DIC/WAIC to construct a posterior predictive distribution that exploits what we know about relative accuracy of the models</span>
<span id="cb795-8697"><a href="#cb795-8697" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>This helps guard against overconfidence in model structure, in the same way that using the entire posterior distribution helps guard against overconfidence in parameter values. </span>
<span id="cb795-8698"><a href="#cb795-8698" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>What model averaging does not mean is averaging parameter estimates, because parameters in different models have different meanings and should not be averaged, unless you are sure you are in a special case in which it is safe to do so. </span>
<span id="cb795-8699"><a href="#cb795-8699" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>So it is better to think of model averaging as prediction averaging, because that’s what is actually being done.</span>
<span id="cb795-8700"><a href="#cb795-8700" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb795-8701"><a href="#cb795-8701" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8702"><a href="#cb795-8702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8703"><a href="#cb795-8703" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model comparison</span></span>
<span id="cb795-8704"><a href="#cb795-8704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8705"><a href="#cb795-8705" aria-hidden="true" tabindex="-1"></a>As an example, we’ll repeat the analysis of predicting kilocalories per gram of milk (kcal.per.g) with the two predictor variables neocortex and the logarithm of mass. But now we’ll fit four different models, corresponding to the four simple combinations of linear models with these two predictor variables: </span>
<span id="cb795-8706"><a href="#cb795-8706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8707"><a href="#cb795-8707" aria-hidden="true" tabindex="-1"></a>(1) a model with both neocortex and log mass</span>
<span id="cb795-8708"><a href="#cb795-8708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8709"><a href="#cb795-8709" aria-hidden="true" tabindex="-1"></a>(2) a model with only neocortex</span>
<span id="cb795-8710"><a href="#cb795-8710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8711"><a href="#cb795-8711" aria-hidden="true" tabindex="-1"></a>(3) a model with only log mass</span>
<span id="cb795-8712"><a href="#cb795-8712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8713"><a href="#cb795-8713" aria-hidden="true" tabindex="-1"></a>(4) a model with neither predictor (just an intercept)</span>
<span id="cb795-8714"><a href="#cb795-8714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8715"><a href="#cb795-8715" aria-hidden="true" tabindex="-1"></a>Fitting the four models, using map, is straightforward. The only thing that differs among these models is the equation for $\mu_i$ (mu). </span>
<span id="cb795-8716"><a href="#cb795-8716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8717"><a href="#cb795-8717" aria-hidden="true" tabindex="-1"></a>A way to constrain the standard deviation of the outcome, $\sigma$, to be positive is to estimate the logarithm of $\sigma$, which can be any real number. Then inside the likelihood function we just exponentiate it. Since $exp(x) &gt; 0$ for any real number $x$, this effectively bounds $\sigma$ to positive reals.</span>
<span id="cb795-8718"><a href="#cb795-8718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8719"><a href="#cb795-8719" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.21}</span></span>
<span id="cb795-8720"><a href="#cb795-8720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8721"><a href="#cb795-8721" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the primate milk data, remove the NAs, and rescale one of the explanatory variables</span></span>
<span id="cb795-8722"><a href="#cb795-8722" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(milk)</span>
<span id="cb795-8723"><a href="#cb795-8723" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> milk[ <span class="fu">complete.cases</span>(milk) , ]</span>
<span id="cb795-8724"><a href="#cb795-8724" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>neocortex <span class="ot">&lt;-</span> d<span class="sc">$</span>neocortex.perc <span class="sc">/</span> <span class="dv">100</span></span>
<span id="cb795-8725"><a href="#cb795-8725" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(d)</span>
<span id="cb795-8726"><a href="#cb795-8726" aria-hidden="true" tabindex="-1"></a><span class="co"># data frame now have 17 rows (cases) and 9 columns (variables)</span></span>
<span id="cb795-8727"><a href="#cb795-8727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8728"><a href="#cb795-8728" aria-hidden="true" tabindex="-1"></a><span class="do">## Constrain sigma to be positive and fit the models</span></span>
<span id="cb795-8729"><a href="#cb795-8729" aria-hidden="true" tabindex="-1"></a>a.start <span class="ot">&lt;-</span> <span class="fu">mean</span>(d<span class="sc">$</span>kcal.per.g)</span>
<span id="cb795-8730"><a href="#cb795-8730" aria-hidden="true" tabindex="-1"></a>sigma.start <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">sd</span>(d<span class="sc">$</span>kcal.per.g))</span>
<span id="cb795-8731"><a href="#cb795-8731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8732"><a href="#cb795-8732" aria-hidden="true" tabindex="-1"></a><span class="co"># The priors are all flat which is clearly not the best idea. But this will let you get </span></span>
<span id="cb795-8733"><a href="#cb795-8733" aria-hidden="true" tabindex="-1"></a><span class="co"># a sense of what the sample alone says, in the absence of regularization, and </span></span>
<span id="cb795-8734"><a href="#cb795-8734" aria-hidden="true" tabindex="-1"></a><span class="co"># how WAIC measures overfitting. </span></span>
<span id="cb795-8735"><a href="#cb795-8735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8736"><a href="#cb795-8736" aria-hidden="true" tabindex="-1"></a><span class="co"># Model with neither predictor (just intercept)</span></span>
<span id="cb795-8737"><a href="#cb795-8737" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.11</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-8738"><a href="#cb795-8738" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-8739"><a href="#cb795-8739" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( a , <span class="fu">exp</span>(log.sigma) )</span>
<span id="cb795-8740"><a href="#cb795-8740" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-8741"><a href="#cb795-8741" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d , <span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span>a.start,<span class="at">log.sigma=</span>sigma.start) )</span>
<span id="cb795-8742"><a href="#cb795-8742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8743"><a href="#cb795-8743" aria-hidden="true" tabindex="-1"></a><span class="co"># Model with only neocortex</span></span>
<span id="cb795-8744"><a href="#cb795-8744" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.12</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-8745"><a href="#cb795-8745" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-8746"><a href="#cb795-8746" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , <span class="fu">exp</span>(log.sigma) ) ,</span>
<span id="cb795-8747"><a href="#cb795-8747" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bn<span class="sc">*</span>neocortex</span>
<span id="cb795-8748"><a href="#cb795-8748" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-8749"><a href="#cb795-8749" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d , <span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span>a.start,<span class="at">bn=</span><span class="dv">0</span>,<span class="at">log.sigma=</span>sigma.start) )</span>
<span id="cb795-8750"><a href="#cb795-8750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8751"><a href="#cb795-8751" aria-hidden="true" tabindex="-1"></a><span class="co"># Model with only log mass</span></span>
<span id="cb795-8752"><a href="#cb795-8752" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.13</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-8753"><a href="#cb795-8753" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-8754"><a href="#cb795-8754" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , <span class="fu">exp</span>(log.sigma) ) ,</span>
<span id="cb795-8755"><a href="#cb795-8755" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bm<span class="sc">*</span><span class="fu">log</span>(mass)</span>
<span id="cb795-8756"><a href="#cb795-8756" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-8757"><a href="#cb795-8757" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d , <span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span>a.start,<span class="at">bm=</span><span class="dv">0</span>,<span class="at">log.sigma=</span>sigma.start) )</span>
<span id="cb795-8758"><a href="#cb795-8758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8759"><a href="#cb795-8759" aria-hidden="true" tabindex="-1"></a><span class="co"># Model with both neocortex and log mass</span></span>
<span id="cb795-8760"><a href="#cb795-8760" aria-hidden="true" tabindex="-1"></a>m6<span class="fl">.14</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-8761"><a href="#cb795-8761" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-8762"><a href="#cb795-8762" aria-hidden="true" tabindex="-1"></a>        kcal.per.g <span class="sc">~</span> <span class="fu">dnorm</span>( mu , <span class="fu">exp</span>(log.sigma) ) ,</span>
<span id="cb795-8763"><a href="#cb795-8763" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bn<span class="sc">*</span>neocortex <span class="sc">+</span> bm<span class="sc">*</span><span class="fu">log</span>(mass)</span>
<span id="cb795-8764"><a href="#cb795-8764" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-8765"><a href="#cb795-8765" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d , <span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span>a.start,<span class="at">bn=</span><span class="dv">0</span>,<span class="at">bm=</span><span class="dv">0</span>,<span class="at">log.sigma=</span>sigma.start) )</span>
<span id="cb795-8766"><a href="#cb795-8766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8767"><a href="#cb795-8767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8768"><a href="#cb795-8768" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8769"><a href="#cb795-8769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8770"><a href="#cb795-8770" aria-hidden="true" tabindex="-1"></a>Fitting these four models provides answers to questions about how and how much prediction changes when we include either or both predictor variables. With the four sets of estimates, and four deviances, in hand, we’ll look quickly at both (1) comparing the models on the basis of WAIC values and (2) on the basis of parameter estimates. These are complementary approaches, aimed at understanding the best model by understanding how predictions and estimates change as predictors are added and subtracted from a model.</span>
<span id="cb795-8771"><a href="#cb795-8771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8772"><a href="#cb795-8772" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8773"><a href="#cb795-8773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8774"><a href="#cb795-8774" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Comparing WAIC values</span></span>
<span id="cb795-8775"><a href="#cb795-8775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8776"><a href="#cb795-8776" aria-hidden="true" tabindex="-1"></a>To compare models using an information criterion, you first compute the criterion. Then you can rank the models from lowest (best) to highest (worst) and also calculate weights, which provide a more interpretable measure of the relative distances among the models.</span>
<span id="cb795-8777"><a href="#cb795-8777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8778"><a href="#cb795-8778" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.23}</span></span>
<span id="cb795-8779"><a href="#cb795-8779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8780"><a href="#cb795-8780" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">WAIC</span>( m6<span class="fl">.14</span> )</span>
<span id="cb795-8781"><a href="#cb795-8781" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that WAIC value is negative in this case. That’s fine. There’s nothing </span></span>
<span id="cb795-8782"><a href="#cb795-8782" aria-hidden="true" tabindex="-1"></a><span class="co"># preventing deviance from being negative. Smaller values are still better.</span></span>
<span id="cb795-8783"><a href="#cb795-8783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8784"><a href="#cb795-8784" aria-hidden="true" tabindex="-1"></a><span class="co"># The third value is pWAIC. If you subtract pWAIC from lppd and then multiply that </span></span>
<span id="cb795-8785"><a href="#cb795-8785" aria-hidden="true" tabindex="-1"></a><span class="co"># difference by −2, you’ll get the WAIC value.</span></span>
<span id="cb795-8786"><a href="#cb795-8786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8787"><a href="#cb795-8787" aria-hidden="true" tabindex="-1"></a><span class="co"># The standard error (std_err) provides rough guidance to the uncertainty in WAIC </span></span>
<span id="cb795-8788"><a href="#cb795-8788" aria-hidden="true" tabindex="-1"></a><span class="co"># that arises from sampling. It can be very rough guidance, when the sample size is small. </span></span>
<span id="cb795-8789"><a href="#cb795-8789" aria-hidden="true" tabindex="-1"></a><span class="co"># Still, always remember that WAIC is an estimate.</span></span>
<span id="cb795-8790"><a href="#cb795-8790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8791"><a href="#cb795-8791" aria-hidden="true" tabindex="-1"></a><span class="do">## Calculate WAIC for other models</span></span>
<span id="cb795-8792"><a href="#cb795-8792" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">WAIC</span>( m6<span class="fl">.13</span> )</span>
<span id="cb795-8793"><a href="#cb795-8793" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">WAIC</span>( m6<span class="fl">.12</span> )</span>
<span id="cb795-8794"><a href="#cb795-8794" aria-hidden="true" tabindex="-1"></a>rethinking<span class="sc">::</span><span class="fu">WAIC</span>( m6<span class="fl">.11</span> )</span>
<span id="cb795-8795"><a href="#cb795-8795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8796"><a href="#cb795-8796" aria-hidden="true" tabindex="-1"></a><span class="do">## Order the models by their WAIC values using compare()</span></span>
<span id="cb795-8797"><a href="#cb795-8797" aria-hidden="true" tabindex="-1"></a>( milk.models <span class="ot">&lt;-</span> <span class="fu">compare</span>( m6<span class="fl">.11</span> , m6<span class="fl">.12</span> , m6<span class="fl">.13</span> , m6<span class="fl">.14</span> ) )</span>
<span id="cb795-8798"><a href="#cb795-8798" aria-hidden="true" tabindex="-1"></a><span class="co"># The function `compare` takes fit models as input. It returns a table in which </span></span>
<span id="cb795-8799"><a href="#cb795-8799" aria-hidden="true" tabindex="-1"></a><span class="co"># models are ranked from best to worst, with six columns of information.</span></span>
<span id="cb795-8800"><a href="#cb795-8800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8801"><a href="#cb795-8801" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8802"><a href="#cb795-8802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8803"><a href="#cb795-8803" aria-hidden="true" tabindex="-1"></a>(1) WAIC is obviously WAIC for each model. Smaller WAIC indicates better estimated out-of-sample deviance, so model m6.14 is ranked first.</span>
<span id="cb795-8804"><a href="#cb795-8804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8805"><a href="#cb795-8805" aria-hidden="true" tabindex="-1"></a>(2) pWAIC is the estimated effective number of parameters. This provides a clue as to how flexible each model is in fitting the sample.</span>
<span id="cb795-8806"><a href="#cb795-8806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8807"><a href="#cb795-8807" aria-hidden="true" tabindex="-1"></a>(3) dWAIC is the difference between each WAIC and the lowest WAIC. Since only relative deviance matters, this column shows the differences in relative fashion.</span>
<span id="cb795-8808"><a href="#cb795-8808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8809"><a href="#cb795-8809" aria-hidden="true" tabindex="-1"></a>(4) weight is the Akaike weight for each model. These values are transformed information criterion values. </span>
<span id="cb795-8810"><a href="#cb795-8810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8811"><a href="#cb795-8811" aria-hidden="true" tabindex="-1"></a>(5) SE is the standard error of the WAIC estimate. WAIC is an estimate, and provided the sample size N is large enough, its uncertainty will be well approximated by its standard error. So this SE value isn’t necessarily very precise, but it does provide a check against overconfidence in differences between WAIC values.</span>
<span id="cb795-8812"><a href="#cb795-8812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8813"><a href="#cb795-8813" aria-hidden="true" tabindex="-1"></a>(6) dSE is the standard error of the difference in WAIC between each model and the top-ranked model. So it is missing for the top model. If you want the full set of pairwise model differences, you can extract milk.models@dSE.</span>
<span id="cb795-8814"><a href="#cb795-8814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8815"><a href="#cb795-8815" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.25}</span></span>
<span id="cb795-8816"><a href="#cb795-8816" aria-hidden="true" tabindex="-1"></a>milk.models<span class="sc">@</span>dSE</span>
<span id="cb795-8817"><a href="#cb795-8817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8818"><a href="#cb795-8818" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the values, to provide a possibly more-intuitive presentation</span></span>
<span id="cb795-8819"><a href="#cb795-8819" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( milk.models , <span class="at">SE=</span><span class="cn">TRUE</span> , <span class="at">dSE=</span><span class="cn">TRUE</span> )</span>
<span id="cb795-8820"><a href="#cb795-8820" aria-hidden="true" tabindex="-1"></a><span class="co"># Each row is a model, ordered by WAIC. </span></span>
<span id="cb795-8821"><a href="#cb795-8821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8822"><a href="#cb795-8822" aria-hidden="true" tabindex="-1"></a><span class="co"># The filled points are the in-sample deviance of each model, which for WAIC is </span></span>
<span id="cb795-8823"><a href="#cb795-8823" aria-hidden="true" tabindex="-1"></a><span class="co"># calculated as −2 × lppd, which is 2pWAIC from the corresponding WAIC value. </span></span>
<span id="cb795-8824"><a href="#cb795-8824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8825"><a href="#cb795-8825" aria-hidden="true" tabindex="-1"></a><span class="co"># The open points are WAIC. The standard error of each WAIC is shown by the dark line </span></span>
<span id="cb795-8826"><a href="#cb795-8826" aria-hidden="true" tabindex="-1"></a><span class="co"># segment that passes through each open point. </span></span>
<span id="cb795-8827"><a href="#cb795-8827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8828"><a href="#cb795-8828" aria-hidden="true" tabindex="-1"></a><span class="co"># The standard error of the difference between each WAIC and the top-ranked WAIC is shown </span></span>
<span id="cb795-8829"><a href="#cb795-8829" aria-hidden="true" tabindex="-1"></a><span class="co"># by the gray triangles and line segments between the rows. The triangle just above each</span></span>
<span id="cb795-8830"><a href="#cb795-8830" aria-hidden="true" tabindex="-1"></a><span class="co"># WAIC point is the difference between that model and the top model. The gray line segment </span></span>
<span id="cb795-8831"><a href="#cb795-8831" aria-hidden="true" tabindex="-1"></a><span class="co"># is the standard deviation of that difference.</span></span>
<span id="cb795-8832"><a href="#cb795-8832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8833"><a href="#cb795-8833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8834"><a href="#cb795-8834" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8835"><a href="#cb795-8835" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-8836"><a href="#cb795-8836" aria-hidden="true" tabindex="-1"></a> <span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8837"><a href="#cb795-8837" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-8838"><a href="#cb795-8838" aria-hidden="true" tabindex="-1"></a>Akaike weights help by rescaling. A total weight of 1 is partitioned among the considered models, making it easier to compare their relative predictive accuracy. The weight for a model $i$ in a set of $m$ models is given by:</span>
<span id="cb795-8839"><a href="#cb795-8839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8840"><a href="#cb795-8840" aria-hidden="true" tabindex="-1"></a>$$ w_i = \frac{exp \left(- \frac{1}{2}dWAIC_i \right)}{\sum_{j=1}^m exp\left(- \frac{1}{2}dWAIC_j \right)}$$</span>
<span id="cb795-8841"><a href="#cb795-8841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8842"><a href="#cb795-8842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8843"><a href="#cb795-8843" aria-hidden="true" tabindex="-1"></a>The Akaike weight formula might look rather odd, but really all it is doing is putting WAIC on a probability scale, so it just undoes the multiplication by −2 and then exponentiates to reverse the log transformation. Then it standardizes by dividing by the total. So each weight will be a number from 0 to 1, and the weights together always sum to 1. ***Now larger values are better.***</span>
<span id="cb795-8844"><a href="#cb795-8844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8845"><a href="#cb795-8845" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8846"><a href="#cb795-8846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8847"><a href="#cb795-8847" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Akaike’s interpretation of the Akaike weight***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-8848"><a href="#cb795-8848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8849"><a href="#cb795-8849" aria-hidden="true" tabindex="-1"></a>A model’s weight is an estimate of the probability that the model will make the best predictions on new data, conditional on the set of models considered.</span>
<span id="cb795-8850"><a href="#cb795-8850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8851"><a href="#cb795-8851" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8852"><a href="#cb795-8852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8853"><a href="#cb795-8853" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Heuristic explanation of the Akaike weight***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-8854"><a href="#cb795-8854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8855"><a href="#cb795-8855" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>First, regard WAIC as the expected deviance of a model on future data. That is to say that WAIC gives us an estimate of E($D_{test}$). </span>
<span id="cb795-8856"><a href="#cb795-8856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8857"><a href="#cb795-8857" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Akaike weights convert these deviance values, which are log-likelihoods, to plain likelihoods and then standardize them all. This is just like Bayes’ theorem uses a sum in the denominator to standardize the product of the likelihood and prior. </span>
<span id="cb795-8858"><a href="#cb795-8858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8859"><a href="#cb795-8859" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Therefore the Akaike weights are analogous to posterior probabilities of models, conditional on expected future data. </span>
<span id="cb795-8860"><a href="#cb795-8860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8861"><a href="#cb795-8861" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Remember, a probability is a standardized count of all the ways some particular thing might happen, according to our assumptions, among all the things that could happen, also according to our assumptions.</span>
<span id="cb795-8862"><a href="#cb795-8862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8863"><a href="#cb795-8863" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>So you can heuristically read each weight as an estimated probability that each model will perform best on future data. In simulation at least, interpreting weights in this way turns out to be appropriate. However, given all the strong assumptions about repeat sampling that go into calculating WAIC, you can’t take this heuristic too seriously. The future is unlikely to be exactly like the past, after all.</span>
<span id="cb795-8864"><a href="#cb795-8864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8865"><a href="#cb795-8865" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>In this analysis, the best model has more than 90% of the model weight. But with only 12 cases, the error on the WAIC estimates is substantial, and of course that uncertainty should propagate to the Akaike weights. If we take the standard error of the difference from the <span class="in">`compare`</span> table literally, you can think of the difference as Gaussian distribution centered (for the difference between models m6.14 and m6.11) on 7.4 with a standard deviation of 7.16. If you feel hesitant that you know how to calculate from that the probability that the difference is negative, and so reversed, you can just simulate it:</span>
<span id="cb795-8866"><a href="#cb795-8866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8867"><a href="#cb795-8867" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.26}</span></span>
<span id="cb795-8868"><a href="#cb795-8868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8869"><a href="#cb795-8869" aria-hidden="true" tabindex="-1"></a>diff <span class="ot">&lt;-</span> <span class="fu">rnorm</span>( <span class="fl">1e5</span> , <span class="fl">7.4</span> , <span class="fl">7.16</span> )</span>
<span id="cb795-8870"><a href="#cb795-8870" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(diff<span class="sc">&lt;</span><span class="dv">0</span>)<span class="sc">/</span><span class="fl">1e5</span></span>
<span id="cb795-8871"><a href="#cb795-8871" aria-hidden="true" tabindex="-1"></a><span class="co"># This is only of heuristic value, especially with only 12 cases. On the other hand, </span></span>
<span id="cb795-8872"><a href="#cb795-8872" aria-hidden="true" tabindex="-1"></a><span class="co"># for having only 12 cases, this is more than we might have reasonably hoped for.</span></span>
<span id="cb795-8873"><a href="#cb795-8873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8874"><a href="#cb795-8874" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8875"><a href="#cb795-8875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8876"><a href="#cb795-8876" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8877"><a href="#cb795-8877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8878"><a href="#cb795-8878" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Interpreting differences in information criteria***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-8879"><a href="#cb795-8879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8880"><a href="#cb795-8880" aria-hidden="true" tabindex="-1"></a>Akaike weights are conditional upon the set of models considered. If you add another model, or take one away, all of the weights will change. How you interpret differences in information criteria always depend upon context: </span>
<span id="cb795-8881"><a href="#cb795-8881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8882"><a href="#cb795-8882" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>sample size</span>
<span id="cb795-8883"><a href="#cb795-8883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8884"><a href="#cb795-8884" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>past research</span>
<span id="cb795-8885"><a href="#cb795-8885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8886"><a href="#cb795-8886" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>nature of measurements</span>
<span id="cb795-8887"><a href="#cb795-8887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8888"><a href="#cb795-8888" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8889"><a href="#cb795-8889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8890"><a href="#cb795-8890" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Comparing estimates</span></span>
<span id="cb795-8891"><a href="#cb795-8891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8892"><a href="#cb795-8892" aria-hidden="true" tabindex="-1"></a>Comparing estimates helps in at least two major ways:</span>
<span id="cb795-8893"><a href="#cb795-8893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8894"><a href="#cb795-8894" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*It is useful to understand why a particular model or models have lower WAIC values.* Changes in posterior distributions, across models, provide useful hints. </span>
<span id="cb795-8895"><a href="#cb795-8895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8896"><a href="#cb795-8896" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*Regardless of WAIC values, we often want to know whether some parameter’s posterior distribution is stable across models.* For example, to know whether a predictor remains important as other predictors are added and subtracted from the model, one typically looks for a parameter’s posterior distribution to remain stable across models, as well as for all models that contain that parameter to have lower WAIC than those models without it.</span>
<span id="cb795-8897"><a href="#cb795-8897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8898"><a href="#cb795-8898" aria-hidden="true" tabindex="-1"></a>In the primate milk example, comparing estimates confirms that the model with both predictors does much better, because each predictor masks the other. Looking at a consolidated table of the MAP estimates makes the comparison a lot easier. The <span class="in">`coeftab`</span> function takes a series of fit models as input and builds such a table:</span>
<span id="cb795-8899"><a href="#cb795-8899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8900"><a href="#cb795-8900" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.27}</span></span>
<span id="cb795-8901"><a href="#cb795-8901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8902"><a href="#cb795-8902" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftab</span>(m6<span class="fl">.11</span>,m6<span class="fl">.12</span>,m6<span class="fl">.13</span>,m6<span class="fl">.14</span>)</span>
<span id="cb795-8903"><a href="#cb795-8903" aria-hidden="true" tabindex="-1"></a><span class="co"># The nobs at the bottom are the number of observations, just there to help you make sure </span></span>
<span id="cb795-8904"><a href="#cb795-8904" aria-hidden="true" tabindex="-1"></a><span class="co"># you fit each model to the same observations.</span></span>
<span id="cb795-8905"><a href="#cb795-8905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8906"><a href="#cb795-8906" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimates for both bn and bm get farther from zero when they are both present in the model.</span></span>
<span id="cb795-8907"><a href="#cb795-8907" aria-hidden="true" tabindex="-1"></a><span class="co"># But standard errors aren’t represented here, and seeing how the uncertainty changes is </span></span>
<span id="cb795-8908"><a href="#cb795-8908" aria-hidden="true" tabindex="-1"></a><span class="co"># just as important as seeing how the location changes.</span></span>
<span id="cb795-8909"><a href="#cb795-8909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8910"><a href="#cb795-8910" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the estimates </span></span>
<span id="cb795-8911"><a href="#cb795-8911" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( <span class="fu">coeftab</span>(m6<span class="fl">.11</span>,m6<span class="fl">.12</span>,m6<span class="fl">.13</span>,m6<span class="fl">.14</span>) )</span>
<span id="cb795-8912"><a href="#cb795-8912" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing the posterior densities of parameters for the four models fit to the </span></span>
<span id="cb795-8913"><a href="#cb795-8913" aria-hidden="true" tabindex="-1"></a><span class="co"># primate milk data. Each point is a MAP estimate, and each black line segment is </span></span>
<span id="cb795-8914"><a href="#cb795-8914" aria-hidden="true" tabindex="-1"></a><span class="co"># a 89% percentile interval. Estimates are grouped by parameter identity, and </span></span>
<span id="cb795-8915"><a href="#cb795-8915" aria-hidden="true" tabindex="-1"></a><span class="co"># each row in a group is a model.</span></span>
<span id="cb795-8916"><a href="#cb795-8916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8917"><a href="#cb795-8917" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8918"><a href="#cb795-8918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8919"><a href="#cb795-8919" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8920"><a href="#cb795-8920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8921"><a href="#cb795-8921" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model averaging</span></span>
<span id="cb795-8922"><a href="#cb795-8922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8923"><a href="#cb795-8923" aria-hidden="true" tabindex="-1"></a>Treating model weights as heuristic plausibilities that each model will perform best in testing, it makes sense to try to preserve these relative plausibilities when generating predictions. And doing so is mechanically very similar to the procedure with a single model.</span>
<span id="cb795-8924"><a href="#cb795-8924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8925"><a href="#cb795-8925" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 6.29}</span></span>
<span id="cb795-8926"><a href="#cb795-8926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8927"><a href="#cb795-8927" aria-hidden="true" tabindex="-1"></a><span class="do">## simulate and plot counterfactual predictions for the minimum-WAIC model, m6.14</span></span>
<span id="cb795-8928"><a href="#cb795-8928" aria-hidden="true" tabindex="-1"></a><span class="co"># compute counterfactual predictions</span></span>
<span id="cb795-8929"><a href="#cb795-8929" aria-hidden="true" tabindex="-1"></a><span class="co"># neocortex from 0.5 to 0.8</span></span>
<span id="cb795-8930"><a href="#cb795-8930" aria-hidden="true" tabindex="-1"></a>nc.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="fl">0.5</span>,<span class="at">to=</span><span class="fl">0.8</span>,<span class="at">length.out=</span><span class="dv">30</span>)</span>
<span id="cb795-8931"><a href="#cb795-8931" aria-hidden="true" tabindex="-1"></a>d.predict <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb795-8932"><a href="#cb795-8932" aria-hidden="true" tabindex="-1"></a>    <span class="at">kcal.per.g =</span> <span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">30</span>), <span class="co"># empty outcome</span></span>
<span id="cb795-8933"><a href="#cb795-8933" aria-hidden="true" tabindex="-1"></a>    <span class="at">neocortex =</span> nc.seq,     <span class="co"># sequence of neocortex</span></span>
<span id="cb795-8934"><a href="#cb795-8934" aria-hidden="true" tabindex="-1"></a>    <span class="at">mass =</span> <span class="fu">rep</span>(<span class="fl">4.5</span>,<span class="dv">30</span>)      <span class="co"># average mass</span></span>
<span id="cb795-8935"><a href="#cb795-8935" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb795-8936"><a href="#cb795-8936" aria-hidden="true" tabindex="-1"></a>pred.m6<span class="fl">.14</span> <span class="ot">&lt;-</span> <span class="fu">link</span>( m6<span class="fl">.14</span> , <span class="at">data=</span>d.predict )</span>
<span id="cb795-8937"><a href="#cb795-8937" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">apply</span>( pred.m6<span class="fl">.14</span> , <span class="dv">2</span> , mean )</span>
<span id="cb795-8938"><a href="#cb795-8938" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( pred.m6<span class="fl">.14</span> , <span class="dv">2</span> , PI )</span>
<span id="cb795-8939"><a href="#cb795-8939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8940"><a href="#cb795-8940" aria-hidden="true" tabindex="-1"></a><span class="co"># plot it all</span></span>
<span id="cb795-8941"><a href="#cb795-8941" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( kcal.per.g <span class="sc">~</span> neocortex , d , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-8942"><a href="#cb795-8942" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( nc.seq , mu , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-8943"><a href="#cb795-8943" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( nc.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-8944"><a href="#cb795-8944" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( nc.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-8945"><a href="#cb795-8945" aria-hidden="true" tabindex="-1"></a><span class="co"># Focus on the dashed regression line and the dashed 89% percentile interval of the mean. </span></span>
<span id="cb795-8946"><a href="#cb795-8946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8947"><a href="#cb795-8947" aria-hidden="true" tabindex="-1"></a><span class="co"># Now let’s compute and add model averaged posterior predictions. </span></span>
<span id="cb795-8948"><a href="#cb795-8948" aria-hidden="true" tabindex="-1"></a><span class="co"># What we’re going to compute is an ensemble of posterior predictions.</span></span>
<span id="cb795-8949"><a href="#cb795-8949" aria-hidden="true" tabindex="-1"></a>milk.ensemble <span class="ot">&lt;-</span> <span class="fu">ensemble</span>( m6<span class="fl">.11</span> , m6<span class="fl">.12</span> , m6<span class="fl">.13</span> , m6<span class="fl">.14</span> , <span class="at">data=</span>d.predict )</span>
<span id="cb795-8950"><a href="#cb795-8950" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">apply</span>( milk.ensemble<span class="sc">$</span>link , <span class="dv">2</span> , mean )</span>
<span id="cb795-8951"><a href="#cb795-8951" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( milk.ensemble<span class="sc">$</span>link , <span class="dv">2</span> , PI )</span>
<span id="cb795-8952"><a href="#cb795-8952" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( nc.seq , mu )</span>
<span id="cb795-8953"><a href="#cb795-8953" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, nc.seq)</span>
<span id="cb795-8954"><a href="#cb795-8954" aria-hidden="true" tabindex="-1"></a><span class="co"># Model averaged posterior predictive distribution for the primate milk analysis. </span></span>
<span id="cb795-8955"><a href="#cb795-8955" aria-hidden="true" tabindex="-1"></a><span class="co"># The dashed regression line and dashed 89% percentile interval correspond to the </span></span>
<span id="cb795-8956"><a href="#cb795-8956" aria-hidden="true" tabindex="-1"></a><span class="co"># minimum-WAIC model, m6.14. The solid line and shaded 89% percentile region correspond </span></span>
<span id="cb795-8957"><a href="#cb795-8957" aria-hidden="true" tabindex="-1"></a><span class="co"># to the model averaged predictions.</span></span>
<span id="cb795-8958"><a href="#cb795-8958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8959"><a href="#cb795-8959" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-8960"><a href="#cb795-8960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8961"><a href="#cb795-8961" aria-hidden="true" tabindex="-1"></a> The conceptual procedure behind the calculation of an ensemble of posterior predictions:</span>
<span id="cb795-8962"><a href="#cb795-8962" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb795-8963"><a href="#cb795-8963" aria-hidden="true" tabindex="-1"></a>(1) Compute WAIC (or another information criterion) for each model.</span>
<span id="cb795-8964"><a href="#cb795-8964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8965"><a href="#cb795-8965" aria-hidden="true" tabindex="-1"></a>(2) Compute the weight for each model.</span>
<span id="cb795-8966"><a href="#cb795-8966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8967"><a href="#cb795-8967" aria-hidden="true" tabindex="-1"></a>(3) Compute linear model and simulated outcomes for each model.</span>
<span id="cb795-8968"><a href="#cb795-8968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8969"><a href="#cb795-8969" aria-hidden="true" tabindex="-1"></a>(4) Combine these values into an ensemble of predictions, using the model weights as proportions.</span>
<span id="cb795-8970"><a href="#cb795-8970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8971"><a href="#cb795-8971" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8972"><a href="#cb795-8972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8973"><a href="#cb795-8973" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice</span></span>
<span id="cb795-8974"><a href="#cb795-8974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8975"><a href="#cb795-8975" aria-hidden="true" tabindex="-1"></a><span class="fu">### Easy </span></span>
<span id="cb795-8976"><a href="#cb795-8976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8977"><a href="#cb795-8977" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 6E1. State the three motivating criteria that define information entropy. Try to express each in your</span></span>
<span id="cb795-8978"><a href="#cb795-8978" aria-hidden="true" tabindex="-1"></a><span class="at">own words.</span></span>
<span id="cb795-8979"><a href="#cb795-8979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8980"><a href="#cb795-8980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8981"><a href="#cb795-8981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8982"><a href="#cb795-8982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8983"><a href="#cb795-8983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8984"><a href="#cb795-8984" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8985"><a href="#cb795-8985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8986"><a href="#cb795-8986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8987"><a href="#cb795-8987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8988"><a href="#cb795-8988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8989"><a href="#cb795-8989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8990"><a href="#cb795-8990" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8991"><a href="#cb795-8991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8992"><a href="#cb795-8992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8993"><a href="#cb795-8993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8994"><a href="#cb795-8994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8995"><a href="#cb795-8995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8996"><a href="#cb795-8996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8997"><a href="#cb795-8997" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-8998"><a href="#cb795-8998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-8999"><a href="#cb795-8999" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 7: Interactions</span></span>
<span id="cb795-9000"><a href="#cb795-9000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9001"><a href="#cb795-9001" aria-hidden="true" tabindex="-1"></a>To model deeper conditionality<span class="dv">&amp;mdash;</span> where the importance of one predictor depends upon another predictor<span class="dv">&amp;mdash;</span> we need interaction. Interaction is a kind of conditioning, a way of allowing parameters (really their posterior distributions) to be conditional on further aspects of the data. </span>
<span id="cb795-9002"><a href="#cb795-9002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9003"><a href="#cb795-9003" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9004"><a href="#cb795-9004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9005"><a href="#cb795-9005" aria-hidden="true" tabindex="-1"></a><span class="fu">## Building an interaction</span></span>
<span id="cb795-9006"><a href="#cb795-9006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9007"><a href="#cb795-9007" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.1}</span></span>
<span id="cb795-9008"><a href="#cb795-9008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9009"><a href="#cb795-9009" aria-hidden="true" tabindex="-1"></a><span class="do">## Terrain ruggedness aganist economic performance inside and outside of Africa</span></span>
<span id="cb795-9010"><a href="#cb795-9010" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb795-9011"><a href="#cb795-9011" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(rugged)</span>
<span id="cb795-9012"><a href="#cb795-9012" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> rugged</span>
<span id="cb795-9013"><a href="#cb795-9013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9014"><a href="#cb795-9014" aria-hidden="true" tabindex="-1"></a><span class="co"># make log version of outcome</span></span>
<span id="cb795-9015"><a href="#cb795-9015" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>log_gdp <span class="ot">&lt;-</span> <span class="fu">log</span>( d<span class="sc">$</span>rgdppc_2000 )</span>
<span id="cb795-9016"><a href="#cb795-9016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9017"><a href="#cb795-9017" aria-hidden="true" tabindex="-1"></a><span class="co"># extract countries with GDP data</span></span>
<span id="cb795-9018"><a href="#cb795-9018" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">&lt;-</span> d[ <span class="fu">complete.cases</span>(d<span class="sc">$</span>rgdppc_2000) , ]</span>
<span id="cb795-9019"><a href="#cb795-9019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9020"><a href="#cb795-9020" aria-hidden="true" tabindex="-1"></a><span class="co"># split countries into Africa and not-Africa</span></span>
<span id="cb795-9021"><a href="#cb795-9021" aria-hidden="true" tabindex="-1"></a>d.A1 <span class="ot">&lt;-</span> dd[ dd<span class="sc">$</span>cont_africa<span class="sc">==</span><span class="dv">1</span> , ] <span class="co"># Africa</span></span>
<span id="cb795-9022"><a href="#cb795-9022" aria-hidden="true" tabindex="-1"></a>d.A0 <span class="ot">&lt;-</span> dd[ dd<span class="sc">$</span>cont_africa<span class="sc">==</span><span class="dv">0</span> , ] <span class="co"># not Africa</span></span>
<span id="cb795-9023"><a href="#cb795-9023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9024"><a href="#cb795-9024" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the regression models</span></span>
<span id="cb795-9025"><a href="#cb795-9025" aria-hidden="true" tabindex="-1"></a><span class="co"># African nations</span></span>
<span id="cb795-9026"><a href="#cb795-9026" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.1</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9027"><a href="#cb795-9027" aria-hidden="true" tabindex="-1"></a><span class="fu">alist</span>(  log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9028"><a href="#cb795-9028" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>rugged ,</span>
<span id="cb795-9029"><a href="#cb795-9029" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">8</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9030"><a href="#cb795-9030" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9031"><a href="#cb795-9031" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-9032"><a href="#cb795-9032" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d.A1 )</span>
<span id="cb795-9033"><a href="#cb795-9033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9034"><a href="#cb795-9034" aria-hidden="true" tabindex="-1"></a><span class="co"># non-African nations</span></span>
<span id="cb795-9035"><a href="#cb795-9035" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.2</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9036"><a href="#cb795-9036" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9037"><a href="#cb795-9037" aria-hidden="true" tabindex="-1"></a>        log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9038"><a href="#cb795-9038" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>rugged ,</span>
<span id="cb795-9039"><a href="#cb795-9039" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">8</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9040"><a href="#cb795-9040" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9041"><a href="#cb795-9041" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-9042"><a href="#cb795-9042" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>d.A0 )</span>
<span id="cb795-9043"><a href="#cb795-9043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9044"><a href="#cb795-9044" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the posterior</span></span>
<span id="cb795-9045"><a href="#cb795-9045" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-9046"><a href="#cb795-9046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9047"><a href="#cb795-9047" aria-hidden="true" tabindex="-1"></a><span class="co"># African countries</span></span>
<span id="cb795-9048"><a href="#cb795-9048" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(log_gdp <span class="sc">~</span> rugged, d.A1, <span class="at">col =</span> <span class="st">"slateblue"</span>, <span class="at">main =</span> <span class="st">"Africa"</span>,</span>
<span id="cb795-9049"><a href="#cb795-9049" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"log(rgdppc_2000)"</span>)</span>
<span id="cb795-9050"><a href="#cb795-9050" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m7<span class="fl">.1</span>)</span>
<span id="cb795-9051"><a href="#cb795-9051" aria-hidden="true" tabindex="-1"></a>rugged.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">length.out =</span> <span class="dv">40</span>)</span>
<span id="cb795-9052"><a href="#cb795-9052" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m7<span class="fl">.1</span>, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">rugged =</span> rugged.seq))</span>
<span id="cb795-9053"><a href="#cb795-9053" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI)</span>
<span id="cb795-9054"><a href="#cb795-9054" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, rugged.seq)</span>
<span id="cb795-9055"><a href="#cb795-9055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9056"><a href="#cb795-9056" aria-hidden="true" tabindex="-1"></a><span class="co"># Non-african countries</span></span>
<span id="cb795-9057"><a href="#cb795-9057" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(log_gdp <span class="sc">~</span> rugged, d.A0, <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">main =</span> <span class="st">"not Africa"</span>,</span>
<span id="cb795-9058"><a href="#cb795-9058" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"log(rgdppc_2000)"</span>)</span>
<span id="cb795-9059"><a href="#cb795-9059" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m7<span class="fl">.2</span>)</span>
<span id="cb795-9060"><a href="#cb795-9060" aria-hidden="true" tabindex="-1"></a>rugged.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">to =</span> <span class="dv">6</span>, <span class="at">length.out =</span> <span class="dv">40</span>)</span>
<span id="cb795-9061"><a href="#cb795-9061" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">link</span>(m7<span class="fl">.2</span>, <span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">rugged =</span> rugged.seq))</span>
<span id="cb795-9062"><a href="#cb795-9062" aria-hidden="true" tabindex="-1"></a>mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>(mu, <span class="dv">2</span>, PI)</span>
<span id="cb795-9063"><a href="#cb795-9063" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.PI, rugged.seq)</span>
<span id="cb795-9064"><a href="#cb795-9064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9065"><a href="#cb795-9065" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate linear regressions inside and outside of Africa, for log-GDP against terrain ruggedness. </span></span>
<span id="cb795-9066"><a href="#cb795-9066" aria-hidden="true" tabindex="-1"></a><span class="co"># The slope is positive inside Africa, but negative outside. How can we recover this reversal of </span></span>
<span id="cb795-9067"><a href="#cb795-9067" aria-hidden="true" tabindex="-1"></a><span class="co"># the slope, using the combined data?</span></span>
<span id="cb795-9068"><a href="#cb795-9068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9069"><a href="#cb795-9069" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9070"><a href="#cb795-9070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9071"><a href="#cb795-9071" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9072"><a href="#cb795-9072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9073"><a href="#cb795-9073" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***How do we discover and describe such a reversal in the context of a regression model?***<span class="kw">&lt;/span&gt;</span> </span>
<span id="cb795-9074"><a href="#cb795-9074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9075"><a href="#cb795-9075" aria-hidden="true" tabindex="-1"></a>The plots above cheat, because they split the data into two data frames. But it’s not a good idea to split the data in this way. Here are four, of many, reasons.</span>
<span id="cb795-9076"><a href="#cb795-9076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9077"><a href="#cb795-9077" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>There are usually some parameters, such as $\sigma$, that the model says do not depend in any way upon an African identity for each nation. By splitting the data table, you are hurting the accuracy of the estimates for these parameters, because you are essentially making two less-accurate estimates instead of pooling all of the evidence into one estimate. In effect, you have accidentally assumed that variance differs between African and non-African nations. Now, there’s nothing wrong with that sort of assumption. But you want to avoid accidental assumptions.</span>
<span id="cb795-9078"><a href="#cb795-9078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9079"><a href="#cb795-9079" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>In order to acquire probability statements about the variable you used to split the data, <span class="in">`cont_africa`</span> in this case, you need to include it in the model. Otherwise, you have only the weakest sort of statistical argument. Isn’t there uncertainty about the predictive value of distinguishing between African and non-African nations? Of course there is. Unless you analyze all of the data in a single model, you can’t easily quantify that uncertainty. If you just let the posterior distribution do the work for you, you’ll have a useful measure of that uncertainty.</span>
<span id="cb795-9080"><a href="#cb795-9080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9081"><a href="#cb795-9081" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We may want to use information criteria or another method to compare models. In order to compare a model that treats all continents the same way to a model that allows different slopes in different continents, we need models that use all of the same data. This means we can’t split the data, but have to make the model split the data.</span>
<span id="cb795-9082"><a href="#cb795-9082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9083"><a href="#cb795-9083" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>There are advantages to borrowing information across categories like “Africa” and “not Africa.” This is especially true when sample sizes vary across categories, such that overfitting risk is higher within some categories. In other words, what we learn about ruggedness outside of Africa should have some effect on our estimate within Africa, and visa versa.</span>
<span id="cb795-9084"><a href="#cb795-9084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9085"><a href="#cb795-9085" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9086"><a href="#cb795-9086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9087"><a href="#cb795-9087" aria-hidden="true" tabindex="-1"></a><span class="fu">### Adding a dummy variable doesn't work</span></span>
<span id="cb795-9088"><a href="#cb795-9088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9089"><a href="#cb795-9089" aria-hidden="true" tabindex="-1"></a>The first thing to realize is that just including the categorical variable (dummy variable) <span class="in">`cont_africa`</span> won’t reveal the reversed slope. The question is to what extent singling out African nations changes predictions.</span>
<span id="cb795-9090"><a href="#cb795-9090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9091"><a href="#cb795-9091" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.3}</span></span>
<span id="cb795-9092"><a href="#cb795-9092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9093"><a href="#cb795-9093" aria-hidden="true" tabindex="-1"></a><span class="co"># First model: simple linear regression of log-GDP on ruggedness for entire data set</span></span>
<span id="cb795-9094"><a href="#cb795-9094" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.3</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9095"><a href="#cb795-9095" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9096"><a href="#cb795-9096" aria-hidden="true" tabindex="-1"></a>        log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9097"><a href="#cb795-9097" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>rugged ,</span>
<span id="cb795-9098"><a href="#cb795-9098" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">8</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9099"><a href="#cb795-9099" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9100"><a href="#cb795-9100" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> ) ),</span>
<span id="cb795-9101"><a href="#cb795-9101" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>dd )</span>
<span id="cb795-9102"><a href="#cb795-9102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9103"><a href="#cb795-9103" aria-hidden="true" tabindex="-1"></a><span class="co"># Second model: the model that includes a dummy variable for African nations</span></span>
<span id="cb795-9104"><a href="#cb795-9104" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.4</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9105"><a href="#cb795-9105" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9106"><a href="#cb795-9106" aria-hidden="true" tabindex="-1"></a>        log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9107"><a href="#cb795-9107" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>rugged <span class="sc">+</span> bA<span class="sc">*</span>cont_africa ,</span>
<span id="cb795-9108"><a href="#cb795-9108" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">8</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9109"><a href="#cb795-9109" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9110"><a href="#cb795-9110" aria-hidden="true" tabindex="-1"></a>        bA <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9111"><a href="#cb795-9111" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-9112"><a href="#cb795-9112" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>dd )</span>
<span id="cb795-9113"><a href="#cb795-9113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9114"><a href="#cb795-9114" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the two models using WAIC</span></span>
<span id="cb795-9115"><a href="#cb795-9115" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>( m7<span class="fl">.3</span> , m7<span class="fl">.4</span> )</span>
<span id="cb795-9116"><a href="#cb795-9116" aria-hidden="true" tabindex="-1"></a><span class="co"># While the standard error of the difference in WAIC is 15, the difference itself is 63, </span></span>
<span id="cb795-9117"><a href="#cb795-9117" aria-hidden="true" tabindex="-1"></a><span class="co"># implying a 95% interval of 63 ± 30. So the continent predictor variable seems to be picking </span></span>
<span id="cb795-9118"><a href="#cb795-9118" aria-hidden="true" tabindex="-1"></a><span class="co"># up something important to the sample, even accounting for expected overfitting.</span></span>
<span id="cb795-9119"><a href="#cb795-9119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9120"><a href="#cb795-9120" aria-hidden="true" tabindex="-1"></a><span class="do">## Now let’s plot the posterior predictions for m7.4, so you can see how, despite it’s plausible </span></span>
<span id="cb795-9121"><a href="#cb795-9121" aria-hidden="true" tabindex="-1"></a><span class="do">## superiority to m7.3, it still doesn’t manage different slopes inside and outside of Africa.</span></span>
<span id="cb795-9122"><a href="#cb795-9122" aria-hidden="true" tabindex="-1"></a><span class="co"># To sample from the posterior and compute the predicted means and intervals for </span></span>
<span id="cb795-9123"><a href="#cb795-9123" aria-hidden="true" tabindex="-1"></a><span class="co"># both African and non-African nations</span></span>
<span id="cb795-9124"><a href="#cb795-9124" aria-hidden="true" tabindex="-1"></a>rugged.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="sc">-</span><span class="dv">1</span>,<span class="at">to=</span><span class="dv">8</span>,<span class="at">by=</span><span class="fl">0.25</span>)</span>
<span id="cb795-9125"><a href="#cb795-9125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9126"><a href="#cb795-9126" aria-hidden="true" tabindex="-1"></a><span class="co"># compute mu over samples, fixing cont_africa=0</span></span>
<span id="cb795-9127"><a href="#cb795-9127" aria-hidden="true" tabindex="-1"></a>mu.NotAfrica <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.4</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">cont_africa=</span><span class="dv">0</span>,<span class="at">rugged=</span>rugged.seq) )</span>
<span id="cb795-9128"><a href="#cb795-9128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9129"><a href="#cb795-9129" aria-hidden="true" tabindex="-1"></a><span class="co"># compute mu over samples, fixing cont_africa=1</span></span>
<span id="cb795-9130"><a href="#cb795-9130" aria-hidden="true" tabindex="-1"></a>mu.Africa <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.4</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">cont_africa=</span><span class="dv">1</span>,<span class="at">rugged=</span>rugged.seq) )</span>
<span id="cb795-9131"><a href="#cb795-9131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9132"><a href="#cb795-9132" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize to means and intervals</span></span>
<span id="cb795-9133"><a href="#cb795-9133" aria-hidden="true" tabindex="-1"></a>mu.NotAfrica.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.NotAfrica , <span class="dv">2</span> , mean )</span>
<span id="cb795-9134"><a href="#cb795-9134" aria-hidden="true" tabindex="-1"></a>mu.NotAfrica.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.NotAfrica , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9135"><a href="#cb795-9135" aria-hidden="true" tabindex="-1"></a>mu.Africa.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.Africa , <span class="dv">2</span> , mean )</span>
<span id="cb795-9136"><a href="#cb795-9136" aria-hidden="true" tabindex="-1"></a>mu.Africa.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.Africa , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9137"><a href="#cb795-9137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9138"><a href="#cb795-9138" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the posterior</span></span>
<span id="cb795-9139"><a href="#cb795-9139" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mu.Africa.mean <span class="sc">~</span> rugged.seq, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">col =</span> <span class="st">"#446CCF"</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">11</span>), </span>
<span id="cb795-9140"><a href="#cb795-9140" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">6</span>), <span class="at">xlab =</span> <span class="st">"Terrain Ruggedness Index"</span>, <span class="at">ylab =</span> <span class="st">"log GDP year 2000"</span>)</span>
<span id="cb795-9141"><a href="#cb795-9141" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(mu.NotAfrica.mean <span class="sc">~</span> rugged.seq, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb795-9142"><a href="#cb795-9142" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.Africa.PI, rugged.seq, <span class="at">col =</span> <span class="fu">col.alpha</span>(<span class="st">"#446CCF"</span>, <span class="fl">0.3</span>))</span>
<span id="cb795-9143"><a href="#cb795-9143" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>(mu.NotAfrica.PI, rugged.seq)</span>
<span id="cb795-9144"><a href="#cb795-9144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9145"><a href="#cb795-9145" aria-hidden="true" tabindex="-1"></a><span class="co"># Add data points for log_gdp ~ rugged</span></span>
<span id="cb795-9146"><a href="#cb795-9146" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(dd<span class="sc">$</span>rugged[dd<span class="sc">$</span>cont_africa <span class="sc">==</span> <span class="dv">1</span>], dd<span class="sc">$</span>log_gdp[dd<span class="sc">$</span>cont_africa <span class="sc">==</span> <span class="dv">1</span>], <span class="at">col =</span> <span class="st">"#446CCF"</span>, <span class="at">pch =</span> <span class="dv">1</span>)</span>
<span id="cb795-9147"><a href="#cb795-9147" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(dd<span class="sc">$</span>rugged[dd<span class="sc">$</span>cont_africa <span class="sc">==</span> <span class="dv">0</span>], dd<span class="sc">$</span>log_gdp[dd<span class="sc">$</span>cont_africa <span class="sc">==</span> <span class="dv">0</span>], <span class="at">col =</span> <span class="st">"black"</span>, <span class="at">pch =</span> <span class="dv">1</span>)</span>
<span id="cb795-9148"><a href="#cb795-9148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9149"><a href="#cb795-9149" aria-hidden="true" tabindex="-1"></a><span class="co"># Add text</span></span>
<span id="cb795-9150"><a href="#cb795-9150" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">4</span>, <span class="fl">6.5</span>, <span class="st">"Africa"</span>, <span class="at">col =</span> <span class="st">"#446CCF"</span>)</span>
<span id="cb795-9151"><a href="#cb795-9151" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">4</span>, <span class="fl">9.4</span>, <span class="st">"not Africa"</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb795-9152"><a href="#cb795-9152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9153"><a href="#cb795-9153" aria-hidden="true" tabindex="-1"></a><span class="co"># Including a dummy variable for African nations has no effect on the slope. African nations </span></span>
<span id="cb795-9154"><a href="#cb795-9154" aria-hidden="true" tabindex="-1"></a><span class="co"># are shown in blue. Non-African nations are shown in gray. Regression means for each subset </span></span>
<span id="cb795-9155"><a href="#cb795-9155" aria-hidden="true" tabindex="-1"></a><span class="co"># of nations are shown in corresponding colors, along with 97% intervals shown by shading.</span></span>
<span id="cb795-9156"><a href="#cb795-9156" aria-hidden="true" tabindex="-1"></a><span class="do">## The fact that WAIC tells you that the model with the dummy variable is hugely better only</span></span>
<span id="cb795-9157"><a href="#cb795-9157" aria-hidden="true" tabindex="-1"></a><span class="do">## indicates that African nations on average do have lower GDP.</span></span>
<span id="cb795-9158"><a href="#cb795-9158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9159"><a href="#cb795-9159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9160"><a href="#cb795-9160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9161"><a href="#cb795-9161" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9162"><a href="#cb795-9162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9163"><a href="#cb795-9163" aria-hidden="true" tabindex="-1"></a><span class="fu">### Adding a linear interaction does work</span></span>
<span id="cb795-9164"><a href="#cb795-9164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9165"><a href="#cb795-9165" aria-hidden="true" tabindex="-1"></a>A proper interaction effect is needed to recover the change in slope you saw at the start of this section. The likelihood for the model you just plotted, in math form, is:</span>
<span id="cb795-9166"><a href="#cb795-9166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9167"><a href="#cb795-9167" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9168"><a href="#cb795-9168" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9169"><a href="#cb795-9169" aria-hidden="true" tabindex="-1"></a>\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-9170"><a href="#cb795-9170" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_R R_i + \beta_A A_i</span>
<span id="cb795-9171"><a href="#cb795-9171" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9172"><a href="#cb795-9172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9173"><a href="#cb795-9173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9174"><a href="#cb795-9174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9175"><a href="#cb795-9175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9176"><a href="#cb795-9176" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9177"><a href="#cb795-9177" aria-hidden="true" tabindex="-1"></a><span class="in">Y   = log(rgdppc_2000)</span></span>
<span id="cb795-9178"><a href="#cb795-9178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9179"><a href="#cb795-9179" aria-hidden="true" tabindex="-1"></a><span class="in">A   = cont_africa</span></span>
<span id="cb795-9180"><a href="#cb795-9180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9181"><a href="#cb795-9181" aria-hidden="true" tabindex="-1"></a><span class="in">R   = rugged</span></span>
<span id="cb795-9182"><a href="#cb795-9182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9183"><a href="#cb795-9183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9184"><a href="#cb795-9184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9185"><a href="#cb795-9185" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9186"><a href="#cb795-9186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9187"><a href="#cb795-9187" aria-hidden="true" tabindex="-1"></a>Now you want to allow the relationship between Y and R to vary as a function of A. Within the model, this relationship is measured by the slope $\beta_R$. Following the same strategy of replacing parameters with linear models, the most straightforward way to make $\beta_R$ depend upon $A$ is just to define the slope $\beta_R$ as a linear model itself, one that includes $A$.</span>
<span id="cb795-9188"><a href="#cb795-9188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9189"><a href="#cb795-9189" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9190"><a href="#cb795-9190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9191"><a href="#cb795-9191" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9192"><a href="#cb795-9192" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9193"><a href="#cb795-9193" aria-hidden="true" tabindex="-1"></a>\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">likelihood</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb795-9194"><a href="#cb795-9194" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \gamma_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">linear model of}~\mu</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-9195"><a href="#cb795-9195" aria-hidden="true" tabindex="-1"></a>\gamma_i &amp;= \beta_R + \beta_{AR} A_i &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">linear model of slope</span><span class="co">]</span>}</span>
<span id="cb795-9196"><a href="#cb795-9196" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9197"><a href="#cb795-9197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9198"><a href="#cb795-9198" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9199"><a href="#cb795-9199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9200"><a href="#cb795-9200" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9201"><a href="#cb795-9201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9202"><a href="#cb795-9202" aria-hidden="true" tabindex="-1"></a>By defining the relationship between GDP and ruggedness in this way, you are explicitly modeling the hypothesis that the slope between GDP and ruggedness depends<span class="dv">&amp;mdash;</span> is *conditional*<span class="dv">&amp;mdash;</span> upon whether or not a nation is in Africa. The parameter $\beta_{AR}$ defines the strength of this dependency. If you set $\beta_{AR}$ = 0, then you get the previous model back. If instead $\beta_{AR}$ &gt; 0, then African nations have a more positive slope between GDP and ruggedness. If $\beta_{AR}$ &lt; 0, African nations have a more negative slope. For any nation not in Africa, $A_i$ = 0 and so the interaction parameter $\beta_{AR}$ has no effect on prediction for that nation.</span>
<span id="cb795-9203"><a href="#cb795-9203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9204"><a href="#cb795-9204" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9205"><a href="#cb795-9205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9206"><a href="#cb795-9206" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.7}</span></span>
<span id="cb795-9207"><a href="#cb795-9207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9208"><a href="#cb795-9208" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model that includes an interaction between ruggedness and being in Africa</span></span>
<span id="cb795-9209"><a href="#cb795-9209" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.5</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9210"><a href="#cb795-9210" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9211"><a href="#cb795-9211" aria-hidden="true" tabindex="-1"></a>        log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9212"><a href="#cb795-9212" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> gamma<span class="sc">*</span>rugged <span class="sc">+</span> bA<span class="sc">*</span>cont_africa ,</span>
<span id="cb795-9213"><a href="#cb795-9213" aria-hidden="true" tabindex="-1"></a>        gamma <span class="ot">&lt;-</span> bR <span class="sc">+</span> bAR<span class="sc">*</span>cont_africa ,</span>
<span id="cb795-9214"><a href="#cb795-9214" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">8</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9215"><a href="#cb795-9215" aria-hidden="true" tabindex="-1"></a>        bA <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9216"><a href="#cb795-9216" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9217"><a href="#cb795-9217" aria-hidden="true" tabindex="-1"></a>        bAR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9218"><a href="#cb795-9218" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-9219"><a href="#cb795-9219" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>dd )</span>
<span id="cb795-9220"><a href="#cb795-9220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9221"><a href="#cb795-9221" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m7<span class="fl">.5</span>)</span>
<span id="cb795-9222"><a href="#cb795-9222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9223"><a href="#cb795-9223" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the new model to the previous two using WAIC</span></span>
<span id="cb795-9224"><a href="#cb795-9224" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>(m7<span class="fl">.3</span>, m7<span class="fl">.4</span>, m7<span class="fl">.5</span>)</span>
<span id="cb795-9225"><a href="#cb795-9225" aria-hidden="true" tabindex="-1"></a><span class="co"># The modicum of weight given to m7.4 suggests that the posterior means for the slopes in m7.5 </span></span>
<span id="cb795-9226"><a href="#cb795-9226" aria-hidden="true" tabindex="-1"></a><span class="co"># are a little overfit. And the standard error of the difference in WAIC between the top two </span></span>
<span id="cb795-9227"><a href="#cb795-9227" aria-hidden="true" tabindex="-1"></a><span class="co"># models is almost the same as the difference itself. </span></span>
<span id="cb795-9228"><a href="#cb795-9228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9229"><a href="#cb795-9229" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9230"><a href="#cb795-9230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9231"><a href="#cb795-9231" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9232"><a href="#cb795-9232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9233"><a href="#cb795-9233" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:purple"</span><span class="kw">&gt;</span>***Conventional form of interaction***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-9234"><a href="#cb795-9234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9235"><a href="#cb795-9235" aria-hidden="true" tabindex="-1"></a>Instead of a model definition with more than one linear model, as you saw above, it’s conventional to multiply out any interaction effects, so that there is only one linear model. The equation for $\gamma$ can be substituted into the second line and expanded.</span>
<span id="cb795-9236"><a href="#cb795-9236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9237"><a href="#cb795-9237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9238"><a href="#cb795-9238" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9239"><a href="#cb795-9239" aria-hidden="true" tabindex="-1"></a>\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">likelihood</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb795-9240"><a href="#cb795-9240" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_R R_i + \beta_{AR} A_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">linear model of}~\mu</span><span class="co">]</span></span>
<span id="cb795-9241"><a href="#cb795-9241" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9242"><a href="#cb795-9242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9243"><a href="#cb795-9243" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9244"><a href="#cb795-9244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9245"><a href="#cb795-9245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9246"><a href="#cb795-9246" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9247"><a href="#cb795-9247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9248"><a href="#cb795-9248" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.9}</span></span>
<span id="cb795-9249"><a href="#cb795-9249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9250"><a href="#cb795-9250" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.5</span>b <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9251"><a href="#cb795-9251" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9252"><a href="#cb795-9252" aria-hidden="true" tabindex="-1"></a>        log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9253"><a href="#cb795-9253" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>rugged <span class="sc">+</span> bAR<span class="sc">*</span>rugged<span class="sc">*</span>cont_africa <span class="sc">+</span> bA<span class="sc">*</span>cont_africa,</span>
<span id="cb795-9254"><a href="#cb795-9254" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">8</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9255"><a href="#cb795-9255" aria-hidden="true" tabindex="-1"></a>        bA <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9256"><a href="#cb795-9256" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9257"><a href="#cb795-9257" aria-hidden="true" tabindex="-1"></a>        bAR <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">1</span> ) ,</span>
<span id="cb795-9258"><a href="#cb795-9258" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">10</span> )</span>
<span id="cb795-9259"><a href="#cb795-9259" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>dd )</span>
<span id="cb795-9260"><a href="#cb795-9260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9261"><a href="#cb795-9261" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m7<span class="fl">.5</span>b)</span>
<span id="cb795-9262"><a href="#cb795-9262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9263"><a href="#cb795-9263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9264"><a href="#cb795-9264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9265"><a href="#cb795-9265" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9266"><a href="#cb795-9266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9267"><a href="#cb795-9267" aria-hidden="true" tabindex="-1"></a><span class="fu">### Plotting the interaction</span></span>
<span id="cb795-9268"><a href="#cb795-9268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9269"><a href="#cb795-9269" aria-hidden="true" tabindex="-1"></a>The goal is to make two plots. In the first, we’ll display nations in Africa and overlay the posterior mean (MAP) regression line and the 97% interval of that line. In the second, we’ll display nations outside of Africa instead.</span>
<span id="cb795-9270"><a href="#cb795-9270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9271"><a href="#cb795-9271" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.10}</span></span>
<span id="cb795-9272"><a href="#cb795-9272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9273"><a href="#cb795-9273" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the necessary posterior mean line and interval, for both plots</span></span>
<span id="cb795-9274"><a href="#cb795-9274" aria-hidden="true" tabindex="-1"></a>rugged.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from=</span><span class="sc">-</span><span class="dv">1</span>,<span class="at">to=</span><span class="dv">8</span>,<span class="at">by=</span><span class="fl">0.25</span>)</span>
<span id="cb795-9275"><a href="#cb795-9275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9276"><a href="#cb795-9276" aria-hidden="true" tabindex="-1"></a>mu.Africa <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.5</span>b , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">cont_africa=</span><span class="dv">1</span>,<span class="at">rugged=</span>rugged.seq) )</span>
<span id="cb795-9277"><a href="#cb795-9277" aria-hidden="true" tabindex="-1"></a>mu.Africa.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.Africa , <span class="dv">2</span> , mean )</span>
<span id="cb795-9278"><a href="#cb795-9278" aria-hidden="true" tabindex="-1"></a>mu.Africa.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.Africa , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9279"><a href="#cb795-9279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9280"><a href="#cb795-9280" aria-hidden="true" tabindex="-1"></a>mu.NotAfrica <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.5</span>b , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">cont_africa=</span><span class="dv">0</span>,<span class="at">rugged=</span>rugged.seq) )</span>
<span id="cb795-9281"><a href="#cb795-9281" aria-hidden="true" tabindex="-1"></a>mu.NotAfrica.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.NotAfrica , <span class="dv">2</span> , mean )</span>
<span id="cb795-9282"><a href="#cb795-9282" aria-hidden="true" tabindex="-1"></a>mu.NotAfrica.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.NotAfrica , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9283"><a href="#cb795-9283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9284"><a href="#cb795-9284" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb795-9285"><a href="#cb795-9285" aria-hidden="true" tabindex="-1"></a><span class="co"># plot African nations with regression</span></span>
<span id="cb795-9286"><a href="#cb795-9286" aria-hidden="true" tabindex="-1"></a>d.A1 <span class="ot">&lt;-</span> dd[dd<span class="sc">$</span>cont_africa<span class="sc">==</span><span class="dv">1</span>,]</span>
<span id="cb795-9287"><a href="#cb795-9287" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( <span class="fu">log</span>(rgdppc_2000) <span class="sc">~</span> rugged , <span class="at">data=</span>d.A1 ,</span>
<span id="cb795-9288"><a href="#cb795-9288" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>rangi2 , <span class="at">ylab=</span><span class="st">"log GDP year 2000"</span> ,</span>
<span id="cb795-9289"><a href="#cb795-9289" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">"Terrain Ruggedness Index"</span> )</span>
<span id="cb795-9290"><a href="#cb795-9290" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">"African nations"</span> , <span class="dv">3</span> )</span>
<span id="cb795-9291"><a href="#cb795-9291" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( rugged.seq , mu.Africa.mean , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-9292"><a href="#cb795-9292" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.Africa.PI , rugged.seq , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.3</span>) )</span>
<span id="cb795-9293"><a href="#cb795-9293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9294"><a href="#cb795-9294" aria-hidden="true" tabindex="-1"></a><span class="co"># plot non-African nations with regression</span></span>
<span id="cb795-9295"><a href="#cb795-9295" aria-hidden="true" tabindex="-1"></a>d.A0 <span class="ot">&lt;-</span> dd[dd<span class="sc">$</span>cont_africa<span class="sc">==</span><span class="dv">0</span>,]</span>
<span id="cb795-9296"><a href="#cb795-9296" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( <span class="fu">log</span>(rgdppc_2000) <span class="sc">~</span> rugged , <span class="at">data=</span>d.A0 ,</span>
<span id="cb795-9297"><a href="#cb795-9297" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="st">"black"</span> , <span class="at">ylab=</span><span class="st">"log GDP year 2000"</span> ,</span>
<span id="cb795-9298"><a href="#cb795-9298" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">"Terrain Ruggedness Index"</span> )</span>
<span id="cb795-9299"><a href="#cb795-9299" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span>( <span class="st">"Non-African nations"</span> , <span class="dv">3</span> )</span>
<span id="cb795-9300"><a href="#cb795-9300" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( rugged.seq , mu.NotAfrica.mean )</span>
<span id="cb795-9301"><a href="#cb795-9301" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.NotAfrica.PI , rugged.seq )</span>
<span id="cb795-9302"><a href="#cb795-9302" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior predictions for the terrain ruggedness model,including the interaction between </span></span>
<span id="cb795-9303"><a href="#cb795-9303" aria-hidden="true" tabindex="-1"></a><span class="co"># Africa and ruggedness. Shaded regions are 97% posterior intervals of the mean.</span></span>
<span id="cb795-9304"><a href="#cb795-9304" aria-hidden="true" tabindex="-1"></a><span class="do">## Finally, the slope reverses direction inside and outside of Africa.</span></span>
<span id="cb795-9305"><a href="#cb795-9305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9306"><a href="#cb795-9306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9307"><a href="#cb795-9307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9308"><a href="#cb795-9308" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9309"><a href="#cb795-9309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9310"><a href="#cb795-9310" aria-hidden="true" tabindex="-1"></a><span class="fu">### Interpreting an interaction estimate</span></span>
<span id="cb795-9311"><a href="#cb795-9311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9312"><a href="#cb795-9312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9313"><a href="#cb795-9313" aria-hidden="true" tabindex="-1"></a>There are two basic reasons to be wary of interpreting tables of posterior means and standard deviations as a way to understanding interactions.</span>
<span id="cb795-9314"><a href="#cb795-9314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9315"><a href="#cb795-9315" aria-hidden="true" tabindex="-1"></a>(1) When you add an interaction to a model, this changes the meanings of the parameters. A “main effect” coefficient in an interaction model does not mean the same thing as a coefficient of the same name in a model without an interaction. Their distributions cannot usually be directly compared.</span>
<span id="cb795-9316"><a href="#cb795-9316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9317"><a href="#cb795-9317" aria-hidden="true" tabindex="-1"></a>(2) Tables of numbers don’t make it easy to fully incorporate uncertainty in our thinking, since covariance among parameters isn’t usually shown. And this gets much harder once the influence of a predictor depends upon multiple parameters.</span>
<span id="cb795-9318"><a href="#cb795-9318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9319"><a href="#cb795-9319" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9320"><a href="#cb795-9320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9321"><a href="#cb795-9321" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Parameters change meaning</span></span>
<span id="cb795-9322"><a href="#cb795-9322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9323"><a href="#cb795-9323" aria-hidden="true" tabindex="-1"></a>Unlike in the simple linear regression models, you can no longer read the influence of either predictor from the table of estimates in interaction models:</span>
<span id="cb795-9324"><a href="#cb795-9324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9325"><a href="#cb795-9325" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9326"><a href="#cb795-9326" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9327"><a href="#cb795-9327" aria-hidden="true" tabindex="-1"></a>\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">likelihood</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb795-9328"><a href="#cb795-9328" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \gamma_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">linear model of}~\mu</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-9329"><a href="#cb795-9329" aria-hidden="true" tabindex="-1"></a>\gamma_i &amp;= \beta_R + \beta_{AR} A_i &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">linear model of slope</span><span class="co">]</span>}</span>
<span id="cb795-9330"><a href="#cb795-9330" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9331"><a href="#cb795-9331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9332"><a href="#cb795-9332" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9333"><a href="#cb795-9333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9334"><a href="#cb795-9334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9335"><a href="#cb795-9335" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9336"><a href="#cb795-9336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9337"><a href="#cb795-9337" aria-hidden="true" tabindex="-1"></a>Now the change in $\mu_i$ that results from a unit change in $R_i$ is given by $\gamma_i$. And since $\gamma_i$ is a function of three things<span class="dv">&amp;mdash;</span> $\beta_R$, $\beta_{AR}$, and $A_i$<span class="dv">&amp;mdash;</span> we have to know all three in order to know the influence of $R_i$ on the outcome. The only time the slope $\beta_R$ has its old meaning is when $A_i = 0$, which makes $\gamma_i = \beta_R$. Otherwise, to compute the influence of $R_i$ on the outcome, we have to simultaneously consider two parameters and another predictor variable.</span>
<span id="cb795-9338"><a href="#cb795-9338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9339"><a href="#cb795-9339" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.12}</span></span>
<span id="cb795-9340"><a href="#cb795-9340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9341"><a href="#cb795-9341" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m7<span class="fl">.5</span>)</span>
<span id="cb795-9342"><a href="#cb795-9342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9343"><a href="#cb795-9343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9344"><a href="#cb795-9344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9345"><a href="#cb795-9345" aria-hidden="true" tabindex="-1"></a>Since $\gamma$ (gamma) doesn’t appear in this table<span class="dv">&amp;mdash;</span> it wasn’t estimated<span class="dv">&amp;mdash;</span> we have to compute it ourselves. </span>
<span id="cb795-9346"><a href="#cb795-9346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9347"><a href="#cb795-9347" aria-hidden="true" tabindex="-1"></a>For example, the ***MAP*** slope relating ruggedness to log-GDP within Africa is:</span>
<span id="cb795-9348"><a href="#cb795-9348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9349"><a href="#cb795-9349" aria-hidden="true" tabindex="-1"></a>$$\gamma = \beta_R + \beta_{AR}(1) = −0.18 + 0.35 = 0.17$$</span>
<span id="cb795-9350"><a href="#cb795-9350" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9351"><a href="#cb795-9351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9352"><a href="#cb795-9352" aria-hidden="true" tabindex="-1"></a>And outside of Africa:</span>
<span id="cb795-9353"><a href="#cb795-9353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9354"><a href="#cb795-9354" aria-hidden="true" tabindex="-1"></a>$$\gamma = \beta_R + \beta_{AR}(0) = -0.18$$</span>
<span id="cb795-9355"><a href="#cb795-9355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9356"><a href="#cb795-9356" aria-hidden="true" tabindex="-1"></a>So the relationship between ruggedness and log-GDP is essentially reversed inside and out-side of Africa.</span>
<span id="cb795-9357"><a href="#cb795-9357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9358"><a href="#cb795-9358" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9359"><a href="#cb795-9359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9360"><a href="#cb795-9360" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Incorporating uncertainty</span></span>
<span id="cb795-9361"><a href="#cb795-9361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9362"><a href="#cb795-9362" aria-hidden="true" tabindex="-1"></a>Anything calculated using parameters has a distribution. Since $\gamma$ depends upon parameters, and those parameters have a posterior distribution, $\gamma$ must also have a posterior distribution.</span>
<span id="cb795-9363"><a href="#cb795-9363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9364"><a href="#cb795-9364" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.13}</span></span>
<span id="cb795-9365"><a href="#cb795-9365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9366"><a href="#cb795-9366" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the posterior distribution of γ using samples from posterior</span></span>
<span id="cb795-9367"><a href="#cb795-9367" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m7<span class="fl">.5</span> )</span>
<span id="cb795-9368"><a href="#cb795-9368" aria-hidden="true" tabindex="-1"></a>gamma.Africa <span class="ot">&lt;-</span> post<span class="sc">$</span>bR <span class="sc">+</span> post<span class="sc">$</span>bAR<span class="sc">*</span><span class="dv">1</span></span>
<span id="cb795-9369"><a href="#cb795-9369" aria-hidden="true" tabindex="-1"></a>gamma.notAfrica <span class="ot">&lt;-</span> post<span class="sc">$</span>bR <span class="sc">+</span> post<span class="sc">$</span>bAR<span class="sc">*</span><span class="dv">0</span></span>
<span id="cb795-9370"><a href="#cb795-9370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9371"><a href="#cb795-9371" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate means of the distributions</span></span>
<span id="cb795-9372"><a href="#cb795-9372" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(gamma.Africa)</span>
<span id="cb795-9373"><a href="#cb795-9373" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(gamma.notAfrica)</span>
<span id="cb795-9374"><a href="#cb795-9374" aria-hidden="true" tabindex="-1"></a><span class="co"># Nearly identical to the MAP values, of course.</span></span>
<span id="cb795-9375"><a href="#cb795-9375" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we have full distributions of the slopes within and outside of Africa. </span></span>
<span id="cb795-9376"><a href="#cb795-9376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9377"><a href="#cb795-9377" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the distributions on the same axis</span></span>
<span id="cb795-9378"><a href="#cb795-9378" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>( gamma.Africa , <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>,<span class="fl">0.6</span>) , <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">5.5</span>) ,</span>
<span id="cb795-9379"><a href="#cb795-9379" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">"gamma"</span> , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-9380"><a href="#cb795-9380" aria-hidden="true" tabindex="-1"></a><span class="fu">dens</span>( gamma.notAfrica , <span class="at">add=</span><span class="cn">TRUE</span> )</span>
<span id="cb795-9381"><a href="#cb795-9381" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topright"</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">"Africa"</span>, <span class="st">"Not Africa"</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="st">"blue"</span>, <span class="st">"black"</span>), <span class="at">lty =</span> <span class="dv">1</span>)</span>
<span id="cb795-9382"><a href="#cb795-9382" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior distributions of the slope relating terrain ruggedness to log-GDP. </span></span>
<span id="cb795-9383"><a href="#cb795-9383" aria-hidden="true" tabindex="-1"></a><span class="co"># Blue: African nations. Black: non-African nations.</span></span>
<span id="cb795-9384"><a href="#cb795-9384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9385"><a href="#cb795-9385" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9386"><a href="#cb795-9386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9387"><a href="#cb795-9387" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9388"><a href="#cb795-9388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9389"><a href="#cb795-9389" aria-hidden="true" tabindex="-1"></a>From here, you could use the samples to ask a bunch of questions, depending upon your interest. For example, what’s the probability (according to this model and these data) that the slope within Africa is less than the slope outside of Africa? All we need to do is compute the difference between the slopes, for each sample from the posterior, and then ask what proportion of these differences is below zero.</span>
<span id="cb795-9390"><a href="#cb795-9390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9391"><a href="#cb795-9391" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.16}</span></span>
<span id="cb795-9392"><a href="#cb795-9392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9393"><a href="#cb795-9393" aria-hidden="true" tabindex="-1"></a>diff <span class="ot">&lt;-</span> gamma.Africa <span class="sc">-</span> gamma.notAfrica</span>
<span id="cb795-9394"><a href="#cb795-9394" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>( diff <span class="sc">&lt;</span> <span class="dv">0</span> ) <span class="sc">/</span> <span class="fu">length</span>( diff )</span>
<span id="cb795-9395"><a href="#cb795-9395" aria-hidden="true" tabindex="-1"></a><span class="co"># So conditional on this model and these data, it’s highly implausible that the slope </span></span>
<span id="cb795-9396"><a href="#cb795-9396" aria-hidden="true" tabindex="-1"></a><span class="co"># association ruggedness with log-GDP is lower inside Africa than outside it.</span></span>
<span id="cb795-9397"><a href="#cb795-9397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9398"><a href="#cb795-9398" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's try the reverse</span></span>
<span id="cb795-9399"><a href="#cb795-9399" aria-hidden="true" tabindex="-1"></a>diff <span class="ot">&lt;-</span> gamma.notAfrica <span class="sc">-</span> gamma.Africa</span>
<span id="cb795-9400"><a href="#cb795-9400" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>( diff <span class="sc">&lt;</span> <span class="dv">0</span> ) <span class="sc">/</span> <span class="fu">length</span>( diff )</span>
<span id="cb795-9401"><a href="#cb795-9401" aria-hidden="true" tabindex="-1"></a><span class="co"># So, it's highly plausible that the slope association ruggedness with log-GDP is </span></span>
<span id="cb795-9402"><a href="#cb795-9402" aria-hidden="true" tabindex="-1"></a><span class="co"># lower outside Africa than inside it.</span></span>
<span id="cb795-9403"><a href="#cb795-9403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9404"><a href="#cb795-9404" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9405"><a href="#cb795-9405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9406"><a href="#cb795-9406" aria-hidden="true" tabindex="-1"></a>Also note that this probability, 0.004, is very tiny compared to the visual overlap of the two distributions in the figure. The distributions in the figure are marginal, like silhouettes of each distribution, ignoring all of the other dimensions in the posterior. The calculation above is the distribution of the difference between the two. The distribution of their difference is not the same as the visual overlap of their marginal distributions. This is also the reason we can’t use overlap in confidence intervals of different parameters as an informal test of “significance” of the difference. If you care about the difference, you must compute the distribution of the difference directly.</span>
<span id="cb795-9407"><a href="#cb795-9407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9408"><a href="#cb795-9408" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9409"><a href="#cb795-9409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9410"><a href="#cb795-9410" aria-hidden="true" tabindex="-1"></a><span class="fu">## Symmetry of the linear interaction</span></span>
<span id="cb795-9411"><a href="#cb795-9411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9412"><a href="#cb795-9412" aria-hidden="true" tabindex="-1"></a>The linear interaction contains two symmetrical interpretations. Absent some other information, outside the model, there’s no logical basis for preferring one over the other.</span>
<span id="cb795-9413"><a href="#cb795-9413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9414"><a href="#cb795-9414" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9415"><a href="#cb795-9415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9416"><a href="#cb795-9416" aria-hidden="true" tabindex="-1"></a><span class="fu">### Buridan's interaction</span></span>
<span id="cb795-9417"><a href="#cb795-9417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9418"><a href="#cb795-9418" aria-hidden="true" tabindex="-1"></a>We’ll plot the ruggedness and GDP example again, but with the reverse phrasing<span class="dv">&amp;mdash;</span> the influence of Africa depends upon ruggedness.</span>
<span id="cb795-9419"><a href="#cb795-9419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9420"><a href="#cb795-9420" aria-hidden="true" tabindex="-1"></a>Consider yet again the mathematical form of the likelihood:</span>
<span id="cb795-9421"><a href="#cb795-9421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9422"><a href="#cb795-9422" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9423"><a href="#cb795-9423" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9424"><a href="#cb795-9424" aria-hidden="true" tabindex="-1"></a>\ Y_i &amp;\sim \text{Normal}(\mu_i, \sigma) &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">likelihood</span><span class="co">]</span>}<span class="sc">\\</span></span>
<span id="cb795-9425"><a href="#cb795-9425" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \gamma_i R_i + \beta_A A_i &amp;&amp;&amp;    \text{<span class="co">[</span><span class="ot">linear model of}~\mu</span><span class="co">]</span><span class="sc">\\</span></span>
<span id="cb795-9426"><a href="#cb795-9426" aria-hidden="true" tabindex="-1"></a>\gamma_i &amp;\sim \beta_R + \beta_{AR} A_i &amp;&amp;&amp;   \text{<span class="co">[</span><span class="ot">linear model of slope</span><span class="co">]</span>}</span>
<span id="cb795-9427"><a href="#cb795-9427" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9428"><a href="#cb795-9428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9429"><a href="#cb795-9429" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9430"><a href="#cb795-9430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9431"><a href="#cb795-9431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9432"><a href="#cb795-9432" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9433"><a href="#cb795-9433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9434"><a href="#cb795-9434" aria-hidden="true" tabindex="-1"></a>Let’s expand $\gamma_i$ into the expression for $\mu_i$:</span>
<span id="cb795-9435"><a href="#cb795-9435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9436"><a href="#cb795-9436" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9437"><a href="#cb795-9437" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9438"><a href="#cb795-9438" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + (\beta_R + \beta_{AR} A_i) R_i + \beta_A A_i<span class="sc">\\</span></span>
<span id="cb795-9439"><a href="#cb795-9439" aria-hidden="true" tabindex="-1"></a>&amp;= \alpha + \beta_R R_i + \beta_{AR} A_i R_i + \beta_A A_i</span>
<span id="cb795-9440"><a href="#cb795-9440" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9441"><a href="#cb795-9441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9442"><a href="#cb795-9442" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9443"><a href="#cb795-9443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9444"><a href="#cb795-9444" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9445"><a href="#cb795-9445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9446"><a href="#cb795-9446" aria-hidden="true" tabindex="-1"></a>Now factor together the terms with $A_i$ in them:</span>
<span id="cb795-9447"><a href="#cb795-9447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9448"><a href="#cb795-9448" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9449"><a href="#cb795-9449" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9450"><a href="#cb795-9450" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_R R_i + \underbrace{(\beta_A + \beta_{AR}R_i)}_G A_i</span>
<span id="cb795-9451"><a href="#cb795-9451" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9452"><a href="#cb795-9452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9453"><a href="#cb795-9453" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9454"><a href="#cb795-9454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9455"><a href="#cb795-9455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9456"><a href="#cb795-9456" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9457"><a href="#cb795-9457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9458"><a href="#cb795-9458" aria-hidden="true" tabindex="-1"></a>The term labeled $G$ looks a lot like $\gamma_i$ in the original form. This is the same model of $\mu_i$, but re-expressed so that the linear interaction applies to $A_i$<span class="dv">&amp;mdash;</span> prove that linear interactions are symmetric. Within the model, there’s no basis to prefer one interpretation over the other, because in fact they are the same interpretation. But when we reason causally about models, our minds tend to prefer one interpretation over the other, because it’s usually easier to imagine manipulating one of the predictor variables instead of the other<span class="dv">&amp;mdash;</span> hard to imagine manipulating which continent a nation is on, but it's easy to imagine manipulating terrain ruggedness.</span>
<span id="cb795-9459"><a href="#cb795-9459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9460"><a href="#cb795-9460" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9461"><a href="#cb795-9461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9462"><a href="#cb795-9462" aria-hidden="true" tabindex="-1"></a><span class="fu">### Africa depends upon ruggedness</span></span>
<span id="cb795-9463"><a href="#cb795-9463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9464"><a href="#cb795-9464" aria-hidden="true" tabindex="-1"></a>It’ll be helpful to plot the reverse interpretation: *The influence of being in Africa depends upon terrain ruggedness*.</span>
<span id="cb795-9465"><a href="#cb795-9465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9466"><a href="#cb795-9466" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.17}</span></span>
<span id="cb795-9467"><a href="#cb795-9467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9468"><a href="#cb795-9468" aria-hidden="true" tabindex="-1"></a><span class="co"># get minimum and maximum rugged values</span></span>
<span id="cb795-9469"><a href="#cb795-9469" aria-hidden="true" tabindex="-1"></a>q.rugged <span class="ot">&lt;-</span> <span class="fu">range</span>(dd<span class="sc">$</span>rugged)</span>
<span id="cb795-9470"><a href="#cb795-9470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9471"><a href="#cb795-9471" aria-hidden="true" tabindex="-1"></a><span class="co"># compute lines and confidence intervals</span></span>
<span id="cb795-9472"><a href="#cb795-9472" aria-hidden="true" tabindex="-1"></a>mu.ruggedlo <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.5</span>b ,</span>
<span id="cb795-9473"><a href="#cb795-9473" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">rugged=</span>q.rugged[<span class="dv">1</span>],<span class="at">cont_africa=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>) )</span>
<span id="cb795-9474"><a href="#cb795-9474" aria-hidden="true" tabindex="-1"></a>mu.ruggedlo.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.ruggedlo , <span class="dv">2</span> , mean )</span>
<span id="cb795-9475"><a href="#cb795-9475" aria-hidden="true" tabindex="-1"></a>mu.ruggedlo.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.ruggedlo , <span class="dv">2</span> , PI )</span>
<span id="cb795-9476"><a href="#cb795-9476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9477"><a href="#cb795-9477" aria-hidden="true" tabindex="-1"></a>mu.ruggedhi <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.5</span>b ,</span>
<span id="cb795-9478"><a href="#cb795-9478" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">rugged=</span>q.rugged[<span class="dv">2</span>],<span class="at">cont_africa=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">1</span>) )</span>
<span id="cb795-9479"><a href="#cb795-9479" aria-hidden="true" tabindex="-1"></a>mu.ruggedhi.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.ruggedhi , <span class="dv">2</span> , mean )</span>
<span id="cb795-9480"><a href="#cb795-9480" aria-hidden="true" tabindex="-1"></a>mu.ruggedhi.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu.ruggedhi , <span class="dv">2</span> , PI )</span>
<span id="cb795-9481"><a href="#cb795-9481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9482"><a href="#cb795-9482" aria-hidden="true" tabindex="-1"></a><span class="co"># plot it all, splitting points at median</span></span>
<span id="cb795-9483"><a href="#cb795-9483" aria-hidden="true" tabindex="-1"></a>med.r <span class="ot">&lt;-</span> <span class="fu">median</span>(dd<span class="sc">$</span>rugged)</span>
<span id="cb795-9484"><a href="#cb795-9484" aria-hidden="true" tabindex="-1"></a>ox <span class="ot">&lt;-</span> <span class="fu">ifelse</span>( dd<span class="sc">$</span>rugged <span class="sc">&gt;</span> med.r , <span class="fl">0.05</span> , <span class="sc">-</span><span class="fl">0.05</span> )</span>
<span id="cb795-9485"><a href="#cb795-9485" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>( dd<span class="sc">$</span>cont_africa <span class="sc">+</span> ox , <span class="fu">log</span>(dd<span class="sc">$</span>rgdppc_2000) ,</span>
<span id="cb795-9486"><a href="#cb795-9486" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="fu">ifelse</span>(dd<span class="sc">$</span>rugged<span class="sc">&gt;</span>med.r,rangi2,<span class="st">"black"</span>) ,</span>
<span id="cb795-9487"><a href="#cb795-9487" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.25</span>,<span class="fl">1.25</span>) , <span class="at">xaxt=</span><span class="st">"n"</span> , <span class="at">ylab=</span><span class="st">"log GDP year 2000"</span> ,</span>
<span id="cb795-9488"><a href="#cb795-9488" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">"Continent"</span> )</span>
<span id="cb795-9489"><a href="#cb795-9489" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>( <span class="dv">1</span> , <span class="at">at=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>) , <span class="at">labels=</span><span class="fu">c</span>(<span class="st">"other"</span>,<span class="st">"Africa"</span>) )</span>
<span id="cb795-9490"><a href="#cb795-9490" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span> , mu.ruggedlo.mean , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9491"><a href="#cb795-9491" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.ruggedlo.PI , <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span> )</span>
<span id="cb795-9492"><a href="#cb795-9492" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>( <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span> , mu.ruggedhi.mean , <span class="at">col=</span>rangi2 )</span>
<span id="cb795-9493"><a href="#cb795-9493" aria-hidden="true" tabindex="-1"></a><span class="fu">shade</span>( mu.ruggedhi.PI , <span class="dv">0</span><span class="sc">:</span><span class="dv">1</span> , <span class="at">col=</span><span class="fu">col.alpha</span>(rangi2,<span class="fl">0.25</span>) )</span>
<span id="cb795-9494"><a href="#cb795-9494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9495"><a href="#cb795-9495" aria-hidden="true" tabindex="-1"></a><span class="co"># The other side of the interaction between ruggedness and continent. </span></span>
<span id="cb795-9496"><a href="#cb795-9496" aria-hidden="true" tabindex="-1"></a><span class="co"># Blue points are nations with above-median ruggedness. </span></span>
<span id="cb795-9497"><a href="#cb795-9497" aria-hidden="true" tabindex="-1"></a><span class="co"># Black points are below the median. </span></span>
<span id="cb795-9498"><a href="#cb795-9498" aria-hidden="true" tabindex="-1"></a><span class="co"># Dashed black line: relationship between continent and log-GDP, for an </span></span>
<span id="cb795-9499"><a href="#cb795-9499" aria-hidden="true" tabindex="-1"></a><span class="co"># imaginary nation with minimum observed ruggedness (0.003). </span></span>
<span id="cb795-9500"><a href="#cb795-9500" aria-hidden="true" tabindex="-1"></a><span class="co"># Blue line: an imaginary nation with maximum observed ruggedness (6.2).</span></span>
<span id="cb795-9501"><a href="#cb795-9501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9502"><a href="#cb795-9502" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9503"><a href="#cb795-9503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9504"><a href="#cb795-9504" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9505"><a href="#cb795-9505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9506"><a href="#cb795-9506" aria-hidden="true" tabindex="-1"></a><span class="fu">## Continuous interactions</span></span>
<span id="cb795-9507"><a href="#cb795-9507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9508"><a href="#cb795-9508" aria-hidden="true" tabindex="-1"></a>A third reason to be wary of using only tables of numbers to interpret interactions is that interactions among continuous variables are especially opaque. It’s one thing to make a slope conditional upon a *category*, as in the previous example of ruggedness and being in Africa. In such a context, the model reduces to estimating a different slope for each category. But, it’s quite a lot harder to understand that a slope varies in a continuous fashion with a continuous variable.</span>
<span id="cb795-9509"><a href="#cb795-9509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9510"><a href="#cb795-9510" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Two common benefits of centering prediction variables**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-9511"><a href="#cb795-9511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9512"><a href="#cb795-9512" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Centering the prediction variables can make it much easier to lean on the coefficients alone in understanding the model, especially when you want to compare the estimates from models with and without an interaction.</span>
<span id="cb795-9513"><a href="#cb795-9513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9514"><a href="#cb795-9514" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sometimes model fitting has a hard time with uncentered variables. Centering (and possibly also standardizing) the data before fitting the model can help you achieve a faster and more reliable set of estimates.</span>
<span id="cb795-9515"><a href="#cb795-9515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9516"><a href="#cb795-9516" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9517"><a href="#cb795-9517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9518"><a href="#cb795-9518" aria-hidden="true" tabindex="-1"></a><span class="fu">### The data</span></span>
<span id="cb795-9519"><a href="#cb795-9519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9520"><a href="#cb795-9520" aria-hidden="true" tabindex="-1"></a>The data in this example are sizes of blooms from beds of tulips grown in greenhouses, under different soil and light conditions.</span>
<span id="cb795-9521"><a href="#cb795-9521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9522"><a href="#cb795-9522" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.18}</span></span>
<span id="cb795-9523"><a href="#cb795-9523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9524"><a href="#cb795-9524" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb795-9525"><a href="#cb795-9525" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(tulips)</span>
<span id="cb795-9526"><a href="#cb795-9526" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> tulips</span>
<span id="cb795-9527"><a href="#cb795-9527" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(d)</span>
<span id="cb795-9528"><a href="#cb795-9528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9529"><a href="#cb795-9529" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9530"><a href="#cb795-9530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9531"><a href="#cb795-9531" aria-hidden="true" tabindex="-1"></a>The <span class="in">`blooms`</span> column will be our outcome. The <span class="in">`water`</span> and <span class="in">`shade`</span> columns will be our predictor variables. Independent effects of sunlight (<span class="in">`shade`</span>) and <span class="in">`water`</span> will produce bigger blooms. We are also interested in the interaction between these two variables. How will the <span class="in">`water`</span> help in the absence of light, or will sunlight helps the blooms in the absence of water? One way to model such an interdependency is to use an interaction effect.</span>
<span id="cb795-9532"><a href="#cb795-9532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9533"><a href="#cb795-9533" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9534"><a href="#cb795-9534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9535"><a href="#cb795-9535" aria-hidden="true" tabindex="-1"></a><span class="fu">### The un-centered models</span></span>
<span id="cb795-9536"><a href="#cb795-9536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9537"><a href="#cb795-9537" aria-hidden="true" tabindex="-1"></a>Example focusing on just two models: </span>
<span id="cb795-9538"><a href="#cb795-9538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9539"><a href="#cb795-9539" aria-hidden="true" tabindex="-1"></a>(1) the model with both <span class="in">`water`</span> and <span class="in">`shade`</span> but no interaction </span>
<span id="cb795-9540"><a href="#cb795-9540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9541"><a href="#cb795-9541" aria-hidden="true" tabindex="-1"></a>(2) the model with both main effects and the interaction of <span class="in">`water`</span> with <span class="in">`shade`</span></span>
<span id="cb795-9542"><a href="#cb795-9542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9543"><a href="#cb795-9543" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9544"><a href="#cb795-9544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9545"><a href="#cb795-9545" aria-hidden="true" tabindex="-1"></a>The main effect likelihood is:</span>
<span id="cb795-9546"><a href="#cb795-9546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9547"><a href="#cb795-9547" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9548"><a href="#cb795-9548" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9549"><a href="#cb795-9549" aria-hidden="true" tabindex="-1"></a>\ B_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-9550"><a href="#cb795-9550" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_W W_i + \beta_S S_i</span>
<span id="cb795-9551"><a href="#cb795-9551" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9552"><a href="#cb795-9552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9553"><a href="#cb795-9553" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9554"><a href="#cb795-9554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9555"><a href="#cb795-9555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9556"><a href="#cb795-9556" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9557"><a href="#cb795-9557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9558"><a href="#cb795-9558" aria-hidden="true" tabindex="-1"></a>And the full interaction likelihood is:</span>
<span id="cb795-9559"><a href="#cb795-9559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9560"><a href="#cb795-9560" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9561"><a href="#cb795-9561" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9562"><a href="#cb795-9562" aria-hidden="true" tabindex="-1"></a>\ B_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-9563"><a href="#cb795-9563" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_W W_i + \beta_S S_i + \beta_{WS} W_i S_i</span>
<span id="cb795-9564"><a href="#cb795-9564" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9565"><a href="#cb795-9565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9566"><a href="#cb795-9566" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9567"><a href="#cb795-9567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9568"><a href="#cb795-9568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9569"><a href="#cb795-9569" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9570"><a href="#cb795-9570" aria-hidden="true" tabindex="-1"></a><span class="in">B_i    = the value of bloom on row i </span></span>
<span id="cb795-9571"><a href="#cb795-9571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9572"><a href="#cb795-9572" aria-hidden="true" tabindex="-1"></a><span class="in">W_i    = the value of water</span></span>
<span id="cb795-9573"><a href="#cb795-9573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9574"><a href="#cb795-9574" aria-hidden="true" tabindex="-1"></a><span class="in">S_i    = the value of shade.</span></span>
<span id="cb795-9575"><a href="#cb795-9575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9576"><a href="#cb795-9576" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9577"><a href="#cb795-9577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9578"><a href="#cb795-9578" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.19}</span></span>
<span id="cb795-9579"><a href="#cb795-9579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9580"><a href="#cb795-9580" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">717</span>)</span>
<span id="cb795-9581"><a href="#cb795-9581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9582"><a href="#cb795-9582" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.6</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9583"><a href="#cb795-9583" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9584"><a href="#cb795-9584" aria-hidden="true" tabindex="-1"></a>        blooms <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9585"><a href="#cb795-9585" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bW<span class="sc">*</span>water <span class="sc">+</span> bS<span class="sc">*</span>shade ,</span>
<span id="cb795-9586"><a href="#cb795-9586" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9587"><a href="#cb795-9587" aria-hidden="true" tabindex="-1"></a>        bW <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9588"><a href="#cb795-9588" aria-hidden="true" tabindex="-1"></a>        bS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9589"><a href="#cb795-9589" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ),</span>
<span id="cb795-9590"><a href="#cb795-9590" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d )</span>
<span id="cb795-9591"><a href="#cb795-9591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9592"><a href="#cb795-9592" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.7</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9593"><a href="#cb795-9593" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9594"><a href="#cb795-9594" aria-hidden="true" tabindex="-1"></a>        blooms <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9595"><a href="#cb795-9595" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bW<span class="sc">*</span>water <span class="sc">+</span> bS<span class="sc">*</span>shade <span class="sc">+</span> bWS<span class="sc">*</span>water<span class="sc">*</span>shade ,</span>
<span id="cb795-9596"><a href="#cb795-9596" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9597"><a href="#cb795-9597" aria-hidden="true" tabindex="-1"></a>        bW <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9598"><a href="#cb795-9598" aria-hidden="true" tabindex="-1"></a>        bS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9599"><a href="#cb795-9599" aria-hidden="true" tabindex="-1"></a>        bWS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9600"><a href="#cb795-9600" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">100</span> )</span>
<span id="cb795-9601"><a href="#cb795-9601" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>d )</span>
<span id="cb795-9602"><a href="#cb795-9602" aria-hidden="true" tabindex="-1"></a><span class="co"># The model fitting engine, R’s optim, searched for a very long time. It searched so long </span></span>
<span id="cb795-9603"><a href="#cb795-9603" aria-hidden="true" tabindex="-1"></a><span class="co"># that it reached the time limit, the “maximum iterations.” As a result, the estimates are </span></span>
<span id="cb795-9604"><a href="#cb795-9604" aria-hidden="true" tabindex="-1"></a><span class="co"># unreliable and should not be used, unless you are sure they are okay.</span></span>
<span id="cb795-9605"><a href="#cb795-9605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9606"><a href="#cb795-9606" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9607"><a href="#cb795-9607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9608"><a href="#cb795-9608" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9609"><a href="#cb795-9609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9610"><a href="#cb795-9610" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:gray"</span><span class="kw">&gt;</span>***Fix the maximum iterations problem.***<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-9611"><a href="#cb795-9611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9612"><a href="#cb795-9612" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.19a}</span></span>
<span id="cb795-9613"><a href="#cb795-9613" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">719</span>)</span>
<span id="cb795-9614"><a href="#cb795-9614" aria-hidden="true" tabindex="-1"></a><span class="co"># Use  Nelder-Mead method of optimization</span></span>
<span id="cb795-9615"><a href="#cb795-9615" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.6</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9616"><a href="#cb795-9616" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9617"><a href="#cb795-9617" aria-hidden="true" tabindex="-1"></a>        blooms <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9618"><a href="#cb795-9618" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bW<span class="sc">*</span>water <span class="sc">+</span> bS<span class="sc">*</span>shade ,</span>
<span id="cb795-9619"><a href="#cb795-9619" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9620"><a href="#cb795-9620" aria-hidden="true" tabindex="-1"></a>        bW <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9621"><a href="#cb795-9621" aria-hidden="true" tabindex="-1"></a>        bS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9622"><a href="#cb795-9622" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ),</span>
<span id="cb795-9623"><a href="#cb795-9623" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>d ,</span>
<span id="cb795-9624"><a href="#cb795-9624" aria-hidden="true" tabindex="-1"></a>    <span class="at">method=</span><span class="st">"Nelder-Mead"</span> ,</span>
<span id="cb795-9625"><a href="#cb795-9625" aria-hidden="true" tabindex="-1"></a>    <span class="at">control=</span><span class="fu">list</span>(<span class="at">maxit=</span><span class="fl">1e4</span>) )</span>
<span id="cb795-9626"><a href="#cb795-9626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9627"><a href="#cb795-9627" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.7</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9628"><a href="#cb795-9628" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9629"><a href="#cb795-9629" aria-hidden="true" tabindex="-1"></a>        blooms <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9630"><a href="#cb795-9630" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bW<span class="sc">*</span>water <span class="sc">+</span> bS<span class="sc">*</span>shade <span class="sc">+</span> bWS<span class="sc">*</span>water<span class="sc">*</span>shade ,</span>
<span id="cb795-9631"><a href="#cb795-9631" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9632"><a href="#cb795-9632" aria-hidden="true" tabindex="-1"></a>        bW <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9633"><a href="#cb795-9633" aria-hidden="true" tabindex="-1"></a>        bS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9634"><a href="#cb795-9634" aria-hidden="true" tabindex="-1"></a>        bWS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9635"><a href="#cb795-9635" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">100</span> )</span>
<span id="cb795-9636"><a href="#cb795-9636" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-9637"><a href="#cb795-9637" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d , <span class="at">method=</span><span class="st">"Nelder-Mead"</span> , <span class="at">control=</span><span class="fu">list</span>(<span class="at">maxit=</span><span class="fl">1e4</span>) )</span>
<span id="cb795-9638"><a href="#cb795-9638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9639"><a href="#cb795-9639" aria-hidden="true" tabindex="-1"></a><span class="co"># Use coeftab function to check the estimates</span></span>
<span id="cb795-9640"><a href="#cb795-9640" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftab</span>(m7<span class="fl">.6</span>,m7<span class="fl">.7</span>)</span>
<span id="cb795-9641"><a href="#cb795-9641" aria-hidden="true" tabindex="-1"></a><span class="co"># In main-effects-only model (m7.6), for every additional level of soil moisture, </span></span>
<span id="cb795-9642"><a href="#cb795-9642" aria-hidden="true" tabindex="-1"></a><span class="co"># blooms increase by 76, on average. For every addition unit of shade, </span></span>
<span id="cb795-9643"><a href="#cb795-9643" aria-hidden="true" tabindex="-1"></a><span class="co"># blooms decrease by 42, on average. </span></span>
<span id="cb795-9644"><a href="#cb795-9644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9645"><a href="#cb795-9645" aria-hidden="true" tabindex="-1"></a><span class="co"># In interaction model (m7.7), both main effects are positive, but the new interaction</span></span>
<span id="cb795-9646"><a href="#cb795-9646" aria-hidden="true" tabindex="-1"></a><span class="co"># posterior mean is negative.</span></span>
<span id="cb795-9647"><a href="#cb795-9647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9648"><a href="#cb795-9648" aria-hidden="true" tabindex="-1"></a><span class="co"># WAIC values assure that the interaction model is indeed a much better model</span></span>
<span id="cb795-9649"><a href="#cb795-9649" aria-hidden="true" tabindex="-1"></a><span class="fu">compare</span>( m7<span class="fl">.6</span> , m7<span class="fl">.7</span> )</span>
<span id="cb795-9650"><a href="#cb795-9650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9651"><a href="#cb795-9651" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9652"><a href="#cb795-9652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9653"><a href="#cb795-9653" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9654"><a href="#cb795-9654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9655"><a href="#cb795-9655" aria-hidden="true" tabindex="-1"></a><span class="fu">### Center and re-estimate</span></span>
<span id="cb795-9656"><a href="#cb795-9656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9657"><a href="#cb795-9657" aria-hidden="true" tabindex="-1"></a>To *center* a variable means to create a new variable that contains the same information as the original, but has a new mean of zero. Centering can help with two things in this analysis:</span>
<span id="cb795-9658"><a href="#cb795-9658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9659"><a href="#cb795-9659" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>fix our previous problem with maximum iterations</span>
<span id="cb795-9660"><a href="#cb795-9660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9661"><a href="#cb795-9661" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>make the estimates easier to interpret</span>
<span id="cb795-9662"><a href="#cb795-9662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9663"><a href="#cb795-9663" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.23}</span></span>
<span id="cb795-9664"><a href="#cb795-9664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9665"><a href="#cb795-9665" aria-hidden="true" tabindex="-1"></a><span class="co"># Make centered versions of shade and water by subtracting the mean of the original from each value</span></span>
<span id="cb795-9666"><a href="#cb795-9666" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>shade.c <span class="ot">&lt;-</span> d<span class="sc">$</span>shade <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>shade)</span>
<span id="cb795-9667"><a href="#cb795-9667" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>water.c <span class="ot">&lt;-</span> d<span class="sc">$</span>water <span class="sc">-</span> <span class="fu">mean</span>(d<span class="sc">$</span>water)</span>
<span id="cb795-9668"><a href="#cb795-9668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9669"><a href="#cb795-9669" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-estimate m7.6 and m7.7 using centered variables</span></span>
<span id="cb795-9670"><a href="#cb795-9670" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.8</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9671"><a href="#cb795-9671" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9672"><a href="#cb795-9672" aria-hidden="true" tabindex="-1"></a>        blooms <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9673"><a href="#cb795-9673" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bW<span class="sc">*</span>water.c <span class="sc">+</span> bS<span class="sc">*</span>shade.c ,</span>
<span id="cb795-9674"><a href="#cb795-9674" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">130</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9675"><a href="#cb795-9675" aria-hidden="true" tabindex="-1"></a>        bW <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9676"><a href="#cb795-9676" aria-hidden="true" tabindex="-1"></a>        bS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9677"><a href="#cb795-9677" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">100</span> )</span>
<span id="cb795-9678"><a href="#cb795-9678" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-9679"><a href="#cb795-9679" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d , <span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span><span class="fu">mean</span>(d<span class="sc">$</span>blooms),<span class="at">bW=</span><span class="dv">0</span>,<span class="at">bS=</span><span class="dv">0</span>,<span class="at">sigma=</span><span class="fu">sd</span>(d<span class="sc">$</span>blooms)) )</span>
<span id="cb795-9680"><a href="#cb795-9680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9681"><a href="#cb795-9681" aria-hidden="true" tabindex="-1"></a>m7<span class="fl">.9</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-9682"><a href="#cb795-9682" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-9683"><a href="#cb795-9683" aria-hidden="true" tabindex="-1"></a>        blooms <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-9684"><a href="#cb795-9684" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bW<span class="sc">*</span>water.c <span class="sc">+</span> bS<span class="sc">*</span>shade.c <span class="sc">+</span> bWS<span class="sc">*</span>water.c<span class="sc">*</span>shade.c ,</span>
<span id="cb795-9685"><a href="#cb795-9685" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">130</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9686"><a href="#cb795-9686" aria-hidden="true" tabindex="-1"></a>        bW <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9687"><a href="#cb795-9687" aria-hidden="true" tabindex="-1"></a>        bS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9688"><a href="#cb795-9688" aria-hidden="true" tabindex="-1"></a>        bWS <span class="sc">~</span> <span class="fu">dnorm</span>( <span class="dv">0</span> , <span class="dv">100</span> ) ,</span>
<span id="cb795-9689"><a href="#cb795-9689" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>( <span class="dv">0</span> , <span class="dv">100</span> )</span>
<span id="cb795-9690"><a href="#cb795-9690" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-9691"><a href="#cb795-9691" aria-hidden="true" tabindex="-1"></a><span class="at">data=</span>d , <span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span><span class="fu">mean</span>(d<span class="sc">$</span>blooms),<span class="at">bW=</span><span class="dv">0</span>,<span class="at">bS=</span><span class="dv">0</span>,<span class="at">bWS=</span><span class="dv">0</span>,<span class="at">sigma=</span><span class="fu">sd</span>(d<span class="sc">$</span>blooms)) )</span>
<span id="cb795-9692"><a href="#cb795-9692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9693"><a href="#cb795-9693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9694"><a href="#cb795-9694" aria-hidden="true" tabindex="-1"></a><span class="co"># Check estimates</span></span>
<span id="cb795-9695"><a href="#cb795-9695" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftab</span>(m7<span class="fl">.8</span>,m7<span class="fl">.9</span>)</span>
<span id="cb795-9696"><a href="#cb795-9696" aria-hidden="true" tabindex="-1"></a><span class="co"># Now when we compare the posterior means across the two models, the main effects are the same. </span></span>
<span id="cb795-9697"><a href="#cb795-9697" aria-hidden="true" tabindex="-1"></a><span class="co"># Unlike before, the direction of the association for shade has not changed. More water appears </span></span>
<span id="cb795-9698"><a href="#cb795-9698" aria-hidden="true" tabindex="-1"></a><span class="co"># to directly increase blooms, while more shade directly decreases them. Meanwhile, the </span></span>
<span id="cb795-9699"><a href="#cb795-9699" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction posterior mean has remained the same as it was in the non-centered model.</span></span>
<span id="cb795-9700"><a href="#cb795-9700" aria-hidden="true" tabindex="-1"></a><span class="do">## Centering has these effects because: Estimation worked better, Estimates changed less across models.</span></span>
<span id="cb795-9701"><a href="#cb795-9701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9702"><a href="#cb795-9702" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9703"><a href="#cb795-9703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9704"><a href="#cb795-9704" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9705"><a href="#cb795-9705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9706"><a href="#cb795-9706" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Estimation worked better</span></span>
<span id="cb795-9707"><a href="#cb795-9707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9708"><a href="#cb795-9708" aria-hidden="true" tabindex="-1"></a>Estimation failed with the un-centered predictor variables, because there was a long way to go from the <span class="in">`start`</span> values you provided to map and the <span class="in">`MAP`</span> values it was seeking. When the predictors are centered, the MAP value for $\alpha$ is just the empirical mean for the outcome. That is also the <span class="in">`start`</span> value given to <span class="in">`map`</span>. With un-centered predictors, the MAP value for $\alpha$ lies a long way from the empirical mean. Hence, the long search that failed.</span>
<span id="cb795-9709"><a href="#cb795-9709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9710"><a href="#cb795-9710" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9711"><a href="#cb795-9711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9712"><a href="#cb795-9712" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Estimates changed less across models</span></span>
<span id="cb795-9713"><a href="#cb795-9713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9714"><a href="#cb795-9714" aria-hidden="true" tabindex="-1"></a>In the un-centered models, the interaction effect is applied to every case, and so none of the parameters in $\mu$ makes sense alone. This is because neither of the predictors in those models, <span class="in">`shade`</span> and <span class="in">`water`</span>, are ever zero. As a result the interaction parameter always factors into generating a prediction. Consider for example a tulip at the average moisture and shade levels, 2 in each case. The expected blooms for such a tulip is:</span>
<span id="cb795-9715"><a href="#cb795-9715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9716"><a href="#cb795-9716" aria-hidden="true" tabindex="-1"></a>$$\mu_i|_{S_i=2, W_i=2} = \alpha + \beta_W(2) + \beta_S (2) + \beta_{WS}(2 \times 2)$$</span>
<span id="cb795-9717"><a href="#cb795-9717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9718"><a href="#cb795-9718" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.25}</span></span>
<span id="cb795-9719"><a href="#cb795-9719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9720"><a href="#cb795-9720" aria-hidden="true" tabindex="-1"></a><span class="co"># Plugging in the MAP values for the un-centered interaction model, m7.7</span></span>
<span id="cb795-9721"><a href="#cb795-9721" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">coef</span>(m7<span class="fl">.7</span>)</span>
<span id="cb795-9722"><a href="#cb795-9722" aria-hidden="true" tabindex="-1"></a>k[<span class="dv">1</span>] <span class="sc">+</span> k[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">2</span> <span class="sc">+</span> k[<span class="dv">3</span>]<span class="sc">*</span><span class="dv">2</span> <span class="sc">+</span> k[<span class="dv">4</span>]<span class="sc">*</span><span class="dv">2</span><span class="sc">*</span><span class="dv">2</span></span>
<span id="cb795-9723"><a href="#cb795-9723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9724"><a href="#cb795-9724" aria-hidden="true" tabindex="-1"></a><span class="co"># Same prediction from the centered interaction model, m7.9,</span></span>
<span id="cb795-9725"><a href="#cb795-9725" aria-hidden="true" tabindex="-1"></a><span class="co"># also using the mean values of both predictors</span></span>
<span id="cb795-9726"><a href="#cb795-9726" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">coef</span>(m7<span class="fl">.9</span>)</span>
<span id="cb795-9727"><a href="#cb795-9727" aria-hidden="true" tabindex="-1"></a>k[<span class="dv">1</span>] <span class="sc">+</span> k[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> k[<span class="dv">3</span>]<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> k[<span class="dv">4</span>]<span class="sc">*</span><span class="dv">0</span><span class="sc">*</span><span class="dv">0</span></span>
<span id="cb795-9728"><a href="#cb795-9728" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m7<span class="fl">.9</span>)</span>
<span id="cb795-9729"><a href="#cb795-9729" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate a,α, is the expected value of blooms when both water and shade are at </span></span>
<span id="cb795-9730"><a href="#cb795-9730" aria-hidden="true" tabindex="-1"></a><span class="co"># their average values. Their average values are both zero (0), because they were centered </span></span>
<span id="cb795-9731"><a href="#cb795-9731" aria-hidden="true" tabindex="-1"></a><span class="co"># before fitting the model.</span></span>
<span id="cb795-9732"><a href="#cb795-9732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9733"><a href="#cb795-9733" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate bW, βW, is the expected change in blooms when water increases by one unit </span></span>
<span id="cb795-9734"><a href="#cb795-9734" aria-hidden="true" tabindex="-1"></a><span class="co"># and shade is at its average value (of zero). This parameter does not tell you the expected </span></span>
<span id="cb795-9735"><a href="#cb795-9735" aria-hidden="true" tabindex="-1"></a><span class="co"># rate of change for any other value of shade. This estimate suggests that when shade is at </span></span>
<span id="cb795-9736"><a href="#cb795-9736" aria-hidden="true" tabindex="-1"></a><span class="co"># its average value, increasing water is highly beneficial to blooms.</span></span>
<span id="cb795-9737"><a href="#cb795-9737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9738"><a href="#cb795-9738" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate bS, βS, is the expected change in blooms when shade increases by one unit and </span></span>
<span id="cb795-9739"><a href="#cb795-9739" aria-hidden="true" tabindex="-1"></a><span class="co"># water is at its average value (of zero). This parameter does not tell you the expected rate </span></span>
<span id="cb795-9740"><a href="#cb795-9740" aria-hidden="true" tabindex="-1"></a><span class="co"># of change for any other value of water. This estimate suggests that when water is at its </span></span>
<span id="cb795-9741"><a href="#cb795-9741" aria-hidden="true" tabindex="-1"></a><span class="co"># average value, increasing shade is highly detrimental to blooms.</span></span>
<span id="cb795-9742"><a href="#cb795-9742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9743"><a href="#cb795-9743" aria-hidden="true" tabindex="-1"></a><span class="co"># The estimate bWS, βWS, is the interaction effect. Like all linear interactions, it can be </span></span>
<span id="cb795-9744"><a href="#cb795-9744" aria-hidden="true" tabindex="-1"></a><span class="co"># explained in more than one way. First, the estimate tells us the expected change in the </span></span>
<span id="cb795-9745"><a href="#cb795-9745" aria-hidden="true" tabindex="-1"></a><span class="co"># influence of water on blooms when increasing shade by one unit. Second, it tells us the </span></span>
<span id="cb795-9746"><a href="#cb795-9746" aria-hidden="true" tabindex="-1"></a><span class="co"># expected change in the influence of shade on blooms when increasing water by one unit.</span></span>
<span id="cb795-9747"><a href="#cb795-9747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9748"><a href="#cb795-9748" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9749"><a href="#cb795-9749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9750"><a href="#cb795-9750" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9751"><a href="#cb795-9751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9752"><a href="#cb795-9752" aria-hidden="true" tabindex="-1"></a><span class="fu">### Plotting implied predictions</span></span>
<span id="cb795-9753"><a href="#cb795-9753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9754"><a href="#cb795-9754" aria-hidden="true" tabindex="-1"></a>There were no interactions in the models in previous chapters. As a result, when plotting model predictions as a function of any one predictor, you could hold the other predictors constant at any value you liked. So the choice of which values to set the un-viewed predictor variables to hardly mattered.</span>
<span id="cb795-9755"><a href="#cb795-9755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9756"><a href="#cb795-9756" aria-hidden="true" tabindex="-1"></a>Once there are interactions in a model, the effect of changing a predictor depends upon the values of the other predictors. Maybe the simplest way to go about plotting such interdependency is to make a frame of multiple bivariate plots. In each plot, you choose different values for the un-viewed variables. Then by comparing the plots to one another, you can see how big of a difference the changes make.</span>
<span id="cb795-9757"><a href="#cb795-9757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9758"><a href="#cb795-9758" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.28, fig.width=8, fig.height=6}</span></span>
<span id="cb795-9759"><a href="#cb795-9759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9760"><a href="#cb795-9760" aria-hidden="true" tabindex="-1"></a><span class="co"># make a plot window with three panels in a single row</span></span>
<span id="cb795-9761"><a href="#cb795-9761" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>)) <span class="co"># 2 row, 3 columns</span></span>
<span id="cb795-9762"><a href="#cb795-9762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9763"><a href="#cb795-9763" aria-hidden="true" tabindex="-1"></a><span class="do">## Without interaction</span></span>
<span id="cb795-9764"><a href="#cb795-9764" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over values of water.c and plot predictions</span></span>
<span id="cb795-9765"><a href="#cb795-9765" aria-hidden="true" tabindex="-1"></a>shade.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb795-9766"><a href="#cb795-9766" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( w <span class="cf">in</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span> ) {</span>
<span id="cb795-9767"><a href="#cb795-9767" aria-hidden="true" tabindex="-1"></a>    dt <span class="ot">&lt;-</span> d[d<span class="sc">$</span>water.c<span class="sc">==</span>w,]</span>
<span id="cb795-9768"><a href="#cb795-9768" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>( blooms <span class="sc">~</span> shade.c , <span class="at">data=</span>dt , <span class="at">col=</span>rangi2 ,</span>
<span id="cb795-9769"><a href="#cb795-9769" aria-hidden="true" tabindex="-1"></a>        <span class="at">main=</span><span class="fu">paste</span>(<span class="st">"water.c ="</span>,w) , <span class="at">xaxp=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>) , <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">362</span>) ,</span>
<span id="cb795-9770"><a href="#cb795-9770" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">"shade (centered)"</span> )</span>
<span id="cb795-9771"><a href="#cb795-9771" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.8</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">water.c=</span>w,<span class="at">shade.c=</span>shade.seq) )</span>
<span id="cb795-9772"><a href="#cb795-9772" aria-hidden="true" tabindex="-1"></a>    mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-9773"><a href="#cb795-9773" aria-hidden="true" tabindex="-1"></a>    mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9774"><a href="#cb795-9774" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( shade.seq , mu.mean )</span>
<span id="cb795-9775"><a href="#cb795-9775" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( shade.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9776"><a href="#cb795-9776" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( shade.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9777"><a href="#cb795-9777" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-9778"><a href="#cb795-9778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9779"><a href="#cb795-9779" aria-hidden="true" tabindex="-1"></a><span class="do">## With interaction</span></span>
<span id="cb795-9780"><a href="#cb795-9780" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over values of water.c and plot predictions</span></span>
<span id="cb795-9781"><a href="#cb795-9781" aria-hidden="true" tabindex="-1"></a>shade.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb795-9782"><a href="#cb795-9782" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( w <span class="cf">in</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span> ) {</span>
<span id="cb795-9783"><a href="#cb795-9783" aria-hidden="true" tabindex="-1"></a>    dt <span class="ot">&lt;-</span> d[d<span class="sc">$</span>water.c<span class="sc">==</span>w,]</span>
<span id="cb795-9784"><a href="#cb795-9784" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>( blooms <span class="sc">~</span> shade.c , <span class="at">data=</span>dt , <span class="at">col=</span>rangi2 ,</span>
<span id="cb795-9785"><a href="#cb795-9785" aria-hidden="true" tabindex="-1"></a>        <span class="at">main=</span><span class="fu">paste</span>(<span class="st">"water.c ="</span>,w) , <span class="at">xaxp=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>) , <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">362</span>) ,</span>
<span id="cb795-9786"><a href="#cb795-9786" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">"shade (centered)"</span> )</span>
<span id="cb795-9787"><a href="#cb795-9787" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.9</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">water.c=</span>w,<span class="at">shade.c=</span>shade.seq) )</span>
<span id="cb795-9788"><a href="#cb795-9788" aria-hidden="true" tabindex="-1"></a>    mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-9789"><a href="#cb795-9789" aria-hidden="true" tabindex="-1"></a>    mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9790"><a href="#cb795-9790" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( shade.seq , mu.mean )</span>
<span id="cb795-9791"><a href="#cb795-9791" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( shade.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9792"><a href="#cb795-9792" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( shade.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9793"><a href="#cb795-9793" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-9794"><a href="#cb795-9794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9795"><a href="#cb795-9795" aria-hidden="true" tabindex="-1"></a><span class="co"># Triptych plot of predicted blooms across water treatments, without (top row) and </span></span>
<span id="cb795-9796"><a href="#cb795-9796" aria-hidden="true" tabindex="-1"></a><span class="co"># with (bottom row) an interaction effect. Blue points in each plot are data- individual </span></span>
<span id="cb795-9797"><a href="#cb795-9797" aria-hidden="true" tabindex="-1"></a><span class="co"># cases that match the water value displayed at the top of each plot.</span></span>
<span id="cb795-9798"><a href="#cb795-9798" aria-hidden="true" tabindex="-1"></a><span class="co"># The solid line is the posterior mean and the dashed lines give 97% interval of the mean.</span></span>
<span id="cb795-9799"><a href="#cb795-9799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9800"><a href="#cb795-9800" aria-hidden="true" tabindex="-1"></a><span class="co"># Top row: Without the interaction, model m7.8. Each of the three plots of blooms against </span></span>
<span id="cb795-9801"><a href="#cb795-9801" aria-hidden="true" tabindex="-1"></a><span class="co"># shade level is for a different water level. The slope of the regression line in each case </span></span>
<span id="cb795-9802"><a href="#cb795-9802" aria-hidden="true" tabindex="-1"></a><span class="co"># is exactly the same, because there is no interaction in this model. </span></span>
<span id="cb795-9803"><a href="#cb795-9803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9804"><a href="#cb795-9804" aria-hidden="true" tabindex="-1"></a><span class="co"># Bottom row: With the interaction, model m7.9. Now the slope of blooms against shade has </span></span>
<span id="cb795-9805"><a href="#cb795-9805" aria-hidden="true" tabindex="-1"></a><span class="co"># a different value in each plot.At low water levels, shade can’t have much of an effect, </span></span>
<span id="cb795-9806"><a href="#cb795-9806" aria-hidden="true" tabindex="-1"></a><span class="co"># because the tulips don’t have enough water to produce blooms anyway. At higher water levels, </span></span>
<span id="cb795-9807"><a href="#cb795-9807" aria-hidden="true" tabindex="-1"></a><span class="co"># shade can matter more, because the tulips have enough water to produce some blooms. </span></span>
<span id="cb795-9808"><a href="#cb795-9808" aria-hidden="true" tabindex="-1"></a><span class="co"># At very high water levels, water is no longer limiting the blooms very much, and so shade </span></span>
<span id="cb795-9809"><a href="#cb795-9809" aria-hidden="true" tabindex="-1"></a><span class="co"># can have a much more dramatic impact on the outcome.</span></span>
<span id="cb795-9810"><a href="#cb795-9810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9811"><a href="#cb795-9811" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9812"><a href="#cb795-9812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9813"><a href="#cb795-9813" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9814"><a href="#cb795-9814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9815"><a href="#cb795-9815" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.28a, fig.width=8, fig.height=6}</span></span>
<span id="cb795-9816"><a href="#cb795-9816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9817"><a href="#cb795-9817" aria-hidden="true" tabindex="-1"></a><span class="do">## Water on the horizontal axes and shade level varied from left to right</span></span>
<span id="cb795-9818"><a href="#cb795-9818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9819"><a href="#cb795-9819" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb795-9820"><a href="#cb795-9820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9821"><a href="#cb795-9821" aria-hidden="true" tabindex="-1"></a><span class="do">## Without interaction</span></span>
<span id="cb795-9822"><a href="#cb795-9822" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over values of shade.c and plot predictions</span></span>
<span id="cb795-9823"><a href="#cb795-9823" aria-hidden="true" tabindex="-1"></a>water.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb795-9824"><a href="#cb795-9824" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( s <span class="cf">in</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span> ) {</span>
<span id="cb795-9825"><a href="#cb795-9825" aria-hidden="true" tabindex="-1"></a>    dt <span class="ot">&lt;-</span> d[d<span class="sc">$</span>shade.c<span class="sc">==</span>s,]</span>
<span id="cb795-9826"><a href="#cb795-9826" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>( blooms <span class="sc">~</span> water.c , <span class="at">data=</span>dt , <span class="at">col=</span>rangi2 ,</span>
<span id="cb795-9827"><a href="#cb795-9827" aria-hidden="true" tabindex="-1"></a>        <span class="at">main=</span><span class="fu">paste</span>(<span class="st">"shade.c ="</span>,s) , <span class="at">xaxp=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>) , <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">362</span>) ,</span>
<span id="cb795-9828"><a href="#cb795-9828" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">"water (centered)"</span> )</span>
<span id="cb795-9829"><a href="#cb795-9829" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.8</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">shade.c=</span>s,<span class="at">water.c=</span>water.seq) )</span>
<span id="cb795-9830"><a href="#cb795-9830" aria-hidden="true" tabindex="-1"></a>    mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-9831"><a href="#cb795-9831" aria-hidden="true" tabindex="-1"></a>    mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9832"><a href="#cb795-9832" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( water.seq , mu.mean )</span>
<span id="cb795-9833"><a href="#cb795-9833" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( water.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9834"><a href="#cb795-9834" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( water.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9835"><a href="#cb795-9835" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-9836"><a href="#cb795-9836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9837"><a href="#cb795-9837" aria-hidden="true" tabindex="-1"></a><span class="do">## With interaction</span></span>
<span id="cb795-9838"><a href="#cb795-9838" aria-hidden="true" tabindex="-1"></a><span class="co"># loop over values of shade.c and plot predictions</span></span>
<span id="cb795-9839"><a href="#cb795-9839" aria-hidden="true" tabindex="-1"></a>water.seq <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span></span>
<span id="cb795-9840"><a href="#cb795-9840" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( s <span class="cf">in</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span> ) {</span>
<span id="cb795-9841"><a href="#cb795-9841" aria-hidden="true" tabindex="-1"></a>    dt <span class="ot">&lt;-</span> d[d<span class="sc">$</span>shade.c<span class="sc">==</span>s,]</span>
<span id="cb795-9842"><a href="#cb795-9842" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>( blooms <span class="sc">~</span> water.c , <span class="at">data=</span>dt , <span class="at">col=</span>rangi2 ,</span>
<span id="cb795-9843"><a href="#cb795-9843" aria-hidden="true" tabindex="-1"></a>        <span class="at">main=</span><span class="fu">paste</span>(<span class="st">"shade.c ="</span>,s) , <span class="at">xaxp=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>) , <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">362</span>) ,</span>
<span id="cb795-9844"><a href="#cb795-9844" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">"water (centered)"</span> )</span>
<span id="cb795-9845"><a href="#cb795-9845" aria-hidden="true" tabindex="-1"></a>    mu <span class="ot">&lt;-</span> <span class="fu">link</span>( m7<span class="fl">.9</span> , <span class="at">data=</span><span class="fu">data.frame</span>(<span class="at">shade.c=</span>s,<span class="at">water.c=</span>water.seq) )</span>
<span id="cb795-9846"><a href="#cb795-9846" aria-hidden="true" tabindex="-1"></a>    mu.mean <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , mean )</span>
<span id="cb795-9847"><a href="#cb795-9847" aria-hidden="true" tabindex="-1"></a>    mu.PI <span class="ot">&lt;-</span> <span class="fu">apply</span>( mu , <span class="dv">2</span> , PI , <span class="at">prob=</span><span class="fl">0.97</span> )</span>
<span id="cb795-9848"><a href="#cb795-9848" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( water.seq , mu.mean )</span>
<span id="cb795-9849"><a href="#cb795-9849" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( water.seq , mu.PI[<span class="dv">1</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9850"><a href="#cb795-9850" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>( water.seq , mu.PI[<span class="dv">2</span>,] , <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb795-9851"><a href="#cb795-9851" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-9852"><a href="#cb795-9852" aria-hidden="true" tabindex="-1"></a><span class="co"># If there isn’t enough light, then more water hardly helps.</span></span>
<span id="cb795-9853"><a href="#cb795-9853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9854"><a href="#cb795-9854" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9855"><a href="#cb795-9855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9856"><a href="#cb795-9856" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9857"><a href="#cb795-9857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9858"><a href="#cb795-9858" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interactions in design formulas</span></span>
<span id="cb795-9859"><a href="#cb795-9859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9860"><a href="#cb795-9860" aria-hidden="true" tabindex="-1"></a>To specify interaction models using design formulas, like those used by <span class="in">`lm`</span> and other automated model fitting functions, you just strip out the parameters from the linear model.</span>
<span id="cb795-9861"><a href="#cb795-9861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9862"><a href="#cb795-9862" aria-hidden="true" tabindex="-1"></a>For example, here’s a model with an interaction between $x$ and $z$:</span>
<span id="cb795-9863"><a href="#cb795-9863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9864"><a href="#cb795-9864" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9865"><a href="#cb795-9865" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9866"><a href="#cb795-9866" aria-hidden="true" tabindex="-1"></a>\ y_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-9867"><a href="#cb795-9867" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_x x_i + \beta_z z_i + \beta_{xz} x_i z_i</span>
<span id="cb795-9868"><a href="#cb795-9868" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9869"><a href="#cb795-9869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9870"><a href="#cb795-9870" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9871"><a href="#cb795-9871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9872"><a href="#cb795-9872" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9873"><a href="#cb795-9873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9874"><a href="#cb795-9874" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.29}</span></span>
<span id="cb795-9875"><a href="#cb795-9875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9876"><a href="#cb795-9876" aria-hidden="true" tabindex="-1"></a><span class="co"># As a design formula, this is:</span></span>
<span id="cb795-9877"><a href="#cb795-9877" aria-hidden="true" tabindex="-1"></a>m7.x <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> x <span class="sc">+</span> z <span class="sc">+</span> x<span class="sc">*</span>z , <span class="at">data=</span>d )</span>
<span id="cb795-9878"><a href="#cb795-9878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9879"><a href="#cb795-9879" aria-hidden="true" tabindex="-1"></a><span class="co"># You can also omit the pure x and z terms, the main effects, and still get the same model.</span></span>
<span id="cb795-9880"><a href="#cb795-9880" aria-hidden="true" tabindex="-1"></a>m7.x <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> x<span class="sc">*</span>z , <span class="at">data=</span>d )</span>
<span id="cb795-9881"><a href="#cb795-9881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9882"><a href="#cb795-9882" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9883"><a href="#cb795-9883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9884"><a href="#cb795-9884" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9885"><a href="#cb795-9885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9886"><a href="#cb795-9886" aria-hidden="true" tabindex="-1"></a>If you do not want the main effects in the model, you must explicitly subtract them from the formula. For example, here’s a model with an interaction, but without one of the main effects (when you know a priori that there is no direct effect of $z$ on the outcome, when $\beta_z$ = 0 by assumption):</span>
<span id="cb795-9887"><a href="#cb795-9887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9888"><a href="#cb795-9888" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9889"><a href="#cb795-9889" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9890"><a href="#cb795-9890" aria-hidden="true" tabindex="-1"></a>\ y_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-9891"><a href="#cb795-9891" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_x x_i + \beta_{xz} x_i z_i</span>
<span id="cb795-9892"><a href="#cb795-9892" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9893"><a href="#cb795-9893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9894"><a href="#cb795-9894" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9895"><a href="#cb795-9895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9896"><a href="#cb795-9896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9897"><a href="#cb795-9897" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.31}</span></span>
<span id="cb795-9898"><a href="#cb795-9898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9899"><a href="#cb795-9899" aria-hidden="true" tabindex="-1"></a><span class="co"># As a design formula, this model is:</span></span>
<span id="cb795-9900"><a href="#cb795-9900" aria-hidden="true" tabindex="-1"></a>m7.x <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> x <span class="sc">+</span> x<span class="sc">*</span>z <span class="sc">-</span> z , <span class="at">data=</span>d )</span>
<span id="cb795-9901"><a href="#cb795-9901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9902"><a href="#cb795-9902" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9903"><a href="#cb795-9903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9904"><a href="#cb795-9904" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9905"><a href="#cb795-9905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9906"><a href="#cb795-9906" aria-hidden="true" tabindex="-1"></a>For higher-order interactions, just multiply more predictors together. The design formula always implies all of the lower-order interactions, even though you don’t explicitly state them. For example, this model has a three-way interaction between $x$, $z$, and $w$, as well as three two-way interactions and all three main effects:</span>
<span id="cb795-9907"><a href="#cb795-9907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9908"><a href="#cb795-9908" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9909"><a href="#cb795-9909" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb795-9910"><a href="#cb795-9910" aria-hidden="true" tabindex="-1"></a>y_i &amp;\sim \text{Normal}(\mu_i, \sigma)<span class="sc">\\</span></span>
<span id="cb795-9911"><a href="#cb795-9911" aria-hidden="true" tabindex="-1"></a>\mu_i &amp;= \alpha + \beta_x x_i + \beta_z z_i + \beta_w w_i + \beta_{xz} x_i z_i + \beta_{xw} x_i w_i + \beta_{zw} z_i w_i + \beta_{xzw} x_i z_i w_i </span>
<span id="cb795-9912"><a href="#cb795-9912" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb795-9913"><a href="#cb795-9913" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb795-9914"><a href="#cb795-9914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9915"><a href="#cb795-9915" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 7.32}</span></span>
<span id="cb795-9916"><a href="#cb795-9916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9917"><a href="#cb795-9917" aria-hidden="true" tabindex="-1"></a><span class="co"># create mock data set to solve "error:variable lengths differ (found for 'w')"</span></span>
<span id="cb795-9918"><a href="#cb795-9918" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb795-9919"><a href="#cb795-9919" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="fu">rnorm</span>(<span class="dv">40</span>),</span>
<span id="cb795-9920"><a href="#cb795-9920" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">40</span>),</span>
<span id="cb795-9921"><a href="#cb795-9921" aria-hidden="true" tabindex="-1"></a>  <span class="at">z =</span> <span class="fu">rnorm</span>(<span class="dv">40</span>),</span>
<span id="cb795-9922"><a href="#cb795-9922" aria-hidden="true" tabindex="-1"></a>  <span class="at">w =</span> <span class="fu">rnorm</span>(<span class="dv">40</span>)</span>
<span id="cb795-9923"><a href="#cb795-9923" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb795-9924"><a href="#cb795-9924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9925"><a href="#cb795-9925" aria-hidden="true" tabindex="-1"></a><span class="do">## In design formula:</span></span>
<span id="cb795-9926"><a href="#cb795-9926" aria-hidden="true" tabindex="-1"></a>m7.x <span class="ot">&lt;-</span> <span class="fu">lm</span>( y <span class="sc">~</span> x<span class="sc">*</span>z<span class="sc">*</span>w , <span class="at">data=</span>d )</span>
<span id="cb795-9927"><a href="#cb795-9927" aria-hidden="true" tabindex="-1"></a><span class="co"># And you can explicitly subtract any lower-order interactions or main effects to </span></span>
<span id="cb795-9928"><a href="#cb795-9928" aria-hidden="true" tabindex="-1"></a><span class="co"># construct a reduced model.</span></span>
<span id="cb795-9929"><a href="#cb795-9929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9930"><a href="#cb795-9930" aria-hidden="true" tabindex="-1"></a><span class="do">## Expand the design formula to see how it works</span></span>
<span id="cb795-9931"><a href="#cb795-9931" aria-hidden="true" tabindex="-1"></a><span class="co"># Expand a three-way interaction into a full set of terms:</span></span>
<span id="cb795-9932"><a href="#cb795-9932" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> z <span class="ot">&lt;-</span> w <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="co"># any number would do here</span></span>
<span id="cb795-9933"><a href="#cb795-9933" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>( <span class="fu">model.matrix</span>(<span class="sc">~</span>x<span class="sc">*</span>z<span class="sc">*</span>w) )</span>
<span id="cb795-9934"><a href="#cb795-9934" aria-hidden="true" tabindex="-1"></a><span class="co"># That function takes the design formula, absent the outcome variable, and expands it </span></span>
<span id="cb795-9935"><a href="#cb795-9935" aria-hidden="true" tabindex="-1"></a><span class="co"># into a full set of variables for a linear model. This expanded set is the model matrix. </span></span>
<span id="cb795-9936"><a href="#cb795-9936" aria-hidden="true" tabindex="-1"></a><span class="co"># ":" symbols stand for multiplication.</span></span>
<span id="cb795-9937"><a href="#cb795-9937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9938"><a href="#cb795-9938" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-9939"><a href="#cb795-9939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9940"><a href="#cb795-9940" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9941"><a href="#cb795-9941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9942"><a href="#cb795-9942" aria-hidden="true" tabindex="-1"></a><span class="fu">## Practice</span></span>
<span id="cb795-9943"><a href="#cb795-9943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9944"><a href="#cb795-9944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9945"><a href="#cb795-9945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9946"><a href="#cb795-9946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9947"><a href="#cb795-9947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9948"><a href="#cb795-9948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9949"><a href="#cb795-9949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9950"><a href="#cb795-9950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9951"><a href="#cb795-9951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9952"><a href="#cb795-9952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9953"><a href="#cb795-9953" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9954"><a href="#cb795-9954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9955"><a href="#cb795-9955" aria-hidden="true" tabindex="-1"></a><span class="fu"># Chapter 8: Markov Chain Monte Carlo</span></span>
<span id="cb795-9956"><a href="#cb795-9956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9957"><a href="#cb795-9957" aria-hidden="true" tabindex="-1"></a>***Markov chain Monte Carlo (MCMC) estimation*** is the estimation of posterior probability distributions using a stochastic process. It has the ability to directly estimate models, such as the generalized linear and multilevel models, which routinely produce non-Gaussian posterior distributions. </span>
<span id="cb795-9958"><a href="#cb795-9958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9959"><a href="#cb795-9959" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-9960"><a href="#cb795-9960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9961"><a href="#cb795-9961" aria-hidden="true" tabindex="-1"></a><span class="fu">## Good King Markov and his island kingdom</span></span>
<span id="cb795-9962"><a href="#cb795-9962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9963"><a href="#cb795-9963" aria-hidden="true" tabindex="-1"></a>King Markov was a benevolent autocrat of an island kingdom,a circular archipelago, with 10 islands. Each island was neighbored by two others, and the entire archipelago formed a ring. The islands were of different sizes, and so had different sized populations living on them. The second island was about twice as populous as the first, the third about three times as populous as the first, and so on, up to the largest island, which was 10 times as populous as the smallest.</span>
<span id="cb795-9964"><a href="#cb795-9964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9965"><a href="#cb795-9965" aria-hidden="true" tabindex="-1"></a>The king should visit each island in proportion to its population size, visiting the largest island 10 times as often as the smallest, for example. Also, since the archipelago was a ring, the King insisted that he only move among adjacent islands, to minimize time spent on the water. </span>
<span id="cb795-9966"><a href="#cb795-9966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9967"><a href="#cb795-9967" aria-hidden="true" tabindex="-1"></a>The king’s advisor, a Mr Metropolis, engineered a clever solution to these demands. We’ll call this solution the ***Metropolis algorithm***. Here's how it works.</span>
<span id="cb795-9968"><a href="#cb795-9968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9969"><a href="#cb795-9969" aria-hidden="true" tabindex="-1"></a>(1) Wherever the King is, each week he decides between staying put for another week or moving to one of the two adjacent islands. To decide his next move, he flips a coin.</span>
<span id="cb795-9970"><a href="#cb795-9970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9971"><a href="#cb795-9971" aria-hidden="true" tabindex="-1"></a>(2) If the coin turns up heads, the King considers moving to the adjacent island clockwise around the archipelago. If the coin turns up tails, he considers instead moving counterclockwise. Call the island the coin nominates the *proposal* island.</span>
<span id="cb795-9972"><a href="#cb795-9972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9973"><a href="#cb795-9973" aria-hidden="true" tabindex="-1"></a>(3) Now, to see whether or not he moves to the proposal island, King Markov counts out a number of seashells equal to the relative population size of the proposal island. So for example, if the proposal island is number 9, then he counts out 9 seashells. Then he also counts out a number of stones equal to the relative population of the current island. So for example, if the current island is number 10, then King Markov ends up holding 10 stones, in addition to the 9 seashells.</span>
<span id="cb795-9974"><a href="#cb795-9974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9975"><a href="#cb795-9975" aria-hidden="true" tabindex="-1"></a>(4) When there are more seashells than stones, King Markov always moves to the proposal island. But if there are fewer shells than stones, he discards a number of stones equal to the number of shells. So for example, if there are 4 shells and 6 stones, he ends up with 4 shells and 6 − 4 = 2 stones. Then he places the shells and the remaining stones in a bag. He reaches in and randomly pulls out one object. If it is a shell, he moves to the proposal island. Otherwise, he stays put another week. As a result, the probability that he moves is equal to the number of shells divided by the original number of stones.</span>
<span id="cb795-9976"><a href="#cb795-9976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9977"><a href="#cb795-9977" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 8.1, eval=FALSE}</span></span>
<span id="cb795-9978"><a href="#cb795-9978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9979"><a href="#cb795-9979" aria-hidden="true" tabindex="-1"></a><span class="do">## Simulate King Markov’s journey</span></span>
<span id="cb795-9980"><a href="#cb795-9980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9981"><a href="#cb795-9981" aria-hidden="true" tabindex="-1"></a><span class="co"># Set number of weeks to simulate</span></span>
<span id="cb795-9982"><a href="#cb795-9982" aria-hidden="true" tabindex="-1"></a>num_weeks <span class="ot">&lt;-</span> <span class="fl">1e5</span></span>
<span id="cb795-9983"><a href="#cb795-9983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9984"><a href="#cb795-9984" aria-hidden="true" tabindex="-1"></a><span class="co"># Define an empty history vector</span></span>
<span id="cb795-9985"><a href="#cb795-9985" aria-hidden="true" tabindex="-1"></a>positions <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,num_weeks)</span>
<span id="cb795-9986"><a href="#cb795-9986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9987"><a href="#cb795-9987" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a starting island position (the biggest island, number 10)</span></span>
<span id="cb795-9988"><a href="#cb795-9988" aria-hidden="true" tabindex="-1"></a>current <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb795-9989"><a href="#cb795-9989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-9990"><a href="#cb795-9990" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>num_weeks ) {</span>
<span id="cb795-9991"><a href="#cb795-9991" aria-hidden="true" tabindex="-1"></a>    <span class="co"># record current position</span></span>
<span id="cb795-9992"><a href="#cb795-9992" aria-hidden="true" tabindex="-1"></a>    positions[i] <span class="ot">&lt;-</span> current</span>
<span id="cb795-9993"><a href="#cb795-9993" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-9994"><a href="#cb795-9994" aria-hidden="true" tabindex="-1"></a>    <span class="co"># flip coin to generate proposal</span></span>
<span id="cb795-9995"><a href="#cb795-9995" aria-hidden="true" tabindex="-1"></a>    proposal <span class="ot">&lt;-</span> current <span class="sc">+</span> <span class="fu">sample</span>( <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>) , <span class="at">size=</span><span class="dv">1</span> )</span>
<span id="cb795-9996"><a href="#cb795-9996" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-9997"><a href="#cb795-9997" aria-hidden="true" tabindex="-1"></a>    <span class="co"># now make sure he loops around the archipelago</span></span>
<span id="cb795-9998"><a href="#cb795-9998" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ( proposal <span class="sc">&lt;</span> <span class="dv">1</span> ) proposal <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb795-9999"><a href="#cb795-9999" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ( proposal <span class="sc">&gt;</span> <span class="dv">10</span> ) proposal <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb795-10000"><a href="#cb795-10000" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb795-10001"><a href="#cb795-10001" aria-hidden="true" tabindex="-1"></a>    <span class="co"># move?</span></span>
<span id="cb795-10002"><a href="#cb795-10002" aria-hidden="true" tabindex="-1"></a>    prob_move <span class="ot">&lt;-</span> proposal<span class="sc">/</span>current</span>
<span id="cb795-10003"><a href="#cb795-10003" aria-hidden="true" tabindex="-1"></a>    current <span class="ot">&lt;-</span> <span class="fu">ifelse</span>( <span class="fu">runif</span>(<span class="dv">1</span>) <span class="sc">&lt;</span> prob_move , proposal , current )</span>
<span id="cb795-10004"><a href="#cb795-10004" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb795-10005"><a href="#cb795-10005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10006"><a href="#cb795-10006" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data (follow ajkurz's codes)</span></span>
<span id="cb795-10007"><a href="#cb795-10007" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">week   =</span> <span class="dv">1</span><span class="sc">:</span><span class="fl">1e5</span>,</span>
<span id="cb795-10008"><a href="#cb795-10008" aria-hidden="true" tabindex="-1"></a>       <span class="at">island =</span> positions) <span class="sc">%&gt;%</span></span>
<span id="cb795-10009"><a href="#cb795-10009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10010"><a href="#cb795-10010" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> week, <span class="at">y =</span> island)) <span class="sc">+</span></span>
<span id="cb795-10011"><a href="#cb795-10011" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb795-10012"><a href="#cb795-10012" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">20</span>)) <span class="sc">+</span></span>
<span id="cb795-10013"><a href="#cb795-10013" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">10</span>, <span class="at">by =</span> <span class="dv">2</span>)) <span class="sc">+</span></span>
<span id="cb795-10014"><a href="#cb795-10014" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>,</span>
<span id="cb795-10015"><a href="#cb795-10015" aria-hidden="true" tabindex="-1"></a>                  <span class="at">ylim =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb795-10016"><a href="#cb795-10016" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title    =</span> <span class="st">"Behold: The Metropolis algorithm in action!"</span>,</span>
<span id="cb795-10017"><a href="#cb795-10017" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"The dots show the king's path over the first 100 weeks."</span>) <span class="sc">+</span></span>
<span id="cb795-10018"><a href="#cb795-10018" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb795-10019"><a href="#cb795-10019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10020"><a href="#cb795-10020" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10021"><a href="#cb795-10021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10022"><a href="#cb795-10022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10023"><a href="#cb795-10023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10024"><a href="#cb795-10024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10025"><a href="#cb795-10025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10026"><a href="#cb795-10026" aria-hidden="true" tabindex="-1"></a><span class="co"># Results of the king following the Metropolis algorithm. The left-hand plot shows </span></span>
<span id="cb795-10027"><a href="#cb795-10027" aria-hidden="true" tabindex="-1"></a><span class="co"># the king’s position (vertical axis) across first 100 weeks (horizontal axis). </span></span>
<span id="cb795-10028"><a href="#cb795-10028" aria-hidden="true" tabindex="-1"></a><span class="co"># In any particular week, it’s nearly impossible to say where the king will be. </span></span>
<span id="cb795-10029"><a href="#cb795-10029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10030"><a href="#cb795-10030" aria-hidden="true" tabindex="-1"></a><span class="co"># The right-hand plot shows the long-run behavior of the algorithm, as the time spent on </span></span>
<span id="cb795-10031"><a href="#cb795-10031" aria-hidden="true" tabindex="-1"></a><span class="co"># each island turns out to be proportional to its population size.</span></span>
<span id="cb795-10032"><a href="#cb795-10032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10033"><a href="#cb795-10033" aria-hidden="true" tabindex="-1"></a><span class="co"># The algorithm will still work in this way, even if we allow the king to be equally likely </span></span>
<span id="cb795-10034"><a href="#cb795-10034" aria-hidden="true" tabindex="-1"></a><span class="co"># to propose a move to any island from any island, not just among neighbors. The algorithm </span></span>
<span id="cb795-10035"><a href="#cb795-10035" aria-hidden="true" tabindex="-1"></a><span class="co"># would also work for any size archipelago, even if the king didn’t know how many islands </span></span>
<span id="cb795-10036"><a href="#cb795-10036" aria-hidden="true" tabindex="-1"></a><span class="co"># were in it. All he needs to know at any point in time is the population of the current </span></span>
<span id="cb795-10037"><a href="#cb795-10037" aria-hidden="true" tabindex="-1"></a><span class="co"># island and the population of the proposal island.</span></span>
<span id="cb795-10038"><a href="#cb795-10038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10039"><a href="#cb795-10039" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-10040"><a href="#cb795-10040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10041"><a href="#cb795-10041" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10042"><a href="#cb795-10042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10043"><a href="#cb795-10043" aria-hidden="true" tabindex="-1"></a><span class="fu">## Markov chain Monte Carlo</span></span>
<span id="cb795-10044"><a href="#cb795-10044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10045"><a href="#cb795-10045" aria-hidden="true" tabindex="-1"></a>The goal of general **Metropolis Algorithm**, an example of Markov chain Monte Carlo, is to draw samples from an unknown and usually complex target distribution, like a posterior probability distribution.</span>
<span id="cb795-10046"><a href="#cb795-10046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10047"><a href="#cb795-10047" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The “islands” in our objective are parameter values, and they need not be discrete, but can instead take on a continuous range of values as usual.</span>
<span id="cb795-10048"><a href="#cb795-10048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10049"><a href="#cb795-10049" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The “population sizes” in our objective are the posterior probabilities at each parameter value.</span>
<span id="cb795-10050"><a href="#cb795-10050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10051"><a href="#cb795-10051" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The “weeks” in our objective are samples taken from the joint posterior of the parameters in the model.</span>
<span id="cb795-10052"><a href="#cb795-10052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10053"><a href="#cb795-10053" aria-hidden="true" tabindex="-1"></a>Provided the way we choose our proposed parameter values at each step is symmetric<span class="dv">&amp;mdash;</span> so that there is an equal chance of proposing from A to B and from B to A<span class="dv">&amp;mdash;</span> then the Metropolis algorithm will eventually give us a collection of samples from the joint posterior.</span>
<span id="cb795-10054"><a href="#cb795-10054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10055"><a href="#cb795-10055" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10056"><a href="#cb795-10056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10057"><a href="#cb795-10057" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;spans</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:brown"</span><span class="kw">&gt;&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"text-decoration:underline"</span><span class="kw">&gt;</span>**Two of the most important in contemporary Bayesian inference**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb795-10058"><a href="#cb795-10058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10059"><a href="#cb795-10059" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gibbs sampling</span>
<span id="cb795-10060"><a href="#cb795-10060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10061"><a href="#cb795-10061" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hamiltonian (aka Hybrid, aka HMC) Monte Carlo</span>
<span id="cb795-10062"><a href="#cb795-10062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10063"><a href="#cb795-10063" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10064"><a href="#cb795-10064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10065"><a href="#cb795-10065" aria-hidden="true" tabindex="-1"></a><span class="fu">### Gibbs sampling</span></span>
<span id="cb795-10066"><a href="#cb795-10066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10067"><a href="#cb795-10067" aria-hidden="true" tabindex="-1"></a>The Metropolis algorithm works whenever the probability of proposing a jump to B from A is equal to the probability of proposing A from B, when the proposal distribution is symmetric. There is a more general method, known as Metropolis-Hastings, that allows asymmetric proposals. </span>
<span id="cb795-10068"><a href="#cb795-10068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10069"><a href="#cb795-10069" aria-hidden="true" tabindex="-1"></a>An algorithm that allows asymmetric proposals is useful because:</span>
<span id="cb795-10070"><a href="#cb795-10070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10071"><a href="#cb795-10071" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>it makes it easier to handle parameters, like standard deviations, that have boundaries at zero</span>
<span id="cb795-10072"><a href="#cb795-10072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10073"><a href="#cb795-10073" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>we can acquire an equally good image of the posterior distribution in fewer steps</span>
<span id="cb795-10074"><a href="#cb795-10074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10075"><a href="#cb795-10075" aria-hidden="true" tabindex="-1"></a>Gibbs sampling is a variant of the Metropolis-Hastings algorithm that uses clever proposals and is therefore more efficient<span class="dv">&amp;mdash;</span> you can get a good estimate of the posterior from Gibbs sampling with many fewer samples than a comparable Metropolis approach. The improvement arises from ***adaptive proposals*** in which the distribution of proposed parameter values adjusts itself intelligently, depending upon the parameter values at the moment. Gibbs sampling computes these adaptive proposals using particular combinations of prior distributions and likelihoods known as *conjugate pairs*.</span>
<span id="cb795-10076"><a href="#cb795-10076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10077"><a href="#cb795-10077" aria-hidden="true" tabindex="-1"></a>Some limitations of Gibbs sampling:</span>
<span id="cb795-10078"><a href="#cb795-10078" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10079"><a href="#cb795-10079" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Some conjugate priors seem silly, and choosing a prior so that the model fits efficiently isn’t really a strong argument from a scientific perspective.</span>
<span id="cb795-10080"><a href="#cb795-10080" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10081"><a href="#cb795-10081" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>As models become more complex and contain hundreds or thousands or tens of thousands of parameters, Gibbs sampling becomes shockingly inefficient.</span>
<span id="cb795-10082"><a href="#cb795-10082" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10083"><a href="#cb795-10083" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10084"><a href="#cb795-10084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10085"><a href="#cb795-10085" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hamiltonian Monte Carlo</span></span>
<span id="cb795-10086"><a href="#cb795-10086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10087"><a href="#cb795-10087" aria-hidden="true" tabindex="-1"></a>Hamiltonian Monte Carlo (or Hybrid Monte Carlo, HMC) adopts Jaynes’ principle that, *"whenever there is a randomized way of doing something, then there is a non-randomized way that delivers better performance but requires more thought."*</span>
<span id="cb795-10088"><a href="#cb795-10088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10089"><a href="#cb795-10089" aria-hidden="true" tabindex="-1"></a>HMC is much more computationally costly than are Metropolis or Gibbs sampling<span class="dv">&amp;mdash;</span> both highly random procedures. But its proposals are typically much more efficient<span class="dv">&amp;mdash;</span> doesn’t need as many samples to describe the posterior distribution, outshine other algorithms as models become more complex (thousands or tens of thousands of parameters). HMC outperforms Metropolis and Gibbs sampling, but it is not a universal solution to all MCMC problems.</span>
<span id="cb795-10090"><a href="#cb795-10090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10091"><a href="#cb795-10091" aria-hidden="true" tabindex="-1"></a>Monty’s kingdom is not a discrete set of islands. Instead, it is a continuous territory stretched out along a narrow valley. Monty's advisor, Hamilton realized that a much more efficient way to visit the citizens in the continuous Kingdom is to travel back and forth along its length. In order to spend more time in densely settled areas, they should slow the royal vehicle down when houses grow more dense. Likewise, they should speed up when houses grow more sparse. This strategy requires knowing how quickly population density is changing, at their current location. But it doesn’t require remembering where they’ve been or knowing the population distribution anyplace else. And a major benefit of this strategy compared to that of Metropolis is that the King makes a full sweep of the kingdom before revisiting anyone.</span>
<span id="cb795-10092"><a href="#cb795-10092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10093"><a href="#cb795-10093" aria-hidden="true" tabindex="-1"></a>In statistical applications, the royal vehicle is the current vector of parameter values. Let’s consider the single parameter case, just to keep things simple. In that case, the log-posterior is like a bowl, with the MAP at its nadir. Then the job is to sweep across the surface of the bowl, adjusting speed in proportion to how high up we are. In cases where ordinary Metropolis or Gibbs sampling wander slowly through parameter space, Hamiltonian Monte Carlo remains efficient.</span>
<span id="cb795-10094"><a href="#cb795-10094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10095"><a href="#cb795-10095" aria-hidden="true" tabindex="-1"></a>Some limitations of HMC:</span>
<span id="cb795-10096"><a href="#cb795-10096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10097"><a href="#cb795-10097" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>HMC requires continuous parameters. It can’t glide through a discrete parameter. </span>
<span id="cb795-10098"><a href="#cb795-10098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10099"><a href="#cb795-10099" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>it needs to be tuned to a particular model and its data. That’s where an engine like Stan (mc-stan.org) comes in. Stan automates much of that tuning.</span>
<span id="cb795-10100"><a href="#cb795-10100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10101"><a href="#cb795-10101" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10102"><a href="#cb795-10102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10103"><a href="#cb795-10103" aria-hidden="true" tabindex="-1"></a><span class="fu">## Easy HMC: `map2stan`</span></span>
<span id="cb795-10104"><a href="#cb795-10104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10105"><a href="#cb795-10105" aria-hidden="true" tabindex="-1"></a><span class="in">`map2stan`</span> compiles lists of formulas, like the lists you’ve been using so far to construct map estimates, into Stan HMC code. To use <span class="in">`map2stan`</span>, you need to preprocess any variable transformations, and you need to construct a clean data frame with only the variables you will use.</span>
<span id="cb795-10106"><a href="#cb795-10106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10107"><a href="#cb795-10107" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 8.2}</span></span>
<span id="cb795-10108"><a href="#cb795-10108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10109"><a href="#cb795-10109" aria-hidden="true" tabindex="-1"></a><span class="co"># load the data and reduce it down to cases (nations) that have the outcome variable of interest</span></span>
<span id="cb795-10110"><a href="#cb795-10110" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(rugged)</span>
<span id="cb795-10111"><a href="#cb795-10111" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> rugged</span>
<span id="cb795-10112"><a href="#cb795-10112" aria-hidden="true" tabindex="-1"></a>d<span class="sc">$</span>log_gdp <span class="ot">&lt;-</span> <span class="fu">log</span>(d<span class="sc">$</span>rgdppc_2000)</span>
<span id="cb795-10113"><a href="#cb795-10113" aria-hidden="true" tabindex="-1"></a>dd <span class="ot">&lt;-</span> d[ <span class="fu">complete.cases</span>(d<span class="sc">$</span>rgdppc_2000) , ]</span>
<span id="cb795-10114"><a href="#cb795-10114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10115"><a href="#cb795-10115" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the interaction model which  aims to predict log-GDP with terrain ruggedness, </span></span>
<span id="cb795-10116"><a href="#cb795-10116" aria-hidden="true" tabindex="-1"></a><span class="co"># continent, and the interaction of the two</span></span>
<span id="cb795-10117"><a href="#cb795-10117" aria-hidden="true" tabindex="-1"></a>m8<span class="fl">.1</span> <span class="ot">&lt;-</span> rethinking<span class="sc">::</span><span class="fu">map</span>(</span>
<span id="cb795-10118"><a href="#cb795-10118" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-10119"><a href="#cb795-10119" aria-hidden="true" tabindex="-1"></a>        log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-10120"><a href="#cb795-10120" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>rugged <span class="sc">+</span> bA<span class="sc">*</span>cont_africa <span class="sc">+</span> bAR<span class="sc">*</span>rugged<span class="sc">*</span>cont_africa ,</span>
<span id="cb795-10121"><a href="#cb795-10121" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">100</span>),</span>
<span id="cb795-10122"><a href="#cb795-10122" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-10123"><a href="#cb795-10123" aria-hidden="true" tabindex="-1"></a>        bA <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-10124"><a href="#cb795-10124" aria-hidden="true" tabindex="-1"></a>        bAR <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-10125"><a href="#cb795-10125" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dunif</span>(<span class="dv">0</span>,<span class="dv">10</span>)</span>
<span id="cb795-10126"><a href="#cb795-10126" aria-hidden="true" tabindex="-1"></a>),</span>
<span id="cb795-10127"><a href="#cb795-10127" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span>dd )</span>
<span id="cb795-10128"><a href="#cb795-10128" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m8<span class="fl">.1</span>)</span>
<span id="cb795-10129"><a href="#cb795-10129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10130"><a href="#cb795-10130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-10131"><a href="#cb795-10131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10132"><a href="#cb795-10132" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10133"><a href="#cb795-10133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10134"><a href="#cb795-10134" aria-hidden="true" tabindex="-1"></a><span class="fu">### Preparation</span></span>
<span id="cb795-10135"><a href="#cb795-10135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10136"><a href="#cb795-10136" aria-hidden="true" tabindex="-1"></a>But now we’ll also fit this model using Hamiltonian Monte Carlo. This means there will be no more quadratic approximation<span class="dv">&amp;mdash;</span> if the posterior distribution is non-Gaussian, then we’ll get whatever non-Gaussian shape it has. You can use exactly the same formula list as before, but you need to do two additional things.</span>
<span id="cb795-10137"><a href="#cb795-10137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10138"><a href="#cb795-10138" aria-hidden="true" tabindex="-1"></a>(1) Preprocess all variable transformations.</span>
<span id="cb795-10139"><a href="#cb795-10139" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>If the outcome is transformed somehow, like by taking the logarithm, then do this before fitting the model by constructing a new variable in the data frame. </span>
<span id="cb795-10140"><a href="#cb795-10140" aria-hidden="true" tabindex="-1"></a><span class="ss">        - </span>Likewise, if any predictor variables are transformed, including squaring and cubing and such to build polynomial models, then compute these transformed values before fitting the model.</span>
<span id="cb795-10141"><a href="#cb795-10141" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb795-10142"><a href="#cb795-10142" aria-hidden="true" tabindex="-1"></a>\n</span>
<span id="cb795-10143"><a href="#cb795-10143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10144"><a href="#cb795-10144" aria-hidden="true" tabindex="-1"></a>(2) Once you’ve got all the variables ready, make a new trimmed down data frame that contains only the variables you will actually use to fit the model. Technically, you don’t have to do this. But doing so avoids common problems. For example, if any of the unused variables have missing values, NA, then Stan will refuse to work.</span>
<span id="cb795-10145"><a href="#cb795-10145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10146"><a href="#cb795-10146" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 8.4}</span></span>
<span id="cb795-10147"><a href="#cb795-10147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10148"><a href="#cb795-10148" aria-hidden="true" tabindex="-1"></a>dd.trim <span class="ot">&lt;-</span> dd[ , <span class="fu">c</span>(<span class="st">"log_gdp"</span>,<span class="st">"rugged"</span>,<span class="st">"cont_africa"</span>) ]</span>
<span id="cb795-10149"><a href="#cb795-10149" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(dd.trim)</span>
<span id="cb795-10150"><a href="#cb795-10150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10151"><a href="#cb795-10151" aria-hidden="true" tabindex="-1"></a><span class="co"># The data frame dd.trim contains only the three variables we’re using.</span></span>
<span id="cb795-10152"><a href="#cb795-10152" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-10153"><a href="#cb795-10153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10154"><a href="#cb795-10154" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10155"><a href="#cb795-10155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10156"><a href="#cb795-10156" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimation</span></span>
<span id="cb795-10157"><a href="#cb795-10157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10158"><a href="#cb795-10158" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 8.5}</span></span>
<span id="cb795-10159"><a href="#cb795-10159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10160"><a href="#cb795-10160" aria-hidden="true" tabindex="-1"></a><span class="co"># Get samples from the posterior distribution using HMC</span></span>
<span id="cb795-10161"><a href="#cb795-10161" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(m8<span class="fl">.1</span>stan <span class="ot">&lt;-</span> <span class="fu">ulam</span>(</span>
<span id="cb795-10162"><a href="#cb795-10162" aria-hidden="true" tabindex="-1"></a>    <span class="fu">alist</span>(</span>
<span id="cb795-10163"><a href="#cb795-10163" aria-hidden="true" tabindex="-1"></a>        log_gdp <span class="sc">~</span> <span class="fu">dnorm</span>( mu , sigma ) ,</span>
<span id="cb795-10164"><a href="#cb795-10164" aria-hidden="true" tabindex="-1"></a>        mu <span class="ot">&lt;-</span> a <span class="sc">+</span> bR<span class="sc">*</span>rugged <span class="sc">+</span> bA<span class="sc">*</span>cont_africa <span class="sc">+</span> bAR<span class="sc">*</span>rugged<span class="sc">*</span>cont_africa ,</span>
<span id="cb795-10165"><a href="#cb795-10165" aria-hidden="true" tabindex="-1"></a>        a <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">100</span>),</span>
<span id="cb795-10166"><a href="#cb795-10166" aria-hidden="true" tabindex="-1"></a>        bR <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-10167"><a href="#cb795-10167" aria-hidden="true" tabindex="-1"></a>        bA <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-10168"><a href="#cb795-10168" aria-hidden="true" tabindex="-1"></a>        bAR <span class="sc">~</span> <span class="fu">dnorm</span>(<span class="dv">0</span>,<span class="dv">10</span>),</span>
<span id="cb795-10169"><a href="#cb795-10169" aria-hidden="true" tabindex="-1"></a>        sigma <span class="sc">~</span> <span class="fu">dcauchy</span>(<span class="dv">0</span>,<span class="dv">2</span>) <span class="co"># a weakly regularizing prior for standard deviations</span></span>
<span id="cb795-10170"><a href="#cb795-10170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10171"><a href="#cb795-10171" aria-hidden="true" tabindex="-1"></a><span class="co"># The uniform prior on sigma has been changed to a half-Cauchy prior. </span></span>
<span id="cb795-10172"><a href="#cb795-10172" aria-hidden="true" tabindex="-1"></a><span class="co"># The Cauchy distribution is a useful thick-tailed probability distribution </span></span>
<span id="cb795-10173"><a href="#cb795-10173" aria-hidden="true" tabindex="-1"></a><span class="co"># related to the Student t distribution.</span></span>
<span id="cb795-10174"><a href="#cb795-10174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10175"><a href="#cb795-10175" aria-hidden="true" tabindex="-1"></a>), <span class="at">data=</span>dd.trim))</span>
<span id="cb795-10176"><a href="#cb795-10176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10177"><a href="#cb795-10177" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m8<span class="fl">.1</span>stan)</span>
<span id="cb795-10178"><a href="#cb795-10178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10179"><a href="#cb795-10179" aria-hidden="true" tabindex="-1"></a><span class="co"># The interval boundaries in the table are highest posterior density intervals (HPDI), </span></span>
<span id="cb795-10180"><a href="#cb795-10180" aria-hidden="true" tabindex="-1"></a><span class="co"># not ordinary percentile intervals (PI).</span></span>
<span id="cb795-10181"><a href="#cb795-10181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10182"><a href="#cb795-10182" aria-hidden="true" tabindex="-1"></a><span class="co"># n_eff and Rhat provide MCMC diagnostic criteria, to help you tell how well estimation worked.</span></span>
<span id="cb795-10183"><a href="#cb795-10183" aria-hidden="true" tabindex="-1"></a><span class="co"># n_eff is a crude estimate of the number of independent samples you managed to get.</span></span>
<span id="cb795-10184"><a href="#cb795-10184" aria-hidden="true" tabindex="-1"></a><span class="co"># Rhat is a complicated estimate of the convergence of the Markov chains to the target </span></span>
<span id="cb795-10185"><a href="#cb795-10185" aria-hidden="true" tabindex="-1"></a><span class="co"># distribution. It should approach 1.00 from above, when all is well.</span></span>
<span id="cb795-10186"><a href="#cb795-10186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10187"><a href="#cb795-10187" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-10188"><a href="#cb795-10188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10189"><a href="#cb795-10189" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10190"><a href="#cb795-10190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10191"><a href="#cb795-10191" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sampling agian, in parallel</span></span>
<span id="cb795-10192"><a href="#cb795-10192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10193"><a href="#cb795-10193" aria-hidden="true" tabindex="-1"></a>Once you have compiled your Stan model, you can draw more samples from it anytime, running as many independent Markov chains as you like. And you can easily parallelize those chains, as well. To run four independent Markov chains for the model above, and to distribute them across separate processors in your computer, just pass the previous fit back to map2stan:</span>
<span id="cb795-10194"><a href="#cb795-10194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10195"><a href="#cb795-10195" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 8.7}</span></span>
<span id="cb795-10196"><a href="#cb795-10196" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(m8<span class="fl">.1</span>stan_4chains <span class="ot">&lt;-</span> <span class="fu">update</span>( m8<span class="fl">.1</span>stan , <span class="at">chains=</span><span class="dv">4</span> , <span class="at">cores=</span><span class="dv">4</span> ))</span>
<span id="cb795-10197"><a href="#cb795-10197" aria-hidden="true" tabindex="-1"></a><span class="co"># map2stan doesn't work anymore- use update() here. </span></span>
<span id="cb795-10198"><a href="#cb795-10198" aria-hidden="true" tabindex="-1"></a><span class="fu">precis</span>(m8<span class="fl">.1</span>stan_4chains)</span>
<span id="cb795-10199"><a href="#cb795-10199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10200"><a href="#cb795-10200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-10201"><a href="#cb795-10201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10202"><a href="#cb795-10202" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10203"><a href="#cb795-10203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10204"><a href="#cb795-10204" aria-hidden="true" tabindex="-1"></a><span class="fu">### Visualization</span></span>
<span id="cb795-10205"><a href="#cb795-10205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10206"><a href="#cb795-10206" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 8.8}</span></span>
<span id="cb795-10207"><a href="#cb795-10207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10208"><a href="#cb795-10208" aria-hidden="true" tabindex="-1"></a><span class="co"># Pull out the samples</span></span>
<span id="cb795-10209"><a href="#cb795-10209" aria-hidden="true" tabindex="-1"></a>post <span class="ot">&lt;-</span> <span class="fu">extract.samples</span>( m8<span class="fl">.1</span>stan )</span>
<span id="cb795-10210"><a href="#cb795-10210" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(post)</span>
<span id="cb795-10211"><a href="#cb795-10211" aria-hidden="true" tabindex="-1"></a><span class="co"># Samples are in a list- not in a data.frame (useful for multilevel models)</span></span>
<span id="cb795-10212"><a href="#cb795-10212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10213"><a href="#cb795-10213" aria-hidden="true" tabindex="-1"></a><span class="co"># For now, if it doesn’t behave like you expect it to, you can coerce it to a data frame </span></span>
<span id="cb795-10214"><a href="#cb795-10214" aria-hidden="true" tabindex="-1"></a>post<span class="ot">&lt;-</span><span class="fu">as.data.frame</span>(post)</span>
<span id="cb795-10215"><a href="#cb795-10215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10216"><a href="#cb795-10216" aria-hidden="true" tabindex="-1"></a><span class="co"># To plot all these samples at once, provided there aren’t too many parameters</span></span>
<span id="cb795-10217"><a href="#cb795-10217" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(post)</span>
<span id="cb795-10218"><a href="#cb795-10218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10219"><a href="#cb795-10219" aria-hidden="true" tabindex="-1"></a><span class="co"># To display parameter names and parameter correlations</span></span>
<span id="cb795-10220"><a href="#cb795-10220" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(m8<span class="fl">.1</span>stan)</span>
<span id="cb795-10221"><a href="#cb795-10221" aria-hidden="true" tabindex="-1"></a><span class="co"># Pairs plot of the samples produced by Stan. The diagonal shows a density estimate for </span></span>
<span id="cb795-10222"><a href="#cb795-10222" aria-hidden="true" tabindex="-1"></a><span class="co"># each parameter. Below the diagonal, correlations between parameters are shown.</span></span>
<span id="cb795-10223"><a href="#cb795-10223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10224"><a href="#cb795-10224" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-10225"><a href="#cb795-10225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10226"><a href="#cb795-10226" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb795-10227"><a href="#cb795-10227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10228"><a href="#cb795-10228" aria-hidden="true" tabindex="-1"></a><span class="fu">### Using the samples</span></span>
<span id="cb795-10229"><a href="#cb795-10229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10230"><a href="#cb795-10230" aria-hidden="true" tabindex="-1"></a>If you have the samples from the posterior and you know the model, you can do anything: simulate predictions, compute differences between parameters, and calculate DIC and WAIC.</span>
<span id="cb795-10231"><a href="#cb795-10231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10232"><a href="#cb795-10232" aria-hidden="true" tabindex="-1"></a><span class="in">```{r 8.11}</span></span>
<span id="cb795-10233"><a href="#cb795-10233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10234"><a href="#cb795-10234" aria-hidden="true" tabindex="-1"></a><span class="fu">show</span>(m8<span class="fl">.1</span>stan)</span>
<span id="cb795-10235"><a href="#cb795-10235" aria-hidden="true" tabindex="-1"></a><span class="co"># map2stan does not work anymore and ulam doesn't compute WAIC and DIC </span></span>
<span id="cb795-10236"><a href="#cb795-10236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10237"><a href="#cb795-10237" aria-hidden="true" tabindex="-1"></a><span class="do">## Use brms (copy Akjurz's codes)</span></span>
<span id="cb795-10238"><a href="#cb795-10238" aria-hidden="true" tabindex="-1"></a><span class="co"># Run HMC model</span></span>
<span id="cb795-10239"><a href="#cb795-10239" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">capture.output</span>(b8<span class="fl">.1</span> <span class="ot">&lt;-</span></span>
<span id="cb795-10240"><a href="#cb795-10240" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span>(<span class="at">data =</span> dd, <span class="at">family =</span> gaussian,</span>
<span id="cb795-10241"><a href="#cb795-10241" aria-hidden="true" tabindex="-1"></a>      log_gdp <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> rugged <span class="sc">+</span> cont_africa <span class="sc">+</span> rugged<span class="sc">:</span>cont_africa,</span>
<span id="cb795-10242"><a href="#cb795-10242" aria-hidden="true" tabindex="-1"></a>      <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="at">class =</span> Intercept),</span>
<span id="cb795-10243"><a href="#cb795-10243" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">class =</span> b),</span>
<span id="cb795-10244"><a href="#cb795-10244" aria-hidden="true" tabindex="-1"></a>                <span class="fu">prior</span>(<span class="fu">cauchy</span>(<span class="dv">0</span>, <span class="dv">2</span>), <span class="at">class =</span> sigma)),</span>
<span id="cb795-10245"><a href="#cb795-10245" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">8</span>))</span>
<span id="cb795-10246"><a href="#cb795-10246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10247"><a href="#cb795-10247" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(b8<span class="fl">.1</span>)</span>
<span id="cb795-10248"><a href="#cb795-10248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10249"><a href="#cb795-10249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10250"><a href="#cb795-10250" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb795-10251"><a href="#cb795-10251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10252"><a href="#cb795-10252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10253"><a href="#cb795-10253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10254"><a href="#cb795-10254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10255"><a href="#cb795-10255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10256"><a href="#cb795-10256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10257"><a href="#cb795-10257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10258"><a href="#cb795-10258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10259"><a href="#cb795-10259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10260"><a href="#cb795-10260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10261"><a href="#cb795-10261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10262"><a href="#cb795-10262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10263"><a href="#cb795-10263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10264"><a href="#cb795-10264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10265"><a href="#cb795-10265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10266"><a href="#cb795-10266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10267"><a href="#cb795-10267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10268"><a href="#cb795-10268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10269"><a href="#cb795-10269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10270"><a href="#cb795-10270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10271"><a href="#cb795-10271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10272"><a href="#cb795-10272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10273"><a href="#cb795-10273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10274"><a href="#cb795-10274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10275"><a href="#cb795-10275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10276"><a href="#cb795-10276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10277"><a href="#cb795-10277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10278"><a href="#cb795-10278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10279"><a href="#cb795-10279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb795-10280"><a href="#cb795-10280" aria-hidden="true" tabindex="-1"></a>---</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="Statistical_Rethinking_RM_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>